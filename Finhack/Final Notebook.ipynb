{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, train_test_split\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import log_loss, accuracy_score, f1_score, plot_confusion_matrix, confusion_matrix\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "seed = 1\n",
    "\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\sunil\\\\Projects\\\\Machine Hack\\\\Merchandise Popularity Prediction\\\\Dataset'\n",
    "\n",
    "train = pd.read_csv(path + '\\\\Train.csv')\n",
    "test = pd.read_csv(path + '\\\\Test.csv')\n",
    "sample_sub = pd.read_csv(path + '\\\\sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'popularity'\n",
    "features = [col for col in train.columns if col not in [target]]\n",
    "\n",
    "train[target].replace({0:0, 1:1, 3:2, 4:3, 5:4}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing lowest in Score_2\n",
    "train.drop(15372, axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[ test['Score_2'] == 0, 'Score_2'] = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat( [train, test], axis = 0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Score_2'] = np.log(df['Score_2'])\n",
    "df['time'] = np.log(df['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Store_Score']<0, 'Store_Score'] = df[df['Store_Score']<0]['Store_Score']*-1\n",
    "df['Store_Score'] = np.log(df['Store_Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = df[:train.shape[0]].copy(), df[train.shape[0]:].copy()\n",
    "test = test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join(train, test):\n",
    "    df = pd.concat([train, test], axis = 0).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def split(df):\n",
    "    train_new, test_new = df[:train.shape[0]], df[train.shape[0]:]\n",
    "    feats = [col for col in train_new.columns if col not in [target]]\n",
    "    return train_new, test_new, feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = join(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mean_presence_per_store_score'] = df.groupby('Store_Score')['Store_Presence'].transform('mean')\n",
    "df['max_presence_per_store'] = df.groupby('Store_Ratio')['Store_Presence'].transform('max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, features = split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn, val = train_test_split(train, test_size = 0.2, random_state = 1, stratify = train[target])\n",
    "\n",
    "#### Input for model\n",
    "X_trn, X_val = trn[features], val[features]\n",
    "\n",
    "#### Target column\n",
    "y_trn, y_val = trn[target], val[target]\n",
    "\n",
    "#### Features for test data that we will be predicting\n",
    "X_test = test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3786987727318551"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext = ExtraTreesClassifier(random_state = 1)\n",
    "_ = ext.fit(X_trn, y_trn)\n",
    "\n",
    "preds_val = ext.predict_proba(X_val)\n",
    "\n",
    "log_loss(y_val, preds_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunil\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:05:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.38677443808754336"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext = XGBClassifier(random_state = 1)\n",
    "_ = ext.fit(X_trn, y_trn)\n",
    "\n",
    "preds_val = ext.predict_proba(X_val)\n",
    "\n",
    "log_loss(y_val, preds_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
