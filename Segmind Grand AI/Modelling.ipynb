{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "path = os.getcwd()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, BaggingRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_squared_log_error\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\sunil\\\\Projects\\\\Dockship\\\\segmind_grand_ai_challenge_2021-dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunil\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(path + \"\\\\dataset\\\\TRAIN.csv\")\n",
    "test = pd.read_csv(path + \"\\\\dataset\\\\TEST.csv\")\n",
    "ss = pd.read_csv(path + \"\\\\dataset\\\\sample_submission.csv\")\n",
    "shop = pd.read_csv(path + \"\\\\dataset\\\\store.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Date'] = pd.to_datetime(train['Date'])\n",
    "test['Date'] = pd.to_datetime(test['Date'])\n",
    "\n",
    "train['year'] = train['Date'].dt.year\n",
    "train['month'] = train['Date'].dt.month\n",
    "train['day'] = train['Date'].dt.day\n",
    "train['dayofweek'] = train['Date'].dt.dayofweek\n",
    "train['week'] = train['Date'].dt.week\n",
    "\n",
    "test['year'] = test['Date'].dt.year\n",
    "test['month'] = test['Date'].dt.month\n",
    "test['day'] = test['Date'].dt.day\n",
    "test['dayofweek'] = test['Date'].dt.dayofweek\n",
    "test['week'] = test['Date'].dt.week\n",
    "\n",
    "train['StateHoliday'].replace({0 : 0, '0':0, 'a':1, 'b':2, 'c':3}, inplace = True)\n",
    "test['StateHoliday'].replace({0 : 0, '0':0, 'a':1, 'b':2, 'c':3}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging\n",
    "\n",
    "store_type = dict(zip(shop['Store'], shop['StoreType']))\n",
    "store_ass = dict(zip(shop['Store'], shop['Assortment']))\n",
    "store_com = dict(zip(shop['Store'], shop['CompetitionDistance']))\n",
    "store_month = dict(zip(shop['Store'], shop['CompetitionOpenSinceMonth']))\n",
    "store_year = dict(zip(shop['Store'], shop['CompetitionOpenSinceYear']))\n",
    "store_p2 = dict(zip(shop['Store'], shop['Promo2']))\n",
    "store_pweek = dict(zip(shop['Store'], shop['Promo2SinceWeek']))\n",
    "store_pyear = dict(zip(shop['Store'], shop['Promo2SinceYear']))\n",
    "store_pi = dict(zip(shop['Store'], shop['PromoInterval']))\n",
    "\n",
    "train['Store_Type'] = train['Store'].map(store_type)\n",
    "train['Store_Assortment'] = train['Store'].map(store_ass)\n",
    "train['Store_distance'] = train['Store'].map(store_com)\n",
    "train['Store_CompetitionOpenSinceMonth'] = train['Store'].map(store_month)\n",
    "train['Store_CompetitionOpenSinceYear'] = train['Store'].map(store_year)\n",
    "train['Store_Promo2'] = train['Store'].map(store_p2)\n",
    "train['Store_Promo2SinceWeek'] = train['Store'].map(store_pweek)\n",
    "train['Store_Promo2SinceYear'] = train['Store'].map(store_pyear)\n",
    "train['Store_PromoInterval'] = train['Store'].map(store_pi)\n",
    "\n",
    "\n",
    "test['Store_Type'] = test['Store'].map(store_type)\n",
    "test['Store_Assortment'] = test['Store'].map(store_ass)\n",
    "test['Store_distance'] = test['Store'].map(store_com)\n",
    "test['Store_CompetitionOpenSinceMonth'] = test['Store'].map(store_month)\n",
    "test['Store_CompetitionOpenSinceYear'] = test['Store'].map(store_year)\n",
    "test['Store_Promo2'] = test['Store'].map(store_p2)\n",
    "test['Store_Promo2SinceWeek'] = test['Store'].map(store_pweek)\n",
    "test['Store_Promo2SinceYear'] = test['Store'].map(store_pyear)\n",
    "test['Store_PromoInterval'] = test['Store'].map(store_pi)\n",
    "\n",
    "\n",
    "train['Store_Assortment'].unique()\n",
    "train['Store_Assortment'].replace({'a':1, 'b':2, 'c':3}, inplace = True)\n",
    "test['Store_Assortment'].replace({'a':1, 'b':2, 'c':3}, inplace = True)\n",
    "\n",
    "\n",
    "a = [0, 'Jan,Apr,Jul,Oct', 'Feb,May,Aug,Nov', 'Mar,Jun,Sept,Dec']\n",
    "b = [0, 1, 2, 3]\n",
    "\n",
    "train['Store_PromoInterval'].replace(dict(zip(a, b)), inplace = True)\n",
    "test['Store_PromoInterval'].replace(dict(zip(a, b)), inplace = True)\n",
    "\n",
    "train['Store_Type'].replace({'a':1, 'b':2, 'c':3, 'd':4}, inplace = True)\n",
    "test['Store_Type'].replace({'a':1, 'b':2, 'c':3, 'd':4}, inplace = True)\n",
    "\n",
    "train.fillna(0, inplace = True)\n",
    "test.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing Datatype\n",
    "\n",
    "int8_cols = ['DayOfWeek', 'Open', 'Promo','StateHoliday', 'SchoolHoliday', \n",
    "'month', 'day', 'dayofweek','week', 'Store_Type', 'Store_Assortment',\n",
    "'Store_CompetitionOpenSinceMonth','Store_Promo2', \n",
    "'Store_Promo2SinceWeek','Store_PromoInterval']\n",
    "\n",
    "int16_cols = ['Customers', 'year', 'Store', 'Store_CompetitionOpenSinceYear', 'Store_Promo2SinceYear']\n",
    "\n",
    "int32_cols = ['Sales', 'Store_distance']\n",
    "\n",
    "def int8(x):\n",
    "    train[x] = train[x].astype('int8')\n",
    "    \n",
    "    test[x] = test[x].astype('int8')\n",
    "\n",
    "def int16(x):\n",
    "    train[x] = train[x].astype('int16')\n",
    "    if x != 'Customers':\n",
    "        test[x] = test[x].astype('int16')\n",
    "\n",
    "def int32(x):\n",
    "    train[x] = train[x].astype('int32')\n",
    "    if x != 'Sales':\n",
    "        test[x] = test[x].astype('int32')\n",
    "\n",
    "for col in int8_cols:\n",
    "    int8(col)\n",
    "\n",
    "for col in int16_cols:\n",
    "    int16(col)\n",
    "\n",
    "for col in int32_cols:\n",
    "    int32(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Samples with Open=0\n",
    "\n",
    "index = train[ train['Open'] == 0].index\n",
    "train.drop(index, inplace = True, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train['Sales'] = np.sqrt(train['Sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Sales'\n",
    "date = 'Date'\n",
    "customer = 'Customers'\n",
    "\n",
    "cat_cols = ['Store', 'DayOfWeek', 'Open', 'Promo',\n",
    "       'StateHoliday', 'SchoolHoliday', 'year', 'month', 'day', 'dayofweek',\n",
    "       'week', 'Store_Type', 'Store_Assortment',\n",
    "       'Store_CompetitionOpenSinceMonth', 'Store_CompetitionOpenSinceYear',\n",
    "       'Store_Promo2', 'Store_Promo2SinceWeek', 'Store_Promo2SinceYear',\n",
    "       'Store_PromoInterval']\n",
    "\n",
    "features = [col for col in train.columns if col not in [target, date, customer]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn, val = train_test_split(train, test_size = 0.2, random_state = 1999)\n",
    "\n",
    "##### Input for model\n",
    "X_trn, X_val = trn[features], val[features]\n",
    "\n",
    "##### Target column\n",
    "y_trn, y_val = trn[target], val[target]\n",
    "\n",
    "##### Features for test data that we will be predicting\n",
    "X_test = test[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "lr = XGBRegressor(random_state=1)\n",
    "\n",
    "lr.fit(X_trn, y_trn)\n",
    "\n",
    "preds = lr.predict(X_val)\n",
    "preds = np.abs(preds)\n",
    "\n",
    "error = np.sqrt(mean_squared_error((y_val), (preds)))\n",
    "\n",
    "print(f'mean_squared_log_error is : {error}')\n",
    "#1125"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join(train_, test_):\n",
    "    df = pd.concat([train_, test_], axis = 0).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def split(df):\n",
    "    train_, test_ = df[:train.shape[0]], df[train.shape[0]:].reset_index(drop=True)\n",
    "    return train_, test_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Count Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Store Count\n",
    "store_count = train.groupby('Store').count()['Date'].to_dict()\n",
    "store_count = train.groupby('Store').count()['Date'].to_dict()\n",
    "\n",
    "train['Store_Count'] = train['Store'].map(store_count)\n",
    "test['Store_Count'] = test['Store'].map(store_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Total Customers Visted Store\n",
    "\n",
    "cutomers_per_store = train.groupby('Store')['Customers'].sum().to_dict()\n",
    "\n",
    "train['Cus_per_Store'] = train['Store'].map(cutomers_per_store)\n",
    "test['Cus_per_Store'] = test['Store'].map(cutomers_per_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Low Popularity Stores w.r.t Customers < 410\n",
    "\n",
    "store_cus = train.groupby('Store')['Customers'].mean().to_dict()\n",
    "\n",
    "train['is_low_popular'] = train['Store'].apply(lambda x: 1 if store_cus[x] < 410 else 0)\n",
    "test['is_low_popular'] = test['Store'].apply(lambda x: 1 if store_cus[x] < 410 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Low Popularity Stores w.r.t Customers < 410\n",
    "\n",
    "store_sales = train.groupby('Store')['Sales'].mean().to_dict()\n",
    "\n",
    "train['is_low_sales'] = train['Store'].apply(lambda x: 1 if store_sales[x] < 3800 else 0)\n",
    "test['is_low_sales'] = test['Store'].apply(lambda x: 1 if store_sales[x] < 3800 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3.  Store's Mean Sales\n",
    "\n",
    "store_sales = train.groupby('Store')['Sales'].mean().to_dict()\n",
    "\n",
    "train['Store_Median_Sales'] = train['Store'].apply(lambda x: store_sales[x])\n",
    "test['Store_Median_Sales'] = test['Store'].apply(lambda x: store_sales[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#4.  Total Customers Per Week\n",
    "\n",
    "week_store = train.groupby(['day', 'Store'])['Customers'].sum().to_dict()\n",
    "\n",
    "def imputer(x):\n",
    "    try:\n",
    "        val = week_store[(x['day'], x['Store'])]\n",
    "        return val\n",
    "    except:\n",
    "        return 0\n",
    "train['Customers_per_week'] = train.apply(lambda x: imputer(x), axis = 1)\n",
    "test['Customers_per_week'] = test.apply(lambda x: imputer(x), axis = 1)\n",
    "\n",
    "#cus_per_store = train.groupby('Store')['Customers'].median().to_dict()\n",
    "#test.loc[ test['Customers_per_week'] == 0, 'Customers_per_week'] = test.loc[ test['Customers_per_week'] == 0]['Store'].apply(lambda x: cus_per_store[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try later: Impute missing values of 2013\n",
    "month_sales = train.groupby(['month', 'Store'])['Sales'].mean().to_dict()\n",
    "\n",
    "#train['Monthly_Sales'] = train.apply(lambda x: month_sales[(x['month'], x['Store'])], axis = 1)\n",
    "#test['Monthly_Sales'] = test.apply(lambda x: month_sales[(x['month'], x['Store'])], axis = 1)\n",
    "\n",
    "\n",
    "def imputer(x):\n",
    "    try:\n",
    "        val = month_sales[(x['month'], x['Store'])]\n",
    "        return val\n",
    "    except:\n",
    "        return 0fm \n",
    "train['Monthly_Sales'] = train.apply(lambda x: imputer(x), axis = 1)\n",
    "test['Monthly_Sales'] = test.apply(lambda x: imputer(x), axis = 1)\n",
    "\n",
    "#cus_per_store = train.groupby('Store')['Customers'].median().to_dict()\n",
    "#test.loc[ test['Customers_per_week'] == 0, 'Customers_per_week'] = test.loc[ test['Customers_per_week'] == 0]['Store'].apply(lambda x: cus_per_store[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customers w.r.t. StoreType\n",
    "\n",
    "cus_type = train.groupby(['Store_Type', 'StateHoliday'])['Customers'].median()\n",
    "\n",
    "#train['Cus_per_type'] = train.apply(lambda x: cus_type[(x['Store_Type'], x['StateHoliday'])], axis = 1)\n",
    "#test['Cus_per_type'] = test.apply(lambda x: cus_type[(x['Store_Type'], x['StateHoliday'])], axis = 1)\n",
    "\n",
    "def imputer(x):\n",
    "    try:\n",
    "        val = cus_type[(x['Store_Type'], x['StateHoliday'])]\n",
    "        return val\n",
    "    except:\n",
    "        return 0 \n",
    "train['Cus_per_type'] = train.apply(lambda x: imputer(x), axis = 1)\n",
    "test['Cus_per_type'] = test.apply(lambda x: imputer(x), axis = 1)\n",
    "\n",
    "#cus_per_store = train.groupby('Store')['Customers'].median().to_dict()\n",
    "#test.loc[ test['Customers_per_week'] == 0, 'Customers_per_week'] = test.loc[ test['Customers_per_week'] == 0]['Store'].apply(lambda x: cus_per_store[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store's mean, max, min sale\n",
    "\n",
    "mean = train.groupby(['Store'])['Sales'].mean()\n",
    "median = train.groupby(['Store'])['Sales'].median()\n",
    "max_ = train.groupby(['Store'])['Sales'].max()\n",
    "min_ = train.groupby(['Store'])['Sales'].min()\n",
    "\n",
    "train['Mean_sales'] = train['Store'].apply(lambda x: mean[x])\n",
    "train['Median_sales'] = train['Store'].apply(lambda x: median[x])\n",
    "train['Max_sales'] = train['Store'].apply(lambda x: max_[x])\n",
    "train['Min_sales'] = train['Store'].apply(lambda x: min_[x])\n",
    "\n",
    "test['Mean_sales'] = test['Store'].apply(lambda x: mean[x])\n",
    "test['Median_sales'] = test['Store'].apply(lambda x: median[x])\n",
    "test['Max_sales'] = test['Store'].apply(lambda x: max_[x])\n",
    "test['Min_sales'] = test['Store'].apply(lambda x: min_[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean = train.groupby(['Store', 'year'])['Sales'].mean()\n",
    "median = train.groupby(['Store', 'year'])['Sales'].median()\n",
    "max_ = train.groupby(['Store', 'year'])['Sales'].max()\n",
    "min_ = train.groupby(['Store', 'year'])['Sales'].min()\n",
    "\n",
    "def imputer(d, x):\n",
    "    try:\n",
    "        val = d[(x['Store'], x['year'])]\n",
    "        return val\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "train['Mean_sales_month'] = train.apply(lambda x: imputer(mean, x), axis = 1)\n",
    "train['Median_sales_month'] = train.apply(lambda x: imputer(median, x), axis = 1)\n",
    "train['Max_sales_month'] = train.apply(lambda x: imputer(max_, x), axis = 1)\n",
    "train['Min_sales_month'] = train.apply(lambda x: imputer(min_, x), axis = 1)\n",
    "\n",
    "test['Mean_sales_month'] = test.apply(lambda x: imputer(mean, x), axis = 1)\n",
    "test['Median_sales_month'] = test.apply(lambda x: imputer(median, x), axis = 1)\n",
    "test['Max_sales_month'] = test.apply(lambda x: imputer(max_, x), axis = 1)\n",
    "test['Min_sales_month'] = test.apply(lambda x: imputer(min_, x), axis= 1)\n",
    "\n",
    "<!-- # store_sales_mean = train.groupby('Store')['Sales'].mean().to_dict()\n",
    "# store_sales_median = train.groupby('Store')['Sales'].median().to_dict()\n",
    "# store_sales_min = train.groupby('Store')['Sales'].min().to_dict()\n",
    "# store_sales_max = train.groupby('Store')['Sales'].max().to_dict()\n",
    "\n",
    "# test.loc[(test['Mean_sales_month'].isna()), 'Mean_sales_month'] = test[(test['Mean_sales_month'].isna())]['Store'].apply(lambda x:store_sales_mean[x])\n",
    "# test.loc[(test['Median_sales_month'].isna()), 'Median_sales_month'] = test[(test['Median_sales_month'].isna())]['Store'].apply(lambda x:store_sales_median[x])\n",
    "# test.loc[(test['Max_sales_month'].isna()), 'Max_sales_month'] = test[(test['Max_sales_month'].isna())]['Store'].apply(lambda x:store_sales_max[x])\n",
    "# test.loc[(test['Min_sales_month'].isna()), 'Min_sales_month'] = test[(test['Min_sales_month'].isna())]['Store'].apply(lambda x:store_sales_min[x]) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in train.columns if col not in [target, date, customer]]\n",
    "\n",
    "trn, val = train_test_split(train, test_size = 0.2, random_state = 1999)\n",
    "\n",
    "##### Input for model\n",
    "X_trn, X_val = trn[features], val[features]\n",
    "\n",
    "##### Target column\n",
    "y_trn, y_val = trn[target], val[target]\n",
    "\n",
    "##### Features for test data that we will be predicting\n",
    "X_test = test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_log_error is : 1125.9399137304747\n",
      "mean_squared_log_error is : 1701.8725894688628\n",
      "Wall time: 11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lr = XGBRegressor(random_state=1)\n",
    "\n",
    "lr.fit(X_trn, y_trn)\n",
    "\n",
    "preds = lr.predict(X_val)\n",
    "preds = np.abs(preds)\n",
    "\n",
    "error = np.sqrt(mean_squared_error((y_val), (preds)))\n",
    "\n",
    "print(f'mean_squared_log_error is : {error}')\n",
    "#1074\n",
    "#937 --> 2nd feat\n",
    "\n",
    "lr = LGBMRegressor(random_state=1)\n",
    "\n",
    "lr.fit(X_trn, y_trn)\n",
    "\n",
    "preds = lr.predict(X_val)\n",
    "preds = np.abs(preds)\n",
    "\n",
    "error = np.sqrt(mean_squared_error((y_val), (preds)))\n",
    "\n",
    "print(f'mean_squared_log_error is : {error}')\n",
    "#1074\n",
    "#937 --> 2nd feat\n",
    "\n",
    "#834 --> 3rd\n",
    "#820/959 -->mean, median, min, max sales per store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 20.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr = XGBRegressor(random_state=1, n_jobs = -1,)\n",
    "\n",
    "lr.fit(train[features], train[target])\n",
    "\n",
    "preds = lr.predict(test[features])\n",
    "preds = np.abs(preds)\n",
    "# With eval set and no cat_cols: lb score 1093"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_log_error is : 648.1391637500983\n",
      "Wall time: 3min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "params = {'max_depth': 9, 'n_estimators': 819, 'learning_rate': 0.10187280055433054, 'subsample': 0.5611557685582812, \n",
    "          'colsample_bytree': 0.7920162015831868, 'colsample_bylevel': 0.7633175258937133,\n",
    "          'reg_alpha': 82.97737560347895, 'reg_lambda': 27.377692424253066}\n",
    "\n",
    "lr = XGBRegressor(random_state=1, n_jobs = -1,**params)\n",
    "lr.fit(X_trn, y_trn)\n",
    "\n",
    "preds = lr.predict(X_val)\n",
    "preds = np.abs(preds)\n",
    "\n",
    "error = np.sqrt(mean_squared_error((y_val), (preds)))\n",
    "\n",
    "print(f'mean_squared_log_error is : {error}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "params = {'max_depth': 9, 'n_estimators': 819, 'learning_rate': 0.10187280055433054, 'subsample': 0.5611557685582812, \n",
    "          'colsample_bytree': 0.7920162015831868, 'colsample_bylevel': 0.7633175258937133,\n",
    "          'reg_alpha': 82.97737560347895, 'reg_lambda': 27.377692424253066}\n",
    "\n",
    "lr = XGBRegressor(random_state=1, n_jobs = -1,**params)\n",
    "lr.fit(train[features], train[target])\n",
    "\n",
    "preds = lr.predict(test[features])\n",
    "preds = np.abs(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.147523\n",
      "0:\tlearn: 2825.1659356\ttest: 2808.3296255\tbest: 2808.3296255 (0)\ttotal: 137ms\tremaining: 2m 17s\n",
      "1:\tlearn: 2552.9025424\ttest: 2537.9873793\tbest: 2537.9873793 (1)\ttotal: 298ms\tremaining: 2m 28s\n",
      "2:\tlearn: 2326.3198819\ttest: 2312.5955899\tbest: 2312.5955899 (2)\ttotal: 437ms\tremaining: 2m 25s\n",
      "3:\tlearn: 2138.8972406\ttest: 2126.3766689\tbest: 2126.3766689 (3)\ttotal: 572ms\tremaining: 2m 22s\n",
      "4:\tlearn: 1986.6205909\ttest: 1975.3538168\tbest: 1975.3538168 (4)\ttotal: 701ms\tremaining: 2m 19s\n",
      "5:\tlearn: 1860.6329618\ttest: 1850.1373598\tbest: 1850.1373598 (5)\ttotal: 848ms\tremaining: 2m 20s\n",
      "6:\tlearn: 1756.3700127\ttest: 1746.7193743\tbest: 1746.7193743 (6)\ttotal: 975ms\tremaining: 2m 18s\n",
      "7:\tlearn: 1670.9524766\ttest: 1661.4791906\tbest: 1661.4791906 (7)\ttotal: 1.14s\tremaining: 2m 20s\n",
      "8:\tlearn: 1601.5996942\ttest: 1592.9677663\tbest: 1592.9677663 (8)\ttotal: 1.3s\tremaining: 2m 23s\n",
      "9:\tlearn: 1546.1041529\ttest: 1537.7831056\tbest: 1537.7831056 (9)\ttotal: 1.43s\tremaining: 2m 21s\n",
      "10:\tlearn: 1500.3200980\ttest: 1491.8400038\tbest: 1491.8400038 (10)\ttotal: 1.57s\tremaining: 2m 21s\n",
      "11:\tlearn: 1463.6457346\ttest: 1455.5498319\tbest: 1455.5498319 (11)\ttotal: 1.7s\tremaining: 2m 20s\n",
      "12:\tlearn: 1432.1441081\ttest: 1423.9858897\tbest: 1423.9858897 (12)\ttotal: 1.84s\tremaining: 2m 19s\n",
      "13:\tlearn: 1404.4609989\ttest: 1396.4646153\tbest: 1396.4646153 (13)\ttotal: 1.96s\tremaining: 2m 18s\n",
      "14:\tlearn: 1382.7383060\ttest: 1374.4228882\tbest: 1374.4228882 (14)\ttotal: 2.08s\tremaining: 2m 16s\n",
      "15:\tlearn: 1364.9239161\ttest: 1357.1332401\tbest: 1357.1332401 (15)\ttotal: 2.23s\tremaining: 2m 17s\n",
      "16:\tlearn: 1348.4642510\ttest: 1340.7644013\tbest: 1340.7644013 (16)\ttotal: 2.36s\tremaining: 2m 16s\n",
      "17:\tlearn: 1332.9685332\ttest: 1325.6013173\tbest: 1325.6013173 (17)\ttotal: 2.57s\tremaining: 2m 20s\n",
      "18:\tlearn: 1318.1010189\ttest: 1311.8504503\tbest: 1311.8504503 (18)\ttotal: 2.7s\tremaining: 2m 19s\n",
      "19:\tlearn: 1307.7329922\ttest: 1301.4690730\tbest: 1301.4690730 (19)\ttotal: 2.85s\tremaining: 2m 19s\n",
      "20:\tlearn: 1298.2592304\ttest: 1291.8107185\tbest: 1291.8107185 (20)\ttotal: 2.99s\tremaining: 2m 19s\n",
      "21:\tlearn: 1282.9089217\ttest: 1277.1530109\tbest: 1277.1530109 (21)\ttotal: 3.12s\tremaining: 2m 18s\n",
      "22:\tlearn: 1275.5908401\ttest: 1269.9793893\tbest: 1269.9793893 (22)\ttotal: 3.25s\tremaining: 2m 17s\n",
      "23:\tlearn: 1266.1288244\ttest: 1260.6753962\tbest: 1260.6753962 (23)\ttotal: 3.38s\tremaining: 2m 17s\n",
      "24:\tlearn: 1254.7160327\ttest: 1249.6339769\tbest: 1249.6339769 (24)\ttotal: 3.52s\tremaining: 2m 17s\n",
      "25:\tlearn: 1245.8554931\ttest: 1241.3337490\tbest: 1241.3337490 (25)\ttotal: 3.65s\tremaining: 2m 16s\n",
      "26:\tlearn: 1237.6561399\ttest: 1233.0416553\tbest: 1233.0416553 (26)\ttotal: 3.78s\tremaining: 2m 16s\n",
      "27:\tlearn: 1231.7547014\ttest: 1227.8668840\tbest: 1227.8668840 (27)\ttotal: 3.93s\tremaining: 2m 16s\n",
      "28:\tlearn: 1225.0755129\ttest: 1221.0630231\tbest: 1221.0630231 (28)\ttotal: 4.07s\tremaining: 2m 16s\n",
      "29:\tlearn: 1219.0511263\ttest: 1214.7215637\tbest: 1214.7215637 (29)\ttotal: 4.2s\tremaining: 2m 15s\n",
      "30:\tlearn: 1212.7549828\ttest: 1208.3717437\tbest: 1208.3717437 (30)\ttotal: 4.33s\tremaining: 2m 15s\n",
      "31:\tlearn: 1208.5431215\ttest: 1204.1736999\tbest: 1204.1736999 (31)\ttotal: 4.47s\tremaining: 2m 15s\n",
      "32:\tlearn: 1199.4542785\ttest: 1195.4977461\tbest: 1195.4977461 (32)\ttotal: 4.6s\tremaining: 2m 14s\n",
      "33:\tlearn: 1195.5996690\ttest: 1191.4358432\tbest: 1191.4358432 (33)\ttotal: 4.74s\tremaining: 2m 14s\n",
      "34:\tlearn: 1189.9799339\ttest: 1185.8468823\tbest: 1185.8468823 (34)\ttotal: 4.88s\tremaining: 2m 14s\n",
      "35:\tlearn: 1180.7563100\ttest: 1177.2513930\tbest: 1177.2513930 (35)\ttotal: 5.02s\tremaining: 2m 14s\n",
      "36:\tlearn: 1176.0778981\ttest: 1172.4285718\tbest: 1172.4285718 (36)\ttotal: 5.13s\tremaining: 2m 13s\n",
      "37:\tlearn: 1170.5501080\ttest: 1166.9550353\tbest: 1166.9550353 (37)\ttotal: 5.27s\tremaining: 2m 13s\n",
      "38:\tlearn: 1164.0683898\ttest: 1160.5583657\tbest: 1160.5583657 (38)\ttotal: 5.39s\tremaining: 2m 12s\n",
      "39:\tlearn: 1159.4845222\ttest: 1156.0363995\tbest: 1156.0363995 (39)\ttotal: 5.52s\tremaining: 2m 12s\n",
      "40:\tlearn: 1154.7811836\ttest: 1151.5037045\tbest: 1151.5037045 (40)\ttotal: 5.65s\tremaining: 2m 12s\n",
      "41:\tlearn: 1150.8819465\ttest: 1148.2519467\tbest: 1148.2519467 (41)\ttotal: 5.79s\tremaining: 2m 11s\n",
      "42:\tlearn: 1147.3636836\ttest: 1144.8669876\tbest: 1144.8669876 (42)\ttotal: 5.91s\tremaining: 2m 11s\n",
      "43:\tlearn: 1142.8467666\ttest: 1140.3706930\tbest: 1140.3706930 (43)\ttotal: 6.06s\tremaining: 2m 11s\n",
      "44:\tlearn: 1138.2233783\ttest: 1136.1666630\tbest: 1136.1666630 (44)\ttotal: 6.18s\tremaining: 2m 11s\n",
      "45:\tlearn: 1134.1505376\ttest: 1132.1007128\tbest: 1132.1007128 (45)\ttotal: 6.32s\tremaining: 2m 10s\n",
      "46:\tlearn: 1131.1837299\ttest: 1129.2390645\tbest: 1129.2390645 (46)\ttotal: 6.47s\tremaining: 2m 11s\n",
      "47:\tlearn: 1128.0610685\ttest: 1126.2804177\tbest: 1126.2804177 (47)\ttotal: 6.6s\tremaining: 2m 10s\n",
      "48:\tlearn: 1125.4551939\ttest: 1123.6792338\tbest: 1123.6792338 (48)\ttotal: 6.73s\tremaining: 2m 10s\n",
      "49:\tlearn: 1122.5598367\ttest: 1120.8240321\tbest: 1120.8240321 (49)\ttotal: 6.87s\tremaining: 2m 10s\n",
      "50:\tlearn: 1120.1801445\ttest: 1118.4938548\tbest: 1118.4938548 (50)\ttotal: 7s\tremaining: 2m 10s\n",
      "51:\tlearn: 1116.6446667\ttest: 1115.2090573\tbest: 1115.2090573 (51)\ttotal: 7.12s\tremaining: 2m 9s\n",
      "52:\tlearn: 1114.4600554\ttest: 1113.0439303\tbest: 1113.0439303 (52)\ttotal: 7.27s\tremaining: 2m 9s\n",
      "53:\tlearn: 1107.3068626\ttest: 1105.7963580\tbest: 1105.7963580 (53)\ttotal: 7.43s\tremaining: 2m 10s\n",
      "54:\tlearn: 1105.0338352\ttest: 1103.9671430\tbest: 1103.9671430 (54)\ttotal: 7.64s\tremaining: 2m 11s\n",
      "55:\tlearn: 1100.9269822\ttest: 1100.0363728\tbest: 1100.0363728 (55)\ttotal: 7.78s\tremaining: 2m 11s\n",
      "56:\tlearn: 1097.7886948\ttest: 1097.0330254\tbest: 1097.0330254 (56)\ttotal: 7.91s\tremaining: 2m 10s\n",
      "57:\tlearn: 1095.0672379\ttest: 1094.4121075\tbest: 1094.4121075 (57)\ttotal: 8.05s\tremaining: 2m 10s\n",
      "58:\tlearn: 1090.5163885\ttest: 1089.7880708\tbest: 1089.7880708 (58)\ttotal: 8.2s\tremaining: 2m 10s\n",
      "59:\tlearn: 1087.9456080\ttest: 1087.1664464\tbest: 1087.1664464 (59)\ttotal: 8.38s\tremaining: 2m 11s\n",
      "60:\tlearn: 1085.0017384\ttest: 1084.2392326\tbest: 1084.2392326 (60)\ttotal: 8.56s\tremaining: 2m 11s\n",
      "61:\tlearn: 1081.5634961\ttest: 1080.8195482\tbest: 1080.8195482 (61)\ttotal: 8.7s\tremaining: 2m 11s\n",
      "62:\tlearn: 1079.1197456\ttest: 1078.4392951\tbest: 1078.4392951 (62)\ttotal: 8.86s\tremaining: 2m 11s\n",
      "63:\tlearn: 1073.1823806\ttest: 1072.5510025\tbest: 1072.5510025 (63)\ttotal: 9.01s\tremaining: 2m 11s\n",
      "64:\tlearn: 1071.2213738\ttest: 1070.6661121\tbest: 1070.6661121 (64)\ttotal: 9.17s\tremaining: 2m 11s\n",
      "65:\tlearn: 1069.0717733\ttest: 1068.4766781\tbest: 1068.4766781 (65)\ttotal: 9.31s\tremaining: 2m 11s\n",
      "66:\tlearn: 1067.1742279\ttest: 1066.5650587\tbest: 1066.5650587 (66)\ttotal: 9.47s\tremaining: 2m 11s\n",
      "67:\tlearn: 1064.7264745\ttest: 1064.1836412\tbest: 1064.1836412 (67)\ttotal: 9.6s\tremaining: 2m 11s\n",
      "68:\tlearn: 1060.6347985\ttest: 1060.0439061\tbest: 1060.0439061 (68)\ttotal: 9.74s\tremaining: 2m 11s\n",
      "69:\tlearn: 1058.9704388\ttest: 1058.4803138\tbest: 1058.4803138 (69)\ttotal: 9.87s\tremaining: 2m 11s\n",
      "70:\tlearn: 1056.9579640\ttest: 1056.5436854\tbest: 1056.5436854 (70)\ttotal: 9.97s\tremaining: 2m 10s\n",
      "71:\tlearn: 1054.7927645\ttest: 1054.4388904\tbest: 1054.4388904 (71)\ttotal: 10.1s\tremaining: 2m 10s\n",
      "72:\tlearn: 1053.3482732\ttest: 1052.9821857\tbest: 1052.9821857 (72)\ttotal: 10.3s\tremaining: 2m 10s\n",
      "73:\tlearn: 1051.1238347\ttest: 1050.6080393\tbest: 1050.6080393 (73)\ttotal: 10.4s\tremaining: 2m 10s\n",
      "74:\tlearn: 1049.6022715\ttest: 1049.2160911\tbest: 1049.2160911 (74)\ttotal: 10.6s\tremaining: 2m 10s\n",
      "75:\tlearn: 1047.7703582\ttest: 1047.3429328\tbest: 1047.3429328 (75)\ttotal: 10.8s\tremaining: 2m 11s\n",
      "76:\tlearn: 1046.2478492\ttest: 1045.8488873\tbest: 1045.8488873 (76)\ttotal: 11s\tremaining: 2m 11s\n",
      "77:\tlearn: 1044.4538010\ttest: 1043.9424216\tbest: 1043.9424216 (77)\ttotal: 11.1s\tremaining: 2m 11s\n",
      "78:\tlearn: 1041.1360204\ttest: 1040.5648303\tbest: 1040.5648303 (78)\ttotal: 11.3s\tremaining: 2m 12s\n",
      "79:\tlearn: 1039.6449389\ttest: 1038.9934853\tbest: 1038.9934853 (79)\ttotal: 11.5s\tremaining: 2m 12s\n",
      "80:\tlearn: 1036.2398407\ttest: 1035.5981920\tbest: 1035.5981920 (80)\ttotal: 11.7s\tremaining: 2m 12s\n",
      "81:\tlearn: 1033.5950439\ttest: 1033.0342706\tbest: 1033.0342706 (81)\ttotal: 11.8s\tremaining: 2m 12s\n",
      "82:\tlearn: 1031.5051255\ttest: 1031.0508972\tbest: 1031.0508972 (82)\ttotal: 12s\tremaining: 2m 12s\n",
      "83:\tlearn: 1028.9070792\ttest: 1028.5045730\tbest: 1028.5045730 (83)\ttotal: 12.2s\tremaining: 2m 12s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84:\tlearn: 1026.1915131\ttest: 1025.8406355\tbest: 1025.8406355 (84)\ttotal: 12.3s\tremaining: 2m 12s\n",
      "85:\tlearn: 1024.3021433\ttest: 1023.9409927\tbest: 1023.9409927 (85)\ttotal: 12.5s\tremaining: 2m 12s\n",
      "86:\tlearn: 1022.7968193\ttest: 1022.5548326\tbest: 1022.5548326 (86)\ttotal: 12.7s\tremaining: 2m 12s\n",
      "87:\tlearn: 1021.2063610\ttest: 1020.8687332\tbest: 1020.8687332 (87)\ttotal: 12.8s\tremaining: 2m 13s\n",
      "88:\tlearn: 1019.7455407\ttest: 1019.5194285\tbest: 1019.5194285 (88)\ttotal: 13s\tremaining: 2m 13s\n",
      "89:\tlearn: 1018.7657716\ttest: 1018.6181782\tbest: 1018.6181782 (89)\ttotal: 13.2s\tremaining: 2m 13s\n",
      "90:\tlearn: 1017.6924495\ttest: 1017.6371829\tbest: 1017.6371829 (90)\ttotal: 13.3s\tremaining: 2m 12s\n",
      "91:\tlearn: 1016.0739858\ttest: 1016.2134086\tbest: 1016.2134086 (91)\ttotal: 13.4s\tremaining: 2m 12s\n",
      "92:\tlearn: 1014.5629828\ttest: 1014.6712693\tbest: 1014.6712693 (92)\ttotal: 13.6s\tremaining: 2m 12s\n",
      "93:\tlearn: 1012.4854527\ttest: 1012.5825219\tbest: 1012.5825219 (93)\ttotal: 13.7s\tremaining: 2m 12s\n",
      "94:\tlearn: 1011.0715985\ttest: 1011.1774956\tbest: 1011.1774956 (94)\ttotal: 13.9s\tremaining: 2m 12s\n",
      "95:\tlearn: 1009.7581105\ttest: 1009.9042096\tbest: 1009.9042096 (95)\ttotal: 14s\tremaining: 2m 11s\n",
      "96:\tlearn: 1008.9765365\ttest: 1009.2023520\tbest: 1009.2023520 (96)\ttotal: 14.1s\tremaining: 2m 11s\n",
      "97:\tlearn: 1007.8791291\ttest: 1008.2526059\tbest: 1008.2526059 (97)\ttotal: 14.3s\tremaining: 2m 11s\n",
      "98:\tlearn: 1006.6023087\ttest: 1007.2471251\tbest: 1007.2471251 (98)\ttotal: 14.4s\tremaining: 2m 11s\n",
      "99:\tlearn: 1004.4678612\ttest: 1005.0898193\tbest: 1005.0898193 (99)\ttotal: 14.5s\tremaining: 2m 10s\n",
      "100:\tlearn: 1003.1026236\ttest: 1003.8381059\tbest: 1003.8381059 (100)\ttotal: 14.7s\tremaining: 2m 10s\n",
      "101:\tlearn: 1001.8859853\ttest: 1002.7543221\tbest: 1002.7543221 (101)\ttotal: 14.8s\tremaining: 2m 10s\n",
      "102:\tlearn: 1000.5394594\ttest: 1001.4084184\tbest: 1001.4084184 (102)\ttotal: 14.9s\tremaining: 2m 9s\n",
      "103:\tlearn: 998.4295472\ttest: 999.3155891\tbest: 999.3155891 (103)\ttotal: 15s\tremaining: 2m 9s\n",
      "104:\tlearn: 996.8671007\ttest: 997.7131371\tbest: 997.7131371 (104)\ttotal: 15.2s\tremaining: 2m 9s\n",
      "105:\tlearn: 994.0818334\ttest: 994.8532430\tbest: 994.8532430 (105)\ttotal: 15.4s\tremaining: 2m 9s\n",
      "106:\tlearn: 993.1640148\ttest: 994.0829392\tbest: 994.0829392 (106)\ttotal: 15.5s\tremaining: 2m 9s\n",
      "107:\tlearn: 991.8648099\ttest: 992.7206011\tbest: 992.7206011 (107)\ttotal: 15.6s\tremaining: 2m 9s\n",
      "108:\tlearn: 990.4068477\ttest: 991.2812671\tbest: 991.2812671 (108)\ttotal: 15.8s\tremaining: 2m 8s\n",
      "109:\tlearn: 988.9700583\ttest: 989.9999203\tbest: 989.9999203 (109)\ttotal: 15.9s\tremaining: 2m 8s\n",
      "110:\tlearn: 987.9456026\ttest: 989.0098045\tbest: 989.0098045 (110)\ttotal: 16s\tremaining: 2m 8s\n",
      "111:\tlearn: 986.1651287\ttest: 987.0823468\tbest: 987.0823468 (111)\ttotal: 16.2s\tremaining: 2m 8s\n",
      "112:\tlearn: 984.7493254\ttest: 985.8650060\tbest: 985.8650060 (112)\ttotal: 16.3s\tremaining: 2m 8s\n",
      "113:\tlearn: 983.9161361\ttest: 985.0426590\tbest: 985.0426590 (113)\ttotal: 16.4s\tremaining: 2m 7s\n",
      "114:\tlearn: 982.9868656\ttest: 984.0445218\tbest: 984.0445218 (114)\ttotal: 16.6s\tremaining: 2m 7s\n",
      "115:\tlearn: 981.9258369\ttest: 983.0568658\tbest: 983.0568658 (115)\ttotal: 16.7s\tremaining: 2m 7s\n",
      "116:\tlearn: 980.9963842\ttest: 982.2059232\tbest: 982.2059232 (116)\ttotal: 16.8s\tremaining: 2m 6s\n",
      "117:\tlearn: 979.6179041\ttest: 980.7978133\tbest: 980.7978133 (117)\ttotal: 16.9s\tremaining: 2m 6s\n",
      "118:\tlearn: 978.6212483\ttest: 979.9124313\tbest: 979.9124313 (118)\ttotal: 17.1s\tremaining: 2m 6s\n",
      "119:\tlearn: 977.6546370\ttest: 978.9770617\tbest: 978.9770617 (119)\ttotal: 17.3s\tremaining: 2m 6s\n",
      "120:\tlearn: 975.4770561\ttest: 976.5768754\tbest: 976.5768754 (120)\ttotal: 17.5s\tremaining: 2m 6s\n",
      "121:\tlearn: 973.8846136\ttest: 975.0430178\tbest: 975.0430178 (121)\ttotal: 17.6s\tremaining: 2m 6s\n",
      "122:\tlearn: 973.0711984\ttest: 974.3619383\tbest: 974.3619383 (122)\ttotal: 17.7s\tremaining: 2m 6s\n",
      "123:\tlearn: 972.3384129\ttest: 973.5671722\tbest: 973.5671722 (123)\ttotal: 17.9s\tremaining: 2m 6s\n",
      "124:\tlearn: 971.3097362\ttest: 972.5678007\tbest: 972.5678007 (124)\ttotal: 18s\tremaining: 2m 6s\n",
      "125:\tlearn: 970.5445841\ttest: 971.9574004\tbest: 971.9574004 (125)\ttotal: 18.2s\tremaining: 2m 6s\n",
      "126:\tlearn: 968.5729273\ttest: 970.0521846\tbest: 970.0521846 (126)\ttotal: 18.3s\tremaining: 2m 6s\n",
      "127:\tlearn: 967.3761854\ttest: 968.9696417\tbest: 968.9696417 (127)\ttotal: 18.5s\tremaining: 2m 5s\n",
      "128:\tlearn: 965.5910260\ttest: 967.2355055\tbest: 967.2355055 (128)\ttotal: 18.6s\tremaining: 2m 5s\n",
      "129:\tlearn: 964.1596428\ttest: 965.8004487\tbest: 965.8004487 (129)\ttotal: 18.7s\tremaining: 2m 5s\n",
      "130:\tlearn: 962.8163359\ttest: 964.5814380\tbest: 964.5814380 (130)\ttotal: 18.9s\tremaining: 2m 5s\n",
      "131:\tlearn: 961.7129440\ttest: 963.5577273\tbest: 963.5577273 (131)\ttotal: 19s\tremaining: 2m 4s\n",
      "132:\tlearn: 959.2303126\ttest: 960.9802647\tbest: 960.9802647 (132)\ttotal: 19.1s\tremaining: 2m 4s\n",
      "133:\tlearn: 958.0321459\ttest: 959.7440418\tbest: 959.7440418 (133)\ttotal: 19.2s\tremaining: 2m 4s\n",
      "134:\tlearn: 957.1218616\ttest: 958.8774463\tbest: 958.8774463 (134)\ttotal: 19.4s\tremaining: 2m 4s\n",
      "135:\tlearn: 955.5124875\ttest: 957.2788589\tbest: 957.2788589 (135)\ttotal: 19.5s\tremaining: 2m 4s\n",
      "136:\tlearn: 954.5817767\ttest: 956.3168304\tbest: 956.3168304 (136)\ttotal: 19.7s\tremaining: 2m 3s\n",
      "137:\tlearn: 953.7419743\ttest: 955.4562368\tbest: 955.4562368 (137)\ttotal: 19.8s\tremaining: 2m 3s\n",
      "138:\tlearn: 952.9074880\ttest: 954.6567276\tbest: 954.6567276 (138)\ttotal: 20s\tremaining: 2m 3s\n",
      "139:\tlearn: 951.1921772\ttest: 952.8407945\tbest: 952.8407945 (139)\ttotal: 20.1s\tremaining: 2m 3s\n",
      "140:\tlearn: 950.5894192\ttest: 952.3148193\tbest: 952.3148193 (140)\ttotal: 20.2s\tremaining: 2m 3s\n",
      "141:\tlearn: 949.7342869\ttest: 951.4582520\tbest: 951.4582520 (141)\ttotal: 20.3s\tremaining: 2m 2s\n",
      "142:\tlearn: 948.9411383\ttest: 950.6880339\tbest: 950.6880339 (142)\ttotal: 20.5s\tremaining: 2m 2s\n",
      "143:\tlearn: 947.8221325\ttest: 949.5280602\tbest: 949.5280602 (143)\ttotal: 20.6s\tremaining: 2m 2s\n",
      "144:\tlearn: 947.0901198\ttest: 948.7852846\tbest: 948.7852846 (144)\ttotal: 20.7s\tremaining: 2m 2s\n",
      "145:\tlearn: 945.9828476\ttest: 947.7212364\tbest: 947.7212364 (145)\ttotal: 20.9s\tremaining: 2m 2s\n",
      "146:\tlearn: 944.9278717\ttest: 946.7524536\tbest: 946.7524536 (146)\ttotal: 21s\tremaining: 2m 1s\n",
      "147:\tlearn: 943.8124517\ttest: 945.6434216\tbest: 945.6434216 (147)\ttotal: 21.2s\tremaining: 2m 1s\n",
      "148:\tlearn: 942.2036604\ttest: 944.0480215\tbest: 944.0480215 (148)\ttotal: 21.3s\tremaining: 2m 1s\n",
      "149:\tlearn: 941.4469382\ttest: 943.3523123\tbest: 943.3523123 (149)\ttotal: 21.4s\tremaining: 2m 1s\n",
      "150:\tlearn: 940.8605689\ttest: 942.7620528\tbest: 942.7620528 (150)\ttotal: 21.6s\tremaining: 2m 1s\n",
      "151:\tlearn: 939.4675070\ttest: 941.2520033\tbest: 941.2520033 (151)\ttotal: 21.7s\tremaining: 2m 1s\n",
      "152:\tlearn: 938.7528499\ttest: 940.5796724\tbest: 940.5796724 (152)\ttotal: 21.8s\tremaining: 2m\n",
      "153:\tlearn: 937.9922043\ttest: 939.8941803\tbest: 939.8941803 (153)\ttotal: 22s\tremaining: 2m\n",
      "154:\tlearn: 936.8309331\ttest: 938.6590932\tbest: 938.6590932 (154)\ttotal: 22.1s\tremaining: 2m\n",
      "155:\tlearn: 936.2829580\ttest: 938.0320005\tbest: 938.0320005 (155)\ttotal: 22.3s\tremaining: 2m\n",
      "156:\tlearn: 935.8451692\ttest: 937.6376999\tbest: 937.6376999 (156)\ttotal: 22.4s\tremaining: 2m\n",
      "157:\tlearn: 935.3059478\ttest: 937.1271420\tbest: 937.1271420 (157)\ttotal: 22.5s\tremaining: 2m\n",
      "158:\tlearn: 934.1403039\ttest: 935.9558285\tbest: 935.9558285 (158)\ttotal: 22.7s\tremaining: 1m 59s\n",
      "159:\tlearn: 932.7509454\ttest: 934.4640311\tbest: 934.4640311 (159)\ttotal: 22.8s\tremaining: 1m 59s\n",
      "160:\tlearn: 932.1841357\ttest: 933.9668897\tbest: 933.9668897 (160)\ttotal: 22.9s\tremaining: 1m 59s\n",
      "161:\tlearn: 930.6626121\ttest: 932.4269127\tbest: 932.4269127 (161)\ttotal: 23.1s\tremaining: 1m 59s\n",
      "162:\tlearn: 929.7638362\ttest: 931.5634201\tbest: 931.5634201 (162)\ttotal: 23.2s\tremaining: 1m 59s\n",
      "163:\tlearn: 929.4339151\ttest: 931.2641119\tbest: 931.2641119 (163)\ttotal: 23.4s\tremaining: 1m 59s\n",
      "164:\tlearn: 928.4876690\ttest: 930.3367766\tbest: 930.3367766 (164)\ttotal: 23.5s\tremaining: 1m 58s\n",
      "165:\tlearn: 927.5351185\ttest: 929.5386818\tbest: 929.5386818 (165)\ttotal: 23.6s\tremaining: 1m 58s\n",
      "166:\tlearn: 925.9376577\ttest: 928.0019982\tbest: 928.0019982 (166)\ttotal: 23.7s\tremaining: 1m 58s\n",
      "167:\tlearn: 924.9597490\ttest: 927.1023643\tbest: 927.1023643 (167)\ttotal: 23.9s\tremaining: 1m 58s\n",
      "168:\tlearn: 924.3147241\ttest: 926.4355345\tbest: 926.4355345 (168)\ttotal: 24s\tremaining: 1m 58s\n",
      "169:\tlearn: 923.8012661\ttest: 925.9082913\tbest: 925.9082913 (169)\ttotal: 24.1s\tremaining: 1m 57s\n",
      "170:\tlearn: 922.9194700\ttest: 925.0888771\tbest: 925.0888771 (170)\ttotal: 24.3s\tremaining: 1m 57s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171:\tlearn: 922.3588410\ttest: 924.5960756\tbest: 924.5960756 (171)\ttotal: 24.4s\tremaining: 1m 57s\n",
      "172:\tlearn: 921.7088155\ttest: 923.9804003\tbest: 923.9804003 (172)\ttotal: 24.6s\tremaining: 1m 57s\n",
      "173:\tlearn: 921.1080249\ttest: 923.2991978\tbest: 923.2991978 (173)\ttotal: 24.7s\tremaining: 1m 57s\n",
      "174:\tlearn: 920.4582618\ttest: 922.6621019\tbest: 922.6621019 (174)\ttotal: 24.8s\tremaining: 1m 57s\n",
      "175:\tlearn: 919.6950020\ttest: 921.9997306\tbest: 921.9997306 (175)\ttotal: 24.9s\tremaining: 1m 56s\n",
      "176:\tlearn: 919.2136839\ttest: 921.5776500\tbest: 921.5776500 (176)\ttotal: 25.1s\tremaining: 1m 56s\n",
      "177:\tlearn: 918.7433837\ttest: 921.1270148\tbest: 921.1270148 (177)\ttotal: 25.2s\tremaining: 1m 56s\n",
      "178:\tlearn: 917.8985438\ttest: 920.2755967\tbest: 920.2755967 (178)\ttotal: 25.4s\tremaining: 1m 56s\n",
      "179:\tlearn: 917.1980970\ttest: 919.7159737\tbest: 919.7159737 (179)\ttotal: 25.5s\tremaining: 1m 56s\n",
      "180:\tlearn: 916.7935131\ttest: 919.3568256\tbest: 919.3568256 (180)\ttotal: 25.7s\tremaining: 1m 56s\n",
      "181:\tlearn: 916.0946214\ttest: 918.6527765\tbest: 918.6527765 (181)\ttotal: 25.8s\tremaining: 1m 56s\n",
      "182:\tlearn: 915.0151827\ttest: 917.5207469\tbest: 917.5207469 (182)\ttotal: 26s\tremaining: 1m 55s\n",
      "183:\tlearn: 914.4563998\ttest: 916.9258008\tbest: 916.9258008 (183)\ttotal: 26.1s\tremaining: 1m 55s\n",
      "184:\tlearn: 913.8233791\ttest: 916.3616764\tbest: 916.3616764 (184)\ttotal: 26.2s\tremaining: 1m 55s\n",
      "185:\tlearn: 912.9446416\ttest: 915.4015545\tbest: 915.4015545 (185)\ttotal: 26.3s\tremaining: 1m 55s\n",
      "186:\tlearn: 912.2828928\ttest: 914.8409984\tbest: 914.8409984 (186)\ttotal: 26.5s\tremaining: 1m 55s\n",
      "187:\tlearn: 912.0477588\ttest: 914.6458394\tbest: 914.6458394 (187)\ttotal: 26.6s\tremaining: 1m 54s\n",
      "188:\tlearn: 911.4234684\ttest: 913.9782045\tbest: 913.9782045 (188)\ttotal: 26.8s\tremaining: 1m 54s\n",
      "189:\tlearn: 910.4116472\ttest: 912.8557391\tbest: 912.8557391 (189)\ttotal: 26.9s\tremaining: 1m 54s\n",
      "190:\tlearn: 909.7667652\ttest: 912.2108788\tbest: 912.2108788 (190)\ttotal: 27s\tremaining: 1m 54s\n",
      "191:\tlearn: 909.1812907\ttest: 911.5670373\tbest: 911.5670373 (191)\ttotal: 27.2s\tremaining: 1m 54s\n",
      "192:\tlearn: 908.4975308\ttest: 910.8433714\tbest: 910.8433714 (192)\ttotal: 27.3s\tremaining: 1m 54s\n",
      "193:\tlearn: 907.7649907\ttest: 910.0930592\tbest: 910.0930592 (193)\ttotal: 27.4s\tremaining: 1m 54s\n",
      "194:\tlearn: 906.9029281\ttest: 909.1945655\tbest: 909.1945655 (194)\ttotal: 27.6s\tremaining: 1m 53s\n",
      "195:\tlearn: 906.0728209\ttest: 908.3476648\tbest: 908.3476648 (195)\ttotal: 27.7s\tremaining: 1m 53s\n",
      "196:\tlearn: 905.6550229\ttest: 908.0086162\tbest: 908.0086162 (196)\ttotal: 27.8s\tremaining: 1m 53s\n",
      "197:\tlearn: 905.2252402\ttest: 907.5606704\tbest: 907.5606704 (197)\ttotal: 28s\tremaining: 1m 53s\n",
      "198:\tlearn: 904.6708081\ttest: 907.0617324\tbest: 907.0617324 (198)\ttotal: 28.1s\tremaining: 1m 53s\n",
      "199:\tlearn: 904.0641334\ttest: 906.4714286\tbest: 906.4714286 (199)\ttotal: 28.3s\tremaining: 1m 53s\n",
      "200:\tlearn: 903.7270225\ttest: 906.2182519\tbest: 906.2182519 (200)\ttotal: 28.4s\tremaining: 1m 52s\n",
      "201:\tlearn: 902.5892953\ttest: 905.1926022\tbest: 905.1926022 (201)\ttotal: 28.6s\tremaining: 1m 52s\n",
      "202:\tlearn: 902.0531099\ttest: 904.6663118\tbest: 904.6663118 (202)\ttotal: 28.7s\tremaining: 1m 52s\n",
      "203:\tlearn: 901.4969593\ttest: 904.2129618\tbest: 904.2129618 (203)\ttotal: 28.9s\tremaining: 1m 52s\n",
      "204:\tlearn: 900.9066078\ttest: 903.5973703\tbest: 903.5973703 (204)\ttotal: 29s\tremaining: 1m 52s\n",
      "205:\tlearn: 900.5215441\ttest: 903.2195065\tbest: 903.2195065 (205)\ttotal: 29.1s\tremaining: 1m 52s\n",
      "206:\tlearn: 899.9374423\ttest: 902.6788610\tbest: 902.6788610 (206)\ttotal: 29.3s\tremaining: 1m 52s\n",
      "207:\tlearn: 898.7889752\ttest: 901.5985002\tbest: 901.5985002 (207)\ttotal: 29.4s\tremaining: 1m 51s\n",
      "208:\tlearn: 898.2122635\ttest: 900.9468761\tbest: 900.9468761 (208)\ttotal: 29.5s\tremaining: 1m 51s\n",
      "209:\tlearn: 897.3085720\ttest: 900.1140239\tbest: 900.1140239 (209)\ttotal: 29.7s\tremaining: 1m 51s\n",
      "210:\tlearn: 896.7612358\ttest: 899.5586088\tbest: 899.5586088 (210)\ttotal: 29.8s\tremaining: 1m 51s\n",
      "211:\tlearn: 896.3740983\ttest: 899.1523596\tbest: 899.1523596 (211)\ttotal: 29.9s\tremaining: 1m 51s\n",
      "212:\tlearn: 895.8608794\ttest: 898.7065855\tbest: 898.7065855 (212)\ttotal: 30.1s\tremaining: 1m 51s\n",
      "213:\tlearn: 895.3837260\ttest: 898.2347900\tbest: 898.2347900 (213)\ttotal: 30.2s\tremaining: 1m 50s\n",
      "214:\tlearn: 894.9586913\ttest: 897.8513212\tbest: 897.8513212 (214)\ttotal: 30.3s\tremaining: 1m 50s\n",
      "215:\tlearn: 894.4362990\ttest: 897.3448813\tbest: 897.3448813 (215)\ttotal: 30.5s\tremaining: 1m 50s\n",
      "216:\tlearn: 894.0130828\ttest: 896.8605017\tbest: 896.8605017 (216)\ttotal: 30.6s\tremaining: 1m 50s\n",
      "217:\tlearn: 893.5373455\ttest: 896.3069601\tbest: 896.3069601 (217)\ttotal: 30.8s\tremaining: 1m 50s\n",
      "218:\tlearn: 892.8361291\ttest: 895.6806588\tbest: 895.6806588 (218)\ttotal: 30.9s\tremaining: 1m 50s\n",
      "219:\tlearn: 892.3093302\ttest: 895.2221732\tbest: 895.2221732 (219)\ttotal: 31s\tremaining: 1m 50s\n",
      "220:\tlearn: 891.3413474\ttest: 894.2886410\tbest: 894.2886410 (220)\ttotal: 31.2s\tremaining: 1m 49s\n",
      "221:\tlearn: 891.2008575\ttest: 894.1547280\tbest: 894.1547280 (221)\ttotal: 31.3s\tremaining: 1m 49s\n",
      "222:\tlearn: 890.8974771\ttest: 893.9317030\tbest: 893.9317030 (222)\ttotal: 31.5s\tremaining: 1m 49s\n",
      "223:\tlearn: 889.9898784\ttest: 892.8881542\tbest: 892.8881542 (223)\ttotal: 31.6s\tremaining: 1m 49s\n",
      "224:\tlearn: 889.4336572\ttest: 892.2961502\tbest: 892.2961502 (224)\ttotal: 31.7s\tremaining: 1m 49s\n",
      "225:\tlearn: 888.9813152\ttest: 891.8852927\tbest: 891.8852927 (225)\ttotal: 31.8s\tremaining: 1m 49s\n",
      "226:\tlearn: 888.5746513\ttest: 891.5060114\tbest: 891.5060114 (226)\ttotal: 31.9s\tremaining: 1m 48s\n",
      "227:\tlearn: 888.0294004\ttest: 890.9776882\tbest: 890.9776882 (227)\ttotal: 32.1s\tremaining: 1m 48s\n",
      "228:\tlearn: 887.5544161\ttest: 890.4899750\tbest: 890.4899750 (228)\ttotal: 32.2s\tremaining: 1m 48s\n",
      "229:\tlearn: 886.9572054\ttest: 889.8841880\tbest: 889.8841880 (229)\ttotal: 32.4s\tremaining: 1m 48s\n",
      "230:\tlearn: 886.5217495\ttest: 889.4767187\tbest: 889.4767187 (230)\ttotal: 32.5s\tremaining: 1m 48s\n",
      "231:\tlearn: 885.9456669\ttest: 888.9833196\tbest: 888.9833196 (231)\ttotal: 32.6s\tremaining: 1m 48s\n",
      "232:\tlearn: 885.6014778\ttest: 888.6830927\tbest: 888.6830927 (232)\ttotal: 32.8s\tremaining: 1m 47s\n",
      "233:\tlearn: 885.1536822\ttest: 888.2140143\tbest: 888.2140143 (233)\ttotal: 32.9s\tremaining: 1m 47s\n",
      "234:\tlearn: 884.8467184\ttest: 887.8678495\tbest: 887.8678495 (234)\ttotal: 33s\tremaining: 1m 47s\n",
      "235:\tlearn: 884.2762949\ttest: 887.3312590\tbest: 887.3312590 (235)\ttotal: 33.1s\tremaining: 1m 47s\n",
      "236:\tlearn: 883.8850023\ttest: 886.9575646\tbest: 886.9575646 (236)\ttotal: 33.3s\tremaining: 1m 47s\n",
      "237:\tlearn: 883.3932015\ttest: 886.4477979\tbest: 886.4477979 (237)\ttotal: 33.4s\tremaining: 1m 47s\n",
      "238:\tlearn: 883.0031444\ttest: 886.1775370\tbest: 886.1775370 (238)\ttotal: 33.6s\tremaining: 1m 46s\n",
      "239:\tlearn: 882.6503025\ttest: 885.8429554\tbest: 885.8429554 (239)\ttotal: 33.7s\tremaining: 1m 46s\n",
      "240:\tlearn: 882.0697305\ttest: 885.4609673\tbest: 885.4609673 (240)\ttotal: 33.9s\tremaining: 1m 46s\n",
      "241:\tlearn: 881.2215205\ttest: 884.6385223\tbest: 884.6385223 (241)\ttotal: 34.1s\tremaining: 1m 46s\n",
      "242:\tlearn: 880.7310967\ttest: 884.0613353\tbest: 884.0613353 (242)\ttotal: 34.3s\tremaining: 1m 46s\n",
      "243:\tlearn: 880.1721844\ttest: 883.4889492\tbest: 883.4889492 (243)\ttotal: 34.4s\tremaining: 1m 46s\n",
      "244:\tlearn: 879.9207283\ttest: 883.2712334\tbest: 883.2712334 (244)\ttotal: 34.5s\tremaining: 1m 46s\n",
      "245:\tlearn: 879.4621383\ttest: 882.9254725\tbest: 882.9254725 (245)\ttotal: 34.7s\tremaining: 1m 46s\n",
      "246:\tlearn: 878.8918165\ttest: 882.4623468\tbest: 882.4623468 (246)\ttotal: 34.8s\tremaining: 1m 46s\n",
      "247:\tlearn: 878.1288844\ttest: 881.6658929\tbest: 881.6658929 (247)\ttotal: 34.9s\tremaining: 1m 45s\n",
      "248:\tlearn: 877.8167286\ttest: 881.3763637\tbest: 881.3763637 (248)\ttotal: 35.1s\tremaining: 1m 45s\n",
      "249:\tlearn: 877.4756987\ttest: 881.0782188\tbest: 881.0782188 (249)\ttotal: 35.2s\tremaining: 1m 45s\n",
      "250:\tlearn: 877.1612718\ttest: 880.7739952\tbest: 880.7739952 (250)\ttotal: 35.3s\tremaining: 1m 45s\n",
      "251:\tlearn: 876.8129867\ttest: 880.4451009\tbest: 880.4451009 (251)\ttotal: 35.5s\tremaining: 1m 45s\n",
      "252:\tlearn: 876.5366885\ttest: 880.1895440\tbest: 880.1895440 (252)\ttotal: 35.6s\tremaining: 1m 45s\n",
      "253:\tlearn: 876.1465932\ttest: 879.7945770\tbest: 879.7945770 (253)\ttotal: 35.7s\tremaining: 1m 44s\n",
      "254:\tlearn: 875.7558561\ttest: 879.5153204\tbest: 879.5153204 (254)\ttotal: 35.9s\tremaining: 1m 44s\n",
      "255:\tlearn: 875.3604901\ttest: 879.1780045\tbest: 879.1780045 (255)\ttotal: 36s\tremaining: 1m 44s\n",
      "256:\tlearn: 874.7263353\ttest: 878.4615095\tbest: 878.4615095 (256)\ttotal: 36.1s\tremaining: 1m 44s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257:\tlearn: 874.3311138\ttest: 878.1574776\tbest: 878.1574776 (257)\ttotal: 36.3s\tremaining: 1m 44s\n",
      "258:\tlearn: 873.6632507\ttest: 877.4841755\tbest: 877.4841755 (258)\ttotal: 36.4s\tremaining: 1m 44s\n",
      "259:\tlearn: 873.2599882\ttest: 877.0360920\tbest: 877.0360920 (259)\ttotal: 36.5s\tremaining: 1m 43s\n",
      "260:\tlearn: 872.9608222\ttest: 876.7659632\tbest: 876.7659632 (260)\ttotal: 36.7s\tremaining: 1m 43s\n",
      "261:\tlearn: 872.4795679\ttest: 876.2472844\tbest: 876.2472844 (261)\ttotal: 36.8s\tremaining: 1m 43s\n",
      "262:\tlearn: 872.0426631\ttest: 875.8059288\tbest: 875.8059288 (262)\ttotal: 37s\tremaining: 1m 43s\n",
      "263:\tlearn: 871.5469866\ttest: 875.3164448\tbest: 875.3164448 (263)\ttotal: 37.1s\tremaining: 1m 43s\n",
      "264:\tlearn: 871.1843606\ttest: 874.9692367\tbest: 874.9692367 (264)\ttotal: 37.2s\tremaining: 1m 43s\n",
      "265:\tlearn: 870.7357239\ttest: 874.4888239\tbest: 874.4888239 (265)\ttotal: 37.3s\tremaining: 1m 43s\n",
      "266:\tlearn: 870.1662678\ttest: 874.0374516\tbest: 874.0374516 (266)\ttotal: 37.5s\tremaining: 1m 43s\n",
      "267:\tlearn: 869.6772620\ttest: 873.5883944\tbest: 873.5883944 (267)\ttotal: 37.7s\tremaining: 1m 42s\n",
      "268:\tlearn: 869.1756968\ttest: 873.0815240\tbest: 873.0815240 (268)\ttotal: 37.8s\tremaining: 1m 42s\n",
      "269:\tlearn: 868.7740870\ttest: 872.8156167\tbest: 872.8156167 (269)\ttotal: 37.9s\tremaining: 1m 42s\n",
      "270:\tlearn: 868.2271062\ttest: 872.2773970\tbest: 872.2773970 (270)\ttotal: 38s\tremaining: 1m 42s\n",
      "271:\tlearn: 867.7889115\ttest: 871.8465946\tbest: 871.8465946 (271)\ttotal: 38.2s\tremaining: 1m 42s\n",
      "272:\tlearn: 867.4166605\ttest: 871.4645776\tbest: 871.4645776 (272)\ttotal: 38.3s\tremaining: 1m 41s\n",
      "273:\tlearn: 866.9352105\ttest: 870.9485040\tbest: 870.9485040 (273)\ttotal: 38.4s\tremaining: 1m 41s\n",
      "274:\tlearn: 866.5947710\ttest: 870.6471444\tbest: 870.6471444 (274)\ttotal: 38.6s\tremaining: 1m 41s\n",
      "275:\tlearn: 866.1458393\ttest: 870.1826010\tbest: 870.1826010 (275)\ttotal: 38.7s\tremaining: 1m 41s\n",
      "276:\tlearn: 865.4975083\ttest: 869.8194805\tbest: 869.8194805 (276)\ttotal: 38.8s\tremaining: 1m 41s\n",
      "277:\tlearn: 865.1373461\ttest: 869.4911021\tbest: 869.4911021 (277)\ttotal: 38.9s\tremaining: 1m 41s\n",
      "278:\tlearn: 864.8793304\ttest: 869.2583922\tbest: 869.2583922 (278)\ttotal: 39s\tremaining: 1m 40s\n",
      "279:\tlearn: 864.6068634\ttest: 869.0300712\tbest: 869.0300712 (279)\ttotal: 39.1s\tremaining: 1m 40s\n",
      "280:\tlearn: 864.0322191\ttest: 868.7438468\tbest: 868.7438468 (280)\ttotal: 39.3s\tremaining: 1m 40s\n",
      "281:\tlearn: 863.7218059\ttest: 868.4580628\tbest: 868.4580628 (281)\ttotal: 39.4s\tremaining: 1m 40s\n",
      "282:\tlearn: 863.1236659\ttest: 868.1404238\tbest: 868.1404238 (282)\ttotal: 39.5s\tremaining: 1m 40s\n",
      "283:\tlearn: 862.6602802\ttest: 867.6968492\tbest: 867.6968492 (283)\ttotal: 39.7s\tremaining: 1m 40s\n",
      "284:\tlearn: 862.2401556\ttest: 867.3228725\tbest: 867.3228725 (284)\ttotal: 39.8s\tremaining: 1m 39s\n",
      "285:\tlearn: 861.8621354\ttest: 866.9514560\tbest: 866.9514560 (285)\ttotal: 40s\tremaining: 1m 39s\n",
      "286:\tlearn: 861.5718308\ttest: 866.7023002\tbest: 866.7023002 (286)\ttotal: 40.1s\tremaining: 1m 39s\n",
      "287:\tlearn: 861.1211773\ttest: 866.2885032\tbest: 866.2885032 (287)\ttotal: 40.2s\tremaining: 1m 39s\n",
      "288:\tlearn: 860.2661879\ttest: 865.4993641\tbest: 865.4993641 (288)\ttotal: 40.4s\tremaining: 1m 39s\n",
      "289:\tlearn: 859.7329146\ttest: 865.0606269\tbest: 865.0606269 (289)\ttotal: 40.5s\tremaining: 1m 39s\n",
      "290:\tlearn: 859.5002828\ttest: 864.8747223\tbest: 864.8747223 (290)\ttotal: 40.6s\tremaining: 1m 39s\n",
      "291:\tlearn: 859.2057114\ttest: 864.5920027\tbest: 864.5920027 (291)\ttotal: 40.8s\tremaining: 1m 38s\n",
      "292:\tlearn: 858.9437377\ttest: 864.3716855\tbest: 864.3716855 (292)\ttotal: 40.9s\tremaining: 1m 38s\n",
      "293:\tlearn: 858.6194368\ttest: 864.0506667\tbest: 864.0506667 (293)\ttotal: 41s\tremaining: 1m 38s\n",
      "294:\tlearn: 858.3905401\ttest: 863.8169356\tbest: 863.8169356 (294)\ttotal: 41.2s\tremaining: 1m 38s\n",
      "295:\tlearn: 858.1930217\ttest: 863.6274723\tbest: 863.6274723 (295)\ttotal: 41.3s\tremaining: 1m 38s\n",
      "296:\tlearn: 857.4849101\ttest: 862.7996727\tbest: 862.7996727 (296)\ttotal: 41.5s\tremaining: 1m 38s\n",
      "297:\tlearn: 857.1020634\ttest: 862.4388881\tbest: 862.4388881 (297)\ttotal: 41.6s\tremaining: 1m 38s\n",
      "298:\tlearn: 856.6958453\ttest: 862.0567407\tbest: 862.0567407 (298)\ttotal: 41.8s\tremaining: 1m 37s\n",
      "299:\tlearn: 856.3587951\ttest: 861.7675862\tbest: 861.7675862 (299)\ttotal: 41.9s\tremaining: 1m 37s\n",
      "300:\tlearn: 856.0559347\ttest: 861.4885140\tbest: 861.4885140 (300)\ttotal: 42s\tremaining: 1m 37s\n",
      "301:\tlearn: 855.4551853\ttest: 860.7629042\tbest: 860.7629042 (301)\ttotal: 42.2s\tremaining: 1m 37s\n",
      "302:\tlearn: 855.1686832\ttest: 860.4973140\tbest: 860.4973140 (302)\ttotal: 42.3s\tremaining: 1m 37s\n",
      "303:\tlearn: 854.7532285\ttest: 860.0745129\tbest: 860.0745129 (303)\ttotal: 42.4s\tremaining: 1m 37s\n",
      "304:\tlearn: 854.4297797\ttest: 859.7408806\tbest: 859.7408806 (304)\ttotal: 42.6s\tremaining: 1m 37s\n",
      "305:\tlearn: 854.2502004\ttest: 859.5540194\tbest: 859.5540194 (305)\ttotal: 42.7s\tremaining: 1m 36s\n",
      "306:\tlearn: 853.7832054\ttest: 859.0987919\tbest: 859.0987919 (306)\ttotal: 42.9s\tremaining: 1m 36s\n",
      "307:\tlearn: 853.5350846\ttest: 858.8154244\tbest: 858.8154244 (307)\ttotal: 43s\tremaining: 1m 36s\n",
      "308:\tlearn: 852.9431375\ttest: 858.2919093\tbest: 858.2919093 (308)\ttotal: 43.1s\tremaining: 1m 36s\n",
      "309:\tlearn: 852.6623327\ttest: 857.9758401\tbest: 857.9758401 (309)\ttotal: 43.2s\tremaining: 1m 36s\n",
      "310:\tlearn: 852.4724057\ttest: 857.7955726\tbest: 857.7955726 (310)\ttotal: 43.3s\tremaining: 1m 35s\n",
      "311:\tlearn: 852.2466883\ttest: 857.5999300\tbest: 857.5999300 (311)\ttotal: 43.5s\tremaining: 1m 35s\n",
      "312:\tlearn: 851.9849553\ttest: 857.3246297\tbest: 857.3246297 (312)\ttotal: 43.6s\tremaining: 1m 35s\n",
      "313:\tlearn: 851.4856816\ttest: 856.7774540\tbest: 856.7774540 (313)\ttotal: 43.7s\tremaining: 1m 35s\n",
      "314:\tlearn: 851.1618479\ttest: 856.4641883\tbest: 856.4641883 (314)\ttotal: 43.8s\tremaining: 1m 35s\n",
      "315:\tlearn: 850.8369759\ttest: 856.1411623\tbest: 856.1411623 (315)\ttotal: 44s\tremaining: 1m 35s\n",
      "316:\tlearn: 850.4193746\ttest: 855.6799990\tbest: 855.6799990 (316)\ttotal: 44.1s\tremaining: 1m 34s\n",
      "317:\tlearn: 849.8810507\ttest: 855.2317133\tbest: 855.2317133 (317)\ttotal: 44.2s\tremaining: 1m 34s\n",
      "318:\tlearn: 849.6580632\ttest: 855.0206880\tbest: 855.0206880 (318)\ttotal: 44.4s\tremaining: 1m 34s\n",
      "319:\tlearn: 849.1999559\ttest: 854.5002165\tbest: 854.5002165 (319)\ttotal: 44.5s\tremaining: 1m 34s\n",
      "320:\tlearn: 848.8946704\ttest: 854.2903646\tbest: 854.2903646 (320)\ttotal: 44.6s\tremaining: 1m 34s\n",
      "321:\tlearn: 848.6639740\ttest: 854.1006241\tbest: 854.1006241 (321)\ttotal: 44.7s\tremaining: 1m 34s\n",
      "322:\tlearn: 848.3270449\ttest: 853.7399063\tbest: 853.7399063 (322)\ttotal: 44.9s\tremaining: 1m 34s\n",
      "323:\tlearn: 848.0160387\ttest: 853.4256161\tbest: 853.4256161 (323)\ttotal: 45s\tremaining: 1m 33s\n",
      "324:\tlearn: 847.7402453\ttest: 853.1830852\tbest: 853.1830852 (324)\ttotal: 45.1s\tremaining: 1m 33s\n",
      "325:\tlearn: 847.4349035\ttest: 852.9648667\tbest: 852.9648667 (325)\ttotal: 45.3s\tremaining: 1m 33s\n",
      "326:\tlearn: 847.0578352\ttest: 852.6058051\tbest: 852.6058051 (326)\ttotal: 45.4s\tremaining: 1m 33s\n",
      "327:\tlearn: 846.7780709\ttest: 852.3252588\tbest: 852.3252588 (327)\ttotal: 45.5s\tremaining: 1m 33s\n",
      "328:\tlearn: 846.4959539\ttest: 852.0015794\tbest: 852.0015794 (328)\ttotal: 45.6s\tremaining: 1m 33s\n",
      "329:\tlearn: 846.1741136\ttest: 851.7469807\tbest: 851.7469807 (329)\ttotal: 45.8s\tremaining: 1m 32s\n",
      "330:\tlearn: 846.0196718\ttest: 851.5787105\tbest: 851.5787105 (330)\ttotal: 45.9s\tremaining: 1m 32s\n",
      "331:\tlearn: 845.6797702\ttest: 851.3577140\tbest: 851.3577140 (331)\ttotal: 46s\tremaining: 1m 32s\n",
      "332:\tlearn: 845.3484330\ttest: 850.9413201\tbest: 850.9413201 (332)\ttotal: 46.2s\tremaining: 1m 32s\n",
      "333:\tlearn: 845.0974407\ttest: 850.7128534\tbest: 850.7128534 (333)\ttotal: 46.3s\tremaining: 1m 32s\n",
      "334:\tlearn: 844.8428855\ttest: 850.4316131\tbest: 850.4316131 (334)\ttotal: 46.4s\tremaining: 1m 32s\n",
      "335:\tlearn: 844.1965665\ttest: 849.7838270\tbest: 849.7838270 (335)\ttotal: 46.6s\tremaining: 1m 32s\n",
      "336:\tlearn: 843.8542708\ttest: 849.4781419\tbest: 849.4781419 (336)\ttotal: 46.7s\tremaining: 1m 31s\n",
      "337:\tlearn: 843.5507138\ttest: 849.1828131\tbest: 849.1828131 (337)\ttotal: 46.8s\tremaining: 1m 31s\n",
      "338:\tlearn: 843.2714303\ttest: 848.9436489\tbest: 848.9436489 (338)\ttotal: 47s\tremaining: 1m 31s\n",
      "339:\tlearn: 842.7949631\ttest: 848.3621956\tbest: 848.3621956 (339)\ttotal: 47.1s\tremaining: 1m 31s\n",
      "340:\tlearn: 842.3201826\ttest: 847.9319492\tbest: 847.9319492 (340)\ttotal: 47.2s\tremaining: 1m 31s\n",
      "341:\tlearn: 842.0427632\ttest: 847.6379996\tbest: 847.6379996 (341)\ttotal: 47.4s\tremaining: 1m 31s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342:\tlearn: 841.8037734\ttest: 847.4341481\tbest: 847.4341481 (342)\ttotal: 47.5s\tremaining: 1m 30s\n",
      "343:\tlearn: 841.3639682\ttest: 847.0641318\tbest: 847.0641318 (343)\ttotal: 47.6s\tremaining: 1m 30s\n",
      "344:\tlearn: 841.0353265\ttest: 846.7478646\tbest: 846.7478646 (344)\ttotal: 47.7s\tremaining: 1m 30s\n",
      "345:\tlearn: 840.7538412\ttest: 846.6106672\tbest: 846.6106672 (345)\ttotal: 47.9s\tremaining: 1m 30s\n",
      "346:\tlearn: 840.4643111\ttest: 846.3260913\tbest: 846.3260913 (346)\ttotal: 48s\tremaining: 1m 30s\n",
      "347:\tlearn: 840.1166967\ttest: 845.9827943\tbest: 845.9827943 (347)\ttotal: 48.2s\tremaining: 1m 30s\n",
      "348:\tlearn: 839.7994322\ttest: 845.6296695\tbest: 845.6296695 (348)\ttotal: 48.3s\tremaining: 1m 30s\n",
      "349:\tlearn: 839.2160093\ttest: 845.0713892\tbest: 845.0713892 (349)\ttotal: 48.5s\tremaining: 1m 30s\n",
      "350:\tlearn: 838.7112064\ttest: 844.5988086\tbest: 844.5988086 (350)\ttotal: 48.6s\tremaining: 1m 29s\n",
      "351:\tlearn: 838.4212541\ttest: 844.3160165\tbest: 844.3160165 (351)\ttotal: 48.7s\tremaining: 1m 29s\n",
      "352:\tlearn: 838.1880185\ttest: 844.1957142\tbest: 844.1957142 (352)\ttotal: 48.9s\tremaining: 1m 29s\n",
      "353:\tlearn: 837.7941450\ttest: 843.8417104\tbest: 843.8417104 (353)\ttotal: 49s\tremaining: 1m 29s\n",
      "354:\tlearn: 837.5275263\ttest: 843.5816392\tbest: 843.5816392 (354)\ttotal: 49.1s\tremaining: 1m 29s\n",
      "355:\tlearn: 837.1396570\ttest: 843.2580255\tbest: 843.2580255 (355)\ttotal: 49.3s\tremaining: 1m 29s\n",
      "356:\tlearn: 836.8018496\ttest: 843.0021094\tbest: 843.0021094 (356)\ttotal: 49.4s\tremaining: 1m 28s\n",
      "357:\tlearn: 836.3946214\ttest: 842.6244205\tbest: 842.6244205 (357)\ttotal: 49.5s\tremaining: 1m 28s\n",
      "358:\tlearn: 836.1963460\ttest: 842.5600127\tbest: 842.5600127 (358)\ttotal: 49.7s\tremaining: 1m 28s\n",
      "359:\tlearn: 835.9960232\ttest: 842.3353577\tbest: 842.3353577 (359)\ttotal: 49.8s\tremaining: 1m 28s\n",
      "360:\tlearn: 835.8070339\ttest: 842.1505375\tbest: 842.1505375 (360)\ttotal: 50s\tremaining: 1m 28s\n",
      "361:\tlearn: 835.4773638\ttest: 841.7937406\tbest: 841.7937406 (361)\ttotal: 50.1s\tremaining: 1m 28s\n",
      "362:\tlearn: 834.9043116\ttest: 841.1801399\tbest: 841.1801399 (362)\ttotal: 50.3s\tremaining: 1m 28s\n",
      "363:\tlearn: 834.6519192\ttest: 840.9407766\tbest: 840.9407766 (363)\ttotal: 50.4s\tremaining: 1m 28s\n",
      "364:\tlearn: 834.4200275\ttest: 840.7687506\tbest: 840.7687506 (364)\ttotal: 50.5s\tremaining: 1m 27s\n",
      "365:\tlearn: 834.2178027\ttest: 840.5916002\tbest: 840.5916002 (365)\ttotal: 50.6s\tremaining: 1m 27s\n",
      "366:\tlearn: 833.9329276\ttest: 840.2968468\tbest: 840.2968468 (366)\ttotal: 50.8s\tremaining: 1m 27s\n",
      "367:\tlearn: 833.7339863\ttest: 840.1043258\tbest: 840.1043258 (367)\ttotal: 50.9s\tremaining: 1m 27s\n",
      "368:\tlearn: 833.3631124\ttest: 839.7159827\tbest: 839.7159827 (368)\ttotal: 51s\tremaining: 1m 27s\n",
      "369:\tlearn: 833.1117559\ttest: 839.4501046\tbest: 839.4501046 (369)\ttotal: 51.2s\tremaining: 1m 27s\n",
      "370:\tlearn: 832.8324673\ttest: 839.3228168\tbest: 839.3228168 (370)\ttotal: 51.3s\tremaining: 1m 27s\n",
      "371:\tlearn: 832.4494918\ttest: 838.9028093\tbest: 838.9028093 (371)\ttotal: 51.4s\tremaining: 1m 26s\n",
      "372:\tlearn: 832.2840253\ttest: 838.7414667\tbest: 838.7414667 (372)\ttotal: 51.6s\tremaining: 1m 26s\n",
      "373:\tlearn: 832.0073692\ttest: 838.4298379\tbest: 838.4298379 (373)\ttotal: 51.7s\tremaining: 1m 26s\n",
      "374:\tlearn: 831.6935120\ttest: 838.1497569\tbest: 838.1497569 (374)\ttotal: 51.8s\tremaining: 1m 26s\n",
      "375:\tlearn: 831.4987515\ttest: 838.0072821\tbest: 838.0072821 (375)\ttotal: 52s\tremaining: 1m 26s\n",
      "376:\tlearn: 831.0637395\ttest: 837.5699167\tbest: 837.5699167 (376)\ttotal: 52.1s\tremaining: 1m 26s\n",
      "377:\tlearn: 830.7640285\ttest: 837.3198131\tbest: 837.3198131 (377)\ttotal: 52.3s\tremaining: 1m 26s\n",
      "378:\tlearn: 830.5782217\ttest: 837.1396857\tbest: 837.1396857 (378)\ttotal: 52.4s\tremaining: 1m 25s\n",
      "379:\tlearn: 830.2300182\ttest: 836.7186643\tbest: 836.7186643 (379)\ttotal: 52.5s\tremaining: 1m 25s\n",
      "380:\tlearn: 829.9956759\ttest: 836.4939534\tbest: 836.4939534 (380)\ttotal: 52.6s\tremaining: 1m 25s\n",
      "381:\tlearn: 829.5683779\ttest: 836.0441488\tbest: 836.0441488 (381)\ttotal: 52.8s\tremaining: 1m 25s\n",
      "382:\tlearn: 829.1061020\ttest: 835.6265779\tbest: 835.6265779 (382)\ttotal: 52.9s\tremaining: 1m 25s\n",
      "383:\tlearn: 828.8207052\ttest: 835.4427678\tbest: 835.4427678 (383)\ttotal: 53.1s\tremaining: 1m 25s\n",
      "384:\tlearn: 828.5672321\ttest: 835.2363525\tbest: 835.2363525 (384)\ttotal: 53.2s\tremaining: 1m 24s\n",
      "385:\tlearn: 828.2371984\ttest: 834.9601794\tbest: 834.9601794 (385)\ttotal: 53.3s\tremaining: 1m 24s\n",
      "386:\tlearn: 827.7910609\ttest: 834.5257674\tbest: 834.5257674 (386)\ttotal: 53.4s\tremaining: 1m 24s\n",
      "387:\tlearn: 827.5846602\ttest: 834.4109891\tbest: 834.4109891 (387)\ttotal: 53.6s\tremaining: 1m 24s\n",
      "388:\tlearn: 827.3155170\ttest: 834.1616835\tbest: 834.1616835 (388)\ttotal: 53.7s\tremaining: 1m 24s\n",
      "389:\tlearn: 826.8292621\ttest: 833.6220116\tbest: 833.6220116 (389)\ttotal: 53.8s\tremaining: 1m 24s\n",
      "390:\tlearn: 826.6694930\ttest: 833.5105322\tbest: 833.5105322 (390)\ttotal: 54s\tremaining: 1m 24s\n",
      "391:\tlearn: 826.3984780\ttest: 833.2640937\tbest: 833.2640937 (391)\ttotal: 54.1s\tremaining: 1m 23s\n",
      "392:\tlearn: 826.1816149\ttest: 833.1108774\tbest: 833.1108774 (392)\ttotal: 54.3s\tremaining: 1m 23s\n",
      "393:\tlearn: 826.0038989\ttest: 833.0476071\tbest: 833.0476071 (393)\ttotal: 54.4s\tremaining: 1m 23s\n",
      "394:\tlearn: 825.5461622\ttest: 832.5993004\tbest: 832.5993004 (394)\ttotal: 54.5s\tremaining: 1m 23s\n",
      "395:\tlearn: 825.3500835\ttest: 832.4753984\tbest: 832.4753984 (395)\ttotal: 54.6s\tremaining: 1m 23s\n",
      "396:\tlearn: 824.9940875\ttest: 832.1738747\tbest: 832.1738747 (396)\ttotal: 54.8s\tremaining: 1m 23s\n",
      "397:\tlearn: 824.6349514\ttest: 831.8092445\tbest: 831.8092445 (397)\ttotal: 54.9s\tremaining: 1m 23s\n",
      "398:\tlearn: 824.5073578\ttest: 831.7573718\tbest: 831.7573718 (398)\ttotal: 55s\tremaining: 1m 22s\n",
      "399:\tlearn: 824.3365974\ttest: 831.5940861\tbest: 831.5940861 (399)\ttotal: 55.2s\tremaining: 1m 22s\n",
      "400:\tlearn: 823.9706662\ttest: 831.2630047\tbest: 831.2630047 (400)\ttotal: 55.3s\tremaining: 1m 22s\n",
      "401:\tlearn: 823.7376897\ttest: 831.1098918\tbest: 831.1098918 (401)\ttotal: 55.4s\tremaining: 1m 22s\n",
      "402:\tlearn: 823.4241830\ttest: 830.8126288\tbest: 830.8126288 (402)\ttotal: 55.6s\tremaining: 1m 22s\n",
      "403:\tlearn: 823.1364198\ttest: 830.5673597\tbest: 830.5673597 (403)\ttotal: 55.7s\tremaining: 1m 22s\n",
      "404:\tlearn: 822.7952987\ttest: 830.2348356\tbest: 830.2348356 (404)\ttotal: 55.8s\tremaining: 1m 22s\n",
      "405:\tlearn: 822.4651575\ttest: 829.8687794\tbest: 829.8687794 (405)\ttotal: 56s\tremaining: 1m 21s\n",
      "406:\tlearn: 822.3705368\ttest: 829.7490678\tbest: 829.7490678 (406)\ttotal: 56.1s\tremaining: 1m 21s\n",
      "407:\tlearn: 822.0354037\ttest: 829.4780710\tbest: 829.4780710 (407)\ttotal: 56.3s\tremaining: 1m 21s\n",
      "408:\tlearn: 821.6729928\ttest: 829.1157462\tbest: 829.1157462 (408)\ttotal: 56.4s\tremaining: 1m 21s\n",
      "409:\tlearn: 821.3452315\ttest: 828.7635609\tbest: 828.7635609 (409)\ttotal: 56.6s\tremaining: 1m 21s\n",
      "410:\tlearn: 821.0831921\ttest: 828.5087256\tbest: 828.5087256 (410)\ttotal: 56.7s\tremaining: 1m 21s\n",
      "411:\tlearn: 820.7832026\ttest: 828.2216674\tbest: 828.2216674 (411)\ttotal: 56.8s\tremaining: 1m 21s\n",
      "412:\tlearn: 820.5525823\ttest: 828.0038635\tbest: 828.0038635 (412)\ttotal: 57s\tremaining: 1m 21s\n",
      "413:\tlearn: 820.2982582\ttest: 827.7778705\tbest: 827.7778705 (413)\ttotal: 57.2s\tremaining: 1m 20s\n",
      "414:\tlearn: 820.1362183\ttest: 827.6395619\tbest: 827.6395619 (414)\ttotal: 57.3s\tremaining: 1m 20s\n",
      "415:\tlearn: 819.7879770\ttest: 827.3057625\tbest: 827.3057625 (415)\ttotal: 57.5s\tremaining: 1m 20s\n",
      "416:\tlearn: 819.5298224\ttest: 827.0112597\tbest: 827.0112597 (416)\ttotal: 57.6s\tremaining: 1m 20s\n",
      "417:\tlearn: 819.2384551\ttest: 826.6838648\tbest: 826.6838648 (417)\ttotal: 57.7s\tremaining: 1m 20s\n",
      "418:\tlearn: 819.0158667\ttest: 826.4726929\tbest: 826.4726929 (418)\ttotal: 57.9s\tremaining: 1m 20s\n",
      "419:\tlearn: 818.8536237\ttest: 826.3054397\tbest: 826.3054397 (419)\ttotal: 58s\tremaining: 1m 20s\n",
      "420:\tlearn: 818.5654322\ttest: 826.0402186\tbest: 826.0402186 (420)\ttotal: 58.1s\tremaining: 1m 19s\n",
      "421:\tlearn: 818.3626179\ttest: 825.8316229\tbest: 825.8316229 (421)\ttotal: 58.3s\tremaining: 1m 19s\n",
      "422:\tlearn: 818.1052498\ttest: 825.5995009\tbest: 825.5995009 (422)\ttotal: 58.4s\tremaining: 1m 19s\n",
      "423:\tlearn: 817.7095960\ttest: 825.2134166\tbest: 825.2134166 (423)\ttotal: 58.6s\tremaining: 1m 19s\n",
      "424:\tlearn: 817.4338022\ttest: 824.9798536\tbest: 824.9798536 (424)\ttotal: 58.7s\tremaining: 1m 19s\n",
      "425:\tlearn: 817.1640186\ttest: 824.6996564\tbest: 824.6996564 (425)\ttotal: 58.9s\tremaining: 1m 19s\n",
      "426:\tlearn: 816.8527667\ttest: 824.3845681\tbest: 824.3845681 (426)\ttotal: 59s\tremaining: 1m 19s\n",
      "427:\tlearn: 816.6699385\ttest: 824.2018507\tbest: 824.2018507 (427)\ttotal: 59.2s\tremaining: 1m 19s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "428:\tlearn: 816.2873786\ttest: 823.8888011\tbest: 823.8888011 (428)\ttotal: 59.3s\tremaining: 1m 18s\n",
      "429:\tlearn: 816.1604170\ttest: 823.7607158\tbest: 823.7607158 (429)\ttotal: 59.5s\tremaining: 1m 18s\n",
      "430:\tlearn: 815.9126332\ttest: 823.5179411\tbest: 823.5179411 (430)\ttotal: 59.6s\tremaining: 1m 18s\n",
      "431:\tlearn: 815.5699358\ttest: 823.1974200\tbest: 823.1974200 (431)\ttotal: 59.7s\tremaining: 1m 18s\n",
      "432:\tlearn: 815.3549979\ttest: 823.0071337\tbest: 823.0071337 (432)\ttotal: 59.8s\tremaining: 1m 18s\n",
      "433:\tlearn: 815.0430393\ttest: 822.7062828\tbest: 822.7062828 (433)\ttotal: 60s\tremaining: 1m 18s\n",
      "434:\tlearn: 814.7131002\ttest: 822.4352942\tbest: 822.4352942 (434)\ttotal: 1m\tremaining: 1m 18s\n",
      "435:\tlearn: 814.5762945\ttest: 822.2884089\tbest: 822.2884089 (435)\ttotal: 1m\tremaining: 1m 18s\n",
      "436:\tlearn: 814.3074311\ttest: 822.0862931\tbest: 822.0862931 (436)\ttotal: 1m\tremaining: 1m 17s\n",
      "437:\tlearn: 814.0510621\ttest: 821.8286071\tbest: 821.8286071 (437)\ttotal: 1m\tremaining: 1m 17s\n",
      "438:\tlearn: 813.9263689\ttest: 821.7018915\tbest: 821.7018915 (438)\ttotal: 1m\tremaining: 1m 17s\n",
      "439:\tlearn: 813.4978248\ttest: 821.3001834\tbest: 821.3001834 (439)\ttotal: 1m\tremaining: 1m 17s\n",
      "440:\tlearn: 813.2701643\ttest: 821.1183970\tbest: 821.1183970 (440)\ttotal: 1m\tremaining: 1m 17s\n",
      "441:\tlearn: 812.9622296\ttest: 820.8210587\tbest: 820.8210587 (441)\ttotal: 1m 1s\tremaining: 1m 17s\n",
      "442:\tlearn: 812.6567658\ttest: 820.5215758\tbest: 820.5215758 (442)\ttotal: 1m 1s\tremaining: 1m 17s\n",
      "443:\tlearn: 812.2642876\ttest: 820.1518063\tbest: 820.1518063 (443)\ttotal: 1m 1s\tremaining: 1m 16s\n",
      "444:\tlearn: 812.1270832\ttest: 820.0410829\tbest: 820.0410829 (444)\ttotal: 1m 1s\tremaining: 1m 16s\n",
      "445:\tlearn: 811.8673215\ttest: 819.7937721\tbest: 819.7937721 (445)\ttotal: 1m 1s\tremaining: 1m 16s\n",
      "446:\tlearn: 811.5734111\ttest: 819.5925037\tbest: 819.5925037 (446)\ttotal: 1m 1s\tremaining: 1m 16s\n",
      "447:\tlearn: 811.4303875\ttest: 819.4348375\tbest: 819.4348375 (447)\ttotal: 1m 1s\tremaining: 1m 16s\n",
      "448:\tlearn: 811.3019542\ttest: 819.3196095\tbest: 819.3196095 (448)\ttotal: 1m 2s\tremaining: 1m 16s\n",
      "449:\tlearn: 811.0266458\ttest: 819.0484422\tbest: 819.0484422 (449)\ttotal: 1m 2s\tremaining: 1m 16s\n",
      "450:\tlearn: 810.7447082\ttest: 818.7632117\tbest: 818.7632117 (450)\ttotal: 1m 2s\tremaining: 1m 15s\n",
      "451:\tlearn: 810.4407404\ttest: 818.5066938\tbest: 818.5066938 (451)\ttotal: 1m 2s\tremaining: 1m 15s\n",
      "452:\tlearn: 810.2966434\ttest: 818.4517542\tbest: 818.4517542 (452)\ttotal: 1m 2s\tremaining: 1m 15s\n",
      "453:\tlearn: 810.1490769\ttest: 818.3136522\tbest: 818.3136522 (453)\ttotal: 1m 2s\tremaining: 1m 15s\n",
      "454:\tlearn: 809.9329560\ttest: 818.1173139\tbest: 818.1173139 (454)\ttotal: 1m 2s\tremaining: 1m 15s\n",
      "455:\tlearn: 809.7097503\ttest: 817.8448999\tbest: 817.8448999 (455)\ttotal: 1m 2s\tremaining: 1m 15s\n",
      "456:\tlearn: 809.5262841\ttest: 817.6502400\tbest: 817.6502400 (456)\ttotal: 1m 3s\tremaining: 1m 15s\n",
      "457:\tlearn: 809.2854900\ttest: 817.4219768\tbest: 817.4219768 (457)\ttotal: 1m 3s\tremaining: 1m 14s\n",
      "458:\tlearn: 809.1346870\ttest: 817.2786371\tbest: 817.2786371 (458)\ttotal: 1m 3s\tremaining: 1m 14s\n",
      "459:\tlearn: 808.9384165\ttest: 817.1073073\tbest: 817.1073073 (459)\ttotal: 1m 3s\tremaining: 1m 14s\n",
      "460:\tlearn: 808.7108817\ttest: 816.8506814\tbest: 816.8506814 (460)\ttotal: 1m 3s\tremaining: 1m 14s\n",
      "461:\tlearn: 808.5995562\ttest: 816.7700893\tbest: 816.7700893 (461)\ttotal: 1m 3s\tremaining: 1m 14s\n",
      "462:\tlearn: 808.3840347\ttest: 816.5283818\tbest: 816.5283818 (462)\ttotal: 1m 4s\tremaining: 1m 14s\n",
      "463:\tlearn: 808.2106860\ttest: 816.3537671\tbest: 816.3537671 (463)\ttotal: 1m 4s\tremaining: 1m 14s\n",
      "464:\tlearn: 807.9583888\ttest: 816.0557917\tbest: 816.0557917 (464)\ttotal: 1m 4s\tremaining: 1m 13s\n",
      "465:\tlearn: 807.7564337\ttest: 815.8729045\tbest: 815.8729045 (465)\ttotal: 1m 4s\tremaining: 1m 13s\n",
      "466:\tlearn: 807.4086494\ttest: 815.7142821\tbest: 815.7142821 (466)\ttotal: 1m 4s\tremaining: 1m 13s\n",
      "467:\tlearn: 807.2520944\ttest: 815.5686841\tbest: 815.5686841 (467)\ttotal: 1m 4s\tremaining: 1m 13s\n",
      "468:\tlearn: 807.0807605\ttest: 815.4188168\tbest: 815.4188168 (468)\ttotal: 1m 4s\tremaining: 1m 13s\n",
      "469:\tlearn: 806.8968015\ttest: 815.2319759\tbest: 815.2319759 (469)\ttotal: 1m 4s\tremaining: 1m 13s\n",
      "470:\tlearn: 806.7170262\ttest: 815.0559570\tbest: 815.0559570 (470)\ttotal: 1m 5s\tremaining: 1m 13s\n",
      "471:\tlearn: 806.4745872\ttest: 814.7880429\tbest: 814.7880429 (471)\ttotal: 1m 5s\tremaining: 1m 12s\n",
      "472:\tlearn: 806.3171339\ttest: 814.6647558\tbest: 814.6647558 (472)\ttotal: 1m 5s\tremaining: 1m 12s\n",
      "473:\tlearn: 806.1636676\ttest: 814.5487212\tbest: 814.5487212 (473)\ttotal: 1m 5s\tremaining: 1m 12s\n",
      "474:\tlearn: 805.8998664\ttest: 814.5117224\tbest: 814.5117224 (474)\ttotal: 1m 5s\tremaining: 1m 12s\n",
      "475:\tlearn: 805.7679826\ttest: 814.3772331\tbest: 814.3772331 (475)\ttotal: 1m 5s\tremaining: 1m 12s\n",
      "476:\tlearn: 805.6466537\ttest: 814.2592009\tbest: 814.2592009 (476)\ttotal: 1m 5s\tremaining: 1m 12s\n",
      "477:\tlearn: 805.4583350\ttest: 814.0170037\tbest: 814.0170037 (477)\ttotal: 1m 6s\tremaining: 1m 12s\n",
      "478:\tlearn: 805.2393303\ttest: 813.8134572\tbest: 813.8134572 (478)\ttotal: 1m 6s\tremaining: 1m 11s\n",
      "479:\tlearn: 804.9674419\ttest: 813.5435252\tbest: 813.5435252 (479)\ttotal: 1m 6s\tremaining: 1m 11s\n",
      "480:\tlearn: 804.6218124\ttest: 813.1884666\tbest: 813.1884666 (480)\ttotal: 1m 6s\tremaining: 1m 11s\n",
      "481:\tlearn: 804.1966014\ttest: 812.7681888\tbest: 812.7681888 (481)\ttotal: 1m 6s\tremaining: 1m 11s\n",
      "482:\tlearn: 804.0259279\ttest: 812.5866638\tbest: 812.5866638 (482)\ttotal: 1m 6s\tremaining: 1m 11s\n",
      "483:\tlearn: 803.7052067\ttest: 812.2595452\tbest: 812.2595452 (483)\ttotal: 1m 6s\tremaining: 1m 11s\n",
      "484:\tlearn: 803.4189469\ttest: 812.0019572\tbest: 812.0019572 (484)\ttotal: 1m 6s\tremaining: 1m 11s\n",
      "485:\tlearn: 803.2200498\ttest: 811.8368904\tbest: 811.8368904 (485)\ttotal: 1m 7s\tremaining: 1m 10s\n",
      "486:\tlearn: 803.0856084\ttest: 811.7594529\tbest: 811.7594529 (486)\ttotal: 1m 7s\tremaining: 1m 10s\n",
      "487:\tlearn: 802.9821986\ttest: 811.6713092\tbest: 811.6713092 (487)\ttotal: 1m 7s\tremaining: 1m 10s\n",
      "488:\tlearn: 802.7562381\ttest: 811.4057878\tbest: 811.4057878 (488)\ttotal: 1m 7s\tremaining: 1m 10s\n",
      "489:\tlearn: 802.5319921\ttest: 811.2077103\tbest: 811.2077103 (489)\ttotal: 1m 7s\tremaining: 1m 10s\n",
      "490:\tlearn: 802.1656498\ttest: 810.9693222\tbest: 810.9693222 (490)\ttotal: 1m 7s\tremaining: 1m 10s\n",
      "491:\tlearn: 801.9116590\ttest: 810.7254069\tbest: 810.7254069 (491)\ttotal: 1m 7s\tremaining: 1m 10s\n",
      "492:\tlearn: 801.7052067\ttest: 810.5047843\tbest: 810.5047843 (492)\ttotal: 1m 8s\tremaining: 1m 9s\n",
      "493:\tlearn: 801.3909912\ttest: 810.1477259\tbest: 810.1477259 (493)\ttotal: 1m 8s\tremaining: 1m 9s\n",
      "494:\tlearn: 801.1910635\ttest: 809.9741595\tbest: 809.9741595 (494)\ttotal: 1m 8s\tremaining: 1m 9s\n",
      "495:\tlearn: 800.9436626\ttest: 809.7336458\tbest: 809.7336458 (495)\ttotal: 1m 8s\tremaining: 1m 9s\n",
      "496:\tlearn: 800.5541645\ttest: 809.4567023\tbest: 809.4567023 (496)\ttotal: 1m 8s\tremaining: 1m 9s\n",
      "497:\tlearn: 800.3785200\ttest: 809.2958082\tbest: 809.2958082 (497)\ttotal: 1m 8s\tremaining: 1m 9s\n",
      "498:\tlearn: 800.0471510\ttest: 808.9703502\tbest: 808.9703502 (498)\ttotal: 1m 8s\tremaining: 1m 9s\n",
      "499:\tlearn: 799.5898928\ttest: 808.4891867\tbest: 808.4891867 (499)\ttotal: 1m 9s\tremaining: 1m 9s\n",
      "500:\tlearn: 799.3788028\ttest: 808.2749508\tbest: 808.2749508 (500)\ttotal: 1m 9s\tremaining: 1m 8s\n",
      "501:\tlearn: 799.2179386\ttest: 808.1335156\tbest: 808.1335156 (501)\ttotal: 1m 9s\tremaining: 1m 8s\n",
      "502:\tlearn: 798.8621631\ttest: 807.7856013\tbest: 807.7856013 (502)\ttotal: 1m 9s\tremaining: 1m 8s\n",
      "503:\tlearn: 798.6291309\ttest: 807.5865915\tbest: 807.5865915 (503)\ttotal: 1m 9s\tremaining: 1m 8s\n",
      "504:\tlearn: 798.4429335\ttest: 807.4120587\tbest: 807.4120587 (504)\ttotal: 1m 9s\tremaining: 1m 8s\n",
      "505:\tlearn: 798.3255306\ttest: 807.3278961\tbest: 807.3278961 (505)\ttotal: 1m 9s\tremaining: 1m 8s\n",
      "506:\tlearn: 798.0980042\ttest: 807.1038727\tbest: 807.1038727 (506)\ttotal: 1m 9s\tremaining: 1m 8s\n",
      "507:\tlearn: 797.8589935\ttest: 806.9184517\tbest: 806.9184517 (507)\ttotal: 1m 10s\tremaining: 1m 7s\n",
      "508:\tlearn: 797.6351475\ttest: 806.7300221\tbest: 806.7300221 (508)\ttotal: 1m 10s\tremaining: 1m 7s\n",
      "509:\tlearn: 797.4620319\ttest: 806.5715004\tbest: 806.5715004 (509)\ttotal: 1m 10s\tremaining: 1m 7s\n",
      "510:\tlearn: 797.2800645\ttest: 806.4284916\tbest: 806.4284916 (510)\ttotal: 1m 10s\tremaining: 1m 7s\n",
      "511:\tlearn: 797.1043934\ttest: 806.3049405\tbest: 806.3049405 (511)\ttotal: 1m 10s\tremaining: 1m 7s\n",
      "512:\tlearn: 796.9370603\ttest: 806.1733851\tbest: 806.1733851 (512)\ttotal: 1m 10s\tremaining: 1m 7s\n",
      "513:\tlearn: 796.7353267\ttest: 805.9812048\tbest: 805.9812048 (513)\ttotal: 1m 10s\tremaining: 1m 7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514:\tlearn: 796.5798011\ttest: 805.8102595\tbest: 805.8102595 (514)\ttotal: 1m 11s\tremaining: 1m 6s\n",
      "515:\tlearn: 796.2968598\ttest: 805.5795982\tbest: 805.5795982 (515)\ttotal: 1m 11s\tremaining: 1m 6s\n",
      "516:\tlearn: 796.1196447\ttest: 805.4365749\tbest: 805.4365749 (516)\ttotal: 1m 11s\tremaining: 1m 6s\n",
      "517:\tlearn: 795.8394805\ttest: 805.1294504\tbest: 805.1294504 (517)\ttotal: 1m 11s\tremaining: 1m 6s\n",
      "518:\tlearn: 795.6710043\ttest: 804.9659595\tbest: 804.9659595 (518)\ttotal: 1m 11s\tremaining: 1m 6s\n",
      "519:\tlearn: 795.4943846\ttest: 804.7925537\tbest: 804.7925537 (519)\ttotal: 1m 11s\tremaining: 1m 6s\n",
      "520:\tlearn: 795.3184870\ttest: 804.6171273\tbest: 804.6171273 (520)\ttotal: 1m 11s\tremaining: 1m 6s\n",
      "521:\tlearn: 795.1925808\ttest: 804.4905419\tbest: 804.4905419 (521)\ttotal: 1m 12s\tremaining: 1m 5s\n",
      "522:\tlearn: 794.9842261\ttest: 804.2984969\tbest: 804.2984969 (522)\ttotal: 1m 12s\tremaining: 1m 5s\n",
      "523:\tlearn: 794.6252725\ttest: 803.9217320\tbest: 803.9217320 (523)\ttotal: 1m 12s\tremaining: 1m 5s\n",
      "524:\tlearn: 794.4717234\ttest: 803.8215805\tbest: 803.8215805 (524)\ttotal: 1m 12s\tremaining: 1m 5s\n",
      "525:\tlearn: 794.3042023\ttest: 803.7073822\tbest: 803.7073822 (525)\ttotal: 1m 12s\tremaining: 1m 5s\n",
      "526:\tlearn: 794.1019183\ttest: 803.5146854\tbest: 803.5146854 (526)\ttotal: 1m 12s\tremaining: 1m 5s\n",
      "527:\tlearn: 793.8192981\ttest: 803.2236519\tbest: 803.2236519 (527)\ttotal: 1m 12s\tremaining: 1m 5s\n",
      "528:\tlearn: 793.6078493\ttest: 803.0377770\tbest: 803.0377770 (528)\ttotal: 1m 13s\tremaining: 1m 5s\n",
      "529:\tlearn: 793.4037292\ttest: 802.7922603\tbest: 802.7922603 (529)\ttotal: 1m 13s\tremaining: 1m 4s\n",
      "530:\tlearn: 793.2792697\ttest: 802.7516328\tbest: 802.7516328 (530)\ttotal: 1m 13s\tremaining: 1m 4s\n",
      "531:\tlearn: 793.1429498\ttest: 802.5913046\tbest: 802.5913046 (531)\ttotal: 1m 13s\tremaining: 1m 4s\n",
      "532:\tlearn: 792.9983043\ttest: 802.5791318\tbest: 802.5791318 (532)\ttotal: 1m 13s\tremaining: 1m 4s\n",
      "533:\tlearn: 792.8021814\ttest: 802.4240484\tbest: 802.4240484 (533)\ttotal: 1m 13s\tremaining: 1m 4s\n",
      "534:\tlearn: 792.6722719\ttest: 802.3562376\tbest: 802.3562376 (534)\ttotal: 1m 14s\tremaining: 1m 4s\n",
      "535:\tlearn: 792.5284540\ttest: 802.2137763\tbest: 802.2137763 (535)\ttotal: 1m 14s\tremaining: 1m 4s\n",
      "536:\tlearn: 792.3460564\ttest: 802.0448433\tbest: 802.0448433 (536)\ttotal: 1m 14s\tremaining: 1m 4s\n",
      "537:\tlearn: 792.1822022\ttest: 801.8880496\tbest: 801.8880496 (537)\ttotal: 1m 14s\tremaining: 1m 3s\n",
      "538:\tlearn: 791.8798550\ttest: 801.6077050\tbest: 801.6077050 (538)\ttotal: 1m 14s\tremaining: 1m 3s\n",
      "539:\tlearn: 791.6958494\ttest: 801.4510106\tbest: 801.4510106 (539)\ttotal: 1m 14s\tremaining: 1m 3s\n",
      "540:\tlearn: 791.5013927\ttest: 801.2953370\tbest: 801.2953370 (540)\ttotal: 1m 14s\tremaining: 1m 3s\n",
      "541:\tlearn: 791.3106934\ttest: 801.0964634\tbest: 801.0964634 (541)\ttotal: 1m 15s\tremaining: 1m 3s\n",
      "542:\tlearn: 791.0693001\ttest: 800.8681307\tbest: 800.8681307 (542)\ttotal: 1m 15s\tremaining: 1m 3s\n",
      "543:\tlearn: 790.9868557\ttest: 800.8139998\tbest: 800.8139998 (543)\ttotal: 1m 15s\tremaining: 1m 3s\n",
      "544:\tlearn: 790.8262428\ttest: 800.6839656\tbest: 800.6839656 (544)\ttotal: 1m 15s\tremaining: 1m 2s\n",
      "545:\tlearn: 790.4468901\ttest: 800.2834506\tbest: 800.2834506 (545)\ttotal: 1m 15s\tremaining: 1m 2s\n",
      "546:\tlearn: 790.2845293\ttest: 800.1334253\tbest: 800.1334253 (546)\ttotal: 1m 15s\tremaining: 1m 2s\n",
      "547:\tlearn: 790.1481100\ttest: 800.0089634\tbest: 800.0089634 (547)\ttotal: 1m 15s\tremaining: 1m 2s\n",
      "548:\tlearn: 789.8810471\ttest: 799.7837270\tbest: 799.7837270 (548)\ttotal: 1m 15s\tremaining: 1m 2s\n",
      "549:\tlearn: 789.7170129\ttest: 799.6157065\tbest: 799.6157065 (549)\ttotal: 1m 16s\tremaining: 1m 2s\n",
      "550:\tlearn: 789.5645021\ttest: 799.5598462\tbest: 799.5598462 (550)\ttotal: 1m 16s\tremaining: 1m 2s\n",
      "551:\tlearn: 789.3322761\ttest: 799.2582401\tbest: 799.2582401 (551)\ttotal: 1m 16s\tremaining: 1m 1s\n",
      "552:\tlearn: 789.1072589\ttest: 799.0705707\tbest: 799.0705707 (552)\ttotal: 1m 16s\tremaining: 1m 1s\n",
      "553:\tlearn: 788.9860776\ttest: 799.0138313\tbest: 799.0138313 (553)\ttotal: 1m 16s\tremaining: 1m 1s\n",
      "554:\tlearn: 788.8381164\ttest: 798.8604606\tbest: 798.8604606 (554)\ttotal: 1m 16s\tremaining: 1m 1s\n",
      "555:\tlearn: 788.6234509\ttest: 798.5455292\tbest: 798.5455292 (555)\ttotal: 1m 16s\tremaining: 1m 1s\n",
      "556:\tlearn: 788.4770389\ttest: 798.4808941\tbest: 798.4808941 (556)\ttotal: 1m 16s\tremaining: 1m 1s\n",
      "557:\tlearn: 788.2863129\ttest: 798.3231511\tbest: 798.3231511 (557)\ttotal: 1m 17s\tremaining: 1m 1s\n",
      "558:\tlearn: 788.0586392\ttest: 798.0728392\tbest: 798.0728392 (558)\ttotal: 1m 17s\tremaining: 1m\n",
      "559:\tlearn: 787.8225581\ttest: 797.8191009\tbest: 797.8191009 (559)\ttotal: 1m 17s\tremaining: 1m\n",
      "560:\tlearn: 787.7525902\ttest: 797.7447758\tbest: 797.7447758 (560)\ttotal: 1m 17s\tremaining: 1m\n",
      "561:\tlearn: 787.5980765\ttest: 797.6077791\tbest: 797.6077791 (561)\ttotal: 1m 17s\tremaining: 1m\n",
      "562:\tlearn: 787.4490743\ttest: 797.4473506\tbest: 797.4473506 (562)\ttotal: 1m 17s\tremaining: 1m\n",
      "563:\tlearn: 787.2178537\ttest: 797.2724604\tbest: 797.2724604 (563)\ttotal: 1m 17s\tremaining: 1m\n",
      "564:\tlearn: 786.9989375\ttest: 797.0361026\tbest: 797.0361026 (564)\ttotal: 1m 18s\tremaining: 1m\n",
      "565:\tlearn: 786.8476973\ttest: 796.8985469\tbest: 796.8985469 (565)\ttotal: 1m 18s\tremaining: 60s\n",
      "566:\tlearn: 786.7049958\ttest: 796.7889226\tbest: 796.7889226 (566)\ttotal: 1m 18s\tremaining: 59.8s\n",
      "567:\tlearn: 786.4894919\ttest: 796.6041364\tbest: 796.6041364 (567)\ttotal: 1m 18s\tremaining: 59.7s\n",
      "568:\tlearn: 786.2699769\ttest: 796.3942884\tbest: 796.3942884 (568)\ttotal: 1m 18s\tremaining: 59.5s\n",
      "569:\tlearn: 786.1429893\ttest: 796.2462466\tbest: 796.2462466 (569)\ttotal: 1m 18s\tremaining: 59.4s\n",
      "570:\tlearn: 786.0154058\ttest: 796.1127883\tbest: 796.1127883 (570)\ttotal: 1m 18s\tremaining: 59.3s\n",
      "571:\tlearn: 785.7736613\ttest: 795.9355419\tbest: 795.9355419 (571)\ttotal: 1m 19s\tremaining: 59.1s\n",
      "572:\tlearn: 785.5496110\ttest: 795.7253780\tbest: 795.7253780 (572)\ttotal: 1m 19s\tremaining: 59s\n",
      "573:\tlearn: 785.4482370\ttest: 795.6449385\tbest: 795.6449385 (573)\ttotal: 1m 19s\tremaining: 58.8s\n",
      "574:\tlearn: 785.3188047\ttest: 795.5401245\tbest: 795.5401245 (574)\ttotal: 1m 19s\tremaining: 58.7s\n",
      "575:\tlearn: 785.1553437\ttest: 795.4350890\tbest: 795.4350890 (575)\ttotal: 1m 19s\tremaining: 58.5s\n",
      "576:\tlearn: 784.9819238\ttest: 795.3111886\tbest: 795.3111886 (576)\ttotal: 1m 19s\tremaining: 58.4s\n",
      "577:\tlearn: 784.7027848\ttest: 795.0065125\tbest: 795.0065125 (577)\ttotal: 1m 19s\tremaining: 58.3s\n",
      "578:\tlearn: 784.5753443\ttest: 794.8993595\tbest: 794.8993595 (578)\ttotal: 1m 19s\tremaining: 58.1s\n",
      "579:\tlearn: 784.3976680\ttest: 794.7333592\tbest: 794.7333592 (579)\ttotal: 1m 20s\tremaining: 58s\n",
      "580:\tlearn: 784.2793578\ttest: 794.6307442\tbest: 794.6307442 (580)\ttotal: 1m 20s\tremaining: 57.9s\n",
      "581:\tlearn: 784.1640587\ttest: 794.5273152\tbest: 794.5273152 (581)\ttotal: 1m 20s\tremaining: 57.8s\n",
      "582:\tlearn: 784.0102089\ttest: 794.3750381\tbest: 794.3750381 (582)\ttotal: 1m 20s\tremaining: 57.6s\n",
      "583:\tlearn: 783.8219495\ttest: 794.1869446\tbest: 794.1869446 (583)\ttotal: 1m 20s\tremaining: 57.5s\n",
      "584:\tlearn: 783.5917719\ttest: 793.9758191\tbest: 793.9758191 (584)\ttotal: 1m 20s\tremaining: 57.3s\n",
      "585:\tlearn: 783.3636094\ttest: 793.7685684\tbest: 793.7685684 (585)\ttotal: 1m 20s\tremaining: 57.2s\n",
      "586:\tlearn: 783.1391517\ttest: 793.5266955\tbest: 793.5266955 (586)\ttotal: 1m 21s\tremaining: 57.1s\n",
      "587:\tlearn: 782.9286300\ttest: 793.3128559\tbest: 793.3128559 (587)\ttotal: 1m 21s\tremaining: 56.9s\n",
      "588:\tlearn: 782.7572770\ttest: 793.1189781\tbest: 793.1189781 (588)\ttotal: 1m 21s\tremaining: 56.8s\n",
      "589:\tlearn: 782.5810752\ttest: 792.9959597\tbest: 792.9959597 (589)\ttotal: 1m 21s\tremaining: 56.6s\n",
      "590:\tlearn: 782.4458648\ttest: 792.8869187\tbest: 792.8869187 (590)\ttotal: 1m 21s\tremaining: 56.5s\n",
      "591:\tlearn: 782.2969128\ttest: 792.7634446\tbest: 792.7634446 (591)\ttotal: 1m 21s\tremaining: 56.4s\n",
      "592:\tlearn: 782.0789477\ttest: 792.5680842\tbest: 792.5680842 (592)\ttotal: 1m 21s\tremaining: 56.3s\n",
      "593:\tlearn: 781.9901039\ttest: 792.4743641\tbest: 792.4743641 (593)\ttotal: 1m 22s\tremaining: 56.2s\n",
      "594:\tlearn: 781.7794008\ttest: 792.2717261\tbest: 792.2717261 (594)\ttotal: 1m 22s\tremaining: 56s\n",
      "595:\tlearn: 781.6432096\ttest: 792.1770650\tbest: 792.1770650 (595)\ttotal: 1m 22s\tremaining: 55.9s\n",
      "596:\tlearn: 781.4478112\ttest: 792.0008066\tbest: 792.0008066 (596)\ttotal: 1m 22s\tremaining: 55.7s\n",
      "597:\tlearn: 781.2585917\ttest: 791.8105981\tbest: 791.8105981 (597)\ttotal: 1m 22s\tremaining: 55.6s\n",
      "598:\tlearn: 781.0892557\ttest: 791.6286064\tbest: 791.6286064 (598)\ttotal: 1m 22s\tremaining: 55.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "599:\tlearn: 780.7438630\ttest: 791.3000693\tbest: 791.3000693 (599)\ttotal: 1m 23s\tremaining: 55.3s\n",
      "600:\tlearn: 780.5552369\ttest: 791.1453314\tbest: 791.1453314 (600)\ttotal: 1m 23s\tremaining: 55.2s\n",
      "601:\tlearn: 780.3706545\ttest: 791.0228888\tbest: 791.0228888 (601)\ttotal: 1m 23s\tremaining: 55.1s\n",
      "602:\tlearn: 780.1980629\ttest: 790.8353656\tbest: 790.8353656 (602)\ttotal: 1m 23s\tremaining: 54.9s\n",
      "603:\tlearn: 780.0729639\ttest: 790.8005162\tbest: 790.8005162 (603)\ttotal: 1m 23s\tremaining: 54.8s\n",
      "604:\tlearn: 779.9213779\ttest: 790.6690140\tbest: 790.6690140 (604)\ttotal: 1m 23s\tremaining: 54.6s\n",
      "605:\tlearn: 779.7735816\ttest: 790.5578556\tbest: 790.5578556 (605)\ttotal: 1m 23s\tremaining: 54.5s\n",
      "606:\tlearn: 779.6387647\ttest: 790.4148294\tbest: 790.4148294 (606)\ttotal: 1m 23s\tremaining: 54.3s\n",
      "607:\tlearn: 779.4517265\ttest: 790.2305935\tbest: 790.2305935 (607)\ttotal: 1m 24s\tremaining: 54.2s\n",
      "608:\tlearn: 779.2484968\ttest: 790.0265380\tbest: 790.0265380 (608)\ttotal: 1m 24s\tremaining: 54s\n",
      "609:\tlearn: 779.0822546\ttest: 789.8689163\tbest: 789.8689163 (609)\ttotal: 1m 24s\tremaining: 53.9s\n",
      "610:\tlearn: 778.8823074\ttest: 789.6620556\tbest: 789.6620556 (610)\ttotal: 1m 24s\tremaining: 53.7s\n",
      "611:\tlearn: 778.6386070\ttest: 789.4212665\tbest: 789.4212665 (611)\ttotal: 1m 24s\tremaining: 53.6s\n",
      "612:\tlearn: 778.4813533\ttest: 789.2040940\tbest: 789.2040940 (612)\ttotal: 1m 24s\tremaining: 53.5s\n",
      "613:\tlearn: 778.3696881\ttest: 789.0866388\tbest: 789.0866388 (613)\ttotal: 1m 24s\tremaining: 53.3s\n",
      "614:\tlearn: 778.1908798\ttest: 788.9186931\tbest: 788.9186931 (614)\ttotal: 1m 24s\tremaining: 53.2s\n",
      "615:\tlearn: 777.9837166\ttest: 788.7344630\tbest: 788.7344630 (615)\ttotal: 1m 25s\tremaining: 53s\n",
      "616:\tlearn: 777.7649876\ttest: 788.4899373\tbest: 788.4899373 (616)\ttotal: 1m 25s\tremaining: 52.9s\n",
      "617:\tlearn: 777.5650534\ttest: 788.3247395\tbest: 788.3247395 (617)\ttotal: 1m 25s\tremaining: 52.7s\n",
      "618:\tlearn: 777.4175933\ttest: 788.1666256\tbest: 788.1666256 (618)\ttotal: 1m 25s\tremaining: 52.6s\n",
      "619:\tlearn: 777.3128707\ttest: 788.0765056\tbest: 788.0765056 (619)\ttotal: 1m 25s\tremaining: 52.5s\n",
      "620:\tlearn: 777.2288026\ttest: 788.0130496\tbest: 788.0130496 (620)\ttotal: 1m 25s\tremaining: 52.3s\n",
      "621:\tlearn: 777.1408440\ttest: 787.9391465\tbest: 787.9391465 (621)\ttotal: 1m 25s\tremaining: 52.2s\n",
      "622:\tlearn: 776.9808887\ttest: 787.9253480\tbest: 787.9253480 (622)\ttotal: 1m 25s\tremaining: 52s\n",
      "623:\tlearn: 776.8649363\ttest: 787.8060987\tbest: 787.8060987 (623)\ttotal: 1m 26s\tremaining: 51.9s\n",
      "624:\tlearn: 776.5805016\ttest: 787.5204739\tbest: 787.5204739 (624)\ttotal: 1m 26s\tremaining: 51.8s\n",
      "625:\tlearn: 776.5150909\ttest: 787.4719024\tbest: 787.4719024 (625)\ttotal: 1m 26s\tremaining: 51.6s\n",
      "626:\tlearn: 776.3342705\ttest: 787.3326615\tbest: 787.3326615 (626)\ttotal: 1m 26s\tremaining: 51.5s\n",
      "627:\tlearn: 775.9972631\ttest: 786.9236601\tbest: 786.9236601 (627)\ttotal: 1m 26s\tremaining: 51.3s\n",
      "628:\tlearn: 775.7540201\ttest: 786.7547615\tbest: 786.7547615 (628)\ttotal: 1m 26s\tremaining: 51.2s\n",
      "629:\tlearn: 775.5640677\ttest: 786.5660661\tbest: 786.5660661 (629)\ttotal: 1m 26s\tremaining: 51s\n",
      "630:\tlearn: 775.4238836\ttest: 786.4220869\tbest: 786.4220869 (630)\ttotal: 1m 27s\tremaining: 50.9s\n",
      "631:\tlearn: 775.2665703\ttest: 786.2103834\tbest: 786.2103834 (631)\ttotal: 1m 27s\tremaining: 50.7s\n",
      "632:\tlearn: 775.0270798\ttest: 785.9336002\tbest: 785.9336002 (632)\ttotal: 1m 27s\tremaining: 50.6s\n",
      "633:\tlearn: 774.9276564\ttest: 785.8396787\tbest: 785.8396787 (633)\ttotal: 1m 27s\tremaining: 50.5s\n",
      "634:\tlearn: 774.6843295\ttest: 785.6014266\tbest: 785.6014266 (634)\ttotal: 1m 27s\tremaining: 50.3s\n",
      "635:\tlearn: 774.5134274\ttest: 785.4194790\tbest: 785.4194790 (635)\ttotal: 1m 27s\tremaining: 50.2s\n",
      "636:\tlearn: 774.3399468\ttest: 785.2369996\tbest: 785.2369996 (636)\ttotal: 1m 27s\tremaining: 50s\n",
      "637:\tlearn: 774.1659130\ttest: 785.1077457\tbest: 785.1077457 (637)\ttotal: 1m 27s\tremaining: 49.9s\n",
      "638:\tlearn: 774.0235167\ttest: 784.9847451\tbest: 784.9847451 (638)\ttotal: 1m 28s\tremaining: 49.7s\n",
      "639:\tlearn: 773.9224913\ttest: 784.9208236\tbest: 784.9208236 (639)\ttotal: 1m 28s\tremaining: 49.6s\n",
      "640:\tlearn: 773.8150809\ttest: 784.8003010\tbest: 784.8003010 (640)\ttotal: 1m 28s\tremaining: 49.5s\n",
      "641:\tlearn: 773.6548370\ttest: 784.6796017\tbest: 784.6796017 (641)\ttotal: 1m 28s\tremaining: 49.3s\n",
      "642:\tlearn: 773.5394221\ttest: 784.5843183\tbest: 784.5843183 (642)\ttotal: 1m 28s\tremaining: 49.2s\n",
      "643:\tlearn: 773.4063713\ttest: 784.4619221\tbest: 784.4619221 (643)\ttotal: 1m 28s\tremaining: 49.1s\n",
      "644:\tlearn: 773.1537713\ttest: 784.2392167\tbest: 784.2392167 (644)\ttotal: 1m 28s\tremaining: 48.9s\n",
      "645:\tlearn: 773.0241540\ttest: 784.1569740\tbest: 784.1569740 (645)\ttotal: 1m 29s\tremaining: 48.8s\n",
      "646:\tlearn: 772.9412213\ttest: 784.0851758\tbest: 784.0851758 (646)\ttotal: 1m 29s\tremaining: 48.7s\n",
      "647:\tlearn: 772.7612369\ttest: 783.9172515\tbest: 783.9172515 (647)\ttotal: 1m 29s\tremaining: 48.5s\n",
      "648:\tlearn: 772.6635746\ttest: 783.8339604\tbest: 783.8339604 (648)\ttotal: 1m 29s\tremaining: 48.4s\n",
      "649:\tlearn: 772.5710798\ttest: 783.7637291\tbest: 783.7637291 (649)\ttotal: 1m 29s\tremaining: 48.3s\n",
      "650:\tlearn: 772.3139142\ttest: 783.5615650\tbest: 783.5615650 (650)\ttotal: 1m 29s\tremaining: 48.1s\n",
      "651:\tlearn: 772.1079241\ttest: 783.3930668\tbest: 783.3930668 (651)\ttotal: 1m 29s\tremaining: 48s\n",
      "652:\tlearn: 771.9989131\ttest: 783.2974239\tbest: 783.2974239 (652)\ttotal: 1m 30s\tremaining: 47.9s\n",
      "653:\tlearn: 771.7550796\ttest: 783.0751557\tbest: 783.0751557 (653)\ttotal: 1m 30s\tremaining: 47.7s\n",
      "654:\tlearn: 771.6471964\ttest: 782.9651401\tbest: 782.9651401 (654)\ttotal: 1m 30s\tremaining: 47.6s\n",
      "655:\tlearn: 771.5168235\ttest: 782.8371168\tbest: 782.8371168 (655)\ttotal: 1m 30s\tremaining: 47.4s\n",
      "656:\tlearn: 771.3521291\ttest: 782.8425203\tbest: 782.8371168 (655)\ttotal: 1m 30s\tremaining: 47.3s\n",
      "657:\tlearn: 771.2338499\ttest: 782.7283337\tbest: 782.7283337 (657)\ttotal: 1m 30s\tremaining: 47.2s\n",
      "658:\tlearn: 771.0828472\ttest: 782.6229447\tbest: 782.6229447 (658)\ttotal: 1m 30s\tremaining: 47s\n",
      "659:\tlearn: 770.8952167\ttest: 782.5481006\tbest: 782.5481006 (659)\ttotal: 1m 30s\tremaining: 46.9s\n",
      "660:\tlearn: 770.7944001\ttest: 782.4569356\tbest: 782.4569356 (660)\ttotal: 1m 31s\tremaining: 46.7s\n",
      "661:\tlearn: 770.6855768\ttest: 782.3703982\tbest: 782.3703982 (661)\ttotal: 1m 31s\tremaining: 46.6s\n",
      "662:\tlearn: 770.4321164\ttest: 782.1090553\tbest: 782.1090553 (662)\ttotal: 1m 31s\tremaining: 46.5s\n",
      "663:\tlearn: 770.2396899\ttest: 781.9560501\tbest: 781.9560501 (663)\ttotal: 1m 31s\tremaining: 46.3s\n",
      "664:\tlearn: 769.9940888\ttest: 781.7386619\tbest: 781.7386619 (664)\ttotal: 1m 31s\tremaining: 46.2s\n",
      "665:\tlearn: 769.8450445\ttest: 781.6165272\tbest: 781.6165272 (665)\ttotal: 1m 31s\tremaining: 46s\n",
      "666:\tlearn: 769.7767943\ttest: 781.5674912\tbest: 781.5674912 (666)\ttotal: 1m 31s\tremaining: 45.9s\n",
      "667:\tlearn: 769.5504380\ttest: 781.4466663\tbest: 781.4466663 (667)\ttotal: 1m 32s\tremaining: 45.7s\n",
      "668:\tlearn: 769.4027674\ttest: 781.3427375\tbest: 781.3427375 (668)\ttotal: 1m 32s\tremaining: 45.6s\n",
      "669:\tlearn: 769.3118447\ttest: 781.2615178\tbest: 781.2615178 (669)\ttotal: 1m 32s\tremaining: 45.5s\n",
      "670:\tlearn: 769.1857492\ttest: 781.1564466\tbest: 781.1564466 (670)\ttotal: 1m 32s\tremaining: 45.4s\n",
      "671:\tlearn: 769.0585557\ttest: 781.0645801\tbest: 781.0645801 (671)\ttotal: 1m 32s\tremaining: 45.2s\n",
      "672:\tlearn: 768.9465688\ttest: 780.9651598\tbest: 780.9651598 (672)\ttotal: 1m 32s\tremaining: 45.1s\n",
      "673:\tlearn: 768.7601297\ttest: 780.7695454\tbest: 780.7695454 (673)\ttotal: 1m 32s\tremaining: 44.9s\n",
      "674:\tlearn: 768.6551736\ttest: 780.6661089\tbest: 780.6661089 (674)\ttotal: 1m 32s\tremaining: 44.8s\n",
      "675:\tlearn: 768.5835066\ttest: 780.6042804\tbest: 780.6042804 (675)\ttotal: 1m 33s\tremaining: 44.6s\n",
      "676:\tlearn: 768.3123199\ttest: 780.3664326\tbest: 780.3664326 (676)\ttotal: 1m 33s\tremaining: 44.5s\n",
      "677:\tlearn: 768.1169860\ttest: 780.1820758\tbest: 780.1820758 (677)\ttotal: 1m 33s\tremaining: 44.4s\n",
      "678:\tlearn: 768.0096826\ttest: 780.0740438\tbest: 780.0740438 (678)\ttotal: 1m 33s\tremaining: 44.2s\n",
      "679:\tlearn: 767.9066978\ttest: 779.9810007\tbest: 779.9810007 (679)\ttotal: 1m 33s\tremaining: 44.1s\n",
      "680:\tlearn: 767.7631730\ttest: 779.8932655\tbest: 779.8932655 (680)\ttotal: 1m 33s\tremaining: 43.9s\n",
      "681:\tlearn: 767.6679102\ttest: 779.8183153\tbest: 779.8183153 (681)\ttotal: 1m 33s\tremaining: 43.8s\n",
      "682:\tlearn: 767.5037673\ttest: 779.6751595\tbest: 779.6751595 (682)\ttotal: 1m 34s\tremaining: 43.7s\n",
      "683:\tlearn: 767.3600412\ttest: 779.5250536\tbest: 779.5250536 (683)\ttotal: 1m 34s\tremaining: 43.5s\n",
      "684:\tlearn: 767.2258107\ttest: 779.3588658\tbest: 779.3588658 (684)\ttotal: 1m 34s\tremaining: 43.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "685:\tlearn: 767.1225904\ttest: 779.2817773\tbest: 779.2817773 (685)\ttotal: 1m 34s\tremaining: 43.2s\n",
      "686:\tlearn: 766.9898082\ttest: 779.1510420\tbest: 779.1510420 (686)\ttotal: 1m 34s\tremaining: 43.1s\n",
      "687:\tlearn: 766.8240212\ttest: 778.8140807\tbest: 778.8140807 (687)\ttotal: 1m 34s\tremaining: 43s\n",
      "688:\tlearn: 766.6664108\ttest: 778.7010265\tbest: 778.7010265 (688)\ttotal: 1m 34s\tremaining: 42.8s\n",
      "689:\tlearn: 766.5519336\ttest: 778.6145310\tbest: 778.6145310 (689)\ttotal: 1m 35s\tremaining: 42.7s\n",
      "690:\tlearn: 766.4135030\ttest: 778.4634064\tbest: 778.4634064 (690)\ttotal: 1m 35s\tremaining: 42.6s\n",
      "691:\tlearn: 766.1858516\ttest: 778.2099388\tbest: 778.2099388 (691)\ttotal: 1m 35s\tremaining: 42.4s\n",
      "692:\tlearn: 765.9733301\ttest: 778.0210870\tbest: 778.0210870 (692)\ttotal: 1m 35s\tremaining: 42.3s\n",
      "693:\tlearn: 765.8724182\ttest: 777.9193557\tbest: 777.9193557 (693)\ttotal: 1m 35s\tremaining: 42.2s\n",
      "694:\tlearn: 765.7586463\ttest: 777.8133640\tbest: 777.8133640 (694)\ttotal: 1m 35s\tremaining: 42s\n",
      "695:\tlearn: 765.6910894\ttest: 777.7674134\tbest: 777.7674134 (695)\ttotal: 1m 35s\tremaining: 41.9s\n",
      "696:\tlearn: 765.5732541\ttest: 777.6496340\tbest: 777.6496340 (696)\ttotal: 1m 35s\tremaining: 41.7s\n",
      "697:\tlearn: 765.3711015\ttest: 777.5949713\tbest: 777.5949713 (697)\ttotal: 1m 36s\tremaining: 41.6s\n",
      "698:\tlearn: 765.1523576\ttest: 777.3711206\tbest: 777.3711206 (698)\ttotal: 1m 36s\tremaining: 41.5s\n",
      "699:\tlearn: 765.0194226\ttest: 777.2885939\tbest: 777.2885939 (699)\ttotal: 1m 36s\tremaining: 41.3s\n",
      "700:\tlearn: 764.8154476\ttest: 777.1509965\tbest: 777.1509965 (700)\ttotal: 1m 36s\tremaining: 41.2s\n",
      "701:\tlearn: 764.6870439\ttest: 777.0257764\tbest: 777.0257764 (701)\ttotal: 1m 36s\tremaining: 41s\n",
      "702:\tlearn: 764.5811509\ttest: 776.9267153\tbest: 776.9267153 (702)\ttotal: 1m 36s\tremaining: 40.9s\n",
      "703:\tlearn: 764.4313369\ttest: 776.8088859\tbest: 776.8088859 (703)\ttotal: 1m 36s\tremaining: 40.8s\n",
      "704:\tlearn: 764.3127805\ttest: 776.7214070\tbest: 776.7214070 (704)\ttotal: 1m 37s\tremaining: 40.6s\n",
      "705:\tlearn: 764.2093182\ttest: 776.6389449\tbest: 776.6389449 (705)\ttotal: 1m 37s\tremaining: 40.5s\n",
      "706:\tlearn: 764.0780431\ttest: 776.5196341\tbest: 776.5196341 (706)\ttotal: 1m 37s\tremaining: 40.4s\n",
      "707:\tlearn: 763.9347252\ttest: 776.3944618\tbest: 776.3944618 (707)\ttotal: 1m 37s\tremaining: 40.2s\n",
      "708:\tlearn: 763.8160801\ttest: 776.3989240\tbest: 776.3944618 (707)\ttotal: 1m 37s\tremaining: 40.1s\n",
      "709:\tlearn: 763.5242167\ttest: 776.0747666\tbest: 776.0747666 (709)\ttotal: 1m 37s\tremaining: 39.9s\n",
      "710:\tlearn: 763.4592431\ttest: 776.0107542\tbest: 776.0107542 (710)\ttotal: 1m 37s\tremaining: 39.8s\n",
      "711:\tlearn: 763.3393470\ttest: 775.9171877\tbest: 775.9171877 (711)\ttotal: 1m 38s\tremaining: 39.6s\n",
      "712:\tlearn: 763.2628553\ttest: 775.8405331\tbest: 775.8405331 (712)\ttotal: 1m 38s\tremaining: 39.5s\n",
      "713:\tlearn: 763.1943151\ttest: 775.7736440\tbest: 775.7736440 (713)\ttotal: 1m 38s\tremaining: 39.4s\n",
      "714:\tlearn: 763.1033792\ttest: 775.7228737\tbest: 775.7228737 (714)\ttotal: 1m 38s\tremaining: 39.2s\n",
      "715:\tlearn: 762.9709089\ttest: 775.5520755\tbest: 775.5520755 (715)\ttotal: 1m 38s\tremaining: 39.1s\n",
      "716:\tlearn: 762.8774846\ttest: 775.4835636\tbest: 775.4835636 (716)\ttotal: 1m 38s\tremaining: 38.9s\n",
      "717:\tlearn: 762.7282648\ttest: 775.3317263\tbest: 775.3317263 (717)\ttotal: 1m 38s\tremaining: 38.8s\n",
      "718:\tlearn: 762.5924709\ttest: 775.1828078\tbest: 775.1828078 (718)\ttotal: 1m 38s\tremaining: 38.7s\n",
      "719:\tlearn: 762.4360769\ttest: 775.0673938\tbest: 775.0673938 (719)\ttotal: 1m 39s\tremaining: 38.5s\n",
      "720:\tlearn: 762.2949970\ttest: 774.9313321\tbest: 774.9313321 (720)\ttotal: 1m 39s\tremaining: 38.4s\n",
      "721:\tlearn: 762.2198232\ttest: 774.8830295\tbest: 774.8830295 (721)\ttotal: 1m 39s\tremaining: 38.2s\n",
      "722:\tlearn: 762.0378859\ttest: 774.7383146\tbest: 774.7383146 (722)\ttotal: 1m 39s\tremaining: 38.1s\n",
      "723:\tlearn: 761.9327048\ttest: 774.6528431\tbest: 774.6528431 (723)\ttotal: 1m 39s\tremaining: 38s\n",
      "724:\tlearn: 761.8311168\ttest: 774.5801174\tbest: 774.5801174 (724)\ttotal: 1m 39s\tremaining: 37.8s\n",
      "725:\tlearn: 761.6821175\ttest: 774.4513403\tbest: 774.4513403 (725)\ttotal: 1m 39s\tremaining: 37.7s\n",
      "726:\tlearn: 761.5956631\ttest: 774.3764392\tbest: 774.3764392 (726)\ttotal: 1m 40s\tremaining: 37.6s\n",
      "727:\tlearn: 761.5142157\ttest: 774.3108158\tbest: 774.3108158 (727)\ttotal: 1m 40s\tremaining: 37.4s\n",
      "728:\tlearn: 761.2277522\ttest: 774.0364731\tbest: 774.0364731 (728)\ttotal: 1m 40s\tremaining: 37.3s\n",
      "729:\tlearn: 761.0885975\ttest: 773.8812046\tbest: 773.8812046 (729)\ttotal: 1m 40s\tremaining: 37.1s\n",
      "730:\tlearn: 761.0099277\ttest: 773.8294567\tbest: 773.8294567 (730)\ttotal: 1m 40s\tremaining: 37s\n",
      "731:\tlearn: 760.8529927\ttest: 773.6678963\tbest: 773.6678963 (731)\ttotal: 1m 40s\tremaining: 36.9s\n",
      "732:\tlearn: 760.6853659\ttest: 773.4758529\tbest: 773.4758529 (732)\ttotal: 1m 40s\tremaining: 36.7s\n",
      "733:\tlearn: 760.6385958\ttest: 773.4359304\tbest: 773.4359304 (733)\ttotal: 1m 40s\tremaining: 36.6s\n",
      "734:\tlearn: 760.4696696\ttest: 773.2706301\tbest: 773.2706301 (734)\ttotal: 1m 41s\tremaining: 36.4s\n",
      "735:\tlearn: 760.4015311\ttest: 773.2152098\tbest: 773.2152098 (735)\ttotal: 1m 41s\tremaining: 36.3s\n",
      "736:\tlearn: 760.2643683\ttest: 773.1437263\tbest: 773.1437263 (736)\ttotal: 1m 41s\tremaining: 36.2s\n",
      "737:\tlearn: 760.0798277\ttest: 772.9569438\tbest: 772.9569438 (737)\ttotal: 1m 41s\tremaining: 36s\n",
      "738:\tlearn: 759.8982996\ttest: 772.7878445\tbest: 772.7878445 (738)\ttotal: 1m 41s\tremaining: 35.9s\n",
      "739:\tlearn: 759.8103154\ttest: 772.7307088\tbest: 772.7307088 (739)\ttotal: 1m 41s\tremaining: 35.7s\n",
      "740:\tlearn: 759.5913507\ttest: 772.4711195\tbest: 772.4711195 (740)\ttotal: 1m 41s\tremaining: 35.6s\n",
      "741:\tlearn: 759.4875912\ttest: 772.4025761\tbest: 772.4025761 (741)\ttotal: 1m 42s\tremaining: 35.5s\n",
      "742:\tlearn: 759.3287803\ttest: 772.2616170\tbest: 772.2616170 (742)\ttotal: 1m 42s\tremaining: 35.3s\n",
      "743:\tlearn: 759.1853340\ttest: 772.1575894\tbest: 772.1575894 (743)\ttotal: 1m 42s\tremaining: 35.2s\n",
      "744:\tlearn: 759.0379268\ttest: 771.9999099\tbest: 771.9999099 (744)\ttotal: 1m 42s\tremaining: 35.1s\n",
      "745:\tlearn: 758.9586923\ttest: 771.9333070\tbest: 771.9333070 (745)\ttotal: 1m 42s\tremaining: 34.9s\n",
      "746:\tlearn: 758.8679368\ttest: 771.8405139\tbest: 771.8405139 (746)\ttotal: 1m 42s\tremaining: 34.8s\n",
      "747:\tlearn: 758.7874790\ttest: 771.7686728\tbest: 771.7686728 (747)\ttotal: 1m 42s\tremaining: 34.6s\n",
      "748:\tlearn: 758.6372254\ttest: 771.6362464\tbest: 771.6362464 (748)\ttotal: 1m 42s\tremaining: 34.5s\n",
      "749:\tlearn: 758.4265046\ttest: 771.4284875\tbest: 771.4284875 (749)\ttotal: 1m 43s\tremaining: 34.4s\n",
      "750:\tlearn: 758.2852790\ttest: 771.2793668\tbest: 771.2793668 (750)\ttotal: 1m 43s\tremaining: 34.2s\n",
      "751:\tlearn: 758.2177416\ttest: 771.2207597\tbest: 771.2207597 (751)\ttotal: 1m 43s\tremaining: 34.1s\n",
      "752:\tlearn: 758.0659459\ttest: 771.0788329\tbest: 771.0788329 (752)\ttotal: 1m 43s\tremaining: 34s\n",
      "753:\tlearn: 757.9356841\ttest: 770.9352245\tbest: 770.9352245 (753)\ttotal: 1m 43s\tremaining: 33.8s\n",
      "754:\tlearn: 757.8522066\ttest: 770.8509773\tbest: 770.8509773 (754)\ttotal: 1m 43s\tremaining: 33.7s\n",
      "755:\tlearn: 757.7241383\ttest: 770.7605386\tbest: 770.7605386 (755)\ttotal: 1m 43s\tremaining: 33.6s\n",
      "756:\tlearn: 757.5642194\ttest: 770.6886168\tbest: 770.6886168 (756)\ttotal: 1m 44s\tremaining: 33.4s\n",
      "757:\tlearn: 757.4100499\ttest: 770.5919025\tbest: 770.5919025 (757)\ttotal: 1m 44s\tremaining: 33.3s\n",
      "758:\tlearn: 757.3130857\ttest: 770.4856351\tbest: 770.4856351 (758)\ttotal: 1m 44s\tremaining: 33.2s\n",
      "759:\tlearn: 757.2046972\ttest: 770.4383855\tbest: 770.4383855 (759)\ttotal: 1m 44s\tremaining: 33s\n",
      "760:\tlearn: 757.0629056\ttest: 770.3505920\tbest: 770.3505920 (760)\ttotal: 1m 44s\tremaining: 32.9s\n",
      "761:\tlearn: 756.8228417\ttest: 770.1017441\tbest: 770.1017441 (761)\ttotal: 1m 44s\tremaining: 32.8s\n",
      "762:\tlearn: 756.6863166\ttest: 769.9872096\tbest: 769.9872096 (762)\ttotal: 1m 45s\tremaining: 32.6s\n",
      "763:\tlearn: 756.4720161\ttest: 769.7726843\tbest: 769.7726843 (763)\ttotal: 1m 45s\tremaining: 32.5s\n",
      "764:\tlearn: 756.3479583\ttest: 769.6516279\tbest: 769.6516279 (764)\ttotal: 1m 45s\tremaining: 32.4s\n",
      "765:\tlearn: 756.2090794\ttest: 769.5158098\tbest: 769.5158098 (765)\ttotal: 1m 45s\tremaining: 32.2s\n",
      "766:\tlearn: 756.0638242\ttest: 769.3802917\tbest: 769.3802917 (766)\ttotal: 1m 45s\tremaining: 32.1s\n",
      "767:\tlearn: 755.8927404\ttest: 769.1987215\tbest: 769.1987215 (767)\ttotal: 1m 45s\tremaining: 32s\n",
      "768:\tlearn: 755.8010531\ttest: 769.0927534\tbest: 769.0927534 (768)\ttotal: 1m 46s\tremaining: 31.8s\n",
      "769:\tlearn: 755.6945397\ttest: 769.0233899\tbest: 769.0233899 (769)\ttotal: 1m 46s\tremaining: 31.7s\n",
      "770:\tlearn: 755.6051239\ttest: 768.8568025\tbest: 768.8568025 (770)\ttotal: 1m 46s\tremaining: 31.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "771:\tlearn: 755.4712269\ttest: 768.7446560\tbest: 768.7446560 (771)\ttotal: 1m 46s\tremaining: 31.4s\n",
      "772:\tlearn: 755.3287040\ttest: 768.6130475\tbest: 768.6130475 (772)\ttotal: 1m 46s\tremaining: 31.3s\n",
      "773:\tlearn: 755.2425374\ttest: 768.5493001\tbest: 768.5493001 (773)\ttotal: 1m 46s\tremaining: 31.1s\n",
      "774:\tlearn: 755.1370158\ttest: 768.4577845\tbest: 768.4577845 (774)\ttotal: 1m 46s\tremaining: 31s\n",
      "775:\tlearn: 755.0259699\ttest: 768.3847147\tbest: 768.3847147 (775)\ttotal: 1m 46s\tremaining: 30.9s\n",
      "776:\tlearn: 754.8705963\ttest: 768.2215495\tbest: 768.2215495 (776)\ttotal: 1m 47s\tremaining: 30.7s\n",
      "777:\tlearn: 754.7847659\ttest: 768.1577824\tbest: 768.1577824 (777)\ttotal: 1m 47s\tremaining: 30.6s\n",
      "778:\tlearn: 754.6953237\ttest: 768.1889732\tbest: 768.1577824 (777)\ttotal: 1m 47s\tremaining: 30.5s\n",
      "779:\tlearn: 754.6122545\ttest: 768.1212450\tbest: 768.1212450 (779)\ttotal: 1m 47s\tremaining: 30.3s\n",
      "780:\tlearn: 754.4257285\ttest: 767.9191374\tbest: 767.9191374 (780)\ttotal: 1m 47s\tremaining: 30.2s\n",
      "781:\tlearn: 754.3488977\ttest: 767.8669116\tbest: 767.8669116 (781)\ttotal: 1m 47s\tremaining: 30s\n",
      "782:\tlearn: 754.1848348\ttest: 767.7396073\tbest: 767.7396073 (782)\ttotal: 1m 47s\tremaining: 29.9s\n",
      "783:\tlearn: 754.0402964\ttest: 767.6234444\tbest: 767.6234444 (783)\ttotal: 1m 48s\tremaining: 29.8s\n",
      "784:\tlearn: 753.9430111\ttest: 767.5379032\tbest: 767.5379032 (784)\ttotal: 1m 48s\tremaining: 29.6s\n",
      "785:\tlearn: 753.8214378\ttest: 767.4174096\tbest: 767.4174096 (785)\ttotal: 1m 48s\tremaining: 29.5s\n",
      "786:\tlearn: 753.6686309\ttest: 767.3477781\tbest: 767.3477781 (786)\ttotal: 1m 48s\tremaining: 29.4s\n",
      "787:\tlearn: 753.5006541\ttest: 767.1873007\tbest: 767.1873007 (787)\ttotal: 1m 48s\tremaining: 29.2s\n",
      "788:\tlearn: 753.3674417\ttest: 767.0500909\tbest: 767.0500909 (788)\ttotal: 1m 48s\tremaining: 29.1s\n",
      "789:\tlearn: 753.3184687\ttest: 767.0047485\tbest: 767.0047485 (789)\ttotal: 1m 48s\tremaining: 28.9s\n",
      "790:\tlearn: 753.2100369\ttest: 766.9082762\tbest: 766.9082762 (790)\ttotal: 1m 49s\tremaining: 28.8s\n",
      "791:\tlearn: 753.0484450\ttest: 766.7930002\tbest: 766.7930002 (791)\ttotal: 1m 49s\tremaining: 28.7s\n",
      "792:\tlearn: 752.9132023\ttest: 766.6544199\tbest: 766.6544199 (792)\ttotal: 1m 49s\tremaining: 28.5s\n",
      "793:\tlearn: 752.7822275\ttest: 766.5317737\tbest: 766.5317737 (793)\ttotal: 1m 49s\tremaining: 28.4s\n",
      "794:\tlearn: 752.6191841\ttest: 766.3705167\tbest: 766.3705167 (794)\ttotal: 1m 49s\tremaining: 28.2s\n",
      "795:\tlearn: 752.4839109\ttest: 766.2500861\tbest: 766.2500861 (795)\ttotal: 1m 49s\tremaining: 28.1s\n",
      "796:\tlearn: 752.2919608\ttest: 766.0464106\tbest: 766.0464106 (796)\ttotal: 1m 49s\tremaining: 28s\n",
      "797:\tlearn: 752.1030591\ttest: 765.8725251\tbest: 765.8725251 (797)\ttotal: 1m 49s\tremaining: 27.8s\n",
      "798:\tlearn: 752.0089403\ttest: 765.7787733\tbest: 765.7787733 (798)\ttotal: 1m 50s\tremaining: 27.7s\n",
      "799:\tlearn: 751.8511633\ttest: 765.6085313\tbest: 765.6085313 (799)\ttotal: 1m 50s\tremaining: 27.5s\n",
      "800:\tlearn: 751.7061437\ttest: 765.5043297\tbest: 765.5043297 (800)\ttotal: 1m 50s\tremaining: 27.4s\n",
      "801:\tlearn: 751.5859986\ttest: 765.3872886\tbest: 765.3872886 (801)\ttotal: 1m 50s\tremaining: 27.3s\n",
      "802:\tlearn: 751.4807727\ttest: 765.3016685\tbest: 765.3016685 (802)\ttotal: 1m 50s\tremaining: 27.1s\n",
      "803:\tlearn: 751.3939359\ttest: 765.2166664\tbest: 765.2166664 (803)\ttotal: 1m 50s\tremaining: 27s\n",
      "804:\tlearn: 751.2863624\ttest: 765.1015652\tbest: 765.1015652 (804)\ttotal: 1m 50s\tremaining: 26.8s\n",
      "805:\tlearn: 751.1668252\ttest: 764.9955795\tbest: 764.9955795 (805)\ttotal: 1m 50s\tremaining: 26.7s\n",
      "806:\tlearn: 751.0418302\ttest: 764.8798546\tbest: 764.8798546 (806)\ttotal: 1m 51s\tremaining: 26.6s\n",
      "807:\tlearn: 750.9320274\ttest: 764.7847990\tbest: 764.7847990 (807)\ttotal: 1m 51s\tremaining: 26.4s\n",
      "808:\tlearn: 750.7778787\ttest: 764.7046058\tbest: 764.7046058 (808)\ttotal: 1m 51s\tremaining: 26.3s\n",
      "809:\tlearn: 750.6754948\ttest: 764.6168216\tbest: 764.6168216 (809)\ttotal: 1m 51s\tremaining: 26.2s\n",
      "810:\tlearn: 750.5044235\ttest: 764.4128316\tbest: 764.4128316 (810)\ttotal: 1m 51s\tremaining: 26s\n",
      "811:\tlearn: 750.2729468\ttest: 764.3095333\tbest: 764.3095333 (811)\ttotal: 1m 51s\tremaining: 25.9s\n",
      "812:\tlearn: 750.1705123\ttest: 764.2146243\tbest: 764.2146243 (812)\ttotal: 1m 51s\tremaining: 25.7s\n",
      "813:\tlearn: 750.0639623\ttest: 764.1492625\tbest: 764.1492625 (813)\ttotal: 1m 52s\tremaining: 25.6s\n",
      "814:\tlearn: 749.9854137\ttest: 764.0939552\tbest: 764.0939552 (814)\ttotal: 1m 52s\tremaining: 25.5s\n",
      "815:\tlearn: 749.9040179\ttest: 764.0065648\tbest: 764.0065648 (815)\ttotal: 1m 52s\tremaining: 25.3s\n",
      "816:\tlearn: 749.7228586\ttest: 763.8878829\tbest: 763.8878829 (816)\ttotal: 1m 52s\tremaining: 25.2s\n",
      "817:\tlearn: 749.5756491\ttest: 763.7937389\tbest: 763.7937389 (817)\ttotal: 1m 52s\tremaining: 25.1s\n",
      "818:\tlearn: 749.4888880\ttest: 763.7212126\tbest: 763.7212126 (818)\ttotal: 1m 52s\tremaining: 24.9s\n",
      "819:\tlearn: 749.3941866\ttest: 763.6433586\tbest: 763.6433586 (819)\ttotal: 1m 52s\tremaining: 24.8s\n",
      "820:\tlearn: 749.2443674\ttest: 763.4828781\tbest: 763.4828781 (820)\ttotal: 1m 53s\tremaining: 24.6s\n",
      "821:\tlearn: 749.0940314\ttest: 763.3962492\tbest: 763.3962492 (821)\ttotal: 1m 53s\tremaining: 24.5s\n",
      "822:\tlearn: 748.9514674\ttest: 763.2593504\tbest: 763.2593504 (822)\ttotal: 1m 53s\tremaining: 24.4s\n",
      "823:\tlearn: 748.7647518\ttest: 763.1625500\tbest: 763.1625500 (823)\ttotal: 1m 53s\tremaining: 24.2s\n",
      "824:\tlearn: 748.7032664\ttest: 763.1266257\tbest: 763.1266257 (824)\ttotal: 1m 53s\tremaining: 24.1s\n",
      "825:\tlearn: 748.4784878\ttest: 762.9101191\tbest: 762.9101191 (825)\ttotal: 1m 53s\tremaining: 24s\n",
      "826:\tlearn: 748.3678727\ttest: 762.8510208\tbest: 762.8510208 (826)\ttotal: 1m 53s\tremaining: 23.8s\n",
      "827:\tlearn: 748.2382231\ttest: 762.5934173\tbest: 762.5934173 (827)\ttotal: 1m 54s\tremaining: 23.7s\n",
      "828:\tlearn: 748.1614044\ttest: 762.5217521\tbest: 762.5217521 (828)\ttotal: 1m 54s\tremaining: 23.6s\n",
      "829:\tlearn: 748.0749039\ttest: 762.4073214\tbest: 762.4073214 (829)\ttotal: 1m 54s\tremaining: 23.4s\n",
      "830:\tlearn: 747.9973792\ttest: 762.3619779\tbest: 762.3619779 (830)\ttotal: 1m 54s\tremaining: 23.3s\n",
      "831:\tlearn: 747.9089107\ttest: 762.2837727\tbest: 762.2837727 (831)\ttotal: 1m 54s\tremaining: 23.2s\n",
      "832:\tlearn: 747.7959639\ttest: 762.1704335\tbest: 762.1704335 (832)\ttotal: 1m 54s\tremaining: 23s\n",
      "833:\tlearn: 747.7319745\ttest: 762.1037068\tbest: 762.1037068 (833)\ttotal: 1m 54s\tremaining: 22.9s\n",
      "834:\tlearn: 747.6162415\ttest: 762.0013586\tbest: 762.0013586 (834)\ttotal: 1m 55s\tremaining: 22.7s\n",
      "835:\tlearn: 747.4905138\ttest: 761.8555206\tbest: 761.8555206 (835)\ttotal: 1m 55s\tremaining: 22.6s\n",
      "836:\tlearn: 747.3757003\ttest: 761.7340204\tbest: 761.7340204 (836)\ttotal: 1m 55s\tremaining: 22.5s\n",
      "837:\tlearn: 747.2718551\ttest: 761.6183221\tbest: 761.6183221 (837)\ttotal: 1m 55s\tremaining: 22.3s\n",
      "838:\tlearn: 747.1831939\ttest: 761.5427287\tbest: 761.5427287 (838)\ttotal: 1m 55s\tremaining: 22.2s\n",
      "839:\tlearn: 747.0814933\ttest: 761.4534666\tbest: 761.4534666 (839)\ttotal: 1m 55s\tremaining: 22s\n",
      "840:\tlearn: 747.0011442\ttest: 761.3596532\tbest: 761.3596532 (840)\ttotal: 1m 55s\tremaining: 21.9s\n",
      "841:\tlearn: 746.8940442\ttest: 761.2546644\tbest: 761.2546644 (841)\ttotal: 1m 56s\tremaining: 21.8s\n",
      "842:\tlearn: 746.8464803\ttest: 761.2160775\tbest: 761.2160775 (842)\ttotal: 1m 56s\tremaining: 21.6s\n",
      "843:\tlearn: 746.7073558\ttest: 761.0804887\tbest: 761.0804887 (843)\ttotal: 1m 56s\tremaining: 21.5s\n",
      "844:\tlearn: 746.5422264\ttest: 760.9123761\tbest: 760.9123761 (844)\ttotal: 1m 56s\tremaining: 21.4s\n",
      "845:\tlearn: 746.4297100\ttest: 760.8415596\tbest: 760.8415596 (845)\ttotal: 1m 56s\tremaining: 21.2s\n",
      "846:\tlearn: 746.3015412\ttest: 760.7133125\tbest: 760.7133125 (846)\ttotal: 1m 56s\tremaining: 21.1s\n",
      "847:\tlearn: 746.2013077\ttest: 760.6522630\tbest: 760.6522630 (847)\ttotal: 1m 56s\tremaining: 20.9s\n",
      "848:\tlearn: 746.1166182\ttest: 760.5767910\tbest: 760.5767910 (848)\ttotal: 1m 56s\tremaining: 20.8s\n",
      "849:\tlearn: 746.0423341\ttest: 760.5220218\tbest: 760.5220218 (849)\ttotal: 1m 57s\tremaining: 20.6s\n",
      "850:\tlearn: 745.8364590\ttest: 760.3286310\tbest: 760.3286310 (850)\ttotal: 1m 57s\tremaining: 20.5s\n",
      "851:\tlearn: 745.6972415\ttest: 760.2051071\tbest: 760.2051071 (851)\ttotal: 1m 57s\tremaining: 20.4s\n",
      "852:\tlearn: 745.6056461\ttest: 760.1079267\tbest: 760.1079267 (852)\ttotal: 1m 57s\tremaining: 20.2s\n",
      "853:\tlearn: 745.5060991\ttest: 760.0698454\tbest: 760.0698454 (853)\ttotal: 1m 57s\tremaining: 20.1s\n",
      "854:\tlearn: 745.2800371\ttest: 759.8607041\tbest: 759.8607041 (854)\ttotal: 1m 57s\tremaining: 20s\n",
      "855:\tlearn: 745.2270043\ttest: 759.8446322\tbest: 759.8446322 (855)\ttotal: 1m 57s\tremaining: 19.8s\n",
      "856:\tlearn: 745.0832010\ttest: 759.7134042\tbest: 759.7134042 (856)\ttotal: 1m 57s\tremaining: 19.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "857:\tlearn: 744.9668539\ttest: 759.6229847\tbest: 759.6229847 (857)\ttotal: 1m 58s\tremaining: 19.5s\n",
      "858:\tlearn: 744.9055880\ttest: 759.5598375\tbest: 759.5598375 (858)\ttotal: 1m 58s\tremaining: 19.4s\n",
      "859:\tlearn: 744.8210587\ttest: 759.5243495\tbest: 759.5243495 (859)\ttotal: 1m 58s\tremaining: 19.3s\n",
      "860:\tlearn: 744.7026601\ttest: 759.4500544\tbest: 759.4500544 (860)\ttotal: 1m 58s\tremaining: 19.1s\n",
      "861:\tlearn: 744.6099145\ttest: 759.3473921\tbest: 759.3473921 (861)\ttotal: 1m 58s\tremaining: 19s\n",
      "862:\tlearn: 744.4702108\ttest: 759.2901033\tbest: 759.2901033 (862)\ttotal: 1m 58s\tremaining: 18.8s\n",
      "863:\tlearn: 744.3780797\ttest: 759.1786480\tbest: 759.1786480 (863)\ttotal: 1m 58s\tremaining: 18.7s\n",
      "864:\tlearn: 744.2521656\ttest: 759.0815135\tbest: 759.0815135 (864)\ttotal: 1m 58s\tremaining: 18.6s\n",
      "865:\tlearn: 744.1251539\ttest: 758.9795871\tbest: 758.9795871 (865)\ttotal: 1m 59s\tremaining: 18.4s\n",
      "866:\tlearn: 744.0174709\ttest: 758.9383583\tbest: 758.9383583 (866)\ttotal: 1m 59s\tremaining: 18.3s\n",
      "867:\tlearn: 743.9126081\ttest: 758.8348643\tbest: 758.8348643 (867)\ttotal: 1m 59s\tremaining: 18.2s\n",
      "868:\tlearn: 743.7982263\ttest: 758.6876688\tbest: 758.6876688 (868)\ttotal: 1m 59s\tremaining: 18s\n",
      "869:\tlearn: 743.6968408\ttest: 758.5828225\tbest: 758.5828225 (869)\ttotal: 1m 59s\tremaining: 17.9s\n",
      "870:\tlearn: 743.5676425\ttest: 758.5031506\tbest: 758.5031506 (870)\ttotal: 1m 59s\tremaining: 17.7s\n",
      "871:\tlearn: 743.4009546\ttest: 758.3773161\tbest: 758.3773161 (871)\ttotal: 1m 59s\tremaining: 17.6s\n",
      "872:\tlearn: 743.2804679\ttest: 758.2509521\tbest: 758.2509521 (872)\ttotal: 2m\tremaining: 17.5s\n",
      "873:\tlearn: 743.1662238\ttest: 758.1347571\tbest: 758.1347571 (873)\ttotal: 2m\tremaining: 17.3s\n",
      "874:\tlearn: 743.0467741\ttest: 758.0479304\tbest: 758.0479304 (874)\ttotal: 2m\tremaining: 17.2s\n",
      "875:\tlearn: 742.9714413\ttest: 757.9944399\tbest: 757.9944399 (875)\ttotal: 2m\tremaining: 17.1s\n",
      "876:\tlearn: 742.9179083\ttest: 757.9572504\tbest: 757.9572504 (876)\ttotal: 2m\tremaining: 16.9s\n",
      "877:\tlearn: 742.8633923\ttest: 757.9210352\tbest: 757.9210352 (877)\ttotal: 2m\tremaining: 16.8s\n",
      "878:\tlearn: 742.8188778\ttest: 757.8981754\tbest: 757.8981754 (878)\ttotal: 2m\tremaining: 16.6s\n",
      "879:\tlearn: 742.7280692\ttest: 757.8145248\tbest: 757.8145248 (879)\ttotal: 2m 1s\tremaining: 16.5s\n",
      "880:\tlearn: 742.6447378\ttest: 757.7608268\tbest: 757.7608268 (880)\ttotal: 2m 1s\tremaining: 16.4s\n",
      "881:\tlearn: 742.5766716\ttest: 757.7135730\tbest: 757.7135730 (881)\ttotal: 2m 1s\tremaining: 16.2s\n",
      "882:\tlearn: 742.4973273\ttest: 757.6459248\tbest: 757.6459248 (882)\ttotal: 2m 1s\tremaining: 16.1s\n",
      "883:\tlearn: 742.3029957\ttest: 757.5223257\tbest: 757.5223257 (883)\ttotal: 2m 1s\tremaining: 16s\n",
      "884:\tlearn: 742.2467524\ttest: 757.4715674\tbest: 757.4715674 (884)\ttotal: 2m 1s\tremaining: 15.8s\n",
      "885:\tlearn: 742.1476997\ttest: 757.3680930\tbest: 757.3680930 (885)\ttotal: 2m 1s\tremaining: 15.7s\n",
      "886:\tlearn: 742.0508321\ttest: 757.2752435\tbest: 757.2752435 (886)\ttotal: 2m 2s\tremaining: 15.5s\n",
      "887:\tlearn: 741.9262077\ttest: 757.1693168\tbest: 757.1693168 (887)\ttotal: 2m 2s\tremaining: 15.4s\n",
      "888:\tlearn: 741.7799602\ttest: 757.0225578\tbest: 757.0225578 (888)\ttotal: 2m 2s\tremaining: 15.3s\n",
      "889:\tlearn: 741.6495848\ttest: 756.8989661\tbest: 756.8989661 (889)\ttotal: 2m 2s\tremaining: 15.1s\n",
      "890:\tlearn: 741.5391248\ttest: 756.7563145\tbest: 756.7563145 (890)\ttotal: 2m 2s\tremaining: 15s\n",
      "891:\tlearn: 741.4232803\ttest: 756.6854367\tbest: 756.6854367 (891)\ttotal: 2m 2s\tremaining: 14.9s\n",
      "892:\tlearn: 741.3142978\ttest: 756.5644411\tbest: 756.5644411 (892)\ttotal: 2m 2s\tremaining: 14.7s\n",
      "893:\tlearn: 741.2040142\ttest: 756.4750757\tbest: 756.4750757 (893)\ttotal: 2m 2s\tremaining: 14.6s\n",
      "894:\tlearn: 741.1124364\ttest: 756.4279776\tbest: 756.4279776 (894)\ttotal: 2m 3s\tremaining: 14.4s\n",
      "895:\tlearn: 741.0215795\ttest: 756.3611855\tbest: 756.3611855 (895)\ttotal: 2m 3s\tremaining: 14.3s\n",
      "896:\tlearn: 740.9505745\ttest: 756.2940902\tbest: 756.2940902 (896)\ttotal: 2m 3s\tremaining: 14.2s\n",
      "897:\tlearn: 740.7312105\ttest: 756.0895819\tbest: 756.0895819 (897)\ttotal: 2m 3s\tremaining: 14s\n",
      "898:\tlearn: 740.6082873\ttest: 755.9626795\tbest: 755.9626795 (898)\ttotal: 2m 3s\tremaining: 13.9s\n",
      "899:\tlearn: 740.5304074\ttest: 755.9315624\tbest: 755.9315624 (899)\ttotal: 2m 3s\tremaining: 13.8s\n",
      "900:\tlearn: 740.4059627\ttest: 755.8191824\tbest: 755.8191824 (900)\ttotal: 2m 3s\tremaining: 13.6s\n",
      "901:\tlearn: 740.2498550\ttest: 755.7543916\tbest: 755.7543916 (901)\ttotal: 2m 4s\tremaining: 13.5s\n",
      "902:\tlearn: 740.1879235\ttest: 755.6840365\tbest: 755.6840365 (902)\ttotal: 2m 4s\tremaining: 13.3s\n",
      "903:\tlearn: 740.0599351\ttest: 755.5624072\tbest: 755.5624072 (903)\ttotal: 2m 4s\tremaining: 13.2s\n",
      "904:\tlearn: 739.9184828\ttest: 755.4105550\tbest: 755.4105550 (904)\ttotal: 2m 4s\tremaining: 13.1s\n",
      "905:\tlearn: 739.8035790\ttest: 755.3095599\tbest: 755.3095599 (905)\ttotal: 2m 4s\tremaining: 12.9s\n",
      "906:\tlearn: 739.6359901\ttest: 755.2040409\tbest: 755.2040409 (906)\ttotal: 2m 4s\tremaining: 12.8s\n",
      "907:\tlearn: 739.5724628\ttest: 755.1579956\tbest: 755.1579956 (907)\ttotal: 2m 4s\tremaining: 12.6s\n",
      "908:\tlearn: 739.5008115\ttest: 755.0953670\tbest: 755.0953670 (908)\ttotal: 2m 4s\tremaining: 12.5s\n",
      "909:\tlearn: 739.4243690\ttest: 755.0386788\tbest: 755.0386788 (909)\ttotal: 2m 5s\tremaining: 12.4s\n",
      "910:\tlearn: 739.2897762\ttest: 754.9068095\tbest: 754.9068095 (910)\ttotal: 2m 5s\tremaining: 12.2s\n",
      "911:\tlearn: 739.1188574\ttest: 754.8507448\tbest: 754.8507448 (911)\ttotal: 2m 5s\tremaining: 12.1s\n",
      "912:\tlearn: 739.0488247\ttest: 754.7835107\tbest: 754.7835107 (912)\ttotal: 2m 5s\tremaining: 12s\n",
      "913:\tlearn: 738.9249917\ttest: 754.6764193\tbest: 754.6764193 (913)\ttotal: 2m 5s\tremaining: 11.8s\n",
      "914:\tlearn: 738.8589001\ttest: 754.6165362\tbest: 754.6165362 (914)\ttotal: 2m 5s\tremaining: 11.7s\n",
      "915:\tlearn: 738.7582798\ttest: 754.5574084\tbest: 754.5574084 (915)\ttotal: 2m 5s\tremaining: 11.5s\n",
      "916:\tlearn: 738.6629967\ttest: 754.4745148\tbest: 754.4745148 (916)\ttotal: 2m 5s\tremaining: 11.4s\n",
      "917:\tlearn: 738.5854574\ttest: 754.3500844\tbest: 754.3500844 (917)\ttotal: 2m 6s\tremaining: 11.3s\n",
      "918:\tlearn: 738.4495733\ttest: 754.2157308\tbest: 754.2157308 (918)\ttotal: 2m 6s\tremaining: 11.1s\n",
      "919:\tlearn: 738.3517760\ttest: 754.1313821\tbest: 754.1313821 (919)\ttotal: 2m 6s\tremaining: 11s\n",
      "920:\tlearn: 738.2379014\ttest: 754.0227836\tbest: 754.0227836 (920)\ttotal: 2m 6s\tremaining: 10.8s\n",
      "921:\tlearn: 738.1844794\ttest: 753.9703057\tbest: 753.9703057 (921)\ttotal: 2m 6s\tremaining: 10.7s\n",
      "922:\tlearn: 738.0749672\ttest: 753.8737406\tbest: 753.8737406 (922)\ttotal: 2m 6s\tremaining: 10.6s\n",
      "923:\tlearn: 738.0145663\ttest: 753.8377721\tbest: 753.8377721 (923)\ttotal: 2m 6s\tremaining: 10.4s\n",
      "924:\tlearn: 737.8894142\ttest: 753.7482740\tbest: 753.7482740 (924)\ttotal: 2m 7s\tremaining: 10.3s\n",
      "925:\tlearn: 737.7635332\ttest: 753.6069084\tbest: 753.6069084 (925)\ttotal: 2m 7s\tremaining: 10.2s\n",
      "926:\tlearn: 737.6760689\ttest: 753.5137531\tbest: 753.5137531 (926)\ttotal: 2m 7s\tremaining: 10s\n",
      "927:\tlearn: 737.5368592\ttest: 753.4082400\tbest: 753.4082400 (927)\ttotal: 2m 7s\tremaining: 9.88s\n",
      "928:\tlearn: 737.3713365\ttest: 753.3172980\tbest: 753.3172980 (928)\ttotal: 2m 7s\tremaining: 9.75s\n",
      "929:\tlearn: 737.2798420\ttest: 753.2462079\tbest: 753.2462079 (929)\ttotal: 2m 7s\tremaining: 9.61s\n",
      "930:\tlearn: 737.1739135\ttest: 753.1711925\tbest: 753.1711925 (930)\ttotal: 2m 7s\tremaining: 9.47s\n",
      "931:\tlearn: 737.0806396\ttest: 753.0783365\tbest: 753.0783365 (931)\ttotal: 2m 7s\tremaining: 9.33s\n",
      "932:\tlearn: 736.9831243\ttest: 753.0210830\tbest: 753.0210830 (932)\ttotal: 2m 8s\tremaining: 9.2s\n",
      "933:\tlearn: 736.8409205\ttest: 752.8995862\tbest: 752.8995862 (933)\ttotal: 2m 8s\tremaining: 9.06s\n",
      "934:\tlearn: 736.7543448\ttest: 752.8289885\tbest: 752.8289885 (934)\ttotal: 2m 8s\tremaining: 8.92s\n",
      "935:\tlearn: 736.6795895\ttest: 752.7627011\tbest: 752.7627011 (935)\ttotal: 2m 8s\tremaining: 8.78s\n",
      "936:\tlearn: 736.5724292\ttest: 752.6600382\tbest: 752.6600382 (936)\ttotal: 2m 8s\tremaining: 8.64s\n",
      "937:\tlearn: 736.4908198\ttest: 752.5627263\tbest: 752.5627263 (937)\ttotal: 2m 8s\tremaining: 8.51s\n",
      "938:\tlearn: 736.3883066\ttest: 752.4641559\tbest: 752.4641559 (938)\ttotal: 2m 8s\tremaining: 8.37s\n",
      "939:\tlearn: 736.3375132\ttest: 752.4284078\tbest: 752.4284078 (939)\ttotal: 2m 8s\tremaining: 8.23s\n",
      "940:\tlearn: 736.2415799\ttest: 752.3607961\tbest: 752.3607961 (940)\ttotal: 2m 9s\tremaining: 8.09s\n",
      "941:\tlearn: 736.1646045\ttest: 752.2893667\tbest: 752.2893667 (941)\ttotal: 2m 9s\tremaining: 7.96s\n",
      "942:\tlearn: 736.1134778\ttest: 752.1850064\tbest: 752.1850064 (942)\ttotal: 2m 9s\tremaining: 7.82s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943:\tlearn: 735.9992456\ttest: 752.0871559\tbest: 752.0871559 (943)\ttotal: 2m 9s\tremaining: 7.68s\n",
      "944:\tlearn: 735.8807282\ttest: 751.9584058\tbest: 751.9584058 (944)\ttotal: 2m 9s\tremaining: 7.54s\n",
      "945:\tlearn: 735.7460438\ttest: 751.8541777\tbest: 751.8541777 (945)\ttotal: 2m 9s\tremaining: 7.4s\n",
      "946:\tlearn: 735.5596590\ttest: 751.6610875\tbest: 751.6610875 (946)\ttotal: 2m 9s\tremaining: 7.27s\n",
      "947:\tlearn: 735.4407185\ttest: 751.5580100\tbest: 751.5580100 (947)\ttotal: 2m 9s\tremaining: 7.13s\n",
      "948:\tlearn: 735.3010232\ttest: 751.5201016\tbest: 751.5201016 (948)\ttotal: 2m 10s\tremaining: 6.99s\n",
      "949:\tlearn: 735.2188690\ttest: 751.4385105\tbest: 751.4385105 (949)\ttotal: 2m 10s\tremaining: 6.85s\n",
      "950:\tlearn: 735.0932052\ttest: 751.3976111\tbest: 751.3976111 (950)\ttotal: 2m 10s\tremaining: 6.71s\n",
      "951:\tlearn: 735.0122579\ttest: 751.2987608\tbest: 751.2987608 (951)\ttotal: 2m 10s\tremaining: 6.58s\n",
      "952:\tlearn: 734.9112957\ttest: 751.1840157\tbest: 751.1840157 (952)\ttotal: 2m 10s\tremaining: 6.44s\n",
      "953:\tlearn: 734.7949207\ttest: 751.0889809\tbest: 751.0889809 (953)\ttotal: 2m 10s\tremaining: 6.3s\n",
      "954:\tlearn: 734.6887258\ttest: 750.9770160\tbest: 750.9770160 (954)\ttotal: 2m 10s\tremaining: 6.17s\n",
      "955:\tlearn: 734.6149012\ttest: 750.9200177\tbest: 750.9200177 (955)\ttotal: 2m 10s\tremaining: 6.03s\n",
      "956:\tlearn: 734.4702768\ttest: 750.7586349\tbest: 750.7586349 (956)\ttotal: 2m 11s\tremaining: 5.89s\n",
      "957:\tlearn: 734.2818042\ttest: 750.6138808\tbest: 750.6138808 (957)\ttotal: 2m 11s\tremaining: 5.75s\n",
      "958:\tlearn: 734.1724970\ttest: 750.5050858\tbest: 750.5050858 (958)\ttotal: 2m 11s\tremaining: 5.62s\n",
      "959:\tlearn: 734.0674542\ttest: 750.4253430\tbest: 750.4253430 (959)\ttotal: 2m 11s\tremaining: 5.48s\n",
      "960:\tlearn: 733.9888224\ttest: 750.3712278\tbest: 750.3712278 (960)\ttotal: 2m 11s\tremaining: 5.34s\n",
      "961:\tlearn: 733.9088710\ttest: 750.3071721\tbest: 750.3071721 (961)\ttotal: 2m 11s\tremaining: 5.2s\n",
      "962:\tlearn: 733.7998033\ttest: 750.2135109\tbest: 750.2135109 (962)\ttotal: 2m 11s\tremaining: 5.07s\n",
      "963:\tlearn: 733.6949601\ttest: 750.1168209\tbest: 750.1168209 (963)\ttotal: 2m 11s\tremaining: 4.93s\n",
      "964:\tlearn: 733.5174283\ttest: 749.9280960\tbest: 749.9280960 (964)\ttotal: 2m 12s\tremaining: 4.79s\n",
      "965:\tlearn: 733.4437038\ttest: 749.8688024\tbest: 749.8688024 (965)\ttotal: 2m 12s\tremaining: 4.66s\n",
      "966:\tlearn: 733.3394309\ttest: 749.7692412\tbest: 749.7692412 (966)\ttotal: 2m 12s\tremaining: 4.52s\n",
      "967:\tlearn: 733.2774230\ttest: 749.6874073\tbest: 749.6874073 (967)\ttotal: 2m 12s\tremaining: 4.38s\n",
      "968:\tlearn: 733.2239323\ttest: 749.6792635\tbest: 749.6792635 (968)\ttotal: 2m 12s\tremaining: 4.24s\n",
      "969:\tlearn: 733.1237565\ttest: 749.5953827\tbest: 749.5953827 (969)\ttotal: 2m 12s\tremaining: 4.11s\n",
      "970:\tlearn: 732.9958831\ttest: 749.4807498\tbest: 749.4807498 (970)\ttotal: 2m 12s\tremaining: 3.97s\n",
      "971:\tlearn: 732.8881159\ttest: 749.3849480\tbest: 749.3849480 (971)\ttotal: 2m 13s\tremaining: 3.83s\n",
      "972:\tlearn: 732.8345530\ttest: 749.3343466\tbest: 749.3343466 (972)\ttotal: 2m 13s\tremaining: 3.69s\n",
      "973:\tlearn: 732.7217427\ttest: 749.2061327\tbest: 749.2061327 (973)\ttotal: 2m 13s\tremaining: 3.56s\n",
      "974:\tlearn: 732.6055898\ttest: 749.1627911\tbest: 749.1627911 (974)\ttotal: 2m 13s\tremaining: 3.42s\n",
      "975:\tlearn: 732.5380842\ttest: 749.1015923\tbest: 749.1015923 (975)\ttotal: 2m 13s\tremaining: 3.28s\n",
      "976:\tlearn: 732.4273788\ttest: 748.9960012\tbest: 748.9960012 (976)\ttotal: 2m 13s\tremaining: 3.15s\n",
      "977:\tlearn: 732.3109129\ttest: 748.9006995\tbest: 748.9006995 (977)\ttotal: 2m 13s\tremaining: 3.01s\n",
      "978:\tlearn: 732.2309288\ttest: 748.8222329\tbest: 748.8222329 (978)\ttotal: 2m 13s\tremaining: 2.87s\n",
      "979:\tlearn: 732.0108792\ttest: 748.7330623\tbest: 748.7330623 (979)\ttotal: 2m 14s\tremaining: 2.73s\n",
      "980:\tlearn: 731.9318300\ttest: 748.6774863\tbest: 748.6774863 (980)\ttotal: 2m 14s\tremaining: 2.6s\n",
      "981:\tlearn: 731.8327983\ttest: 748.6670710\tbest: 748.6670710 (981)\ttotal: 2m 14s\tremaining: 2.46s\n",
      "982:\tlearn: 731.7421795\ttest: 748.6227030\tbest: 748.6227030 (982)\ttotal: 2m 14s\tremaining: 2.32s\n",
      "983:\tlearn: 731.6561895\ttest: 748.5663167\tbest: 748.5663167 (983)\ttotal: 2m 14s\tremaining: 2.19s\n",
      "984:\tlearn: 731.6064614\ttest: 748.5321197\tbest: 748.5321197 (984)\ttotal: 2m 14s\tremaining: 2.05s\n",
      "985:\tlearn: 731.5086399\ttest: 748.4824826\tbest: 748.4824826 (985)\ttotal: 2m 14s\tremaining: 1.91s\n",
      "986:\tlearn: 731.3647658\ttest: 748.3607557\tbest: 748.3607557 (986)\ttotal: 2m 14s\tremaining: 1.78s\n",
      "987:\tlearn: 731.3241431\ttest: 748.3517169\tbest: 748.3517169 (987)\ttotal: 2m 15s\tremaining: 1.64s\n",
      "988:\tlearn: 731.2555104\ttest: 748.3037631\tbest: 748.3037631 (988)\ttotal: 2m 15s\tremaining: 1.5s\n",
      "989:\tlearn: 731.1455686\ttest: 748.2049741\tbest: 748.2049741 (989)\ttotal: 2m 15s\tremaining: 1.37s\n",
      "990:\tlearn: 731.0592404\ttest: 748.1204397\tbest: 748.1204397 (990)\ttotal: 2m 15s\tremaining: 1.23s\n",
      "991:\tlearn: 730.9724394\ttest: 748.0080584\tbest: 748.0080584 (991)\ttotal: 2m 15s\tremaining: 1.09s\n",
      "992:\tlearn: 730.8598710\ttest: 747.9302785\tbest: 747.9302785 (992)\ttotal: 2m 15s\tremaining: 957ms\n",
      "993:\tlearn: 730.7661957\ttest: 747.8264701\tbest: 747.8264701 (993)\ttotal: 2m 15s\tremaining: 820ms\n",
      "994:\tlearn: 730.7026762\ttest: 747.7668856\tbest: 747.7668856 (994)\ttotal: 2m 15s\tremaining: 683ms\n",
      "995:\tlearn: 730.5991671\ttest: 747.6607486\tbest: 747.6607486 (995)\ttotal: 2m 16s\tremaining: 547ms\n",
      "996:\tlearn: 730.4626261\ttest: 747.5274401\tbest: 747.5274401 (996)\ttotal: 2m 16s\tremaining: 410ms\n",
      "997:\tlearn: 730.3936094\ttest: 747.4654779\tbest: 747.4654779 (997)\ttotal: 2m 16s\tremaining: 273ms\n",
      "998:\tlearn: 730.3234497\ttest: 747.3836353\tbest: 747.3836353 (998)\ttotal: 2m 16s\tremaining: 137ms\n",
      "999:\tlearn: 730.2872462\ttest: 747.3678868\tbest: 747.3678868 (999)\ttotal: 2m 16s\tremaining: 0us\n",
      "\n",
      "bestTest = 747.3678868\n",
      "bestIteration = 999\n",
      "\n",
      "mean_squared_log_error is : 747.3678867714225\n",
      "Wall time: 2min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cat_cols = ['Store', 'Promo']\n",
    "lr = CatBoostRegressor(random_state=1, cat_features=cat_cols, n_estimators=1000)\n",
    "\n",
    "lr.fit(X_trn, y_trn, eval_set = [(X_val, y_val)], early_stopping_rounds = 80)\n",
    "\n",
    "preds = lr.predict(X_val)\n",
    "preds = np.abs(preds)\n",
    "\n",
    "error = np.sqrt(mean_squared_error((y_val), (preds)))\n",
    "\n",
    "print(f'mean_squared_log_error is : {error}')\n",
    "\n",
    "# lr.fit(train[features], train[target], eval_set = [(X_val, y_val)], early_stopping_rounds = 80)\n",
    "\n",
    "# preds = lr.predict(X_test)\n",
    "# preds = np.abs(preds)\n",
    "# # With eval set and no cat_cols: lb score 1093"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.153878\n",
      "0:\tlearn: 2808.2033007\ttest: 2794.3393205\tbest: 2794.3393205 (0)\ttotal: 167ms\tremaining: 2m 46s\n",
      "1:\tlearn: 2525.2377500\ttest: 2512.9673308\tbest: 2512.9673308 (1)\ttotal: 352ms\tremaining: 2m 55s\n",
      "2:\tlearn: 2292.9988260\ttest: 2281.8336994\tbest: 2281.8336994 (2)\ttotal: 519ms\tremaining: 2m 52s\n",
      "3:\tlearn: 2103.7371976\ttest: 2093.8097058\tbest: 2093.8097058 (3)\ttotal: 682ms\tremaining: 2m 49s\n",
      "4:\tlearn: 1949.0181396\ttest: 1939.8496939\tbest: 1939.8496939 (4)\ttotal: 832ms\tremaining: 2m 45s\n",
      "5:\tlearn: 1825.0615226\ttest: 1816.5260303\tbest: 1816.5260303 (5)\ttotal: 980ms\tremaining: 2m 42s\n",
      "6:\tlearn: 1722.9699957\ttest: 1715.2292225\tbest: 1715.2292225 (6)\ttotal: 1.15s\tremaining: 2m 43s\n",
      "7:\tlearn: 1641.3619587\ttest: 1633.7976673\tbest: 1633.7976673 (7)\ttotal: 1.31s\tremaining: 2m 42s\n",
      "8:\tlearn: 1577.4599851\ttest: 1570.2135597\tbest: 1570.2135597 (8)\ttotal: 1.48s\tremaining: 2m 43s\n",
      "9:\tlearn: 1524.7168874\ttest: 1517.7547164\tbest: 1517.7547164 (9)\ttotal: 1.63s\tremaining: 2m 41s\n",
      "10:\tlearn: 1482.1346828\ttest: 1475.5040502\tbest: 1475.5040502 (10)\ttotal: 1.8s\tremaining: 2m 41s\n",
      "11:\tlearn: 1447.7642772\ttest: 1441.5713784\tbest: 1441.5713784 (11)\ttotal: 1.96s\tremaining: 2m 41s\n",
      "12:\tlearn: 1416.5027797\ttest: 1410.3988910\tbest: 1410.3988910 (12)\ttotal: 2.12s\tremaining: 2m 40s\n",
      "13:\tlearn: 1391.0219746\ttest: 1385.2025272\tbest: 1385.2025272 (13)\ttotal: 2.26s\tremaining: 2m 39s\n",
      "14:\tlearn: 1371.8546484\ttest: 1367.0522561\tbest: 1367.0522561 (14)\ttotal: 2.42s\tremaining: 2m 38s\n",
      "15:\tlearn: 1351.4184429\ttest: 1346.7643205\tbest: 1346.7643205 (15)\ttotal: 2.58s\tremaining: 2m 38s\n",
      "16:\tlearn: 1337.7819713\ttest: 1332.9114720\tbest: 1332.9114720 (16)\ttotal: 2.72s\tremaining: 2m 37s\n",
      "17:\tlearn: 1324.3510073\ttest: 1319.8246527\tbest: 1319.8246527 (17)\ttotal: 2.89s\tremaining: 2m 37s\n",
      "18:\tlearn: 1310.5150083\ttest: 1306.0257109\tbest: 1306.0257109 (18)\ttotal: 3.05s\tremaining: 2m 37s\n",
      "19:\tlearn: 1301.5986972\ttest: 1297.0318608\tbest: 1297.0318608 (19)\ttotal: 3.2s\tremaining: 2m 36s\n",
      "20:\tlearn: 1292.9242954\ttest: 1289.1281599\tbest: 1289.1281599 (20)\ttotal: 3.34s\tremaining: 2m 35s\n",
      "21:\tlearn: 1281.2382494\ttest: 1277.7784814\tbest: 1277.7784814 (21)\ttotal: 3.49s\tremaining: 2m 34s\n",
      "22:\tlearn: 1268.6855288\ttest: 1265.1958381\tbest: 1265.1958381 (22)\ttotal: 3.63s\tremaining: 2m 34s\n",
      "23:\tlearn: 1255.0832734\ttest: 1252.0911042\tbest: 1252.0911042 (23)\ttotal: 3.79s\tremaining: 2m 34s\n",
      "24:\tlearn: 1247.4517127\ttest: 1244.2473056\tbest: 1244.2473056 (24)\ttotal: 3.94s\tremaining: 2m 33s\n",
      "25:\tlearn: 1235.9622522\ttest: 1232.9139134\tbest: 1232.9139134 (25)\ttotal: 4.1s\tremaining: 2m 33s\n",
      "26:\tlearn: 1226.0025327\ttest: 1223.3010694\tbest: 1223.3010694 (26)\ttotal: 4.25s\tremaining: 2m 33s\n",
      "27:\tlearn: 1218.6035077\ttest: 1215.4720937\tbest: 1215.4720937 (27)\ttotal: 4.41s\tremaining: 2m 32s\n",
      "28:\tlearn: 1210.8560711\ttest: 1207.7720307\tbest: 1207.7720307 (28)\ttotal: 4.56s\tremaining: 2m 32s\n",
      "29:\tlearn: 1207.1494323\ttest: 1204.0816880\tbest: 1204.0816880 (29)\ttotal: 4.72s\tremaining: 2m 32s\n",
      "30:\tlearn: 1200.0919017\ttest: 1197.4708128\tbest: 1197.4708128 (30)\ttotal: 4.88s\tremaining: 2m 32s\n",
      "31:\tlearn: 1194.0856391\ttest: 1191.4817682\tbest: 1191.4817682 (31)\ttotal: 5.04s\tremaining: 2m 32s\n",
      "32:\tlearn: 1186.4435366\ttest: 1183.9696849\tbest: 1183.9696849 (32)\ttotal: 5.19s\tremaining: 2m 32s\n",
      "33:\tlearn: 1182.6609152\ttest: 1180.1399524\tbest: 1180.1399524 (33)\ttotal: 5.36s\tremaining: 2m 32s\n",
      "34:\tlearn: 1179.1165354\ttest: 1176.6218465\tbest: 1176.6218465 (34)\ttotal: 5.54s\tremaining: 2m 32s\n",
      "35:\tlearn: 1174.5343216\ttest: 1172.3416670\tbest: 1172.3416670 (35)\ttotal: 5.68s\tremaining: 2m 32s\n",
      "36:\tlearn: 1166.1954186\ttest: 1164.1979481\tbest: 1164.1979481 (36)\ttotal: 5.84s\tremaining: 2m 32s\n",
      "37:\tlearn: 1160.5438351\ttest: 1158.5579386\tbest: 1158.5579386 (37)\ttotal: 5.99s\tremaining: 2m 31s\n",
      "38:\tlearn: 1155.0221718\ttest: 1153.1567195\tbest: 1153.1567195 (38)\ttotal: 6.16s\tremaining: 2m 31s\n",
      "39:\tlearn: 1150.3971640\ttest: 1148.5404158\tbest: 1148.5404158 (39)\ttotal: 6.31s\tremaining: 2m 31s\n",
      "40:\tlearn: 1147.7221379\ttest: 1145.8429911\tbest: 1145.8429911 (40)\ttotal: 6.47s\tremaining: 2m 31s\n",
      "41:\tlearn: 1144.1005516\ttest: 1142.0677017\tbest: 1142.0677017 (41)\ttotal: 6.64s\tremaining: 2m 31s\n",
      "42:\tlearn: 1140.7555395\ttest: 1138.9272176\tbest: 1138.9272176 (42)\ttotal: 6.81s\tremaining: 2m 31s\n",
      "43:\tlearn: 1135.8015444\ttest: 1134.0957765\tbest: 1134.0957765 (43)\ttotal: 6.93s\tremaining: 2m 30s\n",
      "44:\tlearn: 1131.5347010\ttest: 1129.8108548\tbest: 1129.8108548 (44)\ttotal: 7.08s\tremaining: 2m 30s\n",
      "45:\tlearn: 1122.0675822\ttest: 1120.1371032\tbest: 1120.1371032 (45)\ttotal: 7.23s\tremaining: 2m 29s\n",
      "46:\tlearn: 1119.2345255\ttest: 1117.5634168\tbest: 1117.5634168 (46)\ttotal: 7.41s\tremaining: 2m 30s\n",
      "47:\tlearn: 1117.2744624\ttest: 1115.5536599\tbest: 1115.5536599 (47)\ttotal: 7.55s\tremaining: 2m 29s\n",
      "48:\tlearn: 1110.1731295\ttest: 1108.1123631\tbest: 1108.1123631 (48)\ttotal: 7.75s\tremaining: 2m 30s\n",
      "49:\tlearn: 1106.6151009\ttest: 1104.7221771\tbest: 1104.7221771 (49)\ttotal: 7.91s\tremaining: 2m 30s\n",
      "50:\tlearn: 1102.7080769\ttest: 1100.8318322\tbest: 1100.8318322 (50)\ttotal: 8.06s\tremaining: 2m 30s\n",
      "51:\tlearn: 1098.8378647\ttest: 1097.0300228\tbest: 1097.0300228 (51)\ttotal: 8.24s\tremaining: 2m 30s\n",
      "52:\tlearn: 1095.9723898\ttest: 1094.2520511\tbest: 1094.2520511 (52)\ttotal: 8.39s\tremaining: 2m 29s\n",
      "53:\tlearn: 1092.7223189\ttest: 1091.1418024\tbest: 1091.1418024 (53)\ttotal: 8.56s\tremaining: 2m 29s\n",
      "54:\tlearn: 1090.4868677\ttest: 1088.8181373\tbest: 1088.8181373 (54)\ttotal: 8.73s\tremaining: 2m 30s\n",
      "55:\tlearn: 1087.5700311\ttest: 1085.7214562\tbest: 1085.7214562 (55)\ttotal: 8.9s\tremaining: 2m 30s\n",
      "56:\tlearn: 1082.6792166\ttest: 1080.7864870\tbest: 1080.7864870 (56)\ttotal: 9.06s\tremaining: 2m 29s\n",
      "57:\tlearn: 1081.1852366\ttest: 1079.2677999\tbest: 1079.2677999 (57)\ttotal: 9.19s\tremaining: 2m 29s\n",
      "58:\tlearn: 1078.6267851\ttest: 1076.6673537\tbest: 1076.6673537 (58)\ttotal: 9.35s\tremaining: 2m 29s\n",
      "59:\tlearn: 1075.5053430\ttest: 1073.6201567\tbest: 1073.6201567 (59)\ttotal: 9.5s\tremaining: 2m 28s\n",
      "60:\tlearn: 1073.2427448\ttest: 1071.4458551\tbest: 1071.4458551 (60)\ttotal: 9.66s\tremaining: 2m 28s\n",
      "61:\tlearn: 1072.0875639\ttest: 1070.3317961\tbest: 1070.3317961 (61)\ttotal: 9.81s\tremaining: 2m 28s\n",
      "62:\tlearn: 1068.8427647\ttest: 1067.1491559\tbest: 1067.1491559 (62)\ttotal: 9.98s\tremaining: 2m 28s\n",
      "63:\tlearn: 1065.7883026\ttest: 1064.0141671\tbest: 1064.0141671 (63)\ttotal: 10.1s\tremaining: 2m 28s\n",
      "64:\tlearn: 1063.2061936\ttest: 1061.3951926\tbest: 1061.3951926 (64)\ttotal: 10.3s\tremaining: 2m 27s\n",
      "65:\tlearn: 1060.4938938\ttest: 1058.7430422\tbest: 1058.7430422 (65)\ttotal: 10.5s\tremaining: 2m 27s\n",
      "66:\tlearn: 1058.0486433\ttest: 1056.2896548\tbest: 1056.2896548 (66)\ttotal: 10.7s\tremaining: 2m 28s\n",
      "67:\tlearn: 1055.8106631\ttest: 1054.0213832\tbest: 1054.0213832 (67)\ttotal: 10.8s\tremaining: 2m 28s\n",
      "68:\tlearn: 1054.0108304\ttest: 1052.2508746\tbest: 1052.2508746 (68)\ttotal: 11s\tremaining: 2m 28s\n",
      "69:\tlearn: 1051.7045338\ttest: 1049.7846979\tbest: 1049.7846979 (69)\ttotal: 11.2s\tremaining: 2m 28s\n",
      "70:\tlearn: 1048.3094560\ttest: 1046.3449555\tbest: 1046.3449555 (70)\ttotal: 11.3s\tremaining: 2m 28s\n",
      "71:\tlearn: 1045.7985539\ttest: 1044.0164262\tbest: 1044.0164262 (71)\ttotal: 11.5s\tremaining: 2m 28s\n",
      "72:\tlearn: 1042.0201548\ttest: 1040.2333826\tbest: 1040.2333826 (72)\ttotal: 11.7s\tremaining: 2m 28s\n",
      "73:\tlearn: 1039.6885762\ttest: 1037.9592139\tbest: 1037.9592139 (73)\ttotal: 11.8s\tremaining: 2m 27s\n",
      "74:\tlearn: 1036.8111528\ttest: 1035.0598569\tbest: 1035.0598569 (74)\ttotal: 12s\tremaining: 2m 27s\n",
      "75:\tlearn: 1035.3011960\ttest: 1033.5649500\tbest: 1033.5649500 (75)\ttotal: 12.2s\tremaining: 2m 27s\n",
      "76:\tlearn: 1033.6914420\ttest: 1031.9089830\tbest: 1031.9089830 (76)\ttotal: 12.3s\tremaining: 2m 27s\n",
      "77:\tlearn: 1031.9669917\ttest: 1030.1305999\tbest: 1030.1305999 (77)\ttotal: 12.5s\tremaining: 2m 27s\n",
      "78:\tlearn: 1029.2953464\ttest: 1027.4755350\tbest: 1027.4755350 (78)\ttotal: 12.7s\tremaining: 2m 27s\n",
      "79:\tlearn: 1027.7341025\ttest: 1025.9269626\tbest: 1025.9269626 (79)\ttotal: 12.8s\tremaining: 2m 27s\n",
      "80:\tlearn: 1025.1653392\ttest: 1023.2488135\tbest: 1023.2488135 (80)\ttotal: 13s\tremaining: 2m 27s\n",
      "81:\tlearn: 1023.4299522\ttest: 1021.4963544\tbest: 1021.4963544 (81)\ttotal: 13.2s\tremaining: 2m 27s\n",
      "82:\tlearn: 1021.8393162\ttest: 1019.9315526\tbest: 1019.9315526 (82)\ttotal: 13.4s\tremaining: 2m 27s\n",
      "83:\tlearn: 1020.4595697\ttest: 1018.5254385\tbest: 1018.5254385 (83)\ttotal: 13.5s\tremaining: 2m 27s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84:\tlearn: 1018.0108187\ttest: 1016.0204161\tbest: 1016.0204161 (84)\ttotal: 13.7s\tremaining: 2m 27s\n",
      "85:\tlearn: 1016.9242304\ttest: 1015.0020847\tbest: 1015.0020847 (85)\ttotal: 13.9s\tremaining: 2m 28s\n",
      "86:\tlearn: 1015.7224899\ttest: 1013.7758413\tbest: 1013.7758413 (86)\ttotal: 14.1s\tremaining: 2m 28s\n",
      "87:\tlearn: 1014.6578136\ttest: 1012.6451781\tbest: 1012.6451781 (87)\ttotal: 14.3s\tremaining: 2m 28s\n",
      "88:\tlearn: 1013.2483254\ttest: 1011.1959828\tbest: 1011.1959828 (88)\ttotal: 14.5s\tremaining: 2m 28s\n",
      "89:\tlearn: 1011.6495996\ttest: 1009.6101631\tbest: 1009.6101631 (89)\ttotal: 14.6s\tremaining: 2m 27s\n",
      "90:\tlearn: 1008.1545241\ttest: 1006.0043653\tbest: 1006.0043653 (90)\ttotal: 14.8s\tremaining: 2m 27s\n",
      "91:\tlearn: 1006.7856245\ttest: 1004.6361844\tbest: 1004.6361844 (91)\ttotal: 14.9s\tremaining: 2m 27s\n",
      "92:\tlearn: 1005.9993025\ttest: 1003.8894587\tbest: 1003.8894587 (92)\ttotal: 15.1s\tremaining: 2m 27s\n",
      "93:\tlearn: 1003.2046203\ttest: 1001.0374271\tbest: 1001.0374271 (93)\ttotal: 15.3s\tremaining: 2m 27s\n",
      "94:\tlearn: 1001.7375506\ttest: 999.5139343\tbest: 999.5139343 (94)\ttotal: 15.4s\tremaining: 2m 26s\n",
      "95:\tlearn: 1000.2011277\ttest: 997.9813414\tbest: 997.9813414 (95)\ttotal: 15.6s\tremaining: 2m 26s\n",
      "96:\tlearn: 999.0363078\ttest: 996.8709864\tbest: 996.8709864 (96)\ttotal: 15.8s\tremaining: 2m 26s\n",
      "97:\tlearn: 996.4720640\ttest: 994.0820512\tbest: 994.0820512 (97)\ttotal: 15.9s\tremaining: 2m 26s\n",
      "98:\tlearn: 995.0519759\ttest: 992.8228405\tbest: 992.8228405 (98)\ttotal: 16.1s\tremaining: 2m 26s\n",
      "99:\tlearn: 993.5863662\ttest: 991.3394416\tbest: 991.3394416 (99)\ttotal: 16.2s\tremaining: 2m 26s\n",
      "100:\tlearn: 992.2858874\ttest: 990.0246721\tbest: 990.0246721 (100)\ttotal: 16.4s\tremaining: 2m 25s\n",
      "101:\tlearn: 990.6235619\ttest: 988.3712281\tbest: 988.3712281 (101)\ttotal: 16.5s\tremaining: 2m 25s\n",
      "102:\tlearn: 988.6075099\ttest: 986.4303998\tbest: 986.4303998 (102)\ttotal: 16.7s\tremaining: 2m 25s\n",
      "103:\tlearn: 986.5292821\ttest: 984.4166334\tbest: 984.4166334 (103)\ttotal: 16.8s\tremaining: 2m 24s\n",
      "104:\tlearn: 985.4513023\ttest: 983.4656095\tbest: 983.4656095 (104)\ttotal: 16.9s\tremaining: 2m 24s\n",
      "105:\tlearn: 983.6895614\ttest: 981.8269448\tbest: 981.8269448 (105)\ttotal: 17.1s\tremaining: 2m 24s\n",
      "106:\tlearn: 981.6291133\ttest: 979.7540462\tbest: 979.7540462 (106)\ttotal: 17.3s\tremaining: 2m 24s\n",
      "107:\tlearn: 980.6237935\ttest: 978.7675320\tbest: 978.7675320 (107)\ttotal: 17.4s\tremaining: 2m 23s\n",
      "108:\tlearn: 979.6805662\ttest: 977.8306833\tbest: 977.8306833 (108)\ttotal: 17.6s\tremaining: 2m 23s\n",
      "109:\tlearn: 978.8395147\ttest: 977.0370675\tbest: 977.0370675 (109)\ttotal: 17.7s\tremaining: 2m 23s\n",
      "110:\tlearn: 976.7418138\ttest: 974.7430671\tbest: 974.7430671 (110)\ttotal: 17.9s\tremaining: 2m 23s\n",
      "111:\tlearn: 975.2194362\ttest: 973.3211835\tbest: 973.3211835 (111)\ttotal: 18.1s\tremaining: 2m 23s\n",
      "112:\tlearn: 974.2403910\ttest: 972.3907192\tbest: 972.3907192 (112)\ttotal: 18.2s\tremaining: 2m 22s\n",
      "113:\tlearn: 973.1853455\ttest: 971.2533211\tbest: 971.2533211 (113)\ttotal: 18.4s\tremaining: 2m 22s\n",
      "114:\tlearn: 972.0450425\ttest: 970.0705430\tbest: 970.0705430 (114)\ttotal: 18.5s\tremaining: 2m 22s\n",
      "115:\tlearn: 971.1328048\ttest: 969.1799841\tbest: 969.1799841 (115)\ttotal: 18.7s\tremaining: 2m 22s\n",
      "116:\tlearn: 970.0537104\ttest: 968.1553592\tbest: 968.1553592 (116)\ttotal: 18.9s\tremaining: 2m 22s\n",
      "117:\tlearn: 969.0636935\ttest: 967.2707784\tbest: 967.2707784 (117)\ttotal: 19s\tremaining: 2m 22s\n",
      "118:\tlearn: 967.6137362\ttest: 965.7917449\tbest: 965.7917449 (118)\ttotal: 19.2s\tremaining: 2m 21s\n",
      "119:\tlearn: 966.5230727\ttest: 964.6546171\tbest: 964.6546171 (119)\ttotal: 19.3s\tremaining: 2m 21s\n",
      "120:\tlearn: 965.5482114\ttest: 963.7904528\tbest: 963.7904528 (120)\ttotal: 19.5s\tremaining: 2m 21s\n",
      "121:\tlearn: 964.2252755\ttest: 962.4825185\tbest: 962.4825185 (121)\ttotal: 19.6s\tremaining: 2m 21s\n",
      "122:\tlearn: 963.1063832\ttest: 961.3337461\tbest: 961.3337461 (122)\ttotal: 19.8s\tremaining: 2m 21s\n",
      "123:\tlearn: 962.3150093\ttest: 960.5511436\tbest: 960.5511436 (123)\ttotal: 19.9s\tremaining: 2m 20s\n",
      "124:\tlearn: 961.1773135\ttest: 959.3662617\tbest: 959.3662617 (124)\ttotal: 20.1s\tremaining: 2m 20s\n",
      "125:\tlearn: 959.4928287\ttest: 957.6602964\tbest: 957.6602964 (125)\ttotal: 20.2s\tremaining: 2m 20s\n",
      "126:\tlearn: 958.8313893\ttest: 957.0832591\tbest: 957.0832591 (126)\ttotal: 20.4s\tremaining: 2m 20s\n",
      "127:\tlearn: 957.6734875\ttest: 955.9440624\tbest: 955.9440624 (127)\ttotal: 20.6s\tremaining: 2m 20s\n",
      "128:\tlearn: 956.9824714\ttest: 955.2938586\tbest: 955.2938586 (128)\ttotal: 20.7s\tremaining: 2m 19s\n",
      "129:\tlearn: 955.8094184\ttest: 954.1285463\tbest: 954.1285463 (129)\ttotal: 20.9s\tremaining: 2m 19s\n",
      "130:\tlearn: 954.7812045\ttest: 953.0447603\tbest: 953.0447603 (130)\ttotal: 21.1s\tremaining: 2m 19s\n",
      "131:\tlearn: 953.8883578\ttest: 952.1977104\tbest: 952.1977104 (131)\ttotal: 21.2s\tremaining: 2m 19s\n",
      "132:\tlearn: 952.3741140\ttest: 950.6950458\tbest: 950.6950458 (132)\ttotal: 21.4s\tremaining: 2m 19s\n",
      "133:\tlearn: 951.5385727\ttest: 949.9408506\tbest: 949.9408506 (133)\ttotal: 21.6s\tremaining: 2m 19s\n",
      "134:\tlearn: 950.1812654\ttest: 948.6068535\tbest: 948.6068535 (134)\ttotal: 21.7s\tremaining: 2m 19s\n",
      "135:\tlearn: 949.5313457\ttest: 948.0540165\tbest: 948.0540165 (135)\ttotal: 21.9s\tremaining: 2m 18s\n",
      "136:\tlearn: 948.8226365\ttest: 947.3280854\tbest: 947.3280854 (136)\ttotal: 22s\tremaining: 2m 18s\n",
      "137:\tlearn: 947.6345942\ttest: 946.1777581\tbest: 946.1777581 (137)\ttotal: 22.2s\tremaining: 2m 18s\n",
      "138:\tlearn: 946.6185117\ttest: 945.2687646\tbest: 945.2687646 (138)\ttotal: 22.3s\tremaining: 2m 18s\n",
      "139:\tlearn: 944.9032633\ttest: 943.5316381\tbest: 943.5316381 (139)\ttotal: 22.5s\tremaining: 2m 18s\n",
      "140:\tlearn: 943.8318050\ttest: 942.3742521\tbest: 942.3742521 (140)\ttotal: 22.6s\tremaining: 2m 17s\n",
      "141:\tlearn: 942.5561790\ttest: 941.0642689\tbest: 941.0642689 (141)\ttotal: 22.8s\tremaining: 2m 17s\n",
      "142:\tlearn: 941.3791747\ttest: 939.8888638\tbest: 939.8888638 (142)\ttotal: 22.9s\tremaining: 2m 17s\n",
      "143:\tlearn: 940.2830693\ttest: 938.8678250\tbest: 938.8678250 (143)\ttotal: 23.1s\tremaining: 2m 17s\n",
      "144:\tlearn: 939.3903844\ttest: 938.0728336\tbest: 938.0728336 (144)\ttotal: 23.2s\tremaining: 2m 16s\n",
      "145:\tlearn: 938.4795780\ttest: 937.0832711\tbest: 937.0832711 (145)\ttotal: 23.4s\tremaining: 2m 16s\n",
      "146:\tlearn: 937.5889023\ttest: 936.1167179\tbest: 936.1167179 (146)\ttotal: 23.5s\tremaining: 2m 16s\n",
      "147:\tlearn: 936.8603539\ttest: 935.3566259\tbest: 935.3566259 (147)\ttotal: 23.7s\tremaining: 2m 16s\n",
      "148:\tlearn: 935.7729094\ttest: 934.2831909\tbest: 934.2831909 (148)\ttotal: 23.8s\tremaining: 2m 16s\n",
      "149:\tlearn: 935.2212090\ttest: 933.7513896\tbest: 933.7513896 (149)\ttotal: 24s\tremaining: 2m 15s\n",
      "150:\tlearn: 934.5770631\ttest: 933.1028553\tbest: 933.1028553 (150)\ttotal: 24.1s\tremaining: 2m 15s\n",
      "151:\tlearn: 934.1129479\ttest: 932.6032871\tbest: 932.6032871 (151)\ttotal: 24.3s\tremaining: 2m 15s\n",
      "152:\tlearn: 933.4260210\ttest: 931.8892330\tbest: 931.8892330 (152)\ttotal: 24.5s\tremaining: 2m 15s\n",
      "153:\tlearn: 931.8666880\ttest: 930.2070238\tbest: 930.2070238 (153)\ttotal: 24.7s\tremaining: 2m 15s\n",
      "154:\tlearn: 931.0188982\ttest: 929.3644929\tbest: 929.3644929 (154)\ttotal: 24.9s\tremaining: 2m 15s\n",
      "155:\tlearn: 930.5328992\ttest: 928.8890446\tbest: 928.8890446 (155)\ttotal: 25s\tremaining: 2m 15s\n",
      "156:\tlearn: 928.7896035\ttest: 926.9498807\tbest: 926.9498807 (156)\ttotal: 25.2s\tremaining: 2m 15s\n",
      "157:\tlearn: 927.9448513\ttest: 926.1438385\tbest: 926.1438385 (157)\ttotal: 25.4s\tremaining: 2m 15s\n",
      "158:\tlearn: 926.9562901\ttest: 925.1781568\tbest: 925.1781568 (158)\ttotal: 25.6s\tremaining: 2m 15s\n",
      "159:\tlearn: 926.2825645\ttest: 924.5447425\tbest: 924.5447425 (159)\ttotal: 25.7s\tremaining: 2m 15s\n",
      "160:\tlearn: 924.4567086\ttest: 922.5856619\tbest: 922.5856619 (160)\ttotal: 25.9s\tremaining: 2m 14s\n",
      "161:\tlearn: 923.9015557\ttest: 922.0456694\tbest: 922.0456694 (161)\ttotal: 26s\tremaining: 2m 14s\n",
      "162:\tlearn: 922.9956288\ttest: 921.1877607\tbest: 921.1877607 (162)\ttotal: 26.2s\tremaining: 2m 14s\n",
      "163:\tlearn: 922.2983842\ttest: 920.4278795\tbest: 920.4278795 (163)\ttotal: 26.3s\tremaining: 2m 14s\n",
      "164:\tlearn: 921.6691516\ttest: 919.8715237\tbest: 919.8715237 (164)\ttotal: 26.5s\tremaining: 2m 13s\n",
      "165:\tlearn: 921.0931251\ttest: 919.2605599\tbest: 919.2605599 (165)\ttotal: 26.6s\tremaining: 2m 13s\n",
      "166:\tlearn: 920.5390293\ttest: 918.6921338\tbest: 918.6921338 (166)\ttotal: 26.8s\tremaining: 2m 13s\n",
      "167:\tlearn: 919.9290872\ttest: 918.0531802\tbest: 918.0531802 (167)\ttotal: 27s\tremaining: 2m 13s\n",
      "168:\tlearn: 919.1322576\ttest: 917.2584051\tbest: 917.2584051 (168)\ttotal: 27.1s\tremaining: 2m 13s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169:\tlearn: 918.1909696\ttest: 916.3903899\tbest: 916.3903899 (169)\ttotal: 27.3s\tremaining: 2m 13s\n",
      "170:\tlearn: 917.1812665\ttest: 915.3855215\tbest: 915.3855215 (170)\ttotal: 27.5s\tremaining: 2m 13s\n",
      "171:\tlearn: 916.4546186\ttest: 914.6955769\tbest: 914.6955769 (171)\ttotal: 27.7s\tremaining: 2m 13s\n",
      "172:\tlearn: 915.7226472\ttest: 913.9473420\tbest: 913.9473420 (172)\ttotal: 27.9s\tremaining: 2m 13s\n",
      "173:\tlearn: 915.1353847\ttest: 913.3361196\tbest: 913.3361196 (173)\ttotal: 28.1s\tremaining: 2m 13s\n",
      "174:\tlearn: 914.4622909\ttest: 912.4549581\tbest: 912.4549581 (174)\ttotal: 28.3s\tremaining: 2m 13s\n",
      "175:\tlearn: 914.0228774\ttest: 911.9596254\tbest: 911.9596254 (175)\ttotal: 28.4s\tremaining: 2m 13s\n",
      "176:\tlearn: 913.4086139\ttest: 911.3318407\tbest: 911.3318407 (176)\ttotal: 28.6s\tremaining: 2m 13s\n",
      "177:\tlearn: 912.8256270\ttest: 910.7675952\tbest: 910.7675952 (177)\ttotal: 28.8s\tremaining: 2m 13s\n",
      "178:\tlearn: 912.1891469\ttest: 910.1142657\tbest: 910.1142657 (178)\ttotal: 29s\tremaining: 2m 13s\n",
      "179:\tlearn: 911.4206247\ttest: 909.3005127\tbest: 909.3005127 (179)\ttotal: 29.2s\tremaining: 2m 13s\n",
      "180:\tlearn: 910.6798743\ttest: 908.6227784\tbest: 908.6227784 (180)\ttotal: 29.4s\tremaining: 2m 12s\n",
      "181:\tlearn: 910.0848099\ttest: 908.1220234\tbest: 908.1220234 (181)\ttotal: 29.6s\tremaining: 2m 12s\n",
      "182:\tlearn: 909.4978031\ttest: 907.5523637\tbest: 907.5523637 (182)\ttotal: 29.7s\tremaining: 2m 12s\n",
      "183:\tlearn: 908.3912156\ttest: 906.4089056\tbest: 906.4089056 (183)\ttotal: 29.9s\tremaining: 2m 12s\n",
      "184:\tlearn: 907.8804713\ttest: 905.9395149\tbest: 905.9395149 (184)\ttotal: 30.1s\tremaining: 2m 12s\n",
      "185:\tlearn: 907.0983355\ttest: 905.0711192\tbest: 905.0711192 (185)\ttotal: 30.2s\tremaining: 2m 12s\n",
      "186:\tlearn: 906.5657328\ttest: 904.4903488\tbest: 904.4903488 (186)\ttotal: 30.4s\tremaining: 2m 12s\n",
      "187:\tlearn: 905.6872606\ttest: 903.6402217\tbest: 903.6402217 (187)\ttotal: 30.5s\tremaining: 2m 11s\n",
      "188:\tlearn: 905.2060646\ttest: 903.2151720\tbest: 903.2151720 (188)\ttotal: 30.7s\tremaining: 2m 11s\n",
      "189:\tlearn: 904.6769511\ttest: 902.7232108\tbest: 902.7232108 (189)\ttotal: 30.8s\tremaining: 2m 11s\n",
      "190:\tlearn: 903.6502344\ttest: 901.7217338\tbest: 901.7217338 (190)\ttotal: 31s\tremaining: 2m 11s\n",
      "191:\tlearn: 902.6270752\ttest: 900.6759764\tbest: 900.6759764 (191)\ttotal: 31.1s\tremaining: 2m 10s\n",
      "192:\tlearn: 902.0841141\ttest: 900.2253970\tbest: 900.2253970 (192)\ttotal: 31.3s\tremaining: 2m 10s\n",
      "193:\tlearn: 901.5792050\ttest: 899.6821950\tbest: 899.6821950 (193)\ttotal: 31.4s\tremaining: 2m 10s\n",
      "194:\tlearn: 900.6943819\ttest: 898.7066879\tbest: 898.7066879 (194)\ttotal: 31.6s\tremaining: 2m 10s\n",
      "195:\tlearn: 899.8790627\ttest: 897.9726679\tbest: 897.9726679 (195)\ttotal: 31.7s\tremaining: 2m 10s\n",
      "196:\tlearn: 899.2458100\ttest: 897.3173689\tbest: 897.3173689 (196)\ttotal: 31.9s\tremaining: 2m 10s\n",
      "197:\tlearn: 898.6773360\ttest: 896.7367142\tbest: 896.7367142 (197)\ttotal: 32.1s\tremaining: 2m 9s\n",
      "198:\tlearn: 897.9361604\ttest: 896.0037004\tbest: 896.0037004 (198)\ttotal: 32.2s\tremaining: 2m 9s\n",
      "199:\tlearn: 897.4284785\ttest: 895.4688519\tbest: 895.4688519 (199)\ttotal: 32.3s\tremaining: 2m 9s\n",
      "200:\tlearn: 896.8749213\ttest: 894.8887747\tbest: 894.8887747 (200)\ttotal: 32.5s\tremaining: 2m 9s\n",
      "201:\tlearn: 896.2227031\ttest: 894.2231548\tbest: 894.2231548 (201)\ttotal: 32.7s\tremaining: 2m 9s\n",
      "202:\tlearn: 895.8587886\ttest: 893.8668359\tbest: 893.8668359 (202)\ttotal: 32.8s\tremaining: 2m 8s\n",
      "203:\tlearn: 895.4348706\ttest: 893.4997960\tbest: 893.4997960 (203)\ttotal: 33s\tremaining: 2m 8s\n",
      "204:\tlearn: 894.9075277\ttest: 893.0101735\tbest: 893.0101735 (204)\ttotal: 33.1s\tremaining: 2m 8s\n",
      "205:\tlearn: 894.5168712\ttest: 892.6089199\tbest: 892.6089199 (205)\ttotal: 33.3s\tremaining: 2m 8s\n",
      "206:\tlearn: 894.0612175\ttest: 892.1645491\tbest: 892.1645491 (206)\ttotal: 33.5s\tremaining: 2m 8s\n",
      "207:\tlearn: 893.6341974\ttest: 891.8189395\tbest: 891.8189395 (207)\ttotal: 33.6s\tremaining: 2m 7s\n",
      "208:\tlearn: 892.7568023\ttest: 890.9465221\tbest: 890.9465221 (208)\ttotal: 33.8s\tremaining: 2m 7s\n",
      "209:\tlearn: 892.3302491\ttest: 890.4135942\tbest: 890.4135942 (209)\ttotal: 33.9s\tremaining: 2m 7s\n",
      "210:\tlearn: 891.9382492\ttest: 890.0466788\tbest: 890.0466788 (210)\ttotal: 34.1s\tremaining: 2m 7s\n",
      "211:\tlearn: 891.2323491\ttest: 889.4725983\tbest: 889.4725983 (211)\ttotal: 34.2s\tremaining: 2m 7s\n",
      "212:\tlearn: 890.7679192\ttest: 889.0073544\tbest: 889.0073544 (212)\ttotal: 34.4s\tremaining: 2m 7s\n",
      "213:\tlearn: 890.3955200\ttest: 888.6672051\tbest: 888.6672051 (213)\ttotal: 34.6s\tremaining: 2m 7s\n",
      "214:\tlearn: 890.0758629\ttest: 888.3909064\tbest: 888.3909064 (214)\ttotal: 34.8s\tremaining: 2m 6s\n",
      "215:\tlearn: 889.4548997\ttest: 887.8419583\tbest: 887.8419583 (215)\ttotal: 34.9s\tremaining: 2m 6s\n",
      "216:\tlearn: 888.9397063\ttest: 887.4467931\tbest: 887.4467931 (216)\ttotal: 35.1s\tremaining: 2m 6s\n",
      "217:\tlearn: 888.4593021\ttest: 886.9073717\tbest: 886.9073717 (217)\ttotal: 35.2s\tremaining: 2m 6s\n",
      "218:\tlearn: 887.9446402\ttest: 886.4238085\tbest: 886.4238085 (218)\ttotal: 35.4s\tremaining: 2m 6s\n",
      "219:\tlearn: 887.5654148\ttest: 886.0417336\tbest: 886.0417336 (219)\ttotal: 35.5s\tremaining: 2m 5s\n",
      "220:\tlearn: 887.1856290\ttest: 885.6672403\tbest: 885.6672403 (220)\ttotal: 35.7s\tremaining: 2m 5s\n",
      "221:\tlearn: 886.6995219\ttest: 885.1651525\tbest: 885.1651525 (221)\ttotal: 35.9s\tremaining: 2m 5s\n",
      "222:\tlearn: 886.2102864\ttest: 884.7090372\tbest: 884.7090372 (222)\ttotal: 36s\tremaining: 2m 5s\n",
      "223:\tlearn: 885.8304311\ttest: 884.3244626\tbest: 884.3244626 (223)\ttotal: 36.2s\tremaining: 2m 5s\n",
      "224:\tlearn: 885.1327716\ttest: 883.6421455\tbest: 883.6421455 (224)\ttotal: 36.3s\tremaining: 2m 5s\n",
      "225:\tlearn: 884.7472279\ttest: 883.3581990\tbest: 883.3581990 (225)\ttotal: 36.5s\tremaining: 2m 4s\n",
      "226:\tlearn: 884.0417459\ttest: 882.6688506\tbest: 882.6688506 (226)\ttotal: 36.6s\tremaining: 2m 4s\n",
      "227:\tlearn: 883.0089315\ttest: 881.6435181\tbest: 881.6435181 (227)\ttotal: 36.8s\tremaining: 2m 4s\n",
      "228:\tlearn: 882.4306313\ttest: 881.0607754\tbest: 881.0607754 (228)\ttotal: 37s\tremaining: 2m 4s\n",
      "229:\tlearn: 881.8224314\ttest: 880.4615868\tbest: 880.4615868 (229)\ttotal: 37.1s\tremaining: 2m 4s\n",
      "230:\tlearn: 880.6585739\ttest: 879.2204457\tbest: 879.2204457 (230)\ttotal: 37.3s\tremaining: 2m 4s\n",
      "231:\tlearn: 880.1321960\ttest: 878.7406349\tbest: 878.7406349 (231)\ttotal: 37.4s\tremaining: 2m 3s\n",
      "232:\tlearn: 879.7759735\ttest: 878.4424910\tbest: 878.4424910 (232)\ttotal: 37.6s\tremaining: 2m 3s\n",
      "233:\tlearn: 879.1659856\ttest: 877.7816501\tbest: 877.7816501 (233)\ttotal: 37.7s\tremaining: 2m 3s\n",
      "234:\tlearn: 878.7590667\ttest: 877.2887795\tbest: 877.2887795 (234)\ttotal: 37.9s\tremaining: 2m 3s\n",
      "235:\tlearn: 878.3828798\ttest: 876.9008992\tbest: 876.9008992 (235)\ttotal: 38s\tremaining: 2m 3s\n",
      "236:\tlearn: 877.9839776\ttest: 876.5023803\tbest: 876.5023803 (236)\ttotal: 38.2s\tremaining: 2m 2s\n",
      "237:\tlearn: 877.4379607\ttest: 875.9519234\tbest: 875.9519234 (237)\ttotal: 38.3s\tremaining: 2m 2s\n",
      "238:\tlearn: 876.4084505\ttest: 874.8101708\tbest: 874.8101708 (238)\ttotal: 38.5s\tremaining: 2m 2s\n",
      "239:\tlearn: 875.9707711\ttest: 874.3855685\tbest: 874.3855685 (239)\ttotal: 38.6s\tremaining: 2m 2s\n",
      "240:\tlearn: 875.3976199\ttest: 873.7195430\tbest: 873.7195430 (240)\ttotal: 38.8s\tremaining: 2m 2s\n",
      "241:\tlearn: 875.2601841\ttest: 873.5814837\tbest: 873.5814837 (241)\ttotal: 39s\tremaining: 2m 2s\n",
      "242:\tlearn: 874.9471504\ttest: 873.2379222\tbest: 873.2379222 (242)\ttotal: 39.1s\tremaining: 2m 1s\n",
      "243:\tlearn: 874.5581234\ttest: 872.8964147\tbest: 872.8964147 (243)\ttotal: 39.2s\tremaining: 2m 1s\n",
      "244:\tlearn: 874.1893990\ttest: 872.5093199\tbest: 872.5093199 (244)\ttotal: 39.4s\tremaining: 2m 1s\n",
      "245:\tlearn: 873.6609201\ttest: 871.9650645\tbest: 871.9650645 (245)\ttotal: 39.6s\tremaining: 2m 1s\n",
      "246:\tlearn: 873.3096913\ttest: 871.5698050\tbest: 871.5698050 (246)\ttotal: 39.7s\tremaining: 2m 1s\n",
      "247:\tlearn: 872.5639169\ttest: 870.8012005\tbest: 870.8012005 (247)\ttotal: 39.9s\tremaining: 2m\n",
      "248:\tlearn: 872.1161672\ttest: 870.3693189\tbest: 870.3693189 (248)\ttotal: 40s\tremaining: 2m\n",
      "249:\tlearn: 871.5815603\ttest: 869.7904237\tbest: 869.7904237 (249)\ttotal: 40.2s\tremaining: 2m\n",
      "250:\tlearn: 871.1188440\ttest: 869.2876489\tbest: 869.2876489 (250)\ttotal: 40.3s\tremaining: 2m\n",
      "251:\tlearn: 870.5849821\ttest: 868.7468877\tbest: 868.7468877 (251)\ttotal: 40.5s\tremaining: 2m\n",
      "252:\tlearn: 870.0641988\ttest: 868.2298054\tbest: 868.2298054 (252)\ttotal: 40.7s\tremaining: 2m\n",
      "253:\tlearn: 869.6354612\ttest: 867.7127813\tbest: 867.7127813 (253)\ttotal: 40.8s\tremaining: 1m 59s\n",
      "254:\tlearn: 869.2806269\ttest: 867.3154949\tbest: 867.3154949 (254)\ttotal: 41s\tremaining: 1m 59s\n",
      "255:\tlearn: 868.5133637\ttest: 866.4782449\tbest: 866.4782449 (255)\ttotal: 41.1s\tremaining: 1m 59s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256:\tlearn: 868.0250475\ttest: 866.0247137\tbest: 866.0247137 (256)\ttotal: 41.3s\tremaining: 1m 59s\n",
      "257:\tlearn: 867.3875738\ttest: 865.6479897\tbest: 865.6479897 (257)\ttotal: 41.4s\tremaining: 1m 59s\n",
      "258:\tlearn: 867.1177133\ttest: 865.4180663\tbest: 865.4180663 (258)\ttotal: 41.6s\tremaining: 1m 58s\n",
      "259:\tlearn: 866.8964442\ttest: 865.1878001\tbest: 865.1878001 (259)\ttotal: 41.7s\tremaining: 1m 58s\n",
      "260:\tlearn: 866.5444118\ttest: 864.8498272\tbest: 864.8498272 (260)\ttotal: 41.9s\tremaining: 1m 58s\n",
      "261:\tlearn: 866.1395419\ttest: 864.4661938\tbest: 864.4661938 (261)\ttotal: 42s\tremaining: 1m 58s\n",
      "262:\tlearn: 865.7556611\ttest: 864.0842382\tbest: 864.0842382 (262)\ttotal: 42.2s\tremaining: 1m 58s\n",
      "263:\tlearn: 865.3141208\ttest: 863.6064815\tbest: 863.6064815 (263)\ttotal: 42.3s\tremaining: 1m 58s\n",
      "264:\tlearn: 864.8021269\ttest: 863.0612327\tbest: 863.0612327 (264)\ttotal: 42.5s\tremaining: 1m 57s\n",
      "265:\tlearn: 864.0420835\ttest: 862.2524686\tbest: 862.2524686 (265)\ttotal: 42.7s\tremaining: 1m 57s\n",
      "266:\tlearn: 863.6759627\ttest: 861.8968846\tbest: 861.8968846 (266)\ttotal: 42.8s\tremaining: 1m 57s\n",
      "267:\tlearn: 863.3441016\ttest: 861.5992482\tbest: 861.5992482 (267)\ttotal: 43s\tremaining: 1m 57s\n",
      "268:\tlearn: 862.9765281\ttest: 861.3183437\tbest: 861.3183437 (268)\ttotal: 43.1s\tremaining: 1m 57s\n",
      "269:\tlearn: 862.5947018\ttest: 860.9876064\tbest: 860.9876064 (269)\ttotal: 43.3s\tremaining: 1m 56s\n",
      "270:\tlearn: 862.1055108\ttest: 860.5069594\tbest: 860.5069594 (270)\ttotal: 43.4s\tremaining: 1m 56s\n",
      "271:\tlearn: 861.7343878\ttest: 860.1564767\tbest: 860.1564767 (271)\ttotal: 43.6s\tremaining: 1m 56s\n",
      "272:\tlearn: 861.3707978\ttest: 859.7329244\tbest: 859.7329244 (272)\ttotal: 43.8s\tremaining: 1m 56s\n",
      "273:\tlearn: 860.9985466\ttest: 859.3714296\tbest: 859.3714296 (273)\ttotal: 43.9s\tremaining: 1m 56s\n",
      "274:\tlearn: 860.7121491\ttest: 859.1005913\tbest: 859.1005913 (274)\ttotal: 44.1s\tremaining: 1m 56s\n",
      "275:\tlearn: 860.3773525\ttest: 858.8008675\tbest: 858.8008675 (275)\ttotal: 44.2s\tremaining: 1m 56s\n",
      "276:\tlearn: 859.9646546\ttest: 858.3934737\tbest: 858.3934737 (276)\ttotal: 44.4s\tremaining: 1m 55s\n",
      "277:\tlearn: 859.5402685\ttest: 858.0096054\tbest: 858.0096054 (277)\ttotal: 44.5s\tremaining: 1m 55s\n",
      "278:\tlearn: 859.2759025\ttest: 857.7473374\tbest: 857.7473374 (278)\ttotal: 44.7s\tremaining: 1m 55s\n",
      "279:\tlearn: 858.8671220\ttest: 857.3379550\tbest: 857.3379550 (279)\ttotal: 44.9s\tremaining: 1m 55s\n",
      "280:\tlearn: 858.3672537\ttest: 856.8138528\tbest: 856.8138528 (280)\ttotal: 45.1s\tremaining: 1m 55s\n",
      "281:\tlearn: 857.9397610\ttest: 856.4055497\tbest: 856.4055497 (281)\ttotal: 45.3s\tremaining: 1m 55s\n",
      "282:\tlearn: 857.5669000\ttest: 855.9925450\tbest: 855.9925450 (282)\ttotal: 45.5s\tremaining: 1m 55s\n",
      "283:\tlearn: 857.1219198\ttest: 855.5433810\tbest: 855.5433810 (283)\ttotal: 45.6s\tremaining: 1m 55s\n",
      "284:\tlearn: 856.9279770\ttest: 855.3015856\tbest: 855.3015856 (284)\ttotal: 45.8s\tremaining: 1m 54s\n",
      "285:\tlearn: 856.5454592\ttest: 854.9140043\tbest: 854.9140043 (285)\ttotal: 46s\tremaining: 1m 54s\n",
      "286:\tlearn: 856.2195346\ttest: 854.6276113\tbest: 854.6276113 (286)\ttotal: 46.1s\tremaining: 1m 54s\n",
      "287:\tlearn: 855.7944247\ttest: 854.2219951\tbest: 854.2219951 (287)\ttotal: 46.3s\tremaining: 1m 54s\n",
      "288:\tlearn: 855.5240195\ttest: 853.9129535\tbest: 853.9129535 (288)\ttotal: 46.4s\tremaining: 1m 54s\n",
      "289:\tlearn: 855.3477639\ttest: 853.7400342\tbest: 853.7400342 (289)\ttotal: 46.6s\tremaining: 1m 54s\n",
      "290:\tlearn: 855.0330762\ttest: 853.3677727\tbest: 853.3677727 (290)\ttotal: 46.7s\tremaining: 1m 53s\n",
      "291:\tlearn: 854.3833501\ttest: 852.7235271\tbest: 852.7235271 (291)\ttotal: 46.9s\tremaining: 1m 53s\n",
      "292:\tlearn: 854.0522057\ttest: 852.5509102\tbest: 852.5509102 (292)\ttotal: 47.1s\tremaining: 1m 53s\n",
      "293:\tlearn: 853.6371277\ttest: 852.1346547\tbest: 852.1346547 (293)\ttotal: 47.2s\tremaining: 1m 53s\n",
      "294:\tlearn: 853.2649875\ttest: 851.7748122\tbest: 851.7748122 (294)\ttotal: 47.4s\tremaining: 1m 53s\n",
      "295:\tlearn: 852.7099217\ttest: 851.1684726\tbest: 851.1684726 (295)\ttotal: 47.5s\tremaining: 1m 53s\n",
      "296:\tlearn: 852.3719359\ttest: 850.8160621\tbest: 850.8160621 (296)\ttotal: 47.7s\tremaining: 1m 52s\n",
      "297:\tlearn: 852.0952976\ttest: 850.5759192\tbest: 850.5759192 (297)\ttotal: 47.9s\tremaining: 1m 52s\n",
      "298:\tlearn: 851.5401741\ttest: 849.9549650\tbest: 849.9549650 (298)\ttotal: 48s\tremaining: 1m 52s\n",
      "299:\tlearn: 851.1548798\ttest: 849.5563596\tbest: 849.5563596 (299)\ttotal: 48.2s\tremaining: 1m 52s\n",
      "300:\tlearn: 850.7093317\ttest: 849.1127723\tbest: 849.1127723 (300)\ttotal: 48.3s\tremaining: 1m 52s\n",
      "301:\tlearn: 850.4267452\ttest: 848.8766463\tbest: 848.8766463 (301)\ttotal: 48.5s\tremaining: 1m 52s\n",
      "302:\tlearn: 850.0317734\ttest: 848.5684294\tbest: 848.5684294 (302)\ttotal: 48.6s\tremaining: 1m 51s\n",
      "303:\tlearn: 849.6869833\ttest: 848.2243806\tbest: 848.2243806 (303)\ttotal: 48.8s\tremaining: 1m 51s\n",
      "304:\tlearn: 849.4644272\ttest: 848.0041428\tbest: 848.0041428 (304)\ttotal: 48.9s\tremaining: 1m 51s\n",
      "305:\tlearn: 849.1302851\ttest: 847.6385117\tbest: 847.6385117 (305)\ttotal: 49.1s\tremaining: 1m 51s\n",
      "306:\tlearn: 848.7733941\ttest: 847.2817778\tbest: 847.2817778 (306)\ttotal: 49.3s\tremaining: 1m 51s\n",
      "307:\tlearn: 848.4918114\ttest: 846.9810478\tbest: 846.9810478 (307)\ttotal: 49.5s\tremaining: 1m 51s\n",
      "308:\tlearn: 848.1719859\ttest: 846.6852534\tbest: 846.6852534 (308)\ttotal: 49.6s\tremaining: 1m 50s\n",
      "309:\tlearn: 847.7120878\ttest: 846.1921428\tbest: 846.1921428 (309)\ttotal: 49.8s\tremaining: 1m 50s\n",
      "310:\tlearn: 847.3982079\ttest: 845.8099569\tbest: 845.8099569 (310)\ttotal: 49.9s\tremaining: 1m 50s\n",
      "311:\tlearn: 847.0087710\ttest: 845.3746014\tbest: 845.3746014 (311)\ttotal: 50.1s\tremaining: 1m 50s\n",
      "312:\tlearn: 846.7785833\ttest: 845.1713509\tbest: 845.1713509 (312)\ttotal: 50.2s\tremaining: 1m 50s\n",
      "313:\tlearn: 846.5465540\ttest: 844.9272573\tbest: 844.9272573 (313)\ttotal: 50.4s\tremaining: 1m 50s\n",
      "314:\tlearn: 846.1190916\ttest: 844.4603227\tbest: 844.4603227 (314)\ttotal: 50.6s\tremaining: 1m 50s\n",
      "315:\tlearn: 845.7356077\ttest: 844.0476340\tbest: 844.0476340 (315)\ttotal: 50.8s\tremaining: 1m 49s\n",
      "316:\tlearn: 845.4699784\ttest: 843.8278299\tbest: 843.8278299 (316)\ttotal: 50.9s\tremaining: 1m 49s\n",
      "317:\tlearn: 845.2279342\ttest: 843.6330295\tbest: 843.6330295 (317)\ttotal: 51.1s\tremaining: 1m 49s\n",
      "318:\tlearn: 844.9557270\ttest: 843.3922840\tbest: 843.3922840 (318)\ttotal: 51.2s\tremaining: 1m 49s\n",
      "319:\tlearn: 844.5591305\ttest: 843.0148369\tbest: 843.0148369 (319)\ttotal: 51.4s\tremaining: 1m 49s\n",
      "320:\tlearn: 844.2652077\ttest: 842.7624562\tbest: 842.7624562 (320)\ttotal: 51.6s\tremaining: 1m 49s\n",
      "321:\tlearn: 844.0489209\ttest: 842.5666809\tbest: 842.5666809 (321)\ttotal: 51.7s\tremaining: 1m 48s\n",
      "322:\tlearn: 843.7454816\ttest: 842.2694284\tbest: 842.2694284 (322)\ttotal: 51.8s\tremaining: 1m 48s\n",
      "323:\tlearn: 843.2623817\ttest: 841.7574683\tbest: 841.7574683 (323)\ttotal: 52s\tremaining: 1m 48s\n",
      "324:\tlearn: 842.5846763\ttest: 841.0789517\tbest: 841.0789517 (324)\ttotal: 52.2s\tremaining: 1m 48s\n",
      "325:\tlearn: 842.3440398\ttest: 840.8630215\tbest: 840.8630215 (325)\ttotal: 52.4s\tremaining: 1m 48s\n",
      "326:\tlearn: 841.9436906\ttest: 840.4528982\tbest: 840.4528982 (326)\ttotal: 52.5s\tremaining: 1m 48s\n",
      "327:\tlearn: 841.5792880\ttest: 840.0989673\tbest: 840.0989673 (327)\ttotal: 52.6s\tremaining: 1m 47s\n",
      "328:\tlearn: 840.9592824\ttest: 839.4690658\tbest: 839.4690658 (328)\ttotal: 52.8s\tremaining: 1m 47s\n",
      "329:\tlearn: 840.5318633\ttest: 838.9812811\tbest: 838.9812811 (329)\ttotal: 53s\tremaining: 1m 47s\n",
      "330:\tlearn: 840.3101163\ttest: 838.6627815\tbest: 838.6627815 (330)\ttotal: 53.1s\tremaining: 1m 47s\n",
      "331:\tlearn: 839.7554450\ttest: 838.1114519\tbest: 838.1114519 (331)\ttotal: 53.3s\tremaining: 1m 47s\n",
      "332:\tlearn: 839.4287379\ttest: 837.8228654\tbest: 837.8228654 (332)\ttotal: 53.4s\tremaining: 1m 47s\n",
      "333:\tlearn: 838.9833850\ttest: 837.3567334\tbest: 837.3567334 (333)\ttotal: 53.6s\tremaining: 1m 46s\n",
      "334:\tlearn: 838.5914824\ttest: 836.9527795\tbest: 836.9527795 (334)\ttotal: 53.7s\tremaining: 1m 46s\n",
      "335:\tlearn: 838.3133063\ttest: 836.6688843\tbest: 836.6688843 (335)\ttotal: 53.9s\tremaining: 1m 46s\n",
      "336:\tlearn: 838.0128038\ttest: 836.3495363\tbest: 836.3495363 (336)\ttotal: 54.1s\tremaining: 1m 46s\n",
      "337:\tlearn: 837.5899242\ttest: 835.9411487\tbest: 835.9411487 (337)\ttotal: 54.2s\tremaining: 1m 46s\n",
      "338:\tlearn: 837.1447733\ttest: 835.4558593\tbest: 835.4558593 (338)\ttotal: 54.4s\tremaining: 1m 46s\n",
      "339:\tlearn: 836.9102478\ttest: 835.2582152\tbest: 835.2582152 (339)\ttotal: 54.5s\tremaining: 1m 45s\n",
      "340:\tlearn: 836.3136915\ttest: 834.5824883\tbest: 834.5824883 (340)\ttotal: 54.7s\tremaining: 1m 45s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341:\tlearn: 835.7777873\ttest: 834.0577292\tbest: 834.0577292 (341)\ttotal: 54.8s\tremaining: 1m 45s\n",
      "342:\tlearn: 835.4645175\ttest: 833.7576596\tbest: 833.7576596 (342)\ttotal: 55s\tremaining: 1m 45s\n",
      "343:\tlearn: 835.1093628\ttest: 833.4050273\tbest: 833.4050273 (343)\ttotal: 55.1s\tremaining: 1m 45s\n",
      "344:\tlearn: 834.8989890\ttest: 833.2264820\tbest: 833.2264820 (344)\ttotal: 55.3s\tremaining: 1m 44s\n",
      "345:\tlearn: 834.5323909\ttest: 832.8075694\tbest: 832.8075694 (345)\ttotal: 55.4s\tremaining: 1m 44s\n",
      "346:\tlearn: 834.2241464\ttest: 832.4993362\tbest: 832.4993362 (346)\ttotal: 55.6s\tremaining: 1m 44s\n",
      "347:\tlearn: 833.8915781\ttest: 832.1434508\tbest: 832.1434508 (347)\ttotal: 55.7s\tremaining: 1m 44s\n",
      "348:\tlearn: 833.6206972\ttest: 831.8505255\tbest: 831.8505255 (348)\ttotal: 55.9s\tremaining: 1m 44s\n",
      "349:\tlearn: 833.4605520\ttest: 831.6964801\tbest: 831.6964801 (349)\ttotal: 56.1s\tremaining: 1m 44s\n",
      "350:\tlearn: 833.0358867\ttest: 831.2323880\tbest: 831.2323880 (350)\ttotal: 56.2s\tremaining: 1m 43s\n",
      "351:\tlearn: 832.6992579\ttest: 830.8128561\tbest: 830.8128561 (351)\ttotal: 56.4s\tremaining: 1m 43s\n",
      "352:\tlearn: 832.4661571\ttest: 830.6173154\tbest: 830.6173154 (352)\ttotal: 56.6s\tremaining: 1m 43s\n",
      "353:\tlearn: 832.2454391\ttest: 830.4015973\tbest: 830.4015973 (353)\ttotal: 56.7s\tremaining: 1m 43s\n",
      "354:\tlearn: 832.0350854\ttest: 830.2155374\tbest: 830.2155374 (354)\ttotal: 56.9s\tremaining: 1m 43s\n",
      "355:\tlearn: 831.8105695\ttest: 830.0011692\tbest: 830.0011692 (355)\ttotal: 57.1s\tremaining: 1m 43s\n",
      "356:\tlearn: 831.4613477\ttest: 829.5866998\tbest: 829.5866998 (356)\ttotal: 57.2s\tremaining: 1m 43s\n",
      "357:\tlearn: 831.2418864\ttest: 829.3694882\tbest: 829.3694882 (357)\ttotal: 57.4s\tremaining: 1m 42s\n",
      "358:\tlearn: 830.9483247\ttest: 829.1397036\tbest: 829.1397036 (358)\ttotal: 57.5s\tremaining: 1m 42s\n",
      "359:\tlearn: 830.6121588\ttest: 828.7829890\tbest: 828.7829890 (359)\ttotal: 57.7s\tremaining: 1m 42s\n",
      "360:\tlearn: 830.3510748\ttest: 828.3486359\tbest: 828.3486359 (360)\ttotal: 57.8s\tremaining: 1m 42s\n",
      "361:\tlearn: 829.8630732\ttest: 827.8449784\tbest: 827.8449784 (361)\ttotal: 58s\tremaining: 1m 42s\n",
      "362:\tlearn: 829.6491404\ttest: 827.5861865\tbest: 827.5861865 (362)\ttotal: 58.2s\tremaining: 1m 42s\n",
      "363:\tlearn: 829.2610193\ttest: 827.1967565\tbest: 827.1967565 (363)\ttotal: 58.3s\tremaining: 1m 41s\n",
      "364:\tlearn: 829.1910976\ttest: 827.1270540\tbest: 827.1270540 (364)\ttotal: 58.5s\tremaining: 1m 41s\n",
      "365:\tlearn: 828.9274295\ttest: 826.8443696\tbest: 826.8443696 (365)\ttotal: 58.6s\tremaining: 1m 41s\n",
      "366:\tlearn: 828.6766899\ttest: 826.5910317\tbest: 826.5910317 (366)\ttotal: 58.8s\tremaining: 1m 41s\n",
      "367:\tlearn: 828.4081047\ttest: 826.3140981\tbest: 826.3140981 (367)\ttotal: 58.9s\tremaining: 1m 41s\n",
      "368:\tlearn: 828.2105953\ttest: 826.1021667\tbest: 826.1021667 (368)\ttotal: 59.1s\tremaining: 1m 41s\n",
      "369:\tlearn: 827.9966707\ttest: 825.9106668\tbest: 825.9106668 (369)\ttotal: 59.2s\tremaining: 1m 40s\n",
      "370:\tlearn: 827.7377828\ttest: 825.6616988\tbest: 825.6616988 (370)\ttotal: 59.4s\tremaining: 1m 40s\n",
      "371:\tlearn: 827.4356344\ttest: 825.2992236\tbest: 825.2992236 (371)\ttotal: 59.6s\tremaining: 1m 40s\n",
      "372:\tlearn: 827.1944629\ttest: 825.0439318\tbest: 825.0439318 (372)\ttotal: 59.7s\tremaining: 1m 40s\n",
      "373:\tlearn: 826.9188529\ttest: 824.7468050\tbest: 824.7468050 (373)\ttotal: 59.9s\tremaining: 1m 40s\n",
      "374:\tlearn: 826.6516719\ttest: 824.4718545\tbest: 824.4718545 (374)\ttotal: 1m\tremaining: 1m 40s\n",
      "375:\tlearn: 826.4241506\ttest: 824.2503672\tbest: 824.2503672 (375)\ttotal: 1m\tremaining: 1m 39s\n",
      "376:\tlearn: 826.1652751\ttest: 823.9844169\tbest: 823.9844169 (376)\ttotal: 1m\tremaining: 1m 39s\n",
      "377:\tlearn: 825.8229188\ttest: 823.6244976\tbest: 823.6244976 (377)\ttotal: 1m\tremaining: 1m 39s\n",
      "378:\tlearn: 825.5976463\ttest: 823.3872584\tbest: 823.3872584 (378)\ttotal: 1m\tremaining: 1m 39s\n",
      "379:\tlearn: 825.3654208\ttest: 823.1601008\tbest: 823.1601008 (379)\ttotal: 1m\tremaining: 1m 39s\n",
      "380:\tlearn: 825.0292209\ttest: 822.8455518\tbest: 822.8455518 (380)\ttotal: 1m 1s\tremaining: 1m 39s\n",
      "381:\tlearn: 824.8107552\ttest: 822.6418112\tbest: 822.6418112 (381)\ttotal: 1m 1s\tremaining: 1m 38s\n",
      "382:\tlearn: 824.7183967\ttest: 822.5460449\tbest: 822.5460449 (382)\ttotal: 1m 1s\tremaining: 1m 38s\n",
      "383:\tlearn: 824.4655006\ttest: 822.2586518\tbest: 822.2586518 (383)\ttotal: 1m 1s\tremaining: 1m 38s\n",
      "384:\tlearn: 824.1742101\ttest: 821.9592499\tbest: 821.9592499 (384)\ttotal: 1m 1s\tremaining: 1m 38s\n",
      "385:\tlearn: 823.9933046\ttest: 821.7960057\tbest: 821.7960057 (385)\ttotal: 1m 1s\tremaining: 1m 38s\n",
      "386:\tlearn: 823.7383394\ttest: 821.5656571\tbest: 821.5656571 (386)\ttotal: 1m 2s\tremaining: 1m 38s\n",
      "387:\tlearn: 823.6315294\ttest: 821.4753207\tbest: 821.4753207 (387)\ttotal: 1m 2s\tremaining: 1m 38s\n",
      "388:\tlearn: 823.3080197\ttest: 821.2317063\tbest: 821.2317063 (388)\ttotal: 1m 2s\tremaining: 1m 38s\n",
      "389:\tlearn: 822.9665789\ttest: 820.8941697\tbest: 820.8941697 (389)\ttotal: 1m 2s\tremaining: 1m 37s\n",
      "390:\tlearn: 822.8035368\ttest: 820.7486164\tbest: 820.7486164 (390)\ttotal: 1m 2s\tremaining: 1m 37s\n",
      "391:\tlearn: 822.5521966\ttest: 820.4872448\tbest: 820.4872448 (391)\ttotal: 1m 2s\tremaining: 1m 37s\n",
      "392:\tlearn: 822.3145044\ttest: 820.2580010\tbest: 820.2580010 (392)\ttotal: 1m 3s\tremaining: 1m 37s\n",
      "393:\tlearn: 822.1067824\ttest: 820.0274747\tbest: 820.0274747 (393)\ttotal: 1m 3s\tremaining: 1m 37s\n",
      "394:\tlearn: 821.7820343\ttest: 819.6923897\tbest: 819.6923897 (394)\ttotal: 1m 3s\tremaining: 1m 37s\n",
      "395:\tlearn: 821.5552046\ttest: 819.4876062\tbest: 819.4876062 (395)\ttotal: 1m 3s\tremaining: 1m 36s\n",
      "396:\tlearn: 821.1800908\ttest: 819.1346336\tbest: 819.1346336 (396)\ttotal: 1m 3s\tremaining: 1m 36s\n",
      "397:\tlearn: 820.8635405\ttest: 818.9709513\tbest: 818.9709513 (397)\ttotal: 1m 3s\tremaining: 1m 36s\n",
      "398:\tlearn: 820.5430078\ttest: 818.6711583\tbest: 818.6711583 (398)\ttotal: 1m 3s\tremaining: 1m 36s\n",
      "399:\tlearn: 820.3542623\ttest: 818.4908513\tbest: 818.4908513 (399)\ttotal: 1m 4s\tremaining: 1m 36s\n",
      "400:\tlearn: 820.0819453\ttest: 818.1822572\tbest: 818.1822572 (400)\ttotal: 1m 4s\tremaining: 1m 36s\n",
      "401:\tlearn: 819.8021992\ttest: 817.8815559\tbest: 817.8815559 (401)\ttotal: 1m 4s\tremaining: 1m 35s\n",
      "402:\tlearn: 819.6278447\ttest: 817.7002203\tbest: 817.7002203 (402)\ttotal: 1m 4s\tremaining: 1m 35s\n",
      "403:\tlearn: 819.5116622\ttest: 817.6168059\tbest: 817.6168059 (403)\ttotal: 1m 4s\tremaining: 1m 35s\n",
      "404:\tlearn: 819.1725528\ttest: 817.2298139\tbest: 817.2298139 (404)\ttotal: 1m 4s\tremaining: 1m 35s\n",
      "405:\tlearn: 818.8628342\ttest: 816.8778090\tbest: 816.8778090 (405)\ttotal: 1m 5s\tremaining: 1m 35s\n",
      "406:\tlearn: 818.6305667\ttest: 816.6458757\tbest: 816.6458757 (406)\ttotal: 1m 5s\tremaining: 1m 34s\n",
      "407:\tlearn: 818.2190651\ttest: 816.1571796\tbest: 816.1571796 (407)\ttotal: 1m 5s\tremaining: 1m 34s\n",
      "408:\tlearn: 817.9616030\ttest: 815.9744406\tbest: 815.9744406 (408)\ttotal: 1m 5s\tremaining: 1m 34s\n",
      "409:\tlearn: 817.6945049\ttest: 815.6746184\tbest: 815.6746184 (409)\ttotal: 1m 5s\tremaining: 1m 34s\n",
      "410:\tlearn: 817.4632144\ttest: 815.5025101\tbest: 815.5025101 (410)\ttotal: 1m 5s\tremaining: 1m 34s\n",
      "411:\tlearn: 817.1942173\ttest: 815.2367996\tbest: 815.2367996 (411)\ttotal: 1m 5s\tremaining: 1m 34s\n",
      "412:\tlearn: 816.6762528\ttest: 814.7275855\tbest: 814.7275855 (412)\ttotal: 1m 6s\tremaining: 1m 33s\n",
      "413:\tlearn: 816.3774521\ttest: 814.4197398\tbest: 814.4197398 (413)\ttotal: 1m 6s\tremaining: 1m 33s\n",
      "414:\tlearn: 816.1252172\ttest: 814.1869286\tbest: 814.1869286 (414)\ttotal: 1m 6s\tremaining: 1m 33s\n",
      "415:\tlearn: 815.7068909\ttest: 813.7438378\tbest: 813.7438378 (415)\ttotal: 1m 6s\tremaining: 1m 33s\n",
      "416:\tlearn: 815.4165027\ttest: 813.4474467\tbest: 813.4474467 (416)\ttotal: 1m 6s\tremaining: 1m 33s\n",
      "417:\tlearn: 815.1376893\ttest: 813.1396608\tbest: 813.1396608 (417)\ttotal: 1m 6s\tremaining: 1m 33s\n",
      "418:\tlearn: 814.9841522\ttest: 812.9956825\tbest: 812.9956825 (418)\ttotal: 1m 7s\tremaining: 1m 32s\n",
      "419:\tlearn: 814.7203300\ttest: 812.7482707\tbest: 812.7482707 (419)\ttotal: 1m 7s\tremaining: 1m 32s\n",
      "420:\tlearn: 814.3913865\ttest: 812.4417655\tbest: 812.4417655 (420)\ttotal: 1m 7s\tremaining: 1m 32s\n",
      "421:\tlearn: 814.1370021\ttest: 812.1785003\tbest: 812.1785003 (421)\ttotal: 1m 7s\tremaining: 1m 32s\n",
      "422:\tlearn: 813.9042969\ttest: 811.8786288\tbest: 811.8786288 (422)\ttotal: 1m 7s\tremaining: 1m 32s\n",
      "423:\tlearn: 813.5045184\ttest: 811.5226350\tbest: 811.5226350 (423)\ttotal: 1m 7s\tremaining: 1m 32s\n",
      "424:\tlearn: 813.1824471\ttest: 811.1629534\tbest: 811.1629534 (424)\ttotal: 1m 7s\tremaining: 1m 31s\n",
      "425:\tlearn: 812.9749150\ttest: 810.9685041\tbest: 810.9685041 (425)\ttotal: 1m 8s\tremaining: 1m 31s\n",
      "426:\tlearn: 812.5831891\ttest: 810.6133241\tbest: 810.6133241 (426)\ttotal: 1m 8s\tremaining: 1m 31s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "427:\tlearn: 812.0238543\ttest: 810.0931203\tbest: 810.0931203 (427)\ttotal: 1m 8s\tremaining: 1m 31s\n",
      "428:\tlearn: 811.7608881\ttest: 809.8061060\tbest: 809.8061060 (428)\ttotal: 1m 8s\tremaining: 1m 31s\n",
      "429:\tlearn: 811.6010594\ttest: 809.6379860\tbest: 809.6379860 (429)\ttotal: 1m 8s\tremaining: 1m 31s\n",
      "430:\tlearn: 811.3370610\ttest: 809.3993786\tbest: 809.3993786 (430)\ttotal: 1m 8s\tremaining: 1m 30s\n",
      "431:\tlearn: 811.0929303\ttest: 809.1693526\tbest: 809.1693526 (431)\ttotal: 1m 9s\tremaining: 1m 30s\n",
      "432:\tlearn: 810.9413431\ttest: 809.0410413\tbest: 809.0410413 (432)\ttotal: 1m 9s\tremaining: 1m 30s\n",
      "433:\tlearn: 810.7346118\ttest: 808.8053142\tbest: 808.8053142 (433)\ttotal: 1m 9s\tremaining: 1m 30s\n",
      "434:\tlearn: 810.3763148\ttest: 808.4439871\tbest: 808.4439871 (434)\ttotal: 1m 9s\tremaining: 1m 30s\n",
      "435:\tlearn: 810.0917898\ttest: 808.1096821\tbest: 808.1096821 (435)\ttotal: 1m 9s\tremaining: 1m 30s\n",
      "436:\tlearn: 809.7955530\ttest: 807.8356858\tbest: 807.8356858 (436)\ttotal: 1m 9s\tremaining: 1m 29s\n",
      "437:\tlearn: 809.6113401\ttest: 807.6313634\tbest: 807.6313634 (437)\ttotal: 1m 10s\tremaining: 1m 29s\n",
      "438:\tlearn: 809.2832579\ttest: 807.2793702\tbest: 807.2793702 (438)\ttotal: 1m 10s\tremaining: 1m 29s\n",
      "439:\tlearn: 808.9697941\ttest: 806.9969052\tbest: 806.9969052 (439)\ttotal: 1m 10s\tremaining: 1m 29s\n",
      "440:\tlearn: 808.8145337\ttest: 806.8435777\tbest: 806.8435777 (440)\ttotal: 1m 10s\tremaining: 1m 29s\n",
      "441:\tlearn: 808.5132995\ttest: 806.5201169\tbest: 806.5201169 (441)\ttotal: 1m 10s\tremaining: 1m 29s\n",
      "442:\tlearn: 808.2971145\ttest: 806.2907999\tbest: 806.2907999 (442)\ttotal: 1m 10s\tremaining: 1m 29s\n",
      "443:\tlearn: 808.1137180\ttest: 806.1156925\tbest: 806.1156925 (443)\ttotal: 1m 10s\tremaining: 1m 28s\n",
      "444:\tlearn: 807.9101379\ttest: 805.9062520\tbest: 805.9062520 (444)\ttotal: 1m 11s\tremaining: 1m 28s\n",
      "445:\tlearn: 807.6887936\ttest: 805.7319546\tbest: 805.7319546 (445)\ttotal: 1m 11s\tremaining: 1m 28s\n",
      "446:\tlearn: 807.4145260\ttest: 805.4660797\tbest: 805.4660797 (446)\ttotal: 1m 11s\tremaining: 1m 28s\n",
      "447:\tlearn: 807.2209832\ttest: 805.3154901\tbest: 805.3154901 (447)\ttotal: 1m 11s\tremaining: 1m 28s\n",
      "448:\tlearn: 806.9799862\ttest: 805.0515478\tbest: 805.0515478 (448)\ttotal: 1m 11s\tremaining: 1m 28s\n",
      "449:\tlearn: 806.7427609\ttest: 804.7637479\tbest: 804.7637479 (449)\ttotal: 1m 11s\tremaining: 1m 27s\n",
      "450:\tlearn: 806.5319555\ttest: 804.5519658\tbest: 804.5519658 (450)\ttotal: 1m 12s\tremaining: 1m 27s\n",
      "451:\tlearn: 806.3466394\ttest: 804.4601909\tbest: 804.4601909 (451)\ttotal: 1m 12s\tremaining: 1m 27s\n",
      "452:\tlearn: 806.1180927\ttest: 804.2411959\tbest: 804.2411959 (452)\ttotal: 1m 12s\tremaining: 1m 27s\n",
      "453:\tlearn: 805.8978874\ttest: 804.0178594\tbest: 804.0178594 (453)\ttotal: 1m 12s\tremaining: 1m 27s\n",
      "454:\tlearn: 805.5994900\ttest: 803.7082664\tbest: 803.7082664 (454)\ttotal: 1m 12s\tremaining: 1m 27s\n",
      "455:\tlearn: 805.3903073\ttest: 803.6406361\tbest: 803.6406361 (455)\ttotal: 1m 12s\tremaining: 1m 27s\n",
      "456:\tlearn: 805.2190290\ttest: 803.4771061\tbest: 803.4771061 (456)\ttotal: 1m 13s\tremaining: 1m 26s\n",
      "457:\tlearn: 804.9376356\ttest: 803.2171123\tbest: 803.2171123 (457)\ttotal: 1m 13s\tremaining: 1m 26s\n",
      "458:\tlearn: 804.7538346\ttest: 803.0189988\tbest: 803.0189988 (458)\ttotal: 1m 13s\tremaining: 1m 26s\n",
      "459:\tlearn: 804.4628247\ttest: 802.8619290\tbest: 802.8619290 (459)\ttotal: 1m 13s\tremaining: 1m 26s\n",
      "460:\tlearn: 804.3388083\ttest: 802.7016894\tbest: 802.7016894 (460)\ttotal: 1m 13s\tremaining: 1m 26s\n",
      "461:\tlearn: 804.1537980\ttest: 802.5169062\tbest: 802.5169062 (461)\ttotal: 1m 13s\tremaining: 1m 26s\n",
      "462:\tlearn: 803.8792187\ttest: 802.2510972\tbest: 802.2510972 (462)\ttotal: 1m 14s\tremaining: 1m 25s\n",
      "463:\tlearn: 803.4980787\ttest: 801.9054800\tbest: 801.9054800 (463)\ttotal: 1m 14s\tremaining: 1m 25s\n",
      "464:\tlearn: 803.2648970\ttest: 801.6672857\tbest: 801.6672857 (464)\ttotal: 1m 14s\tremaining: 1m 25s\n",
      "465:\tlearn: 802.9740453\ttest: 801.3487654\tbest: 801.3487654 (465)\ttotal: 1m 14s\tremaining: 1m 25s\n",
      "466:\tlearn: 802.6591299\ttest: 801.0074403\tbest: 801.0074403 (466)\ttotal: 1m 14s\tremaining: 1m 25s\n",
      "467:\tlearn: 802.4410390\ttest: 800.7875686\tbest: 800.7875686 (467)\ttotal: 1m 14s\tremaining: 1m 25s\n",
      "468:\tlearn: 802.3390756\ttest: 800.6933770\tbest: 800.6933770 (468)\ttotal: 1m 14s\tremaining: 1m 24s\n",
      "469:\tlearn: 802.0324540\ttest: 800.3580150\tbest: 800.3580150 (469)\ttotal: 1m 15s\tremaining: 1m 24s\n",
      "470:\tlearn: 801.7722519\ttest: 800.1102273\tbest: 800.1102273 (470)\ttotal: 1m 15s\tremaining: 1m 24s\n",
      "471:\tlearn: 801.4498723\ttest: 799.7454159\tbest: 799.7454159 (471)\ttotal: 1m 15s\tremaining: 1m 24s\n",
      "472:\tlearn: 801.2722899\ttest: 799.5820821\tbest: 799.5820821 (472)\ttotal: 1m 15s\tremaining: 1m 24s\n",
      "473:\tlearn: 800.9888443\ttest: 799.3092484\tbest: 799.3092484 (473)\ttotal: 1m 15s\tremaining: 1m 24s\n",
      "474:\tlearn: 800.8202252\ttest: 799.0517373\tbest: 799.0517373 (474)\ttotal: 1m 15s\tremaining: 1m 23s\n",
      "475:\tlearn: 800.6822098\ttest: 798.9166188\tbest: 798.9166188 (475)\ttotal: 1m 16s\tremaining: 1m 23s\n",
      "476:\tlearn: 800.3897829\ttest: 798.6233122\tbest: 798.6233122 (476)\ttotal: 1m 16s\tremaining: 1m 23s\n",
      "477:\tlearn: 800.0147800\ttest: 798.2396170\tbest: 798.2396170 (477)\ttotal: 1m 16s\tremaining: 1m 23s\n",
      "478:\tlearn: 799.8674112\ttest: 798.0892099\tbest: 798.0892099 (478)\ttotal: 1m 16s\tremaining: 1m 23s\n",
      "479:\tlearn: 799.7208651\ttest: 797.9719762\tbest: 797.9719762 (479)\ttotal: 1m 16s\tremaining: 1m 23s\n",
      "480:\tlearn: 799.5761521\ttest: 797.8135189\tbest: 797.8135189 (480)\ttotal: 1m 16s\tremaining: 1m 22s\n",
      "481:\tlearn: 799.1861719\ttest: 797.4392041\tbest: 797.4392041 (481)\ttotal: 1m 17s\tremaining: 1m 22s\n",
      "482:\tlearn: 798.9240130\ttest: 797.1628688\tbest: 797.1628688 (482)\ttotal: 1m 17s\tremaining: 1m 22s\n",
      "483:\tlearn: 798.7754242\ttest: 796.9908565\tbest: 796.9908565 (483)\ttotal: 1m 17s\tremaining: 1m 22s\n",
      "484:\tlearn: 798.6446144\ttest: 796.9208999\tbest: 796.9208999 (484)\ttotal: 1m 17s\tremaining: 1m 22s\n",
      "485:\tlearn: 798.4455679\ttest: 796.7273539\tbest: 796.7273539 (485)\ttotal: 1m 17s\tremaining: 1m 22s\n",
      "486:\tlearn: 798.3153158\ttest: 796.5942089\tbest: 796.5942089 (486)\ttotal: 1m 17s\tremaining: 1m 22s\n",
      "487:\tlearn: 798.1156727\ttest: 796.3885181\tbest: 796.3885181 (487)\ttotal: 1m 18s\tremaining: 1m 21s\n",
      "488:\tlearn: 797.8854339\ttest: 796.1620370\tbest: 796.1620370 (488)\ttotal: 1m 18s\tremaining: 1m 21s\n",
      "489:\tlearn: 797.5029069\ttest: 795.7407508\tbest: 795.7407508 (489)\ttotal: 1m 18s\tremaining: 1m 21s\n",
      "490:\tlearn: 797.3549857\ttest: 795.5816122\tbest: 795.5816122 (490)\ttotal: 1m 18s\tremaining: 1m 21s\n",
      "491:\tlearn: 797.2024593\ttest: 795.4329386\tbest: 795.4329386 (491)\ttotal: 1m 18s\tremaining: 1m 21s\n",
      "492:\tlearn: 796.9532901\ttest: 795.1886687\tbest: 795.1886687 (492)\ttotal: 1m 18s\tremaining: 1m 21s\n",
      "493:\tlearn: 796.7618154\ttest: 794.9573485\tbest: 794.9573485 (493)\ttotal: 1m 19s\tremaining: 1m 20s\n",
      "494:\tlearn: 796.4790445\ttest: 794.6611434\tbest: 794.6611434 (494)\ttotal: 1m 19s\tremaining: 1m 20s\n",
      "495:\tlearn: 796.2374432\ttest: 794.3315480\tbest: 794.3315480 (495)\ttotal: 1m 19s\tremaining: 1m 20s\n",
      "496:\tlearn: 795.7796170\ttest: 793.8775603\tbest: 793.8775603 (496)\ttotal: 1m 19s\tremaining: 1m 20s\n",
      "497:\tlearn: 795.1903823\ttest: 793.2383664\tbest: 793.2383664 (497)\ttotal: 1m 19s\tremaining: 1m 20s\n",
      "498:\tlearn: 794.7333150\ttest: 792.7559520\tbest: 792.7559520 (498)\ttotal: 1m 19s\tremaining: 1m 20s\n",
      "499:\tlearn: 794.5547113\ttest: 792.5456537\tbest: 792.5456537 (499)\ttotal: 1m 19s\tremaining: 1m 19s\n",
      "500:\tlearn: 794.4026909\ttest: 792.3795094\tbest: 792.3795094 (500)\ttotal: 1m 20s\tremaining: 1m 19s\n",
      "501:\tlearn: 794.2768093\ttest: 792.2083143\tbest: 792.2083143 (501)\ttotal: 1m 20s\tremaining: 1m 19s\n",
      "502:\tlearn: 794.1349305\ttest: 792.0802169\tbest: 792.0802169 (502)\ttotal: 1m 20s\tremaining: 1m 19s\n",
      "503:\tlearn: 793.7386110\ttest: 791.6338562\tbest: 791.6338562 (503)\ttotal: 1m 20s\tremaining: 1m 19s\n",
      "504:\tlearn: 793.5172763\ttest: 791.3879392\tbest: 791.3879392 (504)\ttotal: 1m 20s\tremaining: 1m 19s\n",
      "505:\tlearn: 793.4193374\ttest: 791.2695504\tbest: 791.2695504 (505)\ttotal: 1m 20s\tremaining: 1m 18s\n",
      "506:\tlearn: 793.1750131\ttest: 790.9875732\tbest: 790.9875732 (506)\ttotal: 1m 20s\tremaining: 1m 18s\n",
      "507:\tlearn: 793.0906302\ttest: 790.9062801\tbest: 790.9062801 (507)\ttotal: 1m 21s\tremaining: 1m 18s\n",
      "508:\tlearn: 792.8874338\ttest: 790.7246413\tbest: 790.7246413 (508)\ttotal: 1m 21s\tremaining: 1m 18s\n",
      "509:\tlearn: 792.4411319\ttest: 790.3119616\tbest: 790.3119616 (509)\ttotal: 1m 21s\tremaining: 1m 18s\n",
      "510:\tlearn: 792.2192334\ttest: 790.0918050\tbest: 790.0918050 (510)\ttotal: 1m 21s\tremaining: 1m 18s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511:\tlearn: 791.9345630\ttest: 789.7792256\tbest: 789.7792256 (511)\ttotal: 1m 21s\tremaining: 1m 17s\n",
      "512:\tlearn: 791.8071831\ttest: 789.6911769\tbest: 789.6911769 (512)\ttotal: 1m 21s\tremaining: 1m 17s\n",
      "513:\tlearn: 791.6530913\ttest: 789.5319707\tbest: 789.5319707 (513)\ttotal: 1m 22s\tremaining: 1m 17s\n",
      "514:\tlearn: 791.4536806\ttest: 789.2749644\tbest: 789.2749644 (514)\ttotal: 1m 22s\tremaining: 1m 17s\n",
      "515:\tlearn: 791.3457879\ttest: 789.1610986\tbest: 789.1610986 (515)\ttotal: 1m 22s\tremaining: 1m 17s\n",
      "516:\tlearn: 791.0651676\ttest: 788.8621048\tbest: 788.8621048 (516)\ttotal: 1m 22s\tremaining: 1m 17s\n",
      "517:\tlearn: 790.8030398\ttest: 788.6096294\tbest: 788.6096294 (517)\ttotal: 1m 22s\tremaining: 1m 16s\n",
      "518:\tlearn: 790.6014252\ttest: 788.4307529\tbest: 788.4307529 (518)\ttotal: 1m 22s\tremaining: 1m 16s\n",
      "519:\tlearn: 790.3509152\ttest: 788.1771150\tbest: 788.1771150 (519)\ttotal: 1m 23s\tremaining: 1m 16s\n",
      "520:\tlearn: 790.1276173\ttest: 787.9699708\tbest: 787.9699708 (520)\ttotal: 1m 23s\tremaining: 1m 16s\n",
      "521:\tlearn: 789.8571194\ttest: 787.6760469\tbest: 787.6760469 (521)\ttotal: 1m 23s\tremaining: 1m 16s\n",
      "522:\tlearn: 789.6686714\ttest: 787.6280423\tbest: 787.6280423 (522)\ttotal: 1m 23s\tremaining: 1m 16s\n",
      "523:\tlearn: 789.5205832\ttest: 787.4671715\tbest: 787.4671715 (523)\ttotal: 1m 23s\tremaining: 1m 16s\n",
      "524:\tlearn: 789.2634138\ttest: 787.1578715\tbest: 787.1578715 (524)\ttotal: 1m 23s\tremaining: 1m 15s\n",
      "525:\tlearn: 789.0873992\ttest: 786.9608223\tbest: 786.9608223 (525)\ttotal: 1m 23s\tremaining: 1m 15s\n",
      "526:\tlearn: 788.9231117\ttest: 786.8035352\tbest: 786.8035352 (526)\ttotal: 1m 24s\tremaining: 1m 15s\n",
      "527:\tlearn: 788.6439124\ttest: 786.5394610\tbest: 786.5394610 (527)\ttotal: 1m 24s\tremaining: 1m 15s\n",
      "528:\tlearn: 788.4707946\ttest: 786.3544718\tbest: 786.3544718 (528)\ttotal: 1m 24s\tremaining: 1m 15s\n",
      "529:\tlearn: 788.3984953\ttest: 786.2784402\tbest: 786.2784402 (529)\ttotal: 1m 24s\tremaining: 1m 15s\n",
      "530:\tlearn: 788.2023053\ttest: 786.1098459\tbest: 786.1098459 (530)\ttotal: 1m 24s\tremaining: 1m 14s\n",
      "531:\tlearn: 788.0098888\ttest: 785.9416880\tbest: 785.9416880 (531)\ttotal: 1m 24s\tremaining: 1m 14s\n",
      "532:\tlearn: 787.8139224\ttest: 785.7665881\tbest: 785.7665881 (532)\ttotal: 1m 24s\tremaining: 1m 14s\n",
      "533:\tlearn: 787.5870411\ttest: 785.5235199\tbest: 785.5235199 (533)\ttotal: 1m 25s\tremaining: 1m 14s\n",
      "534:\tlearn: 787.3587782\ttest: 785.3080521\tbest: 785.3080521 (534)\ttotal: 1m 25s\tremaining: 1m 14s\n",
      "535:\tlearn: 787.1601418\ttest: 785.0906534\tbest: 785.0906534 (535)\ttotal: 1m 25s\tremaining: 1m 13s\n",
      "536:\tlearn: 787.0418290\ttest: 784.9111003\tbest: 784.9111003 (536)\ttotal: 1m 25s\tremaining: 1m 13s\n",
      "537:\tlearn: 786.8266398\ttest: 784.7126514\tbest: 784.7126514 (537)\ttotal: 1m 25s\tremaining: 1m 13s\n",
      "538:\tlearn: 786.6466140\ttest: 784.5204414\tbest: 784.5204414 (538)\ttotal: 1m 25s\tremaining: 1m 13s\n",
      "539:\tlearn: 786.4851954\ttest: 784.3356038\tbest: 784.3356038 (539)\ttotal: 1m 26s\tremaining: 1m 13s\n",
      "540:\tlearn: 786.2647246\ttest: 784.1069907\tbest: 784.1069907 (540)\ttotal: 1m 26s\tremaining: 1m 13s\n",
      "541:\tlearn: 786.0521515\ttest: 783.8858458\tbest: 783.8858458 (541)\ttotal: 1m 26s\tremaining: 1m 12s\n",
      "542:\tlearn: 785.8260959\ttest: 783.6208283\tbest: 783.6208283 (542)\ttotal: 1m 26s\tremaining: 1m 12s\n",
      "543:\tlearn: 785.6904590\ttest: 783.4869894\tbest: 783.4869894 (543)\ttotal: 1m 26s\tremaining: 1m 12s\n",
      "544:\tlearn: 785.4557512\ttest: 783.3410282\tbest: 783.3410282 (544)\ttotal: 1m 26s\tremaining: 1m 12s\n",
      "545:\tlearn: 785.2643472\ttest: 783.1355318\tbest: 783.1355318 (545)\ttotal: 1m 27s\tremaining: 1m 12s\n",
      "546:\tlearn: 785.0790722\ttest: 782.9393587\tbest: 782.9393587 (546)\ttotal: 1m 27s\tremaining: 1m 12s\n",
      "547:\tlearn: 784.9388085\ttest: 782.7955180\tbest: 782.7955180 (547)\ttotal: 1m 27s\tremaining: 1m 12s\n",
      "548:\tlearn: 784.7667491\ttest: 782.6217497\tbest: 782.6217497 (548)\ttotal: 1m 27s\tremaining: 1m 11s\n",
      "549:\tlearn: 784.6279626\ttest: 782.4823167\tbest: 782.4823167 (549)\ttotal: 1m 27s\tremaining: 1m 11s\n",
      "550:\tlearn: 784.4798771\ttest: 782.2492390\tbest: 782.2492390 (550)\ttotal: 1m 27s\tremaining: 1m 11s\n",
      "551:\tlearn: 784.2591517\ttest: 782.0049896\tbest: 782.0049896 (551)\ttotal: 1m 27s\tremaining: 1m 11s\n",
      "552:\tlearn: 784.0952477\ttest: 781.8346419\tbest: 781.8346419 (552)\ttotal: 1m 28s\tremaining: 1m 11s\n",
      "553:\tlearn: 783.9132102\ttest: 781.6331071\tbest: 781.6331071 (553)\ttotal: 1m 28s\tremaining: 1m 11s\n",
      "554:\tlearn: 783.6401509\ttest: 781.4365621\tbest: 781.4365621 (554)\ttotal: 1m 28s\tremaining: 1m 10s\n",
      "555:\tlearn: 783.5125897\ttest: 781.3161294\tbest: 781.3161294 (555)\ttotal: 1m 28s\tremaining: 1m 10s\n",
      "556:\tlearn: 783.3553862\ttest: 781.1383729\tbest: 781.1383729 (556)\ttotal: 1m 28s\tremaining: 1m 10s\n",
      "557:\tlearn: 783.2178062\ttest: 781.0208877\tbest: 781.0208877 (557)\ttotal: 1m 28s\tremaining: 1m 10s\n",
      "558:\tlearn: 783.0674955\ttest: 780.8769079\tbest: 780.8769079 (558)\ttotal: 1m 29s\tremaining: 1m 10s\n",
      "559:\tlearn: 782.8899477\ttest: 780.6483086\tbest: 780.6483086 (559)\ttotal: 1m 29s\tremaining: 1m 10s\n",
      "560:\tlearn: 782.7662743\ttest: 780.4928685\tbest: 780.4928685 (560)\ttotal: 1m 29s\tremaining: 1m 9s\n",
      "561:\tlearn: 782.3906084\ttest: 780.1310386\tbest: 780.1310386 (561)\ttotal: 1m 29s\tremaining: 1m 9s\n",
      "562:\tlearn: 782.2610435\ttest: 780.0058002\tbest: 780.0058002 (562)\ttotal: 1m 29s\tremaining: 1m 9s\n",
      "563:\tlearn: 781.9768841\ttest: 779.7012659\tbest: 779.7012659 (563)\ttotal: 1m 29s\tremaining: 1m 9s\n",
      "564:\tlearn: 781.8436447\ttest: 779.5825121\tbest: 779.5825121 (564)\ttotal: 1m 30s\tremaining: 1m 9s\n",
      "565:\tlearn: 781.6279632\ttest: 779.3590799\tbest: 779.3590799 (565)\ttotal: 1m 30s\tremaining: 1m 9s\n",
      "566:\tlearn: 781.5089643\ttest: 779.2423063\tbest: 779.2423063 (566)\ttotal: 1m 30s\tremaining: 1m 8s\n",
      "567:\tlearn: 781.3091742\ttest: 779.0756017\tbest: 779.0756017 (567)\ttotal: 1m 30s\tremaining: 1m 8s\n",
      "568:\tlearn: 781.0029880\ttest: 778.7171275\tbest: 778.7171275 (568)\ttotal: 1m 30s\tremaining: 1m 8s\n",
      "569:\tlearn: 780.7898128\ttest: 778.5275619\tbest: 778.5275619 (569)\ttotal: 1m 30s\tremaining: 1m 8s\n",
      "570:\tlearn: 780.6418905\ttest: 778.3787786\tbest: 778.3787786 (570)\ttotal: 1m 30s\tremaining: 1m 8s\n",
      "571:\tlearn: 780.5299064\ttest: 778.2755759\tbest: 778.2755759 (571)\ttotal: 1m 31s\tremaining: 1m 8s\n",
      "572:\tlearn: 780.3737281\ttest: 778.1367683\tbest: 778.1367683 (572)\ttotal: 1m 31s\tremaining: 1m 7s\n",
      "573:\tlearn: 780.2038135\ttest: 778.0154022\tbest: 778.0154022 (573)\ttotal: 1m 31s\tremaining: 1m 7s\n",
      "574:\tlearn: 780.0565987\ttest: 777.8636113\tbest: 777.8636113 (574)\ttotal: 1m 31s\tremaining: 1m 7s\n",
      "575:\tlearn: 779.8708733\ttest: 777.6552302\tbest: 777.6552302 (575)\ttotal: 1m 31s\tremaining: 1m 7s\n",
      "576:\tlearn: 779.6171607\ttest: 777.3934820\tbest: 777.3934820 (576)\ttotal: 1m 31s\tremaining: 1m 7s\n",
      "577:\tlearn: 779.5043713\ttest: 777.2762930\tbest: 777.2762930 (577)\ttotal: 1m 32s\tremaining: 1m 7s\n",
      "578:\tlearn: 779.2985139\ttest: 777.0866336\tbest: 777.0866336 (578)\ttotal: 1m 32s\tremaining: 1m 7s\n",
      "579:\tlearn: 779.1712605\ttest: 776.9613125\tbest: 776.9613125 (579)\ttotal: 1m 32s\tremaining: 1m 6s\n",
      "580:\tlearn: 779.0046516\ttest: 776.7900443\tbest: 776.7900443 (580)\ttotal: 1m 32s\tremaining: 1m 6s\n",
      "581:\tlearn: 778.8994707\ttest: 776.6983883\tbest: 776.6983883 (581)\ttotal: 1m 32s\tremaining: 1m 6s\n",
      "582:\tlearn: 778.7571409\ttest: 776.5995393\tbest: 776.5995393 (582)\ttotal: 1m 32s\tremaining: 1m 6s\n",
      "583:\tlearn: 778.6635618\ttest: 776.5086399\tbest: 776.5086399 (583)\ttotal: 1m 33s\tremaining: 1m 6s\n",
      "584:\tlearn: 778.4100082\ttest: 776.2579777\tbest: 776.2579777 (584)\ttotal: 1m 33s\tremaining: 1m 6s\n",
      "585:\tlearn: 778.0516283\ttest: 775.9173607\tbest: 775.9173607 (585)\ttotal: 1m 33s\tremaining: 1m 5s\n",
      "586:\tlearn: 777.8432798\ttest: 775.7140317\tbest: 775.7140317 (586)\ttotal: 1m 33s\tremaining: 1m 5s\n",
      "587:\tlearn: 777.7451890\ttest: 775.6052946\tbest: 775.6052946 (587)\ttotal: 1m 33s\tremaining: 1m 5s\n",
      "588:\tlearn: 777.6436892\ttest: 775.4976257\tbest: 775.4976257 (588)\ttotal: 1m 33s\tremaining: 1m 5s\n",
      "589:\tlearn: 777.5441225\ttest: 775.4181901\tbest: 775.4181901 (589)\ttotal: 1m 34s\tremaining: 1m 5s\n",
      "590:\tlearn: 777.3781917\ttest: 775.2233240\tbest: 775.2233240 (590)\ttotal: 1m 34s\tremaining: 1m 5s\n",
      "591:\tlearn: 777.2921885\ttest: 775.1434015\tbest: 775.1434015 (591)\ttotal: 1m 34s\tremaining: 1m 5s\n",
      "592:\tlearn: 777.1511597\ttest: 775.0229778\tbest: 775.0229778 (592)\ttotal: 1m 34s\tremaining: 1m 4s\n",
      "593:\tlearn: 776.9241549\ttest: 774.7971098\tbest: 774.7971098 (593)\ttotal: 1m 34s\tremaining: 1m 4s\n",
      "594:\tlearn: 776.6430451\ttest: 774.5612904\tbest: 774.5612904 (594)\ttotal: 1m 34s\tremaining: 1m 4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "595:\tlearn: 776.4028177\ttest: 774.3200744\tbest: 774.3200744 (595)\ttotal: 1m 35s\tremaining: 1m 4s\n",
      "596:\tlearn: 776.2753451\ttest: 774.1813976\tbest: 774.1813976 (596)\ttotal: 1m 35s\tremaining: 1m 4s\n",
      "597:\tlearn: 776.0804388\ttest: 773.9456614\tbest: 773.9456614 (597)\ttotal: 1m 35s\tremaining: 1m 4s\n",
      "598:\tlearn: 775.7984394\ttest: 773.7070589\tbest: 773.7070589 (598)\ttotal: 1m 35s\tremaining: 1m 3s\n",
      "599:\tlearn: 775.7080283\ttest: 773.6168220\tbest: 773.6168220 (599)\ttotal: 1m 35s\tremaining: 1m 3s\n",
      "600:\tlearn: 775.5056645\ttest: 773.4062180\tbest: 773.4062180 (600)\ttotal: 1m 35s\tremaining: 1m 3s\n",
      "601:\tlearn: 775.3704248\ttest: 773.2703033\tbest: 773.2703033 (601)\ttotal: 1m 35s\tremaining: 1m 3s\n",
      "602:\tlearn: 775.2029793\ttest: 773.0972722\tbest: 773.0972722 (602)\ttotal: 1m 36s\tremaining: 1m 3s\n",
      "603:\tlearn: 775.0640821\ttest: 772.9418504\tbest: 772.9418504 (603)\ttotal: 1m 36s\tremaining: 1m 3s\n",
      "604:\tlearn: 774.7248142\ttest: 772.6461211\tbest: 772.6461211 (604)\ttotal: 1m 36s\tremaining: 1m 2s\n",
      "605:\tlearn: 774.5430863\ttest: 772.4784682\tbest: 772.4784682 (605)\ttotal: 1m 36s\tremaining: 1m 2s\n",
      "606:\tlearn: 774.1951668\ttest: 772.0661178\tbest: 772.0661178 (606)\ttotal: 1m 36s\tremaining: 1m 2s\n",
      "607:\tlearn: 773.9917888\ttest: 771.8888436\tbest: 771.8888436 (607)\ttotal: 1m 36s\tremaining: 1m 2s\n",
      "608:\tlearn: 773.7960940\ttest: 771.6572065\tbest: 771.6572065 (608)\ttotal: 1m 37s\tremaining: 1m 2s\n",
      "609:\tlearn: 773.6975819\ttest: 771.5776298\tbest: 771.5776298 (609)\ttotal: 1m 37s\tremaining: 1m 2s\n",
      "610:\tlearn: 773.3777203\ttest: 771.2374877\tbest: 771.2374877 (610)\ttotal: 1m 37s\tremaining: 1m 2s\n",
      "611:\tlearn: 773.2332557\ttest: 771.0952437\tbest: 771.0952437 (611)\ttotal: 1m 37s\tremaining: 1m 1s\n",
      "612:\tlearn: 773.0839277\ttest: 770.9267317\tbest: 770.9267317 (612)\ttotal: 1m 37s\tremaining: 1m 1s\n",
      "613:\tlearn: 772.8164844\ttest: 770.6929672\tbest: 770.6929672 (613)\ttotal: 1m 37s\tremaining: 1m 1s\n",
      "614:\tlearn: 772.5932864\ttest: 770.4709301\tbest: 770.4709301 (614)\ttotal: 1m 38s\tremaining: 1m 1s\n",
      "615:\tlearn: 772.4451080\ttest: 770.3141255\tbest: 770.3141255 (615)\ttotal: 1m 38s\tremaining: 1m 1s\n",
      "616:\tlearn: 772.3391484\ttest: 770.2196462\tbest: 770.2196462 (616)\ttotal: 1m 38s\tremaining: 1m 1s\n",
      "617:\tlearn: 772.1934590\ttest: 770.0685840\tbest: 770.0685840 (617)\ttotal: 1m 38s\tremaining: 1m\n",
      "618:\tlearn: 772.0819876\ttest: 769.9093460\tbest: 769.9093460 (618)\ttotal: 1m 38s\tremaining: 1m\n",
      "619:\tlearn: 771.9153891\ttest: 769.7375565\tbest: 769.7375565 (619)\ttotal: 1m 38s\tremaining: 1m\n",
      "620:\tlearn: 771.7954891\ttest: 769.6613564\tbest: 769.6613564 (620)\ttotal: 1m 39s\tremaining: 1m\n",
      "621:\tlearn: 771.6558332\ttest: 769.5037905\tbest: 769.5037905 (621)\ttotal: 1m 39s\tremaining: 1m\n",
      "622:\tlearn: 771.3955154\ttest: 769.2667660\tbest: 769.2667660 (622)\ttotal: 1m 39s\tremaining: 1m\n",
      "623:\tlearn: 771.2401798\ttest: 769.0915346\tbest: 769.0915346 (623)\ttotal: 1m 39s\tremaining: 60s\n",
      "624:\tlearn: 771.0952792\ttest: 768.9366988\tbest: 768.9366988 (624)\ttotal: 1m 39s\tremaining: 59.8s\n",
      "625:\tlearn: 770.8800187\ttest: 768.7257395\tbest: 768.7257395 (625)\ttotal: 1m 39s\tremaining: 59.7s\n",
      "626:\tlearn: 770.7888173\ttest: 768.6211758\tbest: 768.6211758 (626)\ttotal: 1m 40s\tremaining: 59.5s\n",
      "627:\tlearn: 770.6536997\ttest: 768.4561707\tbest: 768.4561707 (627)\ttotal: 1m 40s\tremaining: 59.4s\n",
      "628:\tlearn: 770.5459704\ttest: 768.3537215\tbest: 768.3537215 (628)\ttotal: 1m 40s\tremaining: 59.2s\n",
      "629:\tlearn: 770.3404612\ttest: 768.1385526\tbest: 768.1385526 (629)\ttotal: 1m 40s\tremaining: 59s\n",
      "630:\tlearn: 770.1842136\ttest: 767.9813975\tbest: 767.9813975 (630)\ttotal: 1m 40s\tremaining: 58.9s\n",
      "631:\tlearn: 770.0301172\ttest: 767.8133539\tbest: 767.8133539 (631)\ttotal: 1m 40s\tremaining: 58.7s\n",
      "632:\tlearn: 769.8300431\ttest: 767.6240152\tbest: 767.6240152 (632)\ttotal: 1m 40s\tremaining: 58.6s\n",
      "633:\tlearn: 769.6982874\ttest: 767.5078564\tbest: 767.5078564 (633)\ttotal: 1m 41s\tremaining: 58.4s\n",
      "634:\tlearn: 769.5483323\ttest: 767.3288128\tbest: 767.3288128 (634)\ttotal: 1m 41s\tremaining: 58.2s\n",
      "635:\tlearn: 769.3702883\ttest: 767.2045362\tbest: 767.2045362 (635)\ttotal: 1m 41s\tremaining: 58.1s\n",
      "636:\tlearn: 769.2813462\ttest: 767.1190912\tbest: 767.1190912 (636)\ttotal: 1m 41s\tremaining: 57.9s\n",
      "637:\tlearn: 769.1575904\ttest: 767.0020203\tbest: 767.0020203 (637)\ttotal: 1m 41s\tremaining: 57.8s\n",
      "638:\tlearn: 768.9348385\ttest: 766.7764498\tbest: 766.7764498 (638)\ttotal: 1m 41s\tremaining: 57.6s\n",
      "639:\tlearn: 768.7673804\ttest: 766.5758327\tbest: 766.5758327 (639)\ttotal: 1m 42s\tremaining: 57.4s\n",
      "640:\tlearn: 768.6479427\ttest: 766.4541854\tbest: 766.4541854 (640)\ttotal: 1m 42s\tremaining: 57.3s\n",
      "641:\tlearn: 768.3465548\ttest: 766.1097677\tbest: 766.1097677 (641)\ttotal: 1m 42s\tremaining: 57.1s\n",
      "642:\tlearn: 768.2015764\ttest: 765.9553094\tbest: 765.9553094 (642)\ttotal: 1m 42s\tremaining: 56.9s\n",
      "643:\tlearn: 768.0828234\ttest: 765.7907787\tbest: 765.7907787 (643)\ttotal: 1m 42s\tremaining: 56.8s\n",
      "644:\tlearn: 767.8803749\ttest: 765.5664255\tbest: 765.5664255 (644)\ttotal: 1m 42s\tremaining: 56.6s\n",
      "645:\tlearn: 767.5776154\ttest: 765.2577043\tbest: 765.2577043 (645)\ttotal: 1m 42s\tremaining: 56.4s\n",
      "646:\tlearn: 767.3762566\ttest: 765.0604757\tbest: 765.0604757 (646)\ttotal: 1m 43s\tremaining: 56.3s\n",
      "647:\tlearn: 767.2726876\ttest: 764.9547997\tbest: 764.9547997 (647)\ttotal: 1m 43s\tremaining: 56.1s\n",
      "648:\tlearn: 767.1133554\ttest: 764.7828723\tbest: 764.7828723 (648)\ttotal: 1m 43s\tremaining: 55.9s\n",
      "649:\tlearn: 766.9982867\ttest: 764.6711328\tbest: 764.6711328 (649)\ttotal: 1m 43s\tremaining: 55.8s\n",
      "650:\tlearn: 766.8496020\ttest: 764.4990915\tbest: 764.4990915 (650)\ttotal: 1m 43s\tremaining: 55.6s\n",
      "651:\tlearn: 766.7438767\ttest: 764.4037483\tbest: 764.4037483 (651)\ttotal: 1m 43s\tremaining: 55.5s\n",
      "652:\tlearn: 766.5071213\ttest: 764.1472653\tbest: 764.1472653 (652)\ttotal: 1m 44s\tremaining: 55.3s\n",
      "653:\tlearn: 766.4055385\ttest: 764.0494527\tbest: 764.0494527 (653)\ttotal: 1m 44s\tremaining: 55.1s\n",
      "654:\tlearn: 766.2348618\ttest: 763.8644106\tbest: 763.8644106 (654)\ttotal: 1m 44s\tremaining: 55s\n",
      "655:\tlearn: 766.1306524\ttest: 763.7331261\tbest: 763.7331261 (655)\ttotal: 1m 44s\tremaining: 54.8s\n",
      "656:\tlearn: 766.0435805\ttest: 763.6188091\tbest: 763.6188091 (656)\ttotal: 1m 44s\tremaining: 54.6s\n",
      "657:\tlearn: 765.7958559\ttest: 763.3586496\tbest: 763.3586496 (657)\ttotal: 1m 44s\tremaining: 54.5s\n",
      "658:\tlearn: 765.6945504\ttest: 763.2666560\tbest: 763.2666560 (658)\ttotal: 1m 45s\tremaining: 54.3s\n",
      "659:\tlearn: 765.6016823\ttest: 763.1800046\tbest: 763.1800046 (659)\ttotal: 1m 45s\tremaining: 54.2s\n",
      "660:\tlearn: 765.4931356\ttest: 763.0711261\tbest: 763.0711261 (660)\ttotal: 1m 45s\tremaining: 54s\n",
      "661:\tlearn: 765.3180288\ttest: 762.8990176\tbest: 762.8990176 (661)\ttotal: 1m 45s\tremaining: 53.9s\n",
      "662:\tlearn: 765.1681536\ttest: 762.7775355\tbest: 762.7775355 (662)\ttotal: 1m 45s\tremaining: 53.7s\n",
      "663:\tlearn: 764.9957886\ttest: 762.5722348\tbest: 762.5722348 (663)\ttotal: 1m 45s\tremaining: 53.6s\n",
      "664:\tlearn: 764.8301369\ttest: 762.4008003\tbest: 762.4008003 (664)\ttotal: 1m 46s\tremaining: 53.4s\n",
      "665:\tlearn: 764.7191380\ttest: 762.2836777\tbest: 762.2836777 (665)\ttotal: 1m 46s\tremaining: 53.3s\n",
      "666:\tlearn: 764.5733718\ttest: 762.1178561\tbest: 762.1178561 (666)\ttotal: 1m 46s\tremaining: 53.1s\n",
      "667:\tlearn: 764.4258216\ttest: 761.9461569\tbest: 761.9461569 (667)\ttotal: 1m 46s\tremaining: 52.9s\n",
      "668:\tlearn: 764.3762738\ttest: 761.8956690\tbest: 761.8956690 (668)\ttotal: 1m 46s\tremaining: 52.8s\n",
      "669:\tlearn: 764.1749671\ttest: 761.7329612\tbest: 761.7329612 (669)\ttotal: 1m 46s\tremaining: 52.6s\n",
      "670:\tlearn: 764.0038706\ttest: 761.5131945\tbest: 761.5131945 (670)\ttotal: 1m 47s\tremaining: 52.5s\n",
      "671:\tlearn: 763.8439553\ttest: 761.3156923\tbest: 761.3156923 (671)\ttotal: 1m 47s\tremaining: 52.3s\n",
      "672:\tlearn: 763.7380211\ttest: 761.2163237\tbest: 761.2163237 (672)\ttotal: 1m 47s\tremaining: 52.1s\n",
      "673:\tlearn: 763.6526246\ttest: 761.1185153\tbest: 761.1185153 (673)\ttotal: 1m 47s\tremaining: 52s\n",
      "674:\tlearn: 763.5428071\ttest: 761.0174579\tbest: 761.0174579 (674)\ttotal: 1m 47s\tremaining: 51.8s\n",
      "675:\tlearn: 763.4105449\ttest: 760.8990028\tbest: 760.8990028 (675)\ttotal: 1m 47s\tremaining: 51.7s\n",
      "676:\tlearn: 763.2816427\ttest: 760.7543755\tbest: 760.7543755 (676)\ttotal: 1m 48s\tremaining: 51.5s\n",
      "677:\tlearn: 763.1940485\ttest: 760.6841995\tbest: 760.6841995 (677)\ttotal: 1m 48s\tremaining: 51.4s\n",
      "678:\tlearn: 763.0774907\ttest: 760.5710989\tbest: 760.5710989 (678)\ttotal: 1m 48s\tremaining: 51.2s\n",
      "679:\tlearn: 762.9569682\ttest: 760.4415161\tbest: 760.4415161 (679)\ttotal: 1m 48s\tremaining: 51.1s\n",
      "680:\tlearn: 762.8344159\ttest: 760.3159396\tbest: 760.3159396 (680)\ttotal: 1m 48s\tremaining: 50.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "681:\tlearn: 762.7439930\ttest: 760.2848150\tbest: 760.2848150 (681)\ttotal: 1m 48s\tremaining: 50.8s\n",
      "682:\tlearn: 762.6222159\ttest: 760.1620862\tbest: 760.1620862 (682)\ttotal: 1m 49s\tremaining: 50.6s\n",
      "683:\tlearn: 762.3321932\ttest: 759.8756967\tbest: 759.8756967 (683)\ttotal: 1m 49s\tremaining: 50.5s\n",
      "684:\tlearn: 762.1606864\ttest: 759.6920961\tbest: 759.6920961 (684)\ttotal: 1m 49s\tremaining: 50.3s\n",
      "685:\tlearn: 762.1022057\ttest: 759.6373890\tbest: 759.6373890 (685)\ttotal: 1m 49s\tremaining: 50.2s\n",
      "686:\tlearn: 761.9456508\ttest: 759.4622911\tbest: 759.4622911 (686)\ttotal: 1m 49s\tremaining: 50s\n",
      "687:\tlearn: 761.8135984\ttest: 759.3304806\tbest: 759.3304806 (687)\ttotal: 1m 49s\tremaining: 49.9s\n",
      "688:\tlearn: 761.6179228\ttest: 759.1410681\tbest: 759.1410681 (688)\ttotal: 1m 50s\tremaining: 49.7s\n",
      "689:\tlearn: 761.5172389\ttest: 759.0240991\tbest: 759.0240991 (689)\ttotal: 1m 50s\tremaining: 49.5s\n",
      "690:\tlearn: 761.3885403\ttest: 758.8547796\tbest: 758.8547796 (690)\ttotal: 1m 50s\tremaining: 49.4s\n",
      "691:\tlearn: 761.2244110\ttest: 758.6791729\tbest: 758.6791729 (691)\ttotal: 1m 50s\tremaining: 49.2s\n",
      "692:\tlearn: 761.0253520\ttest: 758.4859686\tbest: 758.4859686 (692)\ttotal: 1m 50s\tremaining: 49.1s\n",
      "693:\tlearn: 760.8357732\ttest: 758.2904404\tbest: 758.2904404 (693)\ttotal: 1m 50s\tremaining: 48.9s\n",
      "694:\tlearn: 760.6744312\ttest: 758.1030550\tbest: 758.1030550 (694)\ttotal: 1m 51s\tremaining: 48.8s\n",
      "695:\tlearn: 760.5587450\ttest: 757.9646481\tbest: 757.9646481 (695)\ttotal: 1m 51s\tremaining: 48.6s\n",
      "696:\tlearn: 760.4408449\ttest: 757.8414405\tbest: 757.8414405 (696)\ttotal: 1m 51s\tremaining: 48.4s\n",
      "697:\tlearn: 760.2634315\ttest: 757.6567594\tbest: 757.6567594 (697)\ttotal: 1m 51s\tremaining: 48.3s\n",
      "698:\tlearn: 760.1242922\ttest: 757.5133138\tbest: 757.5133138 (698)\ttotal: 1m 51s\tremaining: 48.1s\n",
      "699:\tlearn: 759.9740745\ttest: 757.3415378\tbest: 757.3415378 (699)\ttotal: 1m 51s\tremaining: 48s\n",
      "700:\tlearn: 759.8985060\ttest: 757.2700300\tbest: 757.2700300 (700)\ttotal: 1m 52s\tremaining: 47.8s\n",
      "701:\tlearn: 759.7541611\ttest: 757.1182912\tbest: 757.1182912 (701)\ttotal: 1m 52s\tremaining: 47.6s\n",
      "702:\tlearn: 759.5864158\ttest: 756.9802964\tbest: 756.9802964 (702)\ttotal: 1m 52s\tremaining: 47.5s\n",
      "703:\tlearn: 759.3774141\ttest: 756.7605941\tbest: 756.7605941 (703)\ttotal: 1m 52s\tremaining: 47.3s\n",
      "704:\tlearn: 759.2549664\ttest: 756.6507447\tbest: 756.6507447 (704)\ttotal: 1m 52s\tremaining: 47.2s\n",
      "705:\tlearn: 759.1632491\ttest: 756.5554199\tbest: 756.5554199 (705)\ttotal: 1m 52s\tremaining: 47s\n",
      "706:\tlearn: 759.0504565\ttest: 756.4403892\tbest: 756.4403892 (706)\ttotal: 1m 53s\tremaining: 46.8s\n",
      "707:\tlearn: 758.8432782\ttest: 756.2160040\tbest: 756.2160040 (707)\ttotal: 1m 53s\tremaining: 46.7s\n",
      "708:\tlearn: 758.6992751\ttest: 756.0626841\tbest: 756.0626841 (708)\ttotal: 1m 53s\tremaining: 46.5s\n",
      "709:\tlearn: 758.4924730\ttest: 755.8592352\tbest: 755.8592352 (709)\ttotal: 1m 53s\tremaining: 46.4s\n",
      "710:\tlearn: 758.3440546\ttest: 755.6927155\tbest: 755.6927155 (710)\ttotal: 1m 53s\tremaining: 46.2s\n",
      "711:\tlearn: 758.1929234\ttest: 755.5515715\tbest: 755.5515715 (711)\ttotal: 1m 53s\tremaining: 46.1s\n",
      "712:\tlearn: 758.0759713\ttest: 755.4196592\tbest: 755.4196592 (712)\ttotal: 1m 54s\tremaining: 45.9s\n",
      "713:\tlearn: 757.8922047\ttest: 755.3077012\tbest: 755.3077012 (713)\ttotal: 1m 54s\tremaining: 45.7s\n",
      "714:\tlearn: 757.7755458\ttest: 755.1623001\tbest: 755.1623001 (714)\ttotal: 1m 54s\tremaining: 45.6s\n",
      "715:\tlearn: 757.7172567\ttest: 755.1127286\tbest: 755.1127286 (715)\ttotal: 1m 54s\tremaining: 45.4s\n",
      "716:\tlearn: 757.5571269\ttest: 754.9524180\tbest: 754.9524180 (716)\ttotal: 1m 54s\tremaining: 45.3s\n",
      "717:\tlearn: 757.4681350\ttest: 754.8624879\tbest: 754.8624879 (717)\ttotal: 1m 54s\tremaining: 45.1s\n",
      "718:\tlearn: 757.3568774\ttest: 754.7609306\tbest: 754.7609306 (718)\ttotal: 1m 55s\tremaining: 45s\n",
      "719:\tlearn: 757.2037802\ttest: 754.5947013\tbest: 754.5947013 (719)\ttotal: 1m 55s\tremaining: 44.8s\n",
      "720:\tlearn: 757.1220548\ttest: 754.5310583\tbest: 754.5310583 (720)\ttotal: 1m 55s\tremaining: 44.6s\n",
      "721:\tlearn: 756.9770706\ttest: 754.3702686\tbest: 754.3702686 (721)\ttotal: 1m 55s\tremaining: 44.5s\n",
      "722:\tlearn: 756.8377150\ttest: 754.2420760\tbest: 754.2420760 (722)\ttotal: 1m 55s\tremaining: 44.3s\n",
      "723:\tlearn: 756.7171493\ttest: 754.1311242\tbest: 754.1311242 (723)\ttotal: 1m 55s\tremaining: 44.2s\n",
      "724:\tlearn: 756.6328624\ttest: 754.0664155\tbest: 754.0664155 (724)\ttotal: 1m 55s\tremaining: 44s\n",
      "725:\tlearn: 756.4582766\ttest: 753.8862625\tbest: 753.8862625 (725)\ttotal: 1m 56s\tremaining: 43.8s\n",
      "726:\tlearn: 756.3458065\ttest: 753.7644570\tbest: 753.7644570 (726)\ttotal: 1m 56s\tremaining: 43.7s\n",
      "727:\tlearn: 756.2605517\ttest: 753.6766370\tbest: 753.6766370 (727)\ttotal: 1m 56s\tremaining: 43.5s\n",
      "728:\tlearn: 756.0935401\ttest: 753.4980639\tbest: 753.4980639 (728)\ttotal: 1m 56s\tremaining: 43.4s\n",
      "729:\tlearn: 755.9280865\ttest: 753.3311494\tbest: 753.3311494 (729)\ttotal: 1m 56s\tremaining: 43.2s\n",
      "730:\tlearn: 755.7965102\ttest: 753.1477975\tbest: 753.1477975 (730)\ttotal: 1m 56s\tremaining: 43s\n",
      "731:\tlearn: 755.6887393\ttest: 753.0254385\tbest: 753.0254385 (731)\ttotal: 1m 57s\tremaining: 42.9s\n",
      "732:\tlearn: 755.4630104\ttest: 752.7789196\tbest: 752.7789196 (732)\ttotal: 1m 57s\tremaining: 42.7s\n",
      "733:\tlearn: 755.3396259\ttest: 752.6524422\tbest: 752.6524422 (733)\ttotal: 1m 57s\tremaining: 42.6s\n",
      "734:\tlearn: 755.2337245\ttest: 752.6059028\tbest: 752.6059028 (734)\ttotal: 1m 57s\tremaining: 42.4s\n",
      "735:\tlearn: 755.1074778\ttest: 752.4761875\tbest: 752.4761875 (735)\ttotal: 1m 57s\tremaining: 42.2s\n",
      "736:\tlearn: 754.9216747\ttest: 752.2800667\tbest: 752.2800667 (736)\ttotal: 1m 57s\tremaining: 42.1s\n",
      "737:\tlearn: 754.7956811\ttest: 752.1393028\tbest: 752.1393028 (737)\ttotal: 1m 58s\tremaining: 41.9s\n",
      "738:\tlearn: 754.6692822\ttest: 752.0414283\tbest: 752.0414283 (738)\ttotal: 1m 58s\tremaining: 41.7s\n",
      "739:\tlearn: 754.5506114\ttest: 751.9183857\tbest: 751.9183857 (739)\ttotal: 1m 58s\tremaining: 41.6s\n",
      "740:\tlearn: 754.4747048\ttest: 751.8397074\tbest: 751.8397074 (740)\ttotal: 1m 58s\tremaining: 41.4s\n",
      "741:\tlearn: 754.3747229\ttest: 751.7226982\tbest: 751.7226982 (741)\ttotal: 1m 58s\tremaining: 41.2s\n",
      "742:\tlearn: 754.2629100\ttest: 751.6005477\tbest: 751.6005477 (742)\ttotal: 1m 58s\tremaining: 41.1s\n",
      "743:\tlearn: 754.1581811\ttest: 751.4657017\tbest: 751.4657017 (743)\ttotal: 1m 58s\tremaining: 40.9s\n",
      "744:\tlearn: 754.0866338\ttest: 751.3899683\tbest: 751.3899683 (744)\ttotal: 1m 59s\tremaining: 40.8s\n",
      "745:\tlearn: 753.9470391\ttest: 751.2641663\tbest: 751.2641663 (745)\ttotal: 1m 59s\tremaining: 40.6s\n",
      "746:\tlearn: 753.9297795\ttest: 751.2602099\tbest: 751.2602099 (746)\ttotal: 1m 59s\tremaining: 40.4s\n",
      "747:\tlearn: 753.8210701\ttest: 751.1474894\tbest: 751.1474894 (747)\ttotal: 1m 59s\tremaining: 40.3s\n",
      "748:\tlearn: 753.6822207\ttest: 751.0355942\tbest: 751.0355942 (748)\ttotal: 1m 59s\tremaining: 40.1s\n",
      "749:\tlearn: 753.4908409\ttest: 750.8467894\tbest: 750.8467894 (749)\ttotal: 1m 59s\tremaining: 39.9s\n",
      "750:\tlearn: 753.3643295\ttest: 750.7204983\tbest: 750.7204983 (750)\ttotal: 2m\tremaining: 39.8s\n",
      "751:\tlearn: 753.1969611\ttest: 750.5631562\tbest: 750.5631562 (751)\ttotal: 2m\tremaining: 39.6s\n",
      "752:\tlearn: 753.0428991\ttest: 750.4015725\tbest: 750.4015725 (752)\ttotal: 2m\tremaining: 39.5s\n",
      "753:\tlearn: 752.9316416\ttest: 750.3100889\tbest: 750.3100889 (753)\ttotal: 2m\tremaining: 39.3s\n",
      "754:\tlearn: 752.8217369\ttest: 750.2050068\tbest: 750.2050068 (754)\ttotal: 2m\tremaining: 39.1s\n",
      "755:\tlearn: 752.7096192\ttest: 750.0951920\tbest: 750.0951920 (755)\ttotal: 2m\tremaining: 39s\n",
      "756:\tlearn: 752.6065541\ttest: 749.9978054\tbest: 749.9978054 (756)\ttotal: 2m\tremaining: 38.8s\n",
      "757:\tlearn: 752.4785556\ttest: 749.8323213\tbest: 749.8323213 (757)\ttotal: 2m 1s\tremaining: 38.7s\n",
      "758:\tlearn: 752.2963818\ttest: 749.6548048\tbest: 749.6548048 (758)\ttotal: 2m 1s\tremaining: 38.5s\n",
      "759:\tlearn: 752.1599976\ttest: 749.5183231\tbest: 749.5183231 (759)\ttotal: 2m 1s\tremaining: 38.3s\n",
      "760:\tlearn: 752.0665477\ttest: 749.4603059\tbest: 749.4603059 (760)\ttotal: 2m 1s\tremaining: 38.2s\n",
      "761:\tlearn: 752.0211429\ttest: 749.4290436\tbest: 749.4290436 (761)\ttotal: 2m 1s\tremaining: 38s\n",
      "762:\tlearn: 751.8959534\ttest: 749.3234317\tbest: 749.3234317 (762)\ttotal: 2m 1s\tremaining: 37.9s\n",
      "763:\tlearn: 751.7681690\ttest: 749.1294369\tbest: 749.1294369 (763)\ttotal: 2m 2s\tremaining: 37.7s\n",
      "764:\tlearn: 751.6639230\ttest: 749.0320459\tbest: 749.0320459 (764)\ttotal: 2m 2s\tremaining: 37.5s\n",
      "765:\tlearn: 751.4486760\ttest: 748.8378000\tbest: 748.8378000 (765)\ttotal: 2m 2s\tremaining: 37.4s\n",
      "766:\tlearn: 751.3573688\ttest: 748.7544472\tbest: 748.7544472 (766)\ttotal: 2m 2s\tremaining: 37.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "767:\tlearn: 751.2247718\ttest: 748.6094327\tbest: 748.6094327 (767)\ttotal: 2m 2s\tremaining: 37.1s\n",
      "768:\tlearn: 751.1356859\ttest: 748.5444715\tbest: 748.5444715 (768)\ttotal: 2m 2s\tremaining: 36.9s\n",
      "769:\tlearn: 750.9439964\ttest: 748.4798527\tbest: 748.4798527 (769)\ttotal: 2m 3s\tremaining: 36.7s\n",
      "770:\tlearn: 750.8434110\ttest: 748.3472295\tbest: 748.3472295 (770)\ttotal: 2m 3s\tremaining: 36.6s\n",
      "771:\tlearn: 750.7442595\ttest: 748.2267946\tbest: 748.2267946 (771)\ttotal: 2m 3s\tremaining: 36.4s\n",
      "772:\tlearn: 750.5958875\ttest: 748.0646314\tbest: 748.0646314 (772)\ttotal: 2m 3s\tremaining: 36.3s\n",
      "773:\tlearn: 750.4510819\ttest: 747.8975152\tbest: 747.8975152 (773)\ttotal: 2m 3s\tremaining: 36.1s\n",
      "774:\tlearn: 750.3602654\ttest: 747.7971577\tbest: 747.7971577 (774)\ttotal: 2m 3s\tremaining: 36s\n",
      "775:\tlearn: 750.2565539\ttest: 747.7213917\tbest: 747.7213917 (775)\ttotal: 2m 3s\tremaining: 35.8s\n",
      "776:\tlearn: 750.1518541\ttest: 747.6186083\tbest: 747.6186083 (776)\ttotal: 2m 4s\tremaining: 35.6s\n",
      "777:\tlearn: 749.9497136\ttest: 747.4166541\tbest: 747.4166541 (777)\ttotal: 2m 4s\tremaining: 35.5s\n",
      "778:\tlearn: 749.7657438\ttest: 747.2572409\tbest: 747.2572409 (778)\ttotal: 2m 4s\tremaining: 35.3s\n",
      "779:\tlearn: 749.5524907\ttest: 747.0959881\tbest: 747.0959881 (779)\ttotal: 2m 4s\tremaining: 35.2s\n",
      "780:\tlearn: 749.4691828\ttest: 747.0091198\tbest: 747.0091198 (780)\ttotal: 2m 4s\tremaining: 35s\n",
      "781:\tlearn: 749.3030406\ttest: 746.8761804\tbest: 746.8761804 (781)\ttotal: 2m 5s\tremaining: 34.9s\n",
      "782:\tlearn: 749.1403428\ttest: 746.7074380\tbest: 746.7074380 (782)\ttotal: 2m 5s\tremaining: 34.7s\n",
      "783:\tlearn: 749.0583137\ttest: 746.6202009\tbest: 746.6202009 (783)\ttotal: 2m 5s\tremaining: 34.6s\n",
      "784:\tlearn: 748.9784287\ttest: 746.5146244\tbest: 746.5146244 (784)\ttotal: 2m 5s\tremaining: 34.4s\n",
      "785:\tlearn: 748.7692014\ttest: 746.3183719\tbest: 746.3183719 (785)\ttotal: 2m 5s\tremaining: 34.2s\n",
      "786:\tlearn: 748.6376559\ttest: 746.2601159\tbest: 746.2601159 (786)\ttotal: 2m 5s\tremaining: 34.1s\n",
      "787:\tlearn: 748.5777222\ttest: 746.2068599\tbest: 746.2068599 (787)\ttotal: 2m 6s\tremaining: 33.9s\n",
      "788:\tlearn: 748.4794493\ttest: 746.1119234\tbest: 746.1119234 (788)\ttotal: 2m 6s\tremaining: 33.8s\n",
      "789:\tlearn: 748.3969265\ttest: 746.0206861\tbest: 746.0206861 (789)\ttotal: 2m 6s\tremaining: 33.6s\n",
      "790:\tlearn: 748.3406878\ttest: 745.9567657\tbest: 745.9567657 (790)\ttotal: 2m 6s\tremaining: 33.5s\n",
      "791:\tlearn: 748.2319739\ttest: 745.9138723\tbest: 745.9138723 (791)\ttotal: 2m 6s\tremaining: 33.3s\n",
      "792:\tlearn: 748.1216591\ttest: 745.7988166\tbest: 745.7988166 (792)\ttotal: 2m 6s\tremaining: 33.1s\n",
      "793:\tlearn: 748.0394691\ttest: 745.7696022\tbest: 745.7696022 (793)\ttotal: 2m 7s\tremaining: 33s\n",
      "794:\tlearn: 747.9430264\ttest: 745.6863711\tbest: 745.6863711 (794)\ttotal: 2m 7s\tremaining: 32.8s\n",
      "795:\tlearn: 747.8209867\ttest: 745.5695130\tbest: 745.5695130 (795)\ttotal: 2m 7s\tremaining: 32.6s\n",
      "796:\tlearn: 747.7180717\ttest: 745.4694885\tbest: 745.4694885 (796)\ttotal: 2m 7s\tremaining: 32.5s\n",
      "797:\tlearn: 747.6199137\ttest: 745.3634484\tbest: 745.3634484 (797)\ttotal: 2m 7s\tremaining: 32.3s\n",
      "798:\tlearn: 747.3766655\ttest: 745.0268873\tbest: 745.0268873 (798)\ttotal: 2m 7s\tremaining: 32.2s\n",
      "799:\tlearn: 747.1998002\ttest: 744.8420542\tbest: 744.8420542 (799)\ttotal: 2m 8s\tremaining: 32s\n",
      "800:\tlearn: 747.1348750\ttest: 744.7739247\tbest: 744.7739247 (800)\ttotal: 2m 8s\tremaining: 31.9s\n",
      "801:\tlearn: 747.0620878\ttest: 744.7027243\tbest: 744.7027243 (801)\ttotal: 2m 8s\tremaining: 31.7s\n",
      "802:\tlearn: 746.8885273\ttest: 744.5567240\tbest: 744.5567240 (802)\ttotal: 2m 8s\tremaining: 31.5s\n",
      "803:\tlearn: 746.7746940\ttest: 744.4516690\tbest: 744.4516690 (803)\ttotal: 2m 8s\tremaining: 31.4s\n",
      "804:\tlearn: 746.6816949\ttest: 744.3689175\tbest: 744.3689175 (804)\ttotal: 2m 8s\tremaining: 31.2s\n",
      "805:\tlearn: 746.5586442\ttest: 744.2374294\tbest: 744.2374294 (805)\ttotal: 2m 9s\tremaining: 31.1s\n",
      "806:\tlearn: 746.4257564\ttest: 744.1327686\tbest: 744.1327686 (806)\ttotal: 2m 9s\tremaining: 30.9s\n",
      "807:\tlearn: 746.2590546\ttest: 743.9837375\tbest: 743.9837375 (807)\ttotal: 2m 9s\tremaining: 30.7s\n",
      "808:\tlearn: 746.0729869\ttest: 743.7808636\tbest: 743.7808636 (808)\ttotal: 2m 9s\tremaining: 30.6s\n",
      "809:\tlearn: 745.9876103\ttest: 743.6960535\tbest: 743.6960535 (809)\ttotal: 2m 9s\tremaining: 30.4s\n",
      "810:\tlearn: 745.9021960\ttest: 743.6139403\tbest: 743.6139403 (810)\ttotal: 2m 9s\tremaining: 30.3s\n",
      "811:\tlearn: 745.7880664\ttest: 743.4973930\tbest: 743.4973930 (811)\ttotal: 2m 10s\tremaining: 30.1s\n",
      "812:\tlearn: 745.7319430\ttest: 743.4203994\tbest: 743.4203994 (812)\ttotal: 2m 10s\tremaining: 29.9s\n",
      "813:\tlearn: 745.5383237\ttest: 743.0084112\tbest: 743.0084112 (813)\ttotal: 2m 10s\tremaining: 29.8s\n",
      "814:\tlearn: 745.4272428\ttest: 742.8846149\tbest: 742.8846149 (814)\ttotal: 2m 10s\tremaining: 29.6s\n",
      "815:\tlearn: 745.3100292\ttest: 742.7655399\tbest: 742.7655399 (815)\ttotal: 2m 10s\tremaining: 29.5s\n",
      "816:\tlearn: 745.2525781\ttest: 742.7195199\tbest: 742.7195199 (816)\ttotal: 2m 10s\tremaining: 29.3s\n",
      "817:\tlearn: 745.0690727\ttest: 742.5693879\tbest: 742.5693879 (817)\ttotal: 2m 11s\tremaining: 29.2s\n",
      "818:\tlearn: 745.0084125\ttest: 742.4940802\tbest: 742.4940802 (818)\ttotal: 2m 11s\tremaining: 29s\n",
      "819:\tlearn: 744.9268299\ttest: 742.4593887\tbest: 742.4593887 (819)\ttotal: 2m 11s\tremaining: 28.8s\n",
      "820:\tlearn: 744.8210621\ttest: 742.3675100\tbest: 742.3675100 (820)\ttotal: 2m 11s\tremaining: 28.7s\n",
      "821:\tlearn: 744.7153306\ttest: 742.2967195\tbest: 742.2967195 (821)\ttotal: 2m 11s\tremaining: 28.5s\n",
      "822:\tlearn: 744.5624957\ttest: 742.1177958\tbest: 742.1177958 (822)\ttotal: 2m 11s\tremaining: 28.4s\n",
      "823:\tlearn: 744.4888101\ttest: 741.9995014\tbest: 741.9995014 (823)\ttotal: 2m 12s\tremaining: 28.2s\n",
      "824:\tlearn: 744.3848575\ttest: 741.8973701\tbest: 741.8973701 (824)\ttotal: 2m 12s\tremaining: 28s\n",
      "825:\tlearn: 744.3041227\ttest: 741.8191821\tbest: 741.8191821 (825)\ttotal: 2m 12s\tremaining: 27.9s\n",
      "826:\tlearn: 744.1694875\ttest: 741.6708874\tbest: 741.6708874 (826)\ttotal: 2m 12s\tremaining: 27.7s\n",
      "827:\tlearn: 744.0775935\ttest: 741.5672141\tbest: 741.5672141 (827)\ttotal: 2m 12s\tremaining: 27.6s\n",
      "828:\tlearn: 744.0222322\ttest: 741.5166824\tbest: 741.5166824 (828)\ttotal: 2m 12s\tremaining: 27.4s\n",
      "829:\tlearn: 743.9419164\ttest: 741.4363093\tbest: 741.4363093 (829)\ttotal: 2m 12s\tremaining: 27.2s\n",
      "830:\tlearn: 743.8461744\ttest: 741.3560636\tbest: 741.3560636 (830)\ttotal: 2m 13s\tremaining: 27.1s\n",
      "831:\tlearn: 743.7074229\ttest: 741.2073279\tbest: 741.2073279 (831)\ttotal: 2m 13s\tremaining: 26.9s\n",
      "832:\tlearn: 743.6080144\ttest: 741.1205836\tbest: 741.1205836 (832)\ttotal: 2m 13s\tremaining: 26.7s\n",
      "833:\tlearn: 743.5226765\ttest: 741.0274275\tbest: 741.0274275 (833)\ttotal: 2m 13s\tremaining: 26.6s\n",
      "834:\tlearn: 743.3943927\ttest: 740.8918827\tbest: 740.8918827 (834)\ttotal: 2m 13s\tremaining: 26.4s\n",
      "835:\tlearn: 743.2844739\ttest: 740.7359402\tbest: 740.7359402 (835)\ttotal: 2m 13s\tremaining: 26.3s\n",
      "836:\tlearn: 743.1734521\ttest: 740.6937135\tbest: 740.6937135 (836)\ttotal: 2m 14s\tremaining: 26.1s\n",
      "837:\tlearn: 743.1042054\ttest: 740.6362747\tbest: 740.6362747 (837)\ttotal: 2m 14s\tremaining: 25.9s\n",
      "838:\tlearn: 742.9051271\ttest: 740.4404083\tbest: 740.4404083 (838)\ttotal: 2m 14s\tremaining: 25.8s\n",
      "839:\tlearn: 742.7469366\ttest: 740.2702990\tbest: 740.2702990 (839)\ttotal: 2m 14s\tremaining: 25.6s\n",
      "840:\tlearn: 742.6025011\ttest: 740.0996974\tbest: 740.0996974 (840)\ttotal: 2m 14s\tremaining: 25.5s\n",
      "841:\tlearn: 742.5277458\ttest: 740.0236046\tbest: 740.0236046 (841)\ttotal: 2m 14s\tremaining: 25.3s\n",
      "842:\tlearn: 742.4480210\ttest: 739.9483304\tbest: 739.9483304 (842)\ttotal: 2m 14s\tremaining: 25.1s\n",
      "843:\tlearn: 742.4031129\ttest: 739.8995021\tbest: 739.8995021 (843)\ttotal: 2m 15s\tremaining: 25s\n",
      "844:\tlearn: 742.3210154\ttest: 739.8436144\tbest: 739.8436144 (844)\ttotal: 2m 15s\tremaining: 24.8s\n",
      "845:\tlearn: 742.1369147\ttest: 739.6838145\tbest: 739.6838145 (845)\ttotal: 2m 15s\tremaining: 24.7s\n",
      "846:\tlearn: 742.0116099\ttest: 739.5194125\tbest: 739.5194125 (846)\ttotal: 2m 15s\tremaining: 24.5s\n",
      "847:\tlearn: 741.9145608\ttest: 739.4701609\tbest: 739.4701609 (847)\ttotal: 2m 15s\tremaining: 24.3s\n",
      "848:\tlearn: 741.7803244\ttest: 739.3655486\tbest: 739.3655486 (848)\ttotal: 2m 15s\tremaining: 24.2s\n",
      "849:\tlearn: 741.6823624\ttest: 739.2868313\tbest: 739.2868313 (849)\ttotal: 2m 16s\tremaining: 24s\n",
      "850:\tlearn: 741.5698282\ttest: 739.0860813\tbest: 739.0860813 (850)\ttotal: 2m 16s\tremaining: 23.8s\n",
      "851:\tlearn: 741.4731024\ttest: 738.9968709\tbest: 738.9968709 (851)\ttotal: 2m 16s\tremaining: 23.7s\n",
      "852:\tlearn: 741.3638676\ttest: 738.8814236\tbest: 738.8814236 (852)\ttotal: 2m 16s\tremaining: 23.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "853:\tlearn: 741.2471966\ttest: 738.7525521\tbest: 738.7525521 (853)\ttotal: 2m 16s\tremaining: 23.4s\n",
      "854:\tlearn: 741.1498807\ttest: 738.7400473\tbest: 738.7400473 (854)\ttotal: 2m 16s\tremaining: 23.2s\n",
      "855:\tlearn: 741.0529022\ttest: 738.6229861\tbest: 738.6229861 (855)\ttotal: 2m 17s\tremaining: 23.1s\n",
      "856:\tlearn: 740.9858626\ttest: 738.5375583\tbest: 738.5375583 (856)\ttotal: 2m 17s\tremaining: 22.9s\n",
      "857:\tlearn: 740.9296400\ttest: 738.4496188\tbest: 738.4496188 (857)\ttotal: 2m 17s\tremaining: 22.7s\n",
      "858:\tlearn: 740.8074964\ttest: 738.3049024\tbest: 738.3049024 (858)\ttotal: 2m 17s\tremaining: 22.6s\n",
      "859:\tlearn: 740.7030583\ttest: 738.1892757\tbest: 738.1892757 (859)\ttotal: 2m 17s\tremaining: 22.4s\n",
      "860:\tlearn: 740.5762075\ttest: 738.0743227\tbest: 738.0743227 (860)\ttotal: 2m 17s\tremaining: 22.2s\n",
      "861:\tlearn: 740.4079715\ttest: 737.8832169\tbest: 737.8832169 (861)\ttotal: 2m 17s\tremaining: 22.1s\n",
      "862:\tlearn: 740.2698533\ttest: 737.7392428\tbest: 737.7392428 (862)\ttotal: 2m 18s\tremaining: 21.9s\n",
      "863:\tlearn: 740.1435273\ttest: 737.6106755\tbest: 737.6106755 (863)\ttotal: 2m 18s\tremaining: 21.8s\n",
      "864:\tlearn: 740.0322592\ttest: 737.4841560\tbest: 737.4841560 (864)\ttotal: 2m 18s\tremaining: 21.6s\n",
      "865:\tlearn: 739.9209824\ttest: 737.4048966\tbest: 737.4048966 (865)\ttotal: 2m 18s\tremaining: 21.4s\n",
      "866:\tlearn: 739.8289095\ttest: 737.3142775\tbest: 737.3142775 (866)\ttotal: 2m 18s\tremaining: 21.3s\n",
      "867:\tlearn: 739.6803823\ttest: 737.1726348\tbest: 737.1726348 (867)\ttotal: 2m 18s\tremaining: 21.1s\n",
      "868:\tlearn: 739.5595069\ttest: 737.0554006\tbest: 737.0554006 (868)\ttotal: 2m 19s\tremaining: 21s\n",
      "869:\tlearn: 739.2714476\ttest: 736.7706777\tbest: 736.7706777 (869)\ttotal: 2m 19s\tremaining: 20.8s\n",
      "870:\tlearn: 739.0892744\ttest: 736.6075375\tbest: 736.6075375 (870)\ttotal: 2m 19s\tremaining: 20.7s\n",
      "871:\tlearn: 738.8977063\ttest: 736.4260758\tbest: 736.4260758 (871)\ttotal: 2m 19s\tremaining: 20.5s\n",
      "872:\tlearn: 738.8029674\ttest: 736.3401659\tbest: 736.3401659 (872)\ttotal: 2m 19s\tremaining: 20.3s\n",
      "873:\tlearn: 738.7357245\ttest: 736.2719894\tbest: 736.2719894 (873)\ttotal: 2m 20s\tremaining: 20.2s\n",
      "874:\tlearn: 738.6517215\ttest: 736.1701871\tbest: 736.1701871 (874)\ttotal: 2m 20s\tremaining: 20s\n",
      "875:\tlearn: 738.5651623\ttest: 736.0783694\tbest: 736.0783694 (875)\ttotal: 2m 20s\tremaining: 19.9s\n",
      "876:\tlearn: 738.5129692\ttest: 736.0215801\tbest: 736.0215801 (876)\ttotal: 2m 20s\tremaining: 19.7s\n",
      "877:\tlearn: 738.3851354\ttest: 735.8850918\tbest: 735.8850918 (877)\ttotal: 2m 20s\tremaining: 19.5s\n",
      "878:\tlearn: 738.2836603\ttest: 735.8027576\tbest: 735.8027576 (878)\ttotal: 2m 20s\tremaining: 19.4s\n",
      "879:\tlearn: 738.2100984\ttest: 735.7288042\tbest: 735.7288042 (879)\ttotal: 2m 21s\tremaining: 19.2s\n",
      "880:\tlearn: 738.0964293\ttest: 735.6052107\tbest: 735.6052107 (880)\ttotal: 2m 21s\tremaining: 19.1s\n",
      "881:\tlearn: 738.0173183\ttest: 735.5210826\tbest: 735.5210826 (881)\ttotal: 2m 21s\tremaining: 18.9s\n",
      "882:\tlearn: 737.7997021\ttest: 735.3031114\tbest: 735.3031114 (882)\ttotal: 2m 21s\tremaining: 18.8s\n",
      "883:\tlearn: 737.7211338\ttest: 735.2406021\tbest: 735.2406021 (883)\ttotal: 2m 21s\tremaining: 18.6s\n",
      "884:\tlearn: 737.5941234\ttest: 735.1178985\tbest: 735.1178985 (884)\ttotal: 2m 21s\tremaining: 18.4s\n",
      "885:\tlearn: 737.5024752\ttest: 735.0211096\tbest: 735.0211096 (885)\ttotal: 2m 22s\tremaining: 18.3s\n",
      "886:\tlearn: 737.3921960\ttest: 734.9028395\tbest: 734.9028395 (886)\ttotal: 2m 22s\tremaining: 18.1s\n",
      "887:\tlearn: 737.1797276\ttest: 734.6652487\tbest: 734.6652487 (887)\ttotal: 2m 22s\tremaining: 17.9s\n",
      "888:\tlearn: 737.0932307\ttest: 734.5697067\tbest: 734.5697067 (888)\ttotal: 2m 22s\tremaining: 17.8s\n",
      "889:\tlearn: 737.0026043\ttest: 734.4714687\tbest: 734.4714687 (889)\ttotal: 2m 22s\tremaining: 17.6s\n",
      "890:\tlearn: 736.8908737\ttest: 734.4561109\tbest: 734.4561109 (890)\ttotal: 2m 22s\tremaining: 17.5s\n",
      "891:\tlearn: 736.7277740\ttest: 734.3103192\tbest: 734.3103192 (891)\ttotal: 2m 22s\tremaining: 17.3s\n",
      "892:\tlearn: 736.6408129\ttest: 734.2256983\tbest: 734.2256983 (892)\ttotal: 2m 23s\tremaining: 17.2s\n",
      "893:\tlearn: 736.5580680\ttest: 734.1273219\tbest: 734.1273219 (893)\ttotal: 2m 23s\tremaining: 17s\n",
      "894:\tlearn: 736.4708060\ttest: 734.0730572\tbest: 734.0730572 (894)\ttotal: 2m 23s\tremaining: 16.8s\n",
      "895:\tlearn: 736.3300043\ttest: 733.9071980\tbest: 733.9071980 (895)\ttotal: 2m 23s\tremaining: 16.7s\n",
      "896:\tlearn: 736.2245114\ttest: 733.7954707\tbest: 733.7954707 (896)\ttotal: 2m 23s\tremaining: 16.5s\n",
      "897:\tlearn: 736.0764024\ttest: 733.6627023\tbest: 733.6627023 (897)\ttotal: 2m 23s\tremaining: 16.4s\n",
      "898:\tlearn: 735.9601695\ttest: 733.5579260\tbest: 733.5579260 (898)\ttotal: 2m 24s\tremaining: 16.2s\n",
      "899:\tlearn: 735.8751726\ttest: 733.4685410\tbest: 733.4685410 (899)\ttotal: 2m 24s\tremaining: 16s\n",
      "900:\tlearn: 735.7757361\ttest: 733.3431648\tbest: 733.3431648 (900)\ttotal: 2m 24s\tremaining: 15.9s\n",
      "901:\tlearn: 735.6438023\ttest: 733.2155064\tbest: 733.2155064 (901)\ttotal: 2m 24s\tremaining: 15.7s\n",
      "902:\tlearn: 735.5646181\ttest: 733.1352981\tbest: 733.1352981 (902)\ttotal: 2m 24s\tremaining: 15.6s\n",
      "903:\tlearn: 735.4906267\ttest: 733.0700898\tbest: 733.0700898 (903)\ttotal: 2m 24s\tremaining: 15.4s\n",
      "904:\tlearn: 735.3351024\ttest: 732.9491395\tbest: 732.9491395 (904)\ttotal: 2m 25s\tremaining: 15.2s\n",
      "905:\tlearn: 735.2044076\ttest: 732.8543379\tbest: 732.8543379 (905)\ttotal: 2m 25s\tremaining: 15.1s\n",
      "906:\tlearn: 735.1465411\ttest: 732.7978788\tbest: 732.7978788 (906)\ttotal: 2m 25s\tremaining: 14.9s\n",
      "907:\tlearn: 734.9892531\ttest: 732.6755809\tbest: 732.6755809 (907)\ttotal: 2m 25s\tremaining: 14.8s\n",
      "908:\tlearn: 734.9020805\ttest: 732.5906197\tbest: 732.5906197 (908)\ttotal: 2m 25s\tremaining: 14.6s\n",
      "909:\tlearn: 734.8249325\ttest: 732.5252608\tbest: 732.5252608 (909)\ttotal: 2m 25s\tremaining: 14.4s\n",
      "910:\tlearn: 734.6950544\ttest: 732.3999846\tbest: 732.3999846 (910)\ttotal: 2m 26s\tremaining: 14.3s\n",
      "911:\tlearn: 734.6100952\ttest: 732.3384434\tbest: 732.3384434 (911)\ttotal: 2m 26s\tremaining: 14.1s\n",
      "912:\tlearn: 734.4894091\ttest: 732.2054993\tbest: 732.2054993 (912)\ttotal: 2m 26s\tremaining: 14s\n",
      "913:\tlearn: 734.3850968\ttest: 732.1117788\tbest: 732.1117788 (913)\ttotal: 2m 26s\tremaining: 13.8s\n",
      "914:\tlearn: 734.3070396\ttest: 732.0345259\tbest: 732.0345259 (914)\ttotal: 2m 26s\tremaining: 13.6s\n",
      "915:\tlearn: 734.2676948\ttest: 732.0159865\tbest: 732.0159865 (915)\ttotal: 2m 26s\tremaining: 13.5s\n",
      "916:\tlearn: 734.1724474\ttest: 731.9244875\tbest: 731.9244875 (916)\ttotal: 2m 27s\tremaining: 13.3s\n",
      "917:\tlearn: 734.0111234\ttest: 731.7507996\tbest: 731.7507996 (917)\ttotal: 2m 27s\tremaining: 13.2s\n",
      "918:\tlearn: 733.8601478\ttest: 731.6102601\tbest: 731.6102601 (918)\ttotal: 2m 27s\tremaining: 13s\n",
      "919:\tlearn: 733.7898088\ttest: 731.5499441\tbest: 731.5499441 (919)\ttotal: 2m 27s\tremaining: 12.8s\n",
      "920:\tlearn: 733.7146329\ttest: 731.4818625\tbest: 731.4818625 (920)\ttotal: 2m 27s\tremaining: 12.7s\n",
      "921:\tlearn: 733.6118884\ttest: 731.3681815\tbest: 731.3681815 (921)\ttotal: 2m 27s\tremaining: 12.5s\n",
      "922:\tlearn: 733.5087491\ttest: 731.2711134\tbest: 731.2711134 (922)\ttotal: 2m 28s\tremaining: 12.4s\n",
      "923:\tlearn: 733.4471521\ttest: 731.2112192\tbest: 731.2112192 (923)\ttotal: 2m 28s\tremaining: 12.2s\n",
      "924:\tlearn: 733.3432680\ttest: 731.1353408\tbest: 731.1353408 (924)\ttotal: 2m 28s\tremaining: 12s\n",
      "925:\tlearn: 733.2537438\ttest: 731.0555003\tbest: 731.0555003 (925)\ttotal: 2m 28s\tremaining: 11.9s\n",
      "926:\tlearn: 733.1661518\ttest: 730.9711276\tbest: 730.9711276 (926)\ttotal: 2m 28s\tremaining: 11.7s\n",
      "927:\tlearn: 733.0730700\ttest: 730.9321720\tbest: 730.9321720 (927)\ttotal: 2m 28s\tremaining: 11.5s\n",
      "928:\tlearn: 732.9591652\ttest: 730.8055825\tbest: 730.8055825 (928)\ttotal: 2m 28s\tremaining: 11.4s\n",
      "929:\tlearn: 732.8512085\ttest: 730.6855913\tbest: 730.6855913 (929)\ttotal: 2m 29s\tremaining: 11.2s\n",
      "930:\tlearn: 732.7495257\ttest: 730.5596487\tbest: 730.5596487 (930)\ttotal: 2m 29s\tremaining: 11.1s\n",
      "931:\tlearn: 732.7473001\ttest: 730.5601794\tbest: 730.5596487 (930)\ttotal: 2m 29s\tremaining: 10.9s\n",
      "932:\tlearn: 732.6503159\ttest: 730.4756049\tbest: 730.4756049 (932)\ttotal: 2m 29s\tremaining: 10.7s\n",
      "933:\tlearn: 732.5129286\ttest: 730.3912419\tbest: 730.3912419 (933)\ttotal: 2m 29s\tremaining: 10.6s\n",
      "934:\tlearn: 732.4532841\ttest: 730.3264440\tbest: 730.3264440 (934)\ttotal: 2m 29s\tremaining: 10.4s\n",
      "935:\tlearn: 732.3468526\ttest: 730.2388427\tbest: 730.2388427 (935)\ttotal: 2m 30s\tremaining: 10.3s\n",
      "936:\tlearn: 732.2828806\ttest: 730.1834126\tbest: 730.1834126 (936)\ttotal: 2m 30s\tremaining: 10.1s\n",
      "937:\tlearn: 732.1754588\ttest: 730.0859270\tbest: 730.0859270 (937)\ttotal: 2m 30s\tremaining: 9.94s\n",
      "938:\tlearn: 732.0386129\ttest: 729.9424694\tbest: 729.9424694 (938)\ttotal: 2m 30s\tremaining: 9.78s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "939:\tlearn: 731.9471164\ttest: 729.8418453\tbest: 729.8418453 (939)\ttotal: 2m 30s\tremaining: 9.62s\n",
      "940:\tlearn: 731.8364336\ttest: 729.7402726\tbest: 729.7402726 (940)\ttotal: 2m 30s\tremaining: 9.46s\n",
      "941:\tlearn: 731.7654341\ttest: 729.6621427\tbest: 729.6621427 (941)\ttotal: 2m 31s\tremaining: 9.3s\n",
      "942:\tlearn: 731.7057303\ttest: 729.6124831\tbest: 729.6124831 (942)\ttotal: 2m 31s\tremaining: 9.14s\n",
      "943:\tlearn: 731.6370599\ttest: 729.5584489\tbest: 729.5584489 (943)\ttotal: 2m 31s\tremaining: 8.98s\n",
      "944:\tlearn: 731.4993892\ttest: 729.4247056\tbest: 729.4247056 (944)\ttotal: 2m 31s\tremaining: 8.82s\n",
      "945:\tlearn: 731.3500915\ttest: 729.2855556\tbest: 729.2855556 (945)\ttotal: 2m 31s\tremaining: 8.66s\n",
      "946:\tlearn: 731.2237491\ttest: 729.1876377\tbest: 729.1876377 (946)\ttotal: 2m 31s\tremaining: 8.5s\n",
      "947:\tlearn: 731.1075012\ttest: 729.0549308\tbest: 729.0549308 (947)\ttotal: 2m 32s\tremaining: 8.34s\n",
      "948:\tlearn: 731.0536861\ttest: 729.0109583\tbest: 729.0109583 (948)\ttotal: 2m 32s\tremaining: 8.18s\n",
      "949:\tlearn: 730.9347214\ttest: 728.9170953\tbest: 728.9170953 (949)\ttotal: 2m 32s\tremaining: 8.02s\n",
      "950:\tlearn: 730.8625336\ttest: 728.8390064\tbest: 728.8390064 (950)\ttotal: 2m 32s\tremaining: 7.86s\n",
      "951:\tlearn: 730.8102351\ttest: 728.7874946\tbest: 728.7874946 (951)\ttotal: 2m 32s\tremaining: 7.7s\n",
      "952:\tlearn: 730.7806645\ttest: 728.7636793\tbest: 728.7636793 (952)\ttotal: 2m 32s\tremaining: 7.54s\n",
      "953:\tlearn: 730.7056936\ttest: 728.6987006\tbest: 728.6987006 (953)\ttotal: 2m 32s\tremaining: 7.37s\n",
      "954:\tlearn: 730.6083688\ttest: 728.6286163\tbest: 728.6286163 (954)\ttotal: 2m 33s\tremaining: 7.21s\n",
      "955:\tlearn: 730.4420538\ttest: 728.4709563\tbest: 728.4709563 (955)\ttotal: 2m 33s\tremaining: 7.05s\n",
      "956:\tlearn: 730.3261852\ttest: 728.3652861\tbest: 728.3652861 (956)\ttotal: 2m 33s\tremaining: 6.89s\n",
      "957:\tlearn: 730.1711350\ttest: 728.2153367\tbest: 728.2153367 (957)\ttotal: 2m 33s\tremaining: 6.73s\n",
      "958:\tlearn: 730.1018016\ttest: 728.1614380\tbest: 728.1614380 (958)\ttotal: 2m 33s\tremaining: 6.57s\n",
      "959:\tlearn: 729.9753702\ttest: 728.0387340\tbest: 728.0387340 (959)\ttotal: 2m 33s\tremaining: 6.41s\n",
      "960:\tlearn: 729.8975267\ttest: 727.9506438\tbest: 727.9506438 (960)\ttotal: 2m 34s\tremaining: 6.25s\n",
      "961:\tlearn: 729.8588365\ttest: 727.9070673\tbest: 727.9070673 (961)\ttotal: 2m 34s\tremaining: 6.09s\n",
      "962:\tlearn: 729.6912888\ttest: 727.7566640\tbest: 727.7566640 (962)\ttotal: 2m 34s\tremaining: 5.93s\n",
      "963:\tlearn: 729.5593093\ttest: 727.6188135\tbest: 727.6188135 (963)\ttotal: 2m 34s\tremaining: 5.77s\n",
      "964:\tlearn: 729.3952453\ttest: 727.4505583\tbest: 727.4505583 (964)\ttotal: 2m 34s\tremaining: 5.61s\n",
      "965:\tlearn: 729.3099951\ttest: 727.3779695\tbest: 727.3779695 (965)\ttotal: 2m 34s\tremaining: 5.45s\n",
      "966:\tlearn: 729.1830737\ttest: 727.2578705\tbest: 727.2578705 (966)\ttotal: 2m 34s\tremaining: 5.29s\n",
      "967:\tlearn: 729.0783823\ttest: 727.1619483\tbest: 727.1619483 (967)\ttotal: 2m 35s\tremaining: 5.13s\n",
      "968:\tlearn: 729.0154151\ttest: 727.0896873\tbest: 727.0896873 (968)\ttotal: 2m 35s\tremaining: 4.97s\n",
      "969:\tlearn: 728.9204575\ttest: 726.9947202\tbest: 726.9947202 (969)\ttotal: 2m 35s\tremaining: 4.81s\n",
      "970:\tlearn: 728.7488082\ttest: 726.7012863\tbest: 726.7012863 (970)\ttotal: 2m 35s\tremaining: 4.65s\n",
      "971:\tlearn: 728.6542976\ttest: 726.6315587\tbest: 726.6315587 (971)\ttotal: 2m 35s\tremaining: 4.49s\n",
      "972:\tlearn: 728.5563775\ttest: 726.5253551\tbest: 726.5253551 (972)\ttotal: 2m 35s\tremaining: 4.33s\n",
      "973:\tlearn: 728.4373394\ttest: 726.4070691\tbest: 726.4070691 (973)\ttotal: 2m 36s\tremaining: 4.17s\n",
      "974:\tlearn: 728.3527946\ttest: 726.3391238\tbest: 726.3391238 (974)\ttotal: 2m 36s\tremaining: 4.01s\n",
      "975:\tlearn: 728.2231164\ttest: 726.1978852\tbest: 726.1978852 (975)\ttotal: 2m 36s\tremaining: 3.85s\n",
      "976:\tlearn: 728.1209150\ttest: 726.1133788\tbest: 726.1133788 (976)\ttotal: 2m 36s\tremaining: 3.69s\n",
      "977:\tlearn: 727.9785653\ttest: 725.9747430\tbest: 725.9747430 (977)\ttotal: 2m 36s\tremaining: 3.53s\n",
      "978:\tlearn: 727.8571706\ttest: 725.8697349\tbest: 725.8697349 (978)\ttotal: 2m 37s\tremaining: 3.37s\n",
      "979:\tlearn: 727.7801233\ttest: 725.7785233\tbest: 725.7785233 (979)\ttotal: 2m 37s\tremaining: 3.21s\n",
      "980:\tlearn: 727.7209046\ttest: 725.7615684\tbest: 725.7615684 (980)\ttotal: 2m 37s\tremaining: 3.05s\n",
      "981:\tlearn: 727.6373756\ttest: 725.6788631\tbest: 725.6788631 (981)\ttotal: 2m 37s\tremaining: 2.89s\n",
      "982:\tlearn: 727.5504119\ttest: 725.5814231\tbest: 725.5814231 (982)\ttotal: 2m 37s\tremaining: 2.73s\n",
      "983:\tlearn: 727.4734299\ttest: 725.5081851\tbest: 725.5081851 (983)\ttotal: 2m 37s\tremaining: 2.57s\n",
      "984:\tlearn: 727.3399582\ttest: 725.3919200\tbest: 725.3919200 (984)\ttotal: 2m 38s\tremaining: 2.41s\n",
      "985:\tlearn: 727.2305921\ttest: 725.2616442\tbest: 725.2616442 (985)\ttotal: 2m 38s\tremaining: 2.25s\n",
      "986:\tlearn: 727.0949649\ttest: 725.1128543\tbest: 725.1128543 (986)\ttotal: 2m 38s\tremaining: 2.09s\n",
      "987:\tlearn: 727.0180416\ttest: 725.0310034\tbest: 725.0310034 (987)\ttotal: 2m 38s\tremaining: 1.93s\n",
      "988:\tlearn: 726.8790945\ttest: 724.9018646\tbest: 724.9018646 (988)\ttotal: 2m 38s\tremaining: 1.76s\n",
      "989:\tlearn: 726.7845851\ttest: 724.8129791\tbest: 724.8129791 (989)\ttotal: 2m 38s\tremaining: 1.6s\n",
      "990:\tlearn: 726.6486659\ttest: 724.6771443\tbest: 724.6771443 (990)\ttotal: 2m 39s\tremaining: 1.44s\n",
      "991:\tlearn: 726.5673111\ttest: 724.5952963\tbest: 724.5952963 (991)\ttotal: 2m 39s\tremaining: 1.28s\n",
      "992:\tlearn: 726.4841196\ttest: 724.5035561\tbest: 724.5035561 (992)\ttotal: 2m 39s\tremaining: 1.12s\n",
      "993:\tlearn: 726.4161095\ttest: 724.4452747\tbest: 724.4452747 (993)\ttotal: 2m 39s\tremaining: 963ms\n",
      "994:\tlearn: 726.2883774\ttest: 724.2664617\tbest: 724.2664617 (994)\ttotal: 2m 39s\tremaining: 803ms\n",
      "995:\tlearn: 726.2065928\ttest: 724.1846531\tbest: 724.1846531 (995)\ttotal: 2m 39s\tremaining: 642ms\n",
      "996:\tlearn: 726.0713276\ttest: 724.0532660\tbest: 724.0532660 (996)\ttotal: 2m 40s\tremaining: 482ms\n",
      "997:\tlearn: 725.9703404\ttest: 723.9565482\tbest: 723.9565482 (997)\ttotal: 2m 40s\tremaining: 321ms\n",
      "998:\tlearn: 725.8209045\ttest: 723.7899761\tbest: 723.7899761 (998)\ttotal: 2m 40s\tremaining: 161ms\n",
      "999:\tlearn: 725.6934639\ttest: 723.6860164\tbest: 723.6860164 (999)\ttotal: 2m 40s\tremaining: 0us\n",
      "\n",
      "bestTest = 723.6860164\n",
      "bestIteration = 999\n",
      "\n",
      "Wall time: 2min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cat_cols = ['Store', 'Promo']\n",
    "lr = CatBoostRegressor(random_state=1, cat_features=cat_cols, n_estimators=1000)\n",
    "\n",
    "\n",
    "lr.fit(train[features], train[target], eval_set = [(X_val, y_val)], early_stopping_rounds = 80)\n",
    "\n",
    "preds = lr.predict(X_test)\n",
    "preds = np.abs(preds)\n",
    "# # With eval set and no cat_cols: lb score 1093"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test['Predictions'] = preds\n",
    "test.loc[ test['Open'] == 0, 'Predictions'] = 0\n",
    "preds = test['Predictions']\n",
    "\n",
    "index = [i for i in range(test.shape[0])]\n",
    "\n",
    "d = list(zip(index, preds))\n",
    "\n",
    "ss = pd.DataFrame(d, columns = ['index', 'Sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.to_csv(path + \"\\\\feat_count_xgb.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:08:17,797]\u001b[0m A new study created in memory with name: no-name-7777c3ae-3fa6-4311-b04e-13dffc0a2956\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:3223.95996\n",
      "[100]\tvalidation_0-rmse:1152.48828\n",
      "[200]\tvalidation_0-rmse:1079.49927\n",
      "[300]\tvalidation_0-rmse:1063.00903\n",
      "[342]\tvalidation_0-rmse:1068.02649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:08:52,331]\u001b[0m Trial 0 finished with value: 1061.1435597746365 and parameters: {'max_depth': 7, 'n_estimators': 735, 'learning_rate': 0.7231212485077365, 'subsample': 0.10010179358743695, 'colsample_bytree': 0.3418660581054718, 'colsample_bylevel': 0.21740471265369044, 'reg_alpha': 9.3246256174029, 'reg_lambda': 18.707395116629325}. Best is trial 0 with value: 1061.1435597746365.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:4855.86523\n",
      "[100]\tvalidation_0-rmse:731.60254\n",
      "[118]\tvalidation_0-rmse:733.35455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:09:35,958]\u001b[0m Trial 1 finished with value: 728.9377180757723 and parameters: {'max_depth': 15, 'n_estimators': 1008, 'learning_rate': 0.40279979948836325, 'subsample': 0.5795468932629877, 'colsample_bytree': 0.4353556115226359, 'colsample_bylevel': 0.6481756003174076, 'reg_alpha': 20.524779748178595, 'reg_lambda': 87.82393189545544}. Best is trial 1 with value: 728.9377180757723.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:1945.00574\n",
      "[67]\tvalidation_0-rmse:1115.09851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:10:06,262]\u001b[0m Trial 2 finished with value: 950.7936040283201 and parameters: {'max_depth': 16, 'n_estimators': 1062, 'learning_rate': 0.9148224043334406, 'subsample': 0.5069122791084195, 'colsample_bytree': 0.4445588537477668, 'colsample_bylevel': 0.8513022315389006, 'reg_alpha': 77.8610847100197, 'reg_lambda': 71.62545454523959}. Best is trial 1 with value: 728.9377180757723.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:6983.44434\n",
      "[100]\tvalidation_0-rmse:765.46094\n",
      "[200]\tvalidation_0-rmse:703.04126\n",
      "[300]\tvalidation_0-rmse:674.28613\n",
      "[400]\tvalidation_0-rmse:657.61133\n",
      "[500]\tvalidation_0-rmse:646.00842\n",
      "[600]\tvalidation_0-rmse:638.72852\n",
      "[700]\tvalidation_0-rmse:633.24896\n",
      "[800]\tvalidation_0-rmse:629.18799\n",
      "[818]\tvalidation_0-rmse:628.49359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:14:03,490]\u001b[0m Trial 3 finished with value: 628.4936662023822 and parameters: {'max_depth': 9, 'n_estimators': 819, 'learning_rate': 0.10187280055433054, 'subsample': 0.5611557685582812, 'colsample_bytree': 0.7920162015831868, 'colsample_bylevel': 0.7633175258937133, 'reg_alpha': 82.97737560347895, 'reg_lambda': 27.377692424253066}. Best is trial 3 with value: 628.4936662023822.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:2986.29883\n",
      "[100]\tvalidation_0-rmse:786.14807\n",
      "[114]\tvalidation_0-rmse:788.17493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:14:40,507]\u001b[0m Trial 4 finished with value: 784.873780691056 and parameters: {'max_depth': 12, 'n_estimators': 1133, 'learning_rate': 0.6738227596682561, 'subsample': 0.6278283112852706, 'colsample_bytree': 0.6373232779377075, 'colsample_bylevel': 0.42943030317524244, 'reg_alpha': 19.835334708679646, 'reg_lambda': 29.034001090526665}. Best is trial 3 with value: 628.4936662023822.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:3446.25562\n",
      "[100]\tvalidation_0-rmse:1101.20606\n",
      "[200]\tvalidation_0-rmse:977.16400\n",
      "[300]\tvalidation_0-rmse:933.15497\n",
      "[400]\tvalidation_0-rmse:888.37921\n",
      "[500]\tvalidation_0-rmse:870.17676\n",
      "[600]\tvalidation_0-rmse:862.43494\n",
      "[700]\tvalidation_0-rmse:852.40875\n",
      "[800]\tvalidation_0-rmse:842.48340\n",
      "[900]\tvalidation_0-rmse:833.10199\n",
      "[1000]\tvalidation_0-rmse:829.16693\n",
      "[1087]\tvalidation_0-rmse:824.18573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:17:33,596]\u001b[0m Trial 5 finished with value: 824.1859083756966 and parameters: {'max_depth': 13, 'n_estimators': 1088, 'learning_rate': 0.7854813279679373, 'subsample': 0.4671595689376933, 'colsample_bytree': 0.12733704894867126, 'colsample_bylevel': 0.5992239891818827, 'reg_alpha': 66.09750945077649, 'reg_lambda': 29.91967994582917}. Best is trial 3 with value: 628.4936662023822.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:6267.45410\n",
      "[100]\tvalidation_0-rmse:1144.26624\n",
      "[200]\tvalidation_0-rmse:1073.89734\n",
      "[300]\tvalidation_0-rmse:1032.09070\n",
      "[400]\tvalidation_0-rmse:1012.50873\n",
      "[500]\tvalidation_0-rmse:989.54712\n",
      "[600]\tvalidation_0-rmse:975.10150\n",
      "[700]\tvalidation_0-rmse:960.63214\n",
      "[800]\tvalidation_0-rmse:947.39349\n",
      "[900]\tvalidation_0-rmse:937.29681\n",
      "[970]\tvalidation_0-rmse:931.23761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:19:13,535]\u001b[0m Trial 6 finished with value: 931.1748598753545 and parameters: {'max_depth': 4, 'n_estimators': 971, 'learning_rate': 0.22990330206002108, 'subsample': 0.1652941128509136, 'colsample_bytree': 0.47539082115051456, 'colsample_bylevel': 0.17693780835636935, 'reg_alpha': 90.34667963123884, 'reg_lambda': 12.037097751273611}. Best is trial 3 with value: 628.4936662023822.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:7044.24365\n",
      "[100]\tvalidation_0-rmse:662.60907\n",
      "[200]\tvalidation_0-rmse:661.61859\n",
      "[250]\tvalidation_0-rmse:661.64697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2021-05-05 04:29:01,276]\u001b[0m Trial 7 failed because of the following error: XGBoostError('bad allocation')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sunil\\anaconda3\\lib\\site-packages\\optuna\\_optimize.py\", line 211, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"<timed exec>\", line 32, in objective\n",
      "  File \"C:\\Users\\sunil\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\sunil\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 603, in fit\n",
      "    callbacks=callbacks)\n",
      "  File \"C:\\Users\\sunil\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 235, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"C:\\Users\\sunil\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 149, in _train_internal\n",
      "    return bst.copy()\n",
      "  File \"C:\\Users\\sunil\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1169, in copy\n",
      "    return self.__copy__()\n",
      "  File \"C:\\Users\\sunil\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1155, in __copy__\n",
      "    return self.__deepcopy__(None)\n",
      "  File \"C:\\Users\\sunil\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1159, in __deepcopy__\n",
      "    return Booster(model_file=self)\n",
      "  File \"C:\\Users\\sunil\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1031, in __init__\n",
      "    state = model_file.__getstate__()\n",
      "  File \"C:\\Users\\sunil\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1071, in __getstate__\n",
      "    ctypes.byref(cptr)))\n",
      "  File \"C:\\Users\\sunil\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: bad allocation\u001b[0m\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "bad allocation",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    383\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m             \u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m         )\n\u001b[0;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\optuna\\_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     71\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m                 \u001b[0mprogress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m             )\n\u001b[0;32m     75\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\optuna\\_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m             \u001b[0mtrial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\optuna\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mTrialState\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFAIL\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfunc_err\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\optuna\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m         \u001b[0mvalue_or_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[1;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    420\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 422\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m    601\u001b[0m                               \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 603\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_evaluation_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    233\u001b[0m                           \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                           \u001b[0mmaximize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m                           early_stopping_rounds=early_stopping_rounds)\n\u001b[0m\u001b[0;32m    236\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mbst\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[0;32m    147\u001b[0m     \u001b[1;31m# Copy to serialise and unserialise booster to reset state and free\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[1;31m# training memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mcopy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1167\u001b[0m             \u001b[0ma\u001b[0m \u001b[0mcopied\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m         \"\"\"\n\u001b[1;32m-> 1169\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__copy__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1171\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mload_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m__copy__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__copy__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1155\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__deepcopy__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1157\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__deepcopy__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m__deepcopy__\u001b[1;34m(self, _)\u001b[0m\n\u001b[0;32m   1157\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__deepcopy__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1158\u001b[0m         \u001b[1;34m'''Return a copy of booster.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1159\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mBooster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1161\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, params, cache, model_file)\u001b[0m\n\u001b[0;32m   1029\u001b[0m             \u001b[1;31m# We use the pickle interface for getting memory snapshot from\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m             \u001b[1;31m# another model, and load the snapshot with this booster.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1031\u001b[1;33m             \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getstate__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1032\u001b[0m             \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'handle'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'handle'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m__getstate__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1069\u001b[0m             _check_call(_LIB.XGBoosterSerializeToBuffer(self.handle,\n\u001b[0;32m   1070\u001b[0m                                                         \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1071\u001b[1;33m                                                         ctypes.byref(cptr)))\n\u001b[0m\u001b[0;32m   1072\u001b[0m             \u001b[0mbuf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes2buffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcptr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1073\u001b[0m             \u001b[0mthis\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"handle\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    187\u001b[0m     \"\"\"\n\u001b[0;32m    188\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mXGBoostError\u001b[0m: bad allocation"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "def create_model(trial):\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 2, 30)\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 500, 1500)\n",
    "    learning_rate = trial.suggest_uniform('learning_rate', 0.01, 1)\n",
    "    subsample = trial.suggest_uniform('subsample', 0.1, 0.99)\n",
    "    colsample_bytree = trial.suggest_uniform('colsample_bytree', 0.1, 0.9)\n",
    "    colsample_bylevel = trial.suggest_uniform('colsample_bylevel', 0.1, 0.9)\n",
    "    #num_leaves = trial.suggest_int(\"num_leaves\", 2, 5000)\n",
    "    #min_child_samples = trial.suggest_int('min_child_samples', 3, 200)\n",
    "    reg_alpha = trial.suggest_float(\"reg_alpha\", 0.1, 100)\n",
    "    reg_lambda = trial.suggest_float(\"reg_lambda\", 0.1, 100)\n",
    "    model = XGBRegressor(\n",
    "        max_depth = max_depth,\n",
    "        n_estimators = n_estimators,\n",
    "        learning_rate=learning_rate, \n",
    "        subsample = subsample,\n",
    "        colsample_bytree = colsample_bytree,\n",
    "        colsample_bylevel = colsample_bylevel,\n",
    "        #num_leaves=num_leaves, \n",
    "        #min_child_samples=min_child_samples,\n",
    "        random_state=1,\n",
    "        n_jobs = -1\n",
    "    )\n",
    "    return model\n",
    "\n",
    "sampler = TPESampler(seed=1)\n",
    "def objective(trial):\n",
    "    model = create_model(trial)\n",
    "    model.fit(X_trn, y_trn, eval_set = [ (X_val, y_val)], early_stopping_rounds = 60, verbose = 100)\n",
    "    preds = model.predict(X_val)\n",
    "    score = np.sqrt(mean_squared_error(y_val,preds))\n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\", sampler=sampler)\n",
    "study.optimize(objective, n_trials=40)\n",
    "\n",
    "xgb_params = study.best_params\n",
    "xgb_params['random_state'] = 1\n",
    "xgb = XGBRegressor(**xgb_params)\n",
    "xgb.fit(X_trn, y_trn, eval_set = [(X_val, y_val)], early_stopping_rounds = 60, verbose = False)\n",
    "preds = xgb.predict(X_val)\n",
    "print('Optimized XGB RMSE', np.sqrt(mean_squared_error(y_val, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:29:01,589]\u001b[0m A new study created in memory with name: no-name-7915d17a-27d8-4938-947f-fd86e7b2b14a\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 870.218\tvalid_0's l2: 757280\n",
      "[200]\tvalid_0's rmse: 802.799\tvalid_0's l2: 644486\n",
      "[300]\tvalid_0's rmse: 761.013\tvalid_0's l2: 579140\n",
      "[400]\tvalid_0's rmse: 736.662\tvalid_0's l2: 542671\n",
      "[500]\tvalid_0's rmse: 719.633\tvalid_0's l2: 517872\n",
      "[600]\tvalid_0's rmse: 708.411\tvalid_0's l2: 501846\n",
      "[700]\tvalid_0's rmse: 698.968\tvalid_0's l2: 488556\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[735]\tvalid_0's rmse: 696.305\tvalid_0's l2: 484840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:29:09,951]\u001b[0m Trial 0 finished with value: 696.3045662897358 and parameters: {'max_depth': 7, 'n_estimators': 735, 'learning_rate': 0.7231212485077365, 'subsample': 0.10010179358743695, 'colsample_bytree': 0.3418660581054718, 'colsample_bylevel': 0.21740471265369044, 'reg_alpha': 9.3246256174029, 'reg_lambda': 18.707395116629325}. Best is trial 0 with value: 696.3045662897358.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 827.01\tvalid_0's l2: 683945\n",
      "[200]\tvalid_0's rmse: 767.633\tvalid_0's l2: 589260\n",
      "[300]\tvalid_0's rmse: 738.221\tvalid_0's l2: 544970\n",
      "[400]\tvalid_0's rmse: 720.834\tvalid_0's l2: 519601\n",
      "[500]\tvalid_0's rmse: 710.281\tvalid_0's l2: 504499\n",
      "[600]\tvalid_0's rmse: 702.318\tvalid_0's l2: 493250\n",
      "[700]\tvalid_0's rmse: 695.529\tvalid_0's l2: 483761\n",
      "[800]\tvalid_0's rmse: 689.853\tvalid_0's l2: 475897\n",
      "[900]\tvalid_0's rmse: 685.824\tvalid_0's l2: 470354\n",
      "[1000]\tvalid_0's rmse: 684.005\tvalid_0's l2: 467862\n",
      "[1100]\tvalid_0's rmse: 682.496\tvalid_0's l2: 465801\n",
      "[1200]\tvalid_0's rmse: 680.874\tvalid_0's l2: 463589\n",
      "[1300]\tvalid_0's rmse: 679.796\tvalid_0's l2: 462122\n",
      "[1400]\tvalid_0's rmse: 678.992\tvalid_0's l2: 461030\n",
      "Early stopping, best iteration is:\n",
      "[1388]\tvalid_0's rmse: 678.895\tvalid_0's l2: 460898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:29:26,333]\u001b[0m Trial 1 finished with value: 678.8948464780428 and parameters: {'max_depth': 15, 'n_estimators': 1702, 'learning_rate': 0.8478478075191569, 'subsample': 0.3788134300697249, 'colsample_bytree': 0.5196385276582971, 'colsample_bylevel': 0.4547623150236454, 'reg_alpha': 23.034763651609573, 'reg_lambda': 53.487949503807}. Best is trial 1 with value: 678.8948464780428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 948.134\tvalid_0's l2: 898958\n",
      "[200]\tvalid_0's rmse: 867.954\tvalid_0's l2: 753345\n",
      "[300]\tvalid_0's rmse: 829.47\tvalid_0's l2: 688020\n",
      "[400]\tvalid_0's rmse: 797.218\tvalid_0's l2: 635557\n",
      "[500]\tvalid_0's rmse: 777.331\tvalid_0's l2: 604243\n",
      "[600]\tvalid_0's rmse: 759.351\tvalid_0's l2: 576613\n",
      "[700]\tvalid_0's rmse: 744.027\tvalid_0's l2: 553576\n",
      "[800]\tvalid_0's rmse: 733.615\tvalid_0's l2: 538190\n",
      "[900]\tvalid_0's rmse: 722.712\tvalid_0's l2: 522313\n",
      "[1000]\tvalid_0's rmse: 713.828\tvalid_0's l2: 509551\n",
      "[1100]\tvalid_0's rmse: 705.479\tvalid_0's l2: 497701\n",
      "[1200]\tvalid_0's rmse: 699.124\tvalid_0's l2: 488774\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1253]\tvalid_0's rmse: 695.374\tvalid_0's l2: 483545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:29:44,949]\u001b[0m Trial 2 finished with value: 695.3738425040584 and parameters: {'max_depth': 6, 'n_estimators': 1253, 'learning_rate': 0.14898306920928145, 'subsample': 0.2763103252855421, 'colsample_bytree': 0.7405956549404293, 'colsample_bylevel': 0.874609260575518, 'reg_alpha': 31.411075398108363, 'reg_lambda': 69.26302930536447}. Best is trial 1 with value: 678.8948464780428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 1131.32\tvalid_0's l2: 1.27988e+06\n",
      "[200]\tvalid_0's rmse: 1058.16\tvalid_0's l2: 1.11971e+06\n",
      "[300]\tvalid_0's rmse: 1022.61\tvalid_0's l2: 1.04573e+06\n",
      "[400]\tvalid_0's rmse: 993.114\tvalid_0's l2: 986276\n",
      "[500]\tvalid_0's rmse: 975.975\tvalid_0's l2: 952528\n",
      "[600]\tvalid_0's rmse: 964.788\tvalid_0's l2: 930816\n",
      "[700]\tvalid_0's rmse: 954.611\tvalid_0's l2: 911282\n",
      "[800]\tvalid_0's rmse: 945.324\tvalid_0's l2: 893637\n",
      "[900]\tvalid_0's rmse: 935.4\tvalid_0's l2: 874973\n",
      "[1000]\tvalid_0's rmse: 926.966\tvalid_0's l2: 859267\n",
      "[1100]\tvalid_0's rmse: 921.21\tvalid_0's l2: 848627\n",
      "[1200]\tvalid_0's rmse: 915.215\tvalid_0's l2: 837618\n",
      "[1300]\tvalid_0's rmse: 907.995\tvalid_0's l2: 824455\n",
      "[1400]\tvalid_0's rmse: 903.375\tvalid_0's l2: 816086\n",
      "[1500]\tvalid_0's rmse: 897.851\tvalid_0's l2: 806136\n",
      "[1600]\tvalid_0's rmse: 893.046\tvalid_0's l2: 797531\n",
      "[1700]\tvalid_0's rmse: 888.11\tvalid_0's l2: 788739\n",
      "[1800]\tvalid_0's rmse: 882.981\tvalid_0's l2: 779655\n",
      "[1900]\tvalid_0's rmse: 879.007\tvalid_0's l2: 772654\n",
      "[2000]\tvalid_0's rmse: 873.24\tvalid_0's l2: 762549\n",
      "[2100]\tvalid_0's rmse: 869.766\tvalid_0's l2: 756493\n",
      "[2200]\tvalid_0's rmse: 864.383\tvalid_0's l2: 747158\n",
      "[2300]\tvalid_0's rmse: 859.945\tvalid_0's l2: 739506\n",
      "[2400]\tvalid_0's rmse: 857.202\tvalid_0's l2: 734795\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2420]\tvalid_0's rmse: 856.768\tvalid_0's l2: 734052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:30:02,624]\u001b[0m Trial 3 finished with value: 856.7683859138747 and parameters: {'max_depth': 3, 'n_estimators': 2420, 'learning_rate': 0.8956605968688088, 'subsample': 0.17568934811910236, 'colsample_bytree': 0.1312438265863059, 'colsample_bylevel': 0.23586433565165513, 'reg_alpha': 87.82643609259837, 'reg_lambda': 9.924848699921705}. Best is trial 1 with value: 678.8948464780428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 877.299\tvalid_0's l2: 769653\n",
      "[200]\tvalid_0's rmse: 805.983\tvalid_0's l2: 649608\n",
      "[300]\tvalid_0's rmse: 770.057\tvalid_0's l2: 592987\n",
      "[400]\tvalid_0's rmse: 748.057\tvalid_0's l2: 559589\n",
      "[500]\tvalid_0's rmse: 732.677\tvalid_0's l2: 536816\n",
      "[600]\tvalid_0's rmse: 719.936\tvalid_0's l2: 518307\n",
      "[700]\tvalid_0's rmse: 710.835\tvalid_0's l2: 505286\n",
      "[800]\tvalid_0's rmse: 704.023\tvalid_0's l2: 495649\n",
      "[900]\tvalid_0's rmse: 699.296\tvalid_0's l2: 489014\n",
      "[1000]\tvalid_0's rmse: 693.777\tvalid_0's l2: 481326\n",
      "[1100]\tvalid_0's rmse: 689.313\tvalid_0's l2: 475152\n",
      "[1200]\tvalid_0's rmse: 685.812\tvalid_0's l2: 470338\n",
      "[1300]\tvalid_0's rmse: 682.722\tvalid_0's l2: 466109\n",
      "[1400]\tvalid_0's rmse: 679.91\tvalid_0's l2: 462277\n",
      "[1500]\tvalid_0's rmse: 677.365\tvalid_0's l2: 458824\n",
      "[1600]\tvalid_0's rmse: 675.164\tvalid_0's l2: 455846\n",
      "[1700]\tvalid_0's rmse: 673.512\tvalid_0's l2: 453618\n",
      "[1800]\tvalid_0's rmse: 671.758\tvalid_0's l2: 451258\n",
      "[1900]\tvalid_0's rmse: 670.391\tvalid_0's l2: 449423\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1974]\tvalid_0's rmse: 669.31\tvalid_0's l2: 447976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:30:36,881]\u001b[0m Trial 4 finished with value: 669.3102493325727 and parameters: {'max_depth': 5, 'n_estimators': 1978, 'learning_rate': 0.9583106348489969, 'subsample': 0.5745171036259852, 'colsample_bytree': 0.6535016911603787, 'colsample_bylevel': 0.3524125048048504, 'reg_alpha': 68.6814426753902, 'reg_lambda': 83.47910462254755}. Best is trial 4 with value: 669.3102493325727.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 824.738\tvalid_0's l2: 680192\n",
      "[200]\tvalid_0's rmse: 762.639\tvalid_0's l2: 581618\n",
      "[300]\tvalid_0's rmse: 730.533\tvalid_0's l2: 533678\n",
      "[400]\tvalid_0's rmse: 712.791\tvalid_0's l2: 508071\n",
      "[500]\tvalid_0's rmse: 700.125\tvalid_0's l2: 490175\n",
      "[600]\tvalid_0's rmse: 691.84\tvalid_0's l2: 478643\n",
      "[700]\tvalid_0's rmse: 685.545\tvalid_0's l2: 469972\n",
      "[800]\tvalid_0's rmse: 682.35\tvalid_0's l2: 465601\n",
      "[900]\tvalid_0's rmse: 679.369\tvalid_0's l2: 461542\n",
      "[1000]\tvalid_0's rmse: 676.712\tvalid_0's l2: 457939\n",
      "[1100]\tvalid_0's rmse: 674.272\tvalid_0's l2: 454643\n",
      "[1200]\tvalid_0's rmse: 672.459\tvalid_0's l2: 452201\n",
      "[1300]\tvalid_0's rmse: 671.484\tvalid_0's l2: 450891\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1362]\tvalid_0's rmse: 670.926\tvalid_0's l2: 450141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:30:56,587]\u001b[0m Trial 5 finished with value: 670.9255914495686 and parameters: {'max_depth': 15, 'n_estimators': 1383, 'learning_rate': 0.7526428717955178, 'subsample': 0.9800863691267803, 'colsample_bytree': 0.6985325235038715, 'colsample_bylevel': 0.32435519365152415, 'reg_alpha': 78.9490049123037, 'reg_lambda': 10.41227805710644}. Best is trial 4 with value: 669.3102493325727.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 856.246\tvalid_0's l2: 733158\n",
      "[200]\tvalid_0's rmse: 792.346\tvalid_0's l2: 627812\n",
      "[300]\tvalid_0's rmse: 762.275\tvalid_0's l2: 581063\n",
      "[400]\tvalid_0's rmse: 741.601\tvalid_0's l2: 549972\n",
      "[500]\tvalid_0's rmse: 729.531\tvalid_0's l2: 532215\n",
      "[600]\tvalid_0's rmse: 719.959\tvalid_0's l2: 518341\n",
      "[700]\tvalid_0's rmse: 710.975\tvalid_0's l2: 505486\n",
      "[800]\tvalid_0's rmse: 704.834\tvalid_0's l2: 496791\n",
      "[900]\tvalid_0's rmse: 699.97\tvalid_0's l2: 489958\n",
      "[1000]\tvalid_0's rmse: 697.621\tvalid_0's l2: 486675\n",
      "[1100]\tvalid_0's rmse: 693.918\tvalid_0's l2: 481522\n",
      "[1200]\tvalid_0's rmse: 690.949\tvalid_0's l2: 477411\n",
      "[1300]\tvalid_0's rmse: 689.166\tvalid_0's l2: 474950\n",
      "[1400]\tvalid_0's rmse: 688.488\tvalid_0's l2: 474016\n",
      "[1500]\tvalid_0's rmse: 686.275\tvalid_0's l2: 470973\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1545]\tvalid_0's rmse: 685.428\tvalid_0's l2: 469812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:31:14,231]\u001b[0m Trial 6 finished with value: 685.4282929595713 and parameters: {'max_depth': 10, 'n_estimators': 1546, 'learning_rate': 0.9095095480621646, 'subsample': 0.3613165920525747, 'colsample_bytree': 0.330220270869079, 'colsample_bylevel': 0.20402285769462214, 'reg_alpha': 2.0347590912426776, 'reg_lambda': 67.91566974069511}. Best is trial 4 with value: 669.3102493325727.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 990.412\tvalid_0's l2: 980916\n",
      "[200]\tvalid_0's rmse: 904.673\tvalid_0's l2: 818434\n",
      "[300]\tvalid_0's rmse: 848.697\tvalid_0's l2: 720287\n",
      "[400]\tvalid_0's rmse: 824.947\tvalid_0's l2: 680538\n",
      "[500]\tvalid_0's rmse: 801.974\tvalid_0's l2: 643162\n",
      "[600]\tvalid_0's rmse: 784.893\tvalid_0's l2: 616057\n",
      "[700]\tvalid_0's rmse: 769.556\tvalid_0's l2: 592217\n",
      "[800]\tvalid_0's rmse: 756.162\tvalid_0's l2: 571781\n",
      "[900]\tvalid_0's rmse: 747.417\tvalid_0's l2: 558633\n",
      "[1000]\tvalid_0's rmse: 736.808\tvalid_0's l2: 542885\n",
      "[1100]\tvalid_0's rmse: 728.792\tvalid_0's l2: 531138\n",
      "[1200]\tvalid_0's rmse: 720.969\tvalid_0's l2: 519797\n",
      "[1300]\tvalid_0's rmse: 714.248\tvalid_0's l2: 510151\n",
      "[1400]\tvalid_0's rmse: 708.09\tvalid_0's l2: 501391\n",
      "[1500]\tvalid_0's rmse: 702.027\tvalid_0's l2: 492842\n",
      "[1600]\tvalid_0's rmse: 698.04\tvalid_0's l2: 487259\n",
      "[1700]\tvalid_0's rmse: 693.664\tvalid_0's l2: 481169\n",
      "[1800]\tvalid_0's rmse: 689.742\tvalid_0's l2: 475744\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1812]\tvalid_0's rmse: 689.332\tvalid_0's l2: 475179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:31:32,083]\u001b[0m Trial 7 finished with value: 689.3321534766624 and parameters: {'max_depth': 10, 'n_estimators': 1812, 'learning_rate': 0.27289119277850393, 'subsample': 0.5375001117595011, 'colsample_bytree': 0.14269003609366432, 'colsample_bylevel': 0.5592940843936105, 'reg_alpha': 14.758184633090435, 'reg_lambda': 58.9716231366381}. Best is trial 4 with value: 669.3102493325727.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 953.24\tvalid_0's l2: 908666\n",
      "[200]\tvalid_0's rmse: 869.278\tvalid_0's l2: 755644\n",
      "[300]\tvalid_0's rmse: 825.952\tvalid_0's l2: 682196\n",
      "[400]\tvalid_0's rmse: 797.653\tvalid_0's l2: 636250\n",
      "[500]\tvalid_0's rmse: 776.351\tvalid_0's l2: 602721\n",
      "[600]\tvalid_0's rmse: 758.396\tvalid_0's l2: 575164\n",
      "[700]\tvalid_0's rmse: 742.385\tvalid_0's l2: 551136\n",
      "[800]\tvalid_0's rmse: 729.102\tvalid_0's l2: 531590\n",
      "[900]\tvalid_0's rmse: 719.172\tvalid_0's l2: 517208\n",
      "[1000]\tvalid_0's rmse: 710.639\tvalid_0's l2: 505008\n",
      "[1100]\tvalid_0's rmse: 702.843\tvalid_0's l2: 493989\n",
      "[1200]\tvalid_0's rmse: 696.875\tvalid_0's l2: 485634\n",
      "[1300]\tvalid_0's rmse: 690.236\tvalid_0's l2: 476426\n",
      "[1400]\tvalid_0's rmse: 684.766\tvalid_0's l2: 468904\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1428]\tvalid_0's rmse: 683.158\tvalid_0's l2: 466705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:31:54,163]\u001b[0m Trial 8 finished with value: 683.1577678296392 and parameters: {'max_depth': 16, 'n_estimators': 1428, 'learning_rate': 0.11131108453954758, 'subsample': 0.46850982915941586, 'colsample_bytree': 0.6555201261821961, 'colsample_bylevel': 0.4313434156215221, 'reg_alpha': 5.090350548714107, 'reg_lambda': 53.636050950959614}. Best is trial 4 with value: 669.3102493325727.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 833.315\tvalid_0's l2: 694414\n",
      "[200]\tvalid_0's rmse: 763.203\tvalid_0's l2: 582480\n",
      "[300]\tvalid_0's rmse: 728.167\tvalid_0's l2: 530227\n",
      "[400]\tvalid_0's rmse: 709.049\tvalid_0's l2: 502751\n",
      "[500]\tvalid_0's rmse: 691.686\tvalid_0's l2: 478429\n",
      "[600]\tvalid_0's rmse: 679.993\tvalid_0's l2: 462391\n",
      "[700]\tvalid_0's rmse: 672.574\tvalid_0's l2: 452356\n",
      "[800]\tvalid_0's rmse: 667.285\tvalid_0's l2: 445269\n",
      "[900]\tvalid_0's rmse: 662.384\tvalid_0's l2: 438753\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[969]\tvalid_0's rmse: 659.006\tvalid_0's l2: 434288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:32:08,694]\u001b[0m Trial 9 finished with value: 659.0055030181107 and parameters: {'max_depth': 22, 'n_estimators': 969, 'learning_rate': 0.5197402209377254, 'subsample': 0.9406893328318239, 'colsample_bytree': 0.5692440324015944, 'colsample_bylevel': 0.8227215322303069, 'reg_alpha': 13.833722944209129, 'reg_lambda': 14.01370709035078}. Best is trial 9 with value: 659.0055030181107.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 812.601\tvalid_0's l2: 660321\n",
      "[200]\tvalid_0's rmse: 746.541\tvalid_0's l2: 557323\n",
      "[300]\tvalid_0's rmse: 716.955\tvalid_0's l2: 514024\n",
      "[400]\tvalid_0's rmse: 698.066\tvalid_0's l2: 487296\n",
      "[500]\tvalid_0's rmse: 684.51\tvalid_0's l2: 468553\n",
      "[600]\tvalid_0's rmse: 673.565\tvalid_0's l2: 453690\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[687]\tvalid_0's rmse: 666.104\tvalid_0's l2: 443694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:32:20,007]\u001b[0m Trial 10 finished with value: 666.1038642807525 and parameters: {'max_depth': 30, 'n_estimators': 687, 'learning_rate': 0.5419078415637889, 'subsample': 0.9790140017884259, 'colsample_bytree': 0.8553333409041339, 'colsample_bylevel': 0.8873619907408963, 'reg_alpha': 46.69261952388502, 'reg_lambda': 30.777113450953472}. Best is trial 9 with value: 659.0055030181107.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 820.323\tvalid_0's l2: 672930\n",
      "[200]\tvalid_0's rmse: 752.541\tvalid_0's l2: 566319\n",
      "[300]\tvalid_0's rmse: 722.462\tvalid_0's l2: 521951\n",
      "[400]\tvalid_0's rmse: 697.933\tvalid_0's l2: 487111\n",
      "[500]\tvalid_0's rmse: 683.667\tvalid_0's l2: 467401\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[587]\tvalid_0's rmse: 674.449\tvalid_0's l2: 454882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:32:29,660]\u001b[0m Trial 11 finished with value: 674.4491654451563 and parameters: {'max_depth': 30, 'n_estimators': 587, 'learning_rate': 0.45675253765321744, 'subsample': 0.9420847392768795, 'colsample_bytree': 0.8121429648082519, 'colsample_bylevel': 0.8907743333869794, 'reg_alpha': 51.409273521204554, 'reg_lambda': 33.45537135454889}. Best is trial 9 with value: 659.0055030181107.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 812.559\tvalid_0's l2: 660252\n",
      "[200]\tvalid_0's rmse: 744.829\tvalid_0's l2: 554770\n",
      "[300]\tvalid_0's rmse: 712.602\tvalid_0's l2: 507801\n",
      "[400]\tvalid_0's rmse: 694.178\tvalid_0's l2: 481884\n",
      "[500]\tvalid_0's rmse: 680.175\tvalid_0's l2: 462637\n",
      "[600]\tvalid_0's rmse: 672.072\tvalid_0's l2: 451681\n",
      "[700]\tvalid_0's rmse: 665.029\tvalid_0's l2: 442263\n",
      "[800]\tvalid_0's rmse: 659.7\tvalid_0's l2: 435204\n",
      "[900]\tvalid_0's rmse: 654.825\tvalid_0's l2: 428795\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[949]\tvalid_0's rmse: 652.294\tvalid_0's l2: 425487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:32:44,935]\u001b[0m Trial 12 finished with value: 652.2937957002486 and parameters: {'max_depth': 29, 'n_estimators': 949, 'learning_rate': 0.5338898020785747, 'subsample': 0.7943426198672747, 'colsample_bytree': 0.8967407152269823, 'colsample_bylevel': 0.7048390775493789, 'reg_alpha': 39.67455747671157, 'reg_lambda': 31.52236104774653}. Best is trial 12 with value: 652.2937957002486.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 833.743\tvalid_0's l2: 695128\n",
      "[200]\tvalid_0's rmse: 765.452\tvalid_0's l2: 585917\n",
      "[300]\tvalid_0's rmse: 731.102\tvalid_0's l2: 534511\n",
      "[400]\tvalid_0's rmse: 706.972\tvalid_0's l2: 499809\n",
      "[500]\tvalid_0's rmse: 692.268\tvalid_0's l2: 479235\n",
      "[600]\tvalid_0's rmse: 681.39\tvalid_0's l2: 464293\n",
      "[700]\tvalid_0's rmse: 671.606\tvalid_0's l2: 451054\n",
      "[800]\tvalid_0's rmse: 665.083\tvalid_0's l2: 442336\n",
      "[900]\tvalid_0's rmse: 660.575\tvalid_0's l2: 436359\n",
      "[1000]\tvalid_0's rmse: 656.092\tvalid_0's l2: 430457\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1056]\tvalid_0's rmse: 653.466\tvalid_0's l2: 427018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:32:59,326]\u001b[0m Trial 13 finished with value: 653.4660126822445 and parameters: {'max_depth': 23, 'n_estimators': 1056, 'learning_rate': 0.46174521785188377, 'subsample': 0.7888087155417467, 'colsample_bytree': 0.5118209446249603, 'colsample_bylevel': 0.7007764224813353, 'reg_alpha': 35.588883723387596, 'reg_lambda': 33.028271438534475}. Best is trial 12 with value: 652.2937957002486.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 870.004\tvalid_0's l2: 756907\n",
      "[200]\tvalid_0's rmse: 795.552\tvalid_0's l2: 632903\n",
      "[300]\tvalid_0's rmse: 754.935\tvalid_0's l2: 569927\n",
      "[400]\tvalid_0's rmse: 728.992\tvalid_0's l2: 531429\n",
      "[500]\tvalid_0's rmse: 712.541\tvalid_0's l2: 507715\n",
      "[600]\tvalid_0's rmse: 700.217\tvalid_0's l2: 490304\n",
      "[700]\tvalid_0's rmse: 689.538\tvalid_0's l2: 475463\n",
      "[800]\tvalid_0's rmse: 679.498\tvalid_0's l2: 461717\n",
      "[900]\tvalid_0's rmse: 672.233\tvalid_0's l2: 451897\n",
      "[1000]\tvalid_0's rmse: 666.151\tvalid_0's l2: 443757\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1038]\tvalid_0's rmse: 664.271\tvalid_0's l2: 441256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:33:13,966]\u001b[0m Trial 14 finished with value: 664.270685754071 and parameters: {'max_depth': 25, 'n_estimators': 1039, 'learning_rate': 0.3614537970353546, 'subsample': 0.7580736369114675, 'colsample_bytree': 0.3678372652076093, 'colsample_bylevel': 0.6801153207127649, 'reg_alpha': 40.46443276825731, 'reg_lambda': 34.319182913618434}. Best is trial 12 with value: 652.2937957002486.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 837.328\tvalid_0's l2: 701117\n",
      "[200]\tvalid_0's rmse: 772.395\tvalid_0's l2: 596595\n",
      "[300]\tvalid_0's rmse: 735.052\tvalid_0's l2: 540302\n",
      "[400]\tvalid_0's rmse: 712.618\tvalid_0's l2: 507825\n",
      "[500]\tvalid_0's rmse: 698.369\tvalid_0's l2: 487719\n",
      "[600]\tvalid_0's rmse: 688.341\tvalid_0's l2: 473814\n",
      "[700]\tvalid_0's rmse: 681.674\tvalid_0's l2: 464679\n",
      "[800]\tvalid_0's rmse: 675.911\tvalid_0's l2: 456855\n",
      "[900]\tvalid_0's rmse: 671.215\tvalid_0's l2: 450530\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[988]\tvalid_0's rmse: 667.742\tvalid_0's l2: 445880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:33:27,247]\u001b[0m Trial 15 finished with value: 667.7423364587015 and parameters: {'max_depth': 25, 'n_estimators': 988, 'learning_rate': 0.6523267783125278, 'subsample': 0.795978431993127, 'colsample_bytree': 0.4347268430687879, 'colsample_bylevel': 0.700994714546225, 'reg_alpha': 59.96270145660467, 'reg_lambda': 39.40912161245627}. Best is trial 12 with value: 652.2937957002486.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 835.11\tvalid_0's l2: 697408\n",
      "[200]\tvalid_0's rmse: 766.637\tvalid_0's l2: 587732\n",
      "[300]\tvalid_0's rmse: 730.43\tvalid_0's l2: 533528\n",
      "[400]\tvalid_0's rmse: 708.029\tvalid_0's l2: 501305\n",
      "[500]\tvalid_0's rmse: 691.131\tvalid_0's l2: 477662\n",
      "[600]\tvalid_0's rmse: 676.951\tvalid_0's l2: 458262\n",
      "[700]\tvalid_0's rmse: 667.082\tvalid_0's l2: 444998\n",
      "[800]\tvalid_0's rmse: 658.363\tvalid_0's l2: 433442\n",
      "[900]\tvalid_0's rmse: 652.552\tvalid_0's l2: 425824\n",
      "[1000]\tvalid_0's rmse: 647.671\tvalid_0's l2: 419477\n",
      "[1100]\tvalid_0's rmse: 643.238\tvalid_0's l2: 413755\n",
      "[1200]\tvalid_0's rmse: 639.232\tvalid_0's l2: 408617\n",
      "[1300]\tvalid_0's rmse: 635.511\tvalid_0's l2: 403874\n",
      "[1400]\tvalid_0's rmse: 632.29\tvalid_0's l2: 399791\n",
      "[1500]\tvalid_0's rmse: 629.381\tvalid_0's l2: 396120\n",
      "[1600]\tvalid_0's rmse: 627.198\tvalid_0's l2: 393377\n",
      "[1700]\tvalid_0's rmse: 625.357\tvalid_0's l2: 391072\n",
      "[1800]\tvalid_0's rmse: 623.545\tvalid_0's l2: 388809\n",
      "[1900]\tvalid_0's rmse: 621.965\tvalid_0's l2: 386840\n",
      "[2000]\tvalid_0's rmse: 620.643\tvalid_0's l2: 385198\n",
      "[2100]\tvalid_0's rmse: 619.295\tvalid_0's l2: 383526\n",
      "[2200]\tvalid_0's rmse: 617.101\tvalid_0's l2: 380814\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2246]\tvalid_0's rmse: 616.377\tvalid_0's l2: 379921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:33:59,238]\u001b[0m Trial 16 finished with value: 616.3772737013396 and parameters: {'max_depth': 21, 'n_estimators': 2247, 'learning_rate': 0.3171278950296762, 'subsample': 0.7649945238768737, 'colsample_bytree': 0.8974915026340655, 'colsample_bylevel': 0.7064091722069804, 'reg_alpha': 29.8599911217789, 'reg_lambda': 23.20379780182784}. Best is trial 16 with value: 616.3772737013396.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 854.908\tvalid_0's l2: 730868\n",
      "[200]\tvalid_0's rmse: 782.023\tvalid_0's l2: 611560\n",
      "[300]\tvalid_0's rmse: 744.563\tvalid_0's l2: 554375\n",
      "[400]\tvalid_0's rmse: 721.813\tvalid_0's l2: 521015\n",
      "[500]\tvalid_0's rmse: 705.654\tvalid_0's l2: 497947\n",
      "[600]\tvalid_0's rmse: 691.497\tvalid_0's l2: 478169\n",
      "[700]\tvalid_0's rmse: 680.492\tvalid_0's l2: 463069\n",
      "[800]\tvalid_0's rmse: 670.308\tvalid_0's l2: 449312\n",
      "[900]\tvalid_0's rmse: 663.081\tvalid_0's l2: 439677\n",
      "[1000]\tvalid_0's rmse: 656.828\tvalid_0's l2: 431423\n",
      "[1100]\tvalid_0's rmse: 651.909\tvalid_0's l2: 424986\n",
      "[1200]\tvalid_0's rmse: 647.574\tvalid_0's l2: 419352\n",
      "[1300]\tvalid_0's rmse: 643.561\tvalid_0's l2: 414171\n",
      "[1400]\tvalid_0's rmse: 640.368\tvalid_0's l2: 410072\n",
      "[1500]\tvalid_0's rmse: 636.927\tvalid_0's l2: 405676\n",
      "[1600]\tvalid_0's rmse: 633.591\tvalid_0's l2: 401438\n",
      "[1700]\tvalid_0's rmse: 631.362\tvalid_0's l2: 398618\n",
      "[1800]\tvalid_0's rmse: 629.285\tvalid_0's l2: 396000\n",
      "[1900]\tvalid_0's rmse: 626.876\tvalid_0's l2: 392974\n",
      "[2000]\tvalid_0's rmse: 625.119\tvalid_0's l2: 390774\n",
      "[2100]\tvalid_0's rmse: 623.701\tvalid_0's l2: 389003\n",
      "[2200]\tvalid_0's rmse: 622.112\tvalid_0's l2: 387023\n",
      "[2300]\tvalid_0's rmse: 620.609\tvalid_0's l2: 385156\n",
      "[2400]\tvalid_0's rmse: 619.408\tvalid_0's l2: 383666\n",
      "[2500]\tvalid_0's rmse: 618.289\tvalid_0's l2: 382281\n",
      "[2600]\tvalid_0's rmse: 617.177\tvalid_0's l2: 380907\n",
      "[2700]\tvalid_0's rmse: 615.996\tvalid_0's l2: 379451\n",
      "[2800]\tvalid_0's rmse: 615.145\tvalid_0's l2: 378403\n",
      "[2900]\tvalid_0's rmse: 614.205\tvalid_0's l2: 377248\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2950]\tvalid_0's rmse: 613.743\tvalid_0's l2: 376681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:34:40,857]\u001b[0m Trial 17 finished with value: 613.7431611196896 and parameters: {'max_depth': 20, 'n_estimators': 2950, 'learning_rate': 0.2582190819575042, 'subsample': 0.6804554586765129, 'colsample_bytree': 0.8704485669568625, 'colsample_bylevel': 0.577544696490124, 'reg_alpha': 23.785987579573575, 'reg_lambda': 0.18048883187818632}. Best is trial 17 with value: 613.7431611196896.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 856.449\tvalid_0's l2: 733505\n",
      "[200]\tvalid_0's rmse: 785.586\tvalid_0's l2: 617146\n",
      "[300]\tvalid_0's rmse: 745.538\tvalid_0's l2: 555827\n",
      "[400]\tvalid_0's rmse: 722.744\tvalid_0's l2: 522358\n",
      "[500]\tvalid_0's rmse: 703.086\tvalid_0's l2: 494330\n",
      "[600]\tvalid_0's rmse: 691.758\tvalid_0's l2: 478529\n",
      "[700]\tvalid_0's rmse: 681.638\tvalid_0's l2: 464630\n",
      "[800]\tvalid_0's rmse: 671.864\tvalid_0's l2: 451401\n",
      "[900]\tvalid_0's rmse: 664.525\tvalid_0's l2: 441593\n",
      "[1000]\tvalid_0's rmse: 657.83\tvalid_0's l2: 432740\n",
      "[1100]\tvalid_0's rmse: 652.483\tvalid_0's l2: 425734\n",
      "[1200]\tvalid_0's rmse: 647.726\tvalid_0's l2: 419549\n",
      "[1300]\tvalid_0's rmse: 643.467\tvalid_0's l2: 414050\n",
      "[1400]\tvalid_0's rmse: 640.351\tvalid_0's l2: 410050\n",
      "[1500]\tvalid_0's rmse: 637.2\tvalid_0's l2: 406024\n",
      "[1600]\tvalid_0's rmse: 634.343\tvalid_0's l2: 402391\n",
      "[1700]\tvalid_0's rmse: 631.554\tvalid_0's l2: 398861\n",
      "[1800]\tvalid_0's rmse: 629.19\tvalid_0's l2: 395880\n",
      "[1900]\tvalid_0's rmse: 626.89\tvalid_0's l2: 392991\n",
      "[2000]\tvalid_0's rmse: 624.972\tvalid_0's l2: 390591\n",
      "[2100]\tvalid_0's rmse: 622.856\tvalid_0's l2: 387950\n",
      "[2200]\tvalid_0's rmse: 621.485\tvalid_0's l2: 386244\n",
      "[2300]\tvalid_0's rmse: 619.862\tvalid_0's l2: 384229\n",
      "[2400]\tvalid_0's rmse: 618.728\tvalid_0's l2: 382824\n",
      "[2500]\tvalid_0's rmse: 617.546\tvalid_0's l2: 381364\n",
      "[2600]\tvalid_0's rmse: 616.15\tvalid_0's l2: 379641\n",
      "[2700]\tvalid_0's rmse: 614.904\tvalid_0's l2: 378107\n",
      "[2800]\tvalid_0's rmse: 614.01\tvalid_0's l2: 377008\n",
      "[2900]\tvalid_0's rmse: 613.249\tvalid_0's l2: 376074\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2975]\tvalid_0's rmse: 612.475\tvalid_0's l2: 375126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:35:22,210]\u001b[0m Trial 18 finished with value: 612.475207007456 and parameters: {'max_depth': 19, 'n_estimators': 2975, 'learning_rate': 0.23479563219782487, 'subsample': 0.6669019444682756, 'colsample_bytree': 0.8910004819287553, 'colsample_bylevel': 0.5594810626277972, 'reg_alpha': 25.932205148585854, 'reg_lambda': 0.24707010414012526}. Best is trial 18 with value: 612.475207007456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 1158.86\tvalid_0's l2: 1.34296e+06\n",
      "[200]\tvalid_0's rmse: 1010.66\tvalid_0's l2: 1.02143e+06\n",
      "[300]\tvalid_0's rmse: 955.322\tvalid_0's l2: 912640\n",
      "[400]\tvalid_0's rmse: 920.881\tvalid_0's l2: 848023\n",
      "[500]\tvalid_0's rmse: 891.707\tvalid_0's l2: 795142\n",
      "[600]\tvalid_0's rmse: 868.846\tvalid_0's l2: 754893\n",
      "[700]\tvalid_0's rmse: 852.684\tvalid_0's l2: 727071\n",
      "[800]\tvalid_0's rmse: 838.865\tvalid_0's l2: 703694\n",
      "[900]\tvalid_0's rmse: 825.514\tvalid_0's l2: 681473\n",
      "[1000]\tvalid_0's rmse: 814.245\tvalid_0's l2: 662994\n",
      "[1100]\tvalid_0's rmse: 804.067\tvalid_0's l2: 646524\n",
      "[1200]\tvalid_0's rmse: 794.841\tvalid_0's l2: 631772\n",
      "[1300]\tvalid_0's rmse: 785.969\tvalid_0's l2: 617747\n",
      "[1400]\tvalid_0's rmse: 779.132\tvalid_0's l2: 607047\n",
      "[1500]\tvalid_0's rmse: 772.512\tvalid_0's l2: 596775\n",
      "[1600]\tvalid_0's rmse: 766.518\tvalid_0's l2: 587550\n",
      "[1700]\tvalid_0's rmse: 760.476\tvalid_0's l2: 578323\n",
      "[1800]\tvalid_0's rmse: 755.807\tvalid_0's l2: 571245\n",
      "[1900]\tvalid_0's rmse: 750.748\tvalid_0's l2: 563623\n",
      "[2000]\tvalid_0's rmse: 746.121\tvalid_0's l2: 556696\n",
      "[2100]\tvalid_0's rmse: 741.655\tvalid_0's l2: 550052\n",
      "[2200]\tvalid_0's rmse: 737.645\tvalid_0's l2: 544121\n",
      "[2300]\tvalid_0's rmse: 733.904\tvalid_0's l2: 538615\n",
      "[2400]\tvalid_0's rmse: 730.527\tvalid_0's l2: 533670\n",
      "[2500]\tvalid_0's rmse: 726.993\tvalid_0's l2: 528519\n",
      "[2600]\tvalid_0's rmse: 723.441\tvalid_0's l2: 523367\n",
      "[2700]\tvalid_0's rmse: 719.942\tvalid_0's l2: 518317\n",
      "[2800]\tvalid_0's rmse: 716.788\tvalid_0's l2: 513784\n",
      "[2900]\tvalid_0's rmse: 713.272\tvalid_0's l2: 508757\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2953]\tvalid_0's rmse: 711.657\tvalid_0's l2: 506455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:36:09,960]\u001b[0m Trial 19 finished with value: 711.6568214217413 and parameters: {'max_depth': 18, 'n_estimators': 2953, 'learning_rate': 0.03516112418644968, 'subsample': 0.6581297990018087, 'colsample_bytree': 0.8244877003392451, 'colsample_bylevel': 0.5721186513046963, 'reg_alpha': 21.857376460447682, 'reg_lambda': 2.025776956234079}. Best is trial 18 with value: 612.475207007456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 891.315\tvalid_0's l2: 794443\n",
      "[200]\tvalid_0's rmse: 809.781\tvalid_0's l2: 655745\n",
      "[300]\tvalid_0's rmse: 769.579\tvalid_0's l2: 592252\n",
      "[400]\tvalid_0's rmse: 743.523\tvalid_0's l2: 552826\n",
      "[500]\tvalid_0's rmse: 722.852\tvalid_0's l2: 522515\n",
      "[600]\tvalid_0's rmse: 707.528\tvalid_0's l2: 500596\n",
      "[700]\tvalid_0's rmse: 694.047\tvalid_0's l2: 481701\n",
      "[800]\tvalid_0's rmse: 685.114\tvalid_0's l2: 469381\n",
      "[900]\tvalid_0's rmse: 677.542\tvalid_0's l2: 459063\n",
      "[1000]\tvalid_0's rmse: 670.125\tvalid_0's l2: 449068\n",
      "[1100]\tvalid_0's rmse: 664.465\tvalid_0's l2: 441514\n",
      "[1200]\tvalid_0's rmse: 659.762\tvalid_0's l2: 435286\n",
      "[1300]\tvalid_0's rmse: 654.985\tvalid_0's l2: 429005\n",
      "[1400]\tvalid_0's rmse: 651.048\tvalid_0's l2: 423864\n",
      "[1500]\tvalid_0's rmse: 647.422\tvalid_0's l2: 419155\n",
      "[1600]\tvalid_0's rmse: 643.819\tvalid_0's l2: 414502\n",
      "[1700]\tvalid_0's rmse: 640.752\tvalid_0's l2: 410563\n",
      "[1800]\tvalid_0's rmse: 637.5\tvalid_0's l2: 406407\n",
      "[1900]\tvalid_0's rmse: 635.258\tvalid_0's l2: 403552\n",
      "[2000]\tvalid_0's rmse: 632.857\tvalid_0's l2: 400508\n",
      "[2100]\tvalid_0's rmse: 630.392\tvalid_0's l2: 397394\n",
      "[2200]\tvalid_0's rmse: 628.434\tvalid_0's l2: 394930\n",
      "[2300]\tvalid_0's rmse: 626.714\tvalid_0's l2: 392770\n",
      "[2400]\tvalid_0's rmse: 625.55\tvalid_0's l2: 391312\n",
      "[2500]\tvalid_0's rmse: 624.039\tvalid_0's l2: 389424\n",
      "[2600]\tvalid_0's rmse: 622.359\tvalid_0's l2: 387330\n",
      "[2700]\tvalid_0's rmse: 621.252\tvalid_0's l2: 385954\n",
      "[2800]\tvalid_0's rmse: 619.795\tvalid_0's l2: 384145\n",
      "[2900]\tvalid_0's rmse: 618.525\tvalid_0's l2: 382573\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2983]\tvalid_0's rmse: 617.7\tvalid_0's l2: 381554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:36:51,814]\u001b[0m Trial 20 finished with value: 617.7002685435872 and parameters: {'max_depth': 19, 'n_estimators': 2983, 'learning_rate': 0.1944143601682713, 'subsample': 0.6555723194113539, 'colsample_bytree': 0.7678804415695794, 'colsample_bylevel': 0.10130444076398026, 'reg_alpha': 23.105935487399464, 'reg_lambda': 5.346905960780336}. Best is trial 18 with value: 612.475207007456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 835.622\tvalid_0's l2: 698265\n",
      "[200]\tvalid_0's rmse: 773.328\tvalid_0's l2: 598036\n",
      "[300]\tvalid_0's rmse: 734.82\tvalid_0's l2: 539961\n",
      "[400]\tvalid_0's rmse: 713.774\tvalid_0's l2: 509474\n",
      "[500]\tvalid_0's rmse: 694.423\tvalid_0's l2: 482224\n",
      "[600]\tvalid_0's rmse: 682.024\tvalid_0's l2: 465156\n",
      "[700]\tvalid_0's rmse: 671.959\tvalid_0's l2: 451529\n",
      "[800]\tvalid_0's rmse: 663.36\tvalid_0's l2: 440047\n",
      "[900]\tvalid_0's rmse: 655.863\tvalid_0's l2: 430156\n",
      "[1000]\tvalid_0's rmse: 650.453\tvalid_0's l2: 423089\n",
      "[1100]\tvalid_0's rmse: 645.744\tvalid_0's l2: 416986\n",
      "[1200]\tvalid_0's rmse: 642.4\tvalid_0's l2: 412677\n",
      "[1300]\tvalid_0's rmse: 638.774\tvalid_0's l2: 408033\n",
      "[1400]\tvalid_0's rmse: 635.574\tvalid_0's l2: 403955\n",
      "[1500]\tvalid_0's rmse: 633.041\tvalid_0's l2: 400741\n",
      "[1600]\tvalid_0's rmse: 630.032\tvalid_0's l2: 396941\n",
      "[1700]\tvalid_0's rmse: 628.149\tvalid_0's l2: 394571\n",
      "[1800]\tvalid_0's rmse: 626.082\tvalid_0's l2: 391979\n",
      "[1900]\tvalid_0's rmse: 623.785\tvalid_0's l2: 389107\n",
      "[2000]\tvalid_0's rmse: 622.566\tvalid_0's l2: 387588\n",
      "[2100]\tvalid_0's rmse: 621.177\tvalid_0's l2: 385861\n",
      "[2200]\tvalid_0's rmse: 619.793\tvalid_0's l2: 384143\n",
      "[2300]\tvalid_0's rmse: 618.596\tvalid_0's l2: 382661\n",
      "[2400]\tvalid_0's rmse: 617.493\tvalid_0's l2: 381298\n",
      "[2500]\tvalid_0's rmse: 616.339\tvalid_0's l2: 379874\n",
      "[2600]\tvalid_0's rmse: 615.555\tvalid_0's l2: 378907\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2663]\tvalid_0's rmse: 615.033\tvalid_0's l2: 378266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:37:28,539]\u001b[0m Trial 21 finished with value: 615.0332563549715 and parameters: {'max_depth': 20, 'n_estimators': 2663, 'learning_rate': 0.3144524888636294, 'subsample': 0.6847974851962813, 'colsample_bytree': 0.8967608746794039, 'colsample_bylevel': 0.5946530581016165, 'reg_alpha': 29.34982132744446, 'reg_lambda': 20.333610256943025}. Best is trial 18 with value: 612.475207007456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 869.249\tvalid_0's l2: 755594\n",
      "[200]\tvalid_0's rmse: 787.651\tvalid_0's l2: 620395\n",
      "[300]\tvalid_0's rmse: 749.943\tvalid_0's l2: 562414\n",
      "[400]\tvalid_0's rmse: 725.434\tvalid_0's l2: 526255\n",
      "[500]\tvalid_0's rmse: 707.23\tvalid_0's l2: 500174\n",
      "[600]\tvalid_0's rmse: 693.531\tvalid_0's l2: 480985\n",
      "[700]\tvalid_0's rmse: 681.386\tvalid_0's l2: 464287\n",
      "[800]\tvalid_0's rmse: 672.695\tvalid_0's l2: 452519\n",
      "[900]\tvalid_0's rmse: 663.773\tvalid_0's l2: 440594\n",
      "[1000]\tvalid_0's rmse: 657.491\tvalid_0's l2: 432294\n",
      "[1100]\tvalid_0's rmse: 651.993\tvalid_0's l2: 425094\n",
      "[1200]\tvalid_0's rmse: 647.242\tvalid_0's l2: 418922\n",
      "[1300]\tvalid_0's rmse: 643.624\tvalid_0's l2: 414252\n",
      "[1400]\tvalid_0's rmse: 640.056\tvalid_0's l2: 409672\n",
      "[1500]\tvalid_0's rmse: 637.058\tvalid_0's l2: 405843\n",
      "[1600]\tvalid_0's rmse: 633.833\tvalid_0's l2: 401744\n",
      "[1700]\tvalid_0's rmse: 630.975\tvalid_0's l2: 398130\n",
      "[1800]\tvalid_0's rmse: 628.845\tvalid_0's l2: 395446\n",
      "[1900]\tvalid_0's rmse: 626.305\tvalid_0's l2: 392257\n",
      "[2000]\tvalid_0's rmse: 624.354\tvalid_0's l2: 389818\n",
      "[2100]\tvalid_0's rmse: 622.502\tvalid_0's l2: 387509\n",
      "[2200]\tvalid_0's rmse: 621.025\tvalid_0's l2: 385671\n",
      "[2300]\tvalid_0's rmse: 619.479\tvalid_0's l2: 383754\n",
      "[2400]\tvalid_0's rmse: 618.233\tvalid_0's l2: 382212\n",
      "[2500]\tvalid_0's rmse: 617.248\tvalid_0's l2: 380995\n",
      "[2600]\tvalid_0's rmse: 616.122\tvalid_0's l2: 379606\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2651]\tvalid_0's rmse: 615.553\tvalid_0's l2: 378905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:38:06,572]\u001b[0m Trial 22 finished with value: 615.5526172940282 and parameters: {'max_depth': 19, 'n_estimators': 2651, 'learning_rate': 0.2415930153586192, 'subsample': 0.6724710165706854, 'colsample_bytree': 0.8757915239156695, 'colsample_bylevel': 0.5543500120488704, 'reg_alpha': 25.712092263817972, 'reg_lambda': 2.2283094049894316}. Best is trial 18 with value: 612.475207007456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 827.286\tvalid_0's l2: 684402\n",
      "[200]\tvalid_0's rmse: 758.599\tvalid_0's l2: 575472\n",
      "[300]\tvalid_0's rmse: 724.428\tvalid_0's l2: 524795\n",
      "[400]\tvalid_0's rmse: 703.409\tvalid_0's l2: 494784\n",
      "[500]\tvalid_0's rmse: 686.379\tvalid_0's l2: 471117\n",
      "[600]\tvalid_0's rmse: 674.898\tvalid_0's l2: 455487\n",
      "[700]\tvalid_0's rmse: 665.48\tvalid_0's l2: 442864\n",
      "[800]\tvalid_0's rmse: 657.208\tvalid_0's l2: 431922\n",
      "[900]\tvalid_0's rmse: 652.208\tvalid_0's l2: 425375\n",
      "[1000]\tvalid_0's rmse: 647.048\tvalid_0's l2: 418671\n",
      "[1100]\tvalid_0's rmse: 643.279\tvalid_0's l2: 413808\n",
      "[1200]\tvalid_0's rmse: 639.886\tvalid_0's l2: 409454\n",
      "[1300]\tvalid_0's rmse: 636.67\tvalid_0's l2: 405349\n",
      "[1400]\tvalid_0's rmse: 633.833\tvalid_0's l2: 401744\n",
      "[1500]\tvalid_0's rmse: 631.441\tvalid_0's l2: 398718\n",
      "[1600]\tvalid_0's rmse: 629.557\tvalid_0's l2: 396342\n",
      "[1700]\tvalid_0's rmse: 627.766\tvalid_0's l2: 394090\n",
      "[1800]\tvalid_0's rmse: 626.64\tvalid_0's l2: 392677\n",
      "[1900]\tvalid_0's rmse: 625.099\tvalid_0's l2: 390749\n",
      "[2000]\tvalid_0's rmse: 624.121\tvalid_0's l2: 389527\n",
      "[2100]\tvalid_0's rmse: 622.666\tvalid_0's l2: 387713\n",
      "[2200]\tvalid_0's rmse: 621.659\tvalid_0's l2: 386460\n",
      "[2300]\tvalid_0's rmse: 620.919\tvalid_0's l2: 385540\n",
      "[2400]\tvalid_0's rmse: 620.499\tvalid_0's l2: 385019\n",
      "[2500]\tvalid_0's rmse: 619.757\tvalid_0's l2: 384098\n",
      "[2600]\tvalid_0's rmse: 618.963\tvalid_0's l2: 383115\n",
      "[2700]\tvalid_0's rmse: 618.129\tvalid_0's l2: 382084\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2773]\tvalid_0's rmse: 617.833\tvalid_0's l2: 381718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:38:45,514]\u001b[0m Trial 23 finished with value: 617.8332019809809 and parameters: {'max_depth': 12, 'n_estimators': 2792, 'learning_rate': 0.380614976586823, 'subsample': 0.8694179216050237, 'colsample_bytree': 0.7972947742034844, 'colsample_bylevel': 0.6216046629056126, 'reg_alpha': 47.57127634947988, 'reg_lambda': 1.6052883630635901}. Best is trial 18 with value: 612.475207007456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 1014.17\tvalid_0's l2: 1.02855e+06\n",
      "[200]\tvalid_0's rmse: 922.409\tvalid_0's l2: 850839\n",
      "[300]\tvalid_0's rmse: 870.241\tvalid_0's l2: 757319\n",
      "[400]\tvalid_0's rmse: 835.274\tvalid_0's l2: 697682\n",
      "[500]\tvalid_0's rmse: 809.869\tvalid_0's l2: 655888\n",
      "[600]\tvalid_0's rmse: 789.906\tvalid_0's l2: 623952\n",
      "[700]\tvalid_0's rmse: 774.361\tvalid_0's l2: 599635\n",
      "[800]\tvalid_0's rmse: 762.515\tvalid_0's l2: 581429\n",
      "[900]\tvalid_0's rmse: 751.751\tvalid_0's l2: 565130\n",
      "[1000]\tvalid_0's rmse: 742.553\tvalid_0's l2: 551385\n",
      "[1100]\tvalid_0's rmse: 733.076\tvalid_0's l2: 537401\n",
      "[1200]\tvalid_0's rmse: 725.06\tvalid_0's l2: 525712\n",
      "[1300]\tvalid_0's rmse: 718.372\tvalid_0's l2: 516058\n",
      "[1400]\tvalid_0's rmse: 712.306\tvalid_0's l2: 507380\n",
      "[1500]\tvalid_0's rmse: 706.295\tvalid_0's l2: 498852\n",
      "[1600]\tvalid_0's rmse: 701.584\tvalid_0's l2: 492219\n",
      "[1700]\tvalid_0's rmse: 696.677\tvalid_0's l2: 485359\n",
      "[1800]\tvalid_0's rmse: 692.077\tvalid_0's l2: 478971\n",
      "[1900]\tvalid_0's rmse: 687.603\tvalid_0's l2: 472799\n",
      "[2000]\tvalid_0's rmse: 683.379\tvalid_0's l2: 467007\n",
      "[2100]\tvalid_0's rmse: 679.113\tvalid_0's l2: 461195\n",
      "[2200]\tvalid_0's rmse: 675.93\tvalid_0's l2: 456882\n",
      "[2300]\tvalid_0's rmse: 672.294\tvalid_0's l2: 451979\n",
      "[2400]\tvalid_0's rmse: 669.357\tvalid_0's l2: 448039\n",
      "[2500]\tvalid_0's rmse: 666.429\tvalid_0's l2: 444127\n",
      "[2600]\tvalid_0's rmse: 663.81\tvalid_0's l2: 440644\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2618]\tvalid_0's rmse: 663.392\tvalid_0's l2: 440089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:39:24,646]\u001b[0m Trial 24 finished with value: 663.3920673664232 and parameters: {'max_depth': 26, 'n_estimators': 2618, 'learning_rate': 0.07092354554613789, 'subsample': 0.5591308052945819, 'colsample_bytree': 0.8876347220281653, 'colsample_bylevel': 0.4873186220450525, 'reg_alpha': 16.502096033591062, 'reg_lambda': 20.320999199894285}. Best is trial 18 with value: 612.475207007456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 889.654\tvalid_0's l2: 791484\n",
      "[200]\tvalid_0's rmse: 810.031\tvalid_0's l2: 656150\n",
      "[300]\tvalid_0's rmse: 765.39\tvalid_0's l2: 585822\n",
      "[400]\tvalid_0's rmse: 740.765\tvalid_0's l2: 548732\n",
      "[500]\tvalid_0's rmse: 719.593\tvalid_0's l2: 517814\n",
      "[600]\tvalid_0's rmse: 705.206\tvalid_0's l2: 497316\n",
      "[700]\tvalid_0's rmse: 693.226\tvalid_0's l2: 480562\n",
      "[800]\tvalid_0's rmse: 683.437\tvalid_0's l2: 467086\n",
      "[900]\tvalid_0's rmse: 675.282\tvalid_0's l2: 456006\n",
      "[1000]\tvalid_0's rmse: 668.119\tvalid_0's l2: 446383\n",
      "[1100]\tvalid_0's rmse: 662.877\tvalid_0's l2: 439406\n",
      "[1200]\tvalid_0's rmse: 657.624\tvalid_0's l2: 432469\n",
      "[1300]\tvalid_0's rmse: 652.398\tvalid_0's l2: 425623\n",
      "[1400]\tvalid_0's rmse: 647.811\tvalid_0's l2: 419659\n",
      "[1500]\tvalid_0's rmse: 643.48\tvalid_0's l2: 414067\n",
      "[1600]\tvalid_0's rmse: 639.552\tvalid_0's l2: 409027\n",
      "[1700]\tvalid_0's rmse: 637.163\tvalid_0's l2: 405977\n",
      "[1800]\tvalid_0's rmse: 634.796\tvalid_0's l2: 402966\n",
      "[1900]\tvalid_0's rmse: 632.646\tvalid_0's l2: 400241\n",
      "[2000]\tvalid_0's rmse: 630.312\tvalid_0's l2: 397293\n",
      "[2100]\tvalid_0's rmse: 627.643\tvalid_0's l2: 393936\n",
      "[2200]\tvalid_0's rmse: 625.688\tvalid_0's l2: 391486\n",
      "[2300]\tvalid_0's rmse: 623.962\tvalid_0's l2: 389328\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2306]\tvalid_0's rmse: 623.924\tvalid_0's l2: 389281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:39:57,797]\u001b[0m Trial 25 finished with value: 623.9239302928773 and parameters: {'max_depth': 17, 'n_estimators': 2306, 'learning_rate': 0.20565796484930654, 'subsample': 0.707477127809674, 'colsample_bytree': 0.7227135924166834, 'colsample_bylevel': 0.6249946176855031, 'reg_alpha': 56.31103391004971, 'reg_lambda': 97.89748108366445}. Best is trial 18 with value: 612.475207007456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 888.847\tvalid_0's l2: 790049\n",
      "[200]\tvalid_0's rmse: 821.169\tvalid_0's l2: 674319\n",
      "[300]\tvalid_0's rmse: 782.347\tvalid_0's l2: 612067\n",
      "[400]\tvalid_0's rmse: 754.954\tvalid_0's l2: 569956\n",
      "[500]\tvalid_0's rmse: 736.53\tvalid_0's l2: 542477\n",
      "[600]\tvalid_0's rmse: 721.192\tvalid_0's l2: 520118\n",
      "[700]\tvalid_0's rmse: 709.639\tvalid_0's l2: 503587\n",
      "[800]\tvalid_0's rmse: 698.641\tvalid_0's l2: 488099\n",
      "[900]\tvalid_0's rmse: 690.293\tvalid_0's l2: 476504\n",
      "[1000]\tvalid_0's rmse: 682.975\tvalid_0's l2: 466455\n",
      "[1100]\tvalid_0's rmse: 677.897\tvalid_0's l2: 459544\n",
      "[1200]\tvalid_0's rmse: 672.66\tvalid_0's l2: 452471\n",
      "[1300]\tvalid_0's rmse: 667.378\tvalid_0's l2: 445393\n",
      "[1400]\tvalid_0's rmse: 663.742\tvalid_0's l2: 440554\n",
      "[1500]\tvalid_0's rmse: 660.542\tvalid_0's l2: 436316\n",
      "[1600]\tvalid_0's rmse: 657.233\tvalid_0's l2: 431956\n",
      "[1700]\tvalid_0's rmse: 654.478\tvalid_0's l2: 428342\n",
      "[1800]\tvalid_0's rmse: 652.392\tvalid_0's l2: 425615\n",
      "[1900]\tvalid_0's rmse: 650.056\tvalid_0's l2: 422573\n",
      "[2000]\tvalid_0's rmse: 648.415\tvalid_0's l2: 420442\n",
      "[2100]\tvalid_0's rmse: 646.774\tvalid_0's l2: 418316\n",
      "[2200]\tvalid_0's rmse: 645.292\tvalid_0's l2: 416402\n",
      "[2300]\tvalid_0's rmse: 643.504\tvalid_0's l2: 414097\n",
      "[2400]\tvalid_0's rmse: 642.285\tvalid_0's l2: 412531\n",
      "[2500]\tvalid_0's rmse: 641.248\tvalid_0's l2: 411198\n",
      "[2600]\tvalid_0's rmse: 640.08\tvalid_0's l2: 409703\n",
      "[2700]\tvalid_0's rmse: 639.378\tvalid_0's l2: 408804\n",
      "[2800]\tvalid_0's rmse: 638.359\tvalid_0's l2: 407503\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2815]\tvalid_0's rmse: 638.216\tvalid_0's l2: 407320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:40:25,613]\u001b[0m Trial 26 finished with value: 638.2159123245453 and parameters: {'max_depth': 21, 'n_estimators': 2815, 'learning_rate': 0.39070664758604057, 'subsample': 0.6135427468354637, 'colsample_bytree': 0.2158845596096599, 'colsample_bylevel': 0.38180941980936955, 'reg_alpha': 38.644553717288915, 'reg_lambda': 13.131229438923821}. Best is trial 18 with value: 612.475207007456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 862.019\tvalid_0's l2: 743077\n",
      "[200]\tvalid_0's rmse: 792.361\tvalid_0's l2: 627837\n",
      "[300]\tvalid_0's rmse: 752.653\tvalid_0's l2: 566487\n",
      "[400]\tvalid_0's rmse: 729.234\tvalid_0's l2: 531782\n",
      "[500]\tvalid_0's rmse: 711.136\tvalid_0's l2: 505714\n",
      "[600]\tvalid_0's rmse: 694.064\tvalid_0's l2: 481725\n",
      "[700]\tvalid_0's rmse: 682.974\tvalid_0's l2: 466454\n",
      "[800]\tvalid_0's rmse: 674.6\tvalid_0's l2: 455085\n",
      "[900]\tvalid_0's rmse: 667.031\tvalid_0's l2: 444930\n",
      "[1000]\tvalid_0's rmse: 660.658\tvalid_0's l2: 436469\n",
      "[1100]\tvalid_0's rmse: 655.163\tvalid_0's l2: 429239\n",
      "[1200]\tvalid_0's rmse: 650.758\tvalid_0's l2: 423486\n",
      "[1300]\tvalid_0's rmse: 646.646\tvalid_0's l2: 418151\n",
      "[1400]\tvalid_0's rmse: 642.58\tvalid_0's l2: 412910\n",
      "[1500]\tvalid_0's rmse: 639.6\tvalid_0's l2: 409089\n",
      "[1600]\tvalid_0's rmse: 636.926\tvalid_0's l2: 405674\n",
      "[1700]\tvalid_0's rmse: 634.292\tvalid_0's l2: 402327\n",
      "[1800]\tvalid_0's rmse: 632.059\tvalid_0's l2: 399499\n",
      "[1900]\tvalid_0's rmse: 629.893\tvalid_0's l2: 396765\n",
      "[2000]\tvalid_0's rmse: 628.182\tvalid_0's l2: 394613\n",
      "[2100]\tvalid_0's rmse: 626.549\tvalid_0's l2: 392564\n",
      "[2200]\tvalid_0's rmse: 624.558\tvalid_0's l2: 390073\n",
      "[2300]\tvalid_0's rmse: 623.135\tvalid_0's l2: 388297\n",
      "[2400]\tvalid_0's rmse: 621.586\tvalid_0's l2: 386369\n",
      "[2500]\tvalid_0's rmse: 620.462\tvalid_0's l2: 384973\n",
      "[2600]\tvalid_0's rmse: 619.384\tvalid_0's l2: 383637\n",
      "[2700]\tvalid_0's rmse: 618.264\tvalid_0's l2: 382251\n",
      "[2800]\tvalid_0's rmse: 617.42\tvalid_0's l2: 381207\n",
      "[2900]\tvalid_0's rmse: 616.591\tvalid_0's l2: 380184\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2994]\tvalid_0's rmse: 615.527\tvalid_0's l2: 378874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:41:06,680]\u001b[0m Trial 27 finished with value: 615.5274011696293 and parameters: {'max_depth': 27, 'n_estimators': 2995, 'learning_rate': 0.2712868677417618, 'subsample': 0.48508976730127995, 'colsample_bytree': 0.6081125284769249, 'colsample_bylevel': 0.7854416641933348, 'reg_alpha': 30.418265092676197, 'reg_lambda': 0.10740044632182993}. Best is trial 18 with value: 612.475207007456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 903.819\tvalid_0's l2: 816890\n",
      "[200]\tvalid_0's rmse: 823.677\tvalid_0's l2: 678443\n",
      "[300]\tvalid_0's rmse: 781.995\tvalid_0's l2: 611517\n",
      "[400]\tvalid_0's rmse: 753.825\tvalid_0's l2: 568252\n",
      "[500]\tvalid_0's rmse: 733.686\tvalid_0's l2: 538295\n",
      "[600]\tvalid_0's rmse: 718.289\tvalid_0's l2: 515938\n",
      "[700]\tvalid_0's rmse: 705.32\tvalid_0's l2: 497476\n",
      "[800]\tvalid_0's rmse: 694.884\tvalid_0's l2: 482863\n",
      "[900]\tvalid_0's rmse: 686.229\tvalid_0's l2: 470911\n",
      "[1000]\tvalid_0's rmse: 678.496\tvalid_0's l2: 460356\n",
      "[1100]\tvalid_0's rmse: 671.637\tvalid_0's l2: 451096\n",
      "[1200]\tvalid_0's rmse: 665.744\tvalid_0's l2: 443215\n",
      "[1300]\tvalid_0's rmse: 660.45\tvalid_0's l2: 436194\n",
      "[1400]\tvalid_0's rmse: 656.112\tvalid_0's l2: 430483\n",
      "[1500]\tvalid_0's rmse: 651.946\tvalid_0's l2: 425034\n",
      "[1600]\tvalid_0's rmse: 648.236\tvalid_0's l2: 420210\n",
      "[1700]\tvalid_0's rmse: 645.384\tvalid_0's l2: 416520\n",
      "[1800]\tvalid_0's rmse: 642.176\tvalid_0's l2: 412390\n",
      "[1900]\tvalid_0's rmse: 639.535\tvalid_0's l2: 409005\n",
      "[2000]\tvalid_0's rmse: 637.205\tvalid_0's l2: 406030\n",
      "[2100]\tvalid_0's rmse: 634.828\tvalid_0's l2: 403006\n",
      "[2200]\tvalid_0's rmse: 632.805\tvalid_0's l2: 400442\n",
      "[2300]\tvalid_0's rmse: 630.704\tvalid_0's l2: 397788\n",
      "[2400]\tvalid_0's rmse: 628.83\tvalid_0's l2: 395428\n",
      "[2500]\tvalid_0's rmse: 627.19\tvalid_0's l2: 393368\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2519]\tvalid_0's rmse: 626.957\tvalid_0's l2: 393075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:41:42,702]\u001b[0m Trial 28 finished with value: 626.9569703041814 and parameters: {'max_depth': 12, 'n_estimators': 2519, 'learning_rate': 0.1646346859298572, 'subsample': 0.8623101226322936, 'colsample_bytree': 0.8381289600708106, 'colsample_bylevel': 0.5251786007385376, 'reg_alpha': 18.150531965545145, 'reg_lambda': 44.36852149513577}. Best is trial 18 with value: 612.475207007456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 843.849\tvalid_0's l2: 712081\n",
      "[200]\tvalid_0's rmse: 772.197\tvalid_0's l2: 596288\n",
      "[300]\tvalid_0's rmse: 735.759\tvalid_0's l2: 541342\n",
      "[400]\tvalid_0's rmse: 712.131\tvalid_0's l2: 507130\n",
      "[500]\tvalid_0's rmse: 693.467\tvalid_0's l2: 480896\n",
      "[600]\tvalid_0's rmse: 681.987\tvalid_0's l2: 465107\n",
      "[700]\tvalid_0's rmse: 671.328\tvalid_0's l2: 450681\n",
      "[800]\tvalid_0's rmse: 663.832\tvalid_0's l2: 440673\n",
      "[900]\tvalid_0's rmse: 656.992\tvalid_0's l2: 431639\n",
      "[1000]\tvalid_0's rmse: 651.369\tvalid_0's l2: 424282\n",
      "[1100]\tvalid_0's rmse: 645.977\tvalid_0's l2: 417286\n",
      "[1200]\tvalid_0's rmse: 642.325\tvalid_0's l2: 412582\n",
      "[1300]\tvalid_0's rmse: 638.584\tvalid_0's l2: 407790\n",
      "[1400]\tvalid_0's rmse: 635.613\tvalid_0's l2: 404004\n",
      "[1500]\tvalid_0's rmse: 633.811\tvalid_0's l2: 401716\n",
      "[1600]\tvalid_0's rmse: 631.988\tvalid_0's l2: 399409\n",
      "[1700]\tvalid_0's rmse: 629.778\tvalid_0's l2: 396621\n",
      "[1800]\tvalid_0's rmse: 627.438\tvalid_0's l2: 393679\n",
      "[1900]\tvalid_0's rmse: 625.539\tvalid_0's l2: 391299\n",
      "[2000]\tvalid_0's rmse: 624.361\tvalid_0's l2: 389827\n",
      "[2100]\tvalid_0's rmse: 623.076\tvalid_0's l2: 388223\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2152]\tvalid_0's rmse: 622.105\tvalid_0's l2: 387014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:42:13,035]\u001b[0m Trial 29 finished with value: 622.1045044397891 and parameters: {'max_depth': 23, 'n_estimators': 2152, 'learning_rate': 0.3174887248748618, 'subsample': 0.4838680697427238, 'colsample_bytree': 0.7731920177157805, 'colsample_bylevel': 0.6155438822058922, 'reg_alpha': 10.564278269732771, 'reg_lambda': 23.338649833406198}. Best is trial 18 with value: 612.475207007456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 1191.81\tvalid_0's l2: 1.42041e+06\n",
      "[200]\tvalid_0's rmse: 1032.44\tvalid_0's l2: 1.06594e+06\n",
      "[300]\tvalid_0's rmse: 976.952\tvalid_0's l2: 954436\n",
      "[400]\tvalid_0's rmse: 938.259\tvalid_0's l2: 880330\n",
      "[500]\tvalid_0's rmse: 909.239\tvalid_0's l2: 826716\n",
      "[600]\tvalid_0's rmse: 881.709\tvalid_0's l2: 777411\n",
      "[700]\tvalid_0's rmse: 863.237\tvalid_0's l2: 745178\n",
      "[800]\tvalid_0's rmse: 846.781\tvalid_0's l2: 717038\n",
      "[900]\tvalid_0's rmse: 833.965\tvalid_0's l2: 695498\n",
      "[1000]\tvalid_0's rmse: 823.615\tvalid_0's l2: 678342\n",
      "[1100]\tvalid_0's rmse: 813.273\tvalid_0's l2: 661413\n",
      "[1200]\tvalid_0's rmse: 803.229\tvalid_0's l2: 645178\n",
      "[1300]\tvalid_0's rmse: 794.148\tvalid_0's l2: 630672\n",
      "[1400]\tvalid_0's rmse: 786.308\tvalid_0's l2: 618281\n",
      "[1500]\tvalid_0's rmse: 779.392\tvalid_0's l2: 607452\n",
      "[1600]\tvalid_0's rmse: 772.979\tvalid_0's l2: 597497\n",
      "[1700]\tvalid_0's rmse: 767.451\tvalid_0's l2: 588982\n",
      "[1800]\tvalid_0's rmse: 762.545\tvalid_0's l2: 581476\n",
      "[1900]\tvalid_0's rmse: 756.764\tvalid_0's l2: 572692\n",
      "[2000]\tvalid_0's rmse: 751.618\tvalid_0's l2: 564930\n",
      "[2100]\tvalid_0's rmse: 747.2\tvalid_0's l2: 558308\n",
      "[2200]\tvalid_0's rmse: 742.562\tvalid_0's l2: 551399\n",
      "[2300]\tvalid_0's rmse: 738.624\tvalid_0's l2: 545566\n",
      "[2400]\tvalid_0's rmse: 735.086\tvalid_0's l2: 540352\n",
      "[2500]\tvalid_0's rmse: 731.549\tvalid_0's l2: 535164\n",
      "[2600]\tvalid_0's rmse: 728.086\tvalid_0's l2: 530109\n",
      "[2700]\tvalid_0's rmse: 724.984\tvalid_0's l2: 525601\n",
      "[2800]\tvalid_0's rmse: 722.09\tvalid_0's l2: 521414\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2819]\tvalid_0's rmse: 721.589\tvalid_0's l2: 520690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:42:58,705]\u001b[0m Trial 30 finished with value: 721.5888199207125 and parameters: {'max_depth': 20, 'n_estimators': 2819, 'learning_rate': 0.031013994792756433, 'subsample': 0.7017341912701338, 'colsample_bytree': 0.8972439782216589, 'colsample_bylevel': 0.7567118869130974, 'reg_alpha': 8.562606550850646, 'reg_lambda': 16.534414063834927}. Best is trial 18 with value: 612.475207007456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 853.711\tvalid_0's l2: 728822\n",
      "[200]\tvalid_0's rmse: 781.23\tvalid_0's l2: 610321\n",
      "[300]\tvalid_0's rmse: 745.06\tvalid_0's l2: 555114\n",
      "[400]\tvalid_0's rmse: 718.994\tvalid_0's l2: 516953\n",
      "[500]\tvalid_0's rmse: 699.816\tvalid_0's l2: 489743\n",
      "[600]\tvalid_0's rmse: 686.562\tvalid_0's l2: 471368\n",
      "[700]\tvalid_0's rmse: 676.56\tvalid_0's l2: 457733\n",
      "[800]\tvalid_0's rmse: 667.451\tvalid_0's l2: 445491\n",
      "[900]\tvalid_0's rmse: 661.193\tvalid_0's l2: 437177\n",
      "[1000]\tvalid_0's rmse: 655.492\tvalid_0's l2: 429670\n",
      "[1100]\tvalid_0's rmse: 650.768\tvalid_0's l2: 423499\n",
      "[1200]\tvalid_0's rmse: 647.263\tvalid_0's l2: 418949\n",
      "[1300]\tvalid_0's rmse: 643.439\tvalid_0's l2: 414014\n",
      "[1400]\tvalid_0's rmse: 640.25\tvalid_0's l2: 409920\n",
      "[1500]\tvalid_0's rmse: 637.991\tvalid_0's l2: 407032\n",
      "[1600]\tvalid_0's rmse: 635.653\tvalid_0's l2: 404054\n",
      "[1700]\tvalid_0's rmse: 633.102\tvalid_0's l2: 400819\n",
      "[1800]\tvalid_0's rmse: 630.864\tvalid_0's l2: 397989\n",
      "[1900]\tvalid_0's rmse: 629.001\tvalid_0's l2: 395642\n",
      "[2000]\tvalid_0's rmse: 627.461\tvalid_0's l2: 393708\n",
      "[2100]\tvalid_0's rmse: 626.109\tvalid_0's l2: 392012\n",
      "[2200]\tvalid_0's rmse: 624.538\tvalid_0's l2: 390048\n",
      "[2300]\tvalid_0's rmse: 623.572\tvalid_0's l2: 388842\n",
      "[2400]\tvalid_0's rmse: 622.662\tvalid_0's l2: 387708\n",
      "[2500]\tvalid_0's rmse: 621.447\tvalid_0's l2: 386196\n",
      "[2600]\tvalid_0's rmse: 620.521\tvalid_0's l2: 385047\n",
      "[2700]\tvalid_0's rmse: 619.634\tvalid_0's l2: 383947\n",
      "[2800]\tvalid_0's rmse: 618.85\tvalid_0's l2: 382975\n",
      "[2900]\tvalid_0's rmse: 617.633\tvalid_0's l2: 381471\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2981]\tvalid_0's rmse: 616.862\tvalid_0's l2: 380519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:43:38,835]\u001b[0m Trial 31 finished with value: 616.8619371601346 and parameters: {'max_depth': 28, 'n_estimators': 2981, 'learning_rate': 0.29578642153455575, 'subsample': 0.4698486074884608, 'colsample_bytree': 0.6223373804421302, 'colsample_bylevel': 0.7818092998665881, 'reg_alpha': 30.663386992128828, 'reg_lambda': 6.06055327501163}. Best is trial 18 with value: 612.475207007456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 882.091\tvalid_0's l2: 778085\n",
      "[200]\tvalid_0's rmse: 805.141\tvalid_0's l2: 648252\n",
      "[300]\tvalid_0's rmse: 762.801\tvalid_0's l2: 581865\n",
      "[400]\tvalid_0's rmse: 736.729\tvalid_0's l2: 542769\n",
      "[500]\tvalid_0's rmse: 718.162\tvalid_0's l2: 515757\n",
      "[600]\tvalid_0's rmse: 703.599\tvalid_0's l2: 495052\n",
      "[700]\tvalid_0's rmse: 692.394\tvalid_0's l2: 479410\n",
      "[800]\tvalid_0's rmse: 682.367\tvalid_0's l2: 465625\n",
      "[900]\tvalid_0's rmse: 673.105\tvalid_0's l2: 453070\n",
      "[1000]\tvalid_0's rmse: 665.75\tvalid_0's l2: 443223\n",
      "[1100]\tvalid_0's rmse: 660.354\tvalid_0's l2: 436068\n",
      "[1200]\tvalid_0's rmse: 655.277\tvalid_0's l2: 429388\n",
      "[1300]\tvalid_0's rmse: 651.302\tvalid_0's l2: 424194\n",
      "[1400]\tvalid_0's rmse: 646.544\tvalid_0's l2: 418020\n",
      "[1500]\tvalid_0's rmse: 643.107\tvalid_0's l2: 413587\n",
      "[1600]\tvalid_0's rmse: 639.506\tvalid_0's l2: 408968\n",
      "[1700]\tvalid_0's rmse: 636.412\tvalid_0's l2: 405020\n",
      "[1800]\tvalid_0's rmse: 633.864\tvalid_0's l2: 401784\n",
      "[1900]\tvalid_0's rmse: 631.339\tvalid_0's l2: 398589\n",
      "[2000]\tvalid_0's rmse: 628.956\tvalid_0's l2: 395586\n",
      "[2100]\tvalid_0's rmse: 626.887\tvalid_0's l2: 392987\n",
      "[2200]\tvalid_0's rmse: 625.31\tvalid_0's l2: 391013\n",
      "[2300]\tvalid_0's rmse: 623.744\tvalid_0's l2: 389057\n",
      "[2400]\tvalid_0's rmse: 622.107\tvalid_0's l2: 387017\n",
      "[2500]\tvalid_0's rmse: 620.762\tvalid_0's l2: 385346\n",
      "[2600]\tvalid_0's rmse: 619.296\tvalid_0's l2: 383528\n",
      "[2700]\tvalid_0's rmse: 618.411\tvalid_0's l2: 382432\n",
      "[2800]\tvalid_0's rmse: 617.488\tvalid_0's l2: 381291\n",
      "[2900]\tvalid_0's rmse: 616.374\tvalid_0's l2: 379917\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2992]\tvalid_0's rmse: 615.336\tvalid_0's l2: 378639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:44:20,830]\u001b[0m Trial 32 finished with value: 615.3363630094324 and parameters: {'max_depth': 14, 'n_estimators': 2993, 'learning_rate': 0.220124659361277, 'subsample': 0.6201159326511707, 'colsample_bytree': 0.6978703751728222, 'colsample_bylevel': 0.47282350934101725, 'reg_alpha': 29.03564906209947, 'reg_lambda': 0.22809503917645133}. Best is trial 18 with value: 612.475207007456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 950.631\tvalid_0's l2: 903699\n",
      "[200]\tvalid_0's rmse: 862.853\tvalid_0's l2: 744515\n",
      "[300]\tvalid_0's rmse: 820.469\tvalid_0's l2: 673169\n",
      "[400]\tvalid_0's rmse: 791.741\tvalid_0's l2: 626855\n",
      "[500]\tvalid_0's rmse: 769.298\tvalid_0's l2: 591819\n",
      "[600]\tvalid_0's rmse: 753.039\tvalid_0's l2: 567068\n",
      "[700]\tvalid_0's rmse: 738.854\tvalid_0's l2: 545906\n",
      "[800]\tvalid_0's rmse: 726.761\tvalid_0's l2: 528181\n",
      "[900]\tvalid_0's rmse: 716.236\tvalid_0's l2: 512994\n",
      "[1000]\tvalid_0's rmse: 706.995\tvalid_0's l2: 499841\n",
      "[1100]\tvalid_0's rmse: 699.486\tvalid_0's l2: 489281\n",
      "[1200]\tvalid_0's rmse: 692.099\tvalid_0's l2: 479001\n",
      "[1300]\tvalid_0's rmse: 686.322\tvalid_0's l2: 471038\n",
      "[1400]\tvalid_0's rmse: 680.044\tvalid_0's l2: 462460\n",
      "[1500]\tvalid_0's rmse: 674.772\tvalid_0's l2: 455317\n",
      "[1600]\tvalid_0's rmse: 670.519\tvalid_0's l2: 449595\n",
      "[1700]\tvalid_0's rmse: 666.251\tvalid_0's l2: 443890\n",
      "[1800]\tvalid_0's rmse: 662.614\tvalid_0's l2: 439057\n",
      "[1900]\tvalid_0's rmse: 659.102\tvalid_0's l2: 434415\n",
      "[2000]\tvalid_0's rmse: 655.681\tvalid_0's l2: 429917\n",
      "[2100]\tvalid_0's rmse: 652.691\tvalid_0's l2: 426005\n",
      "[2200]\tvalid_0's rmse: 649.88\tvalid_0's l2: 422344\n",
      "[2300]\tvalid_0's rmse: 647.314\tvalid_0's l2: 419015\n",
      "[2400]\tvalid_0's rmse: 645.373\tvalid_0's l2: 416506\n",
      "[2500]\tvalid_0's rmse: 643.097\tvalid_0's l2: 413573\n",
      "[2600]\tvalid_0's rmse: 640.75\tvalid_0's l2: 410560\n",
      "[2700]\tvalid_0's rmse: 638.64\tvalid_0's l2: 407861\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2719]\tvalid_0's rmse: 638.307\tvalid_0's l2: 407436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:45:01,378]\u001b[0m Trial 33 finished with value: 638.3070011389754 and parameters: {'max_depth': 13, 'n_estimators': 2720, 'learning_rate': 0.11647890285949056, 'subsample': 0.6105662113763046, 'colsample_bytree': 0.6991218329544785, 'colsample_bylevel': 0.44102041049110674, 'reg_alpha': 25.25669779585574, 'reg_lambda': 8.479934563606742}. Best is trial 18 with value: 612.475207007456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 877.007\tvalid_0's l2: 769142\n",
      "[200]\tvalid_0's rmse: 801.251\tvalid_0's l2: 642004\n",
      "[300]\tvalid_0's rmse: 760.568\tvalid_0's l2: 578464\n",
      "[400]\tvalid_0's rmse: 734.894\tvalid_0's l2: 540069\n",
      "[500]\tvalid_0's rmse: 713.902\tvalid_0's l2: 509657\n",
      "[600]\tvalid_0's rmse: 697.842\tvalid_0's l2: 486983\n",
      "[700]\tvalid_0's rmse: 686.897\tvalid_0's l2: 471828\n",
      "[800]\tvalid_0's rmse: 678.676\tvalid_0's l2: 460601\n",
      "[900]\tvalid_0's rmse: 671.224\tvalid_0's l2: 450542\n",
      "[1000]\tvalid_0's rmse: 664.148\tvalid_0's l2: 441093\n",
      "[1100]\tvalid_0's rmse: 658.875\tvalid_0's l2: 434116\n",
      "[1200]\tvalid_0's rmse: 653.996\tvalid_0's l2: 427711\n",
      "[1300]\tvalid_0's rmse: 649.646\tvalid_0's l2: 422041\n",
      "[1400]\tvalid_0's rmse: 645.95\tvalid_0's l2: 417252\n",
      "[1500]\tvalid_0's rmse: 642.448\tvalid_0's l2: 412740\n",
      "[1600]\tvalid_0's rmse: 638.665\tvalid_0's l2: 407892\n",
      "[1700]\tvalid_0's rmse: 635.936\tvalid_0's l2: 404414\n",
      "[1800]\tvalid_0's rmse: 632.98\tvalid_0's l2: 400663\n",
      "[1900]\tvalid_0's rmse: 630.749\tvalid_0's l2: 397845\n",
      "[2000]\tvalid_0's rmse: 628.445\tvalid_0's l2: 394943\n",
      "[2100]\tvalid_0's rmse: 626.209\tvalid_0's l2: 392138\n",
      "[2200]\tvalid_0's rmse: 624.261\tvalid_0's l2: 389702\n",
      "[2300]\tvalid_0's rmse: 622.774\tvalid_0's l2: 387847\n",
      "[2400]\tvalid_0's rmse: 621.522\tvalid_0's l2: 386289\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2414]\tvalid_0's rmse: 621.394\tvalid_0's l2: 386130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:45:36,609]\u001b[0m Trial 34 finished with value: 621.3936156842775 and parameters: {'max_depth': 17, 'n_estimators': 2414, 'learning_rate': 0.2180317217205743, 'subsample': 0.7278367143530595, 'colsample_bytree': 0.7712659290001583, 'colsample_bylevel': 0.48356551211788634, 'reg_alpha': 34.33516141221032, 'reg_lambda': 0.13138148429467786}. Best is trial 18 with value: 612.475207007456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 828.149\tvalid_0's l2: 685831\n",
      "[200]\tvalid_0's rmse: 756.234\tvalid_0's l2: 571890\n",
      "[300]\tvalid_0's rmse: 719.673\tvalid_0's l2: 517930\n",
      "[400]\tvalid_0's rmse: 699.61\tvalid_0's l2: 489454\n",
      "[500]\tvalid_0's rmse: 684.919\tvalid_0's l2: 469114\n",
      "[600]\tvalid_0's rmse: 673.206\tvalid_0's l2: 453206\n",
      "[700]\tvalid_0's rmse: 665.012\tvalid_0's l2: 442241\n",
      "[800]\tvalid_0's rmse: 658.554\tvalid_0's l2: 433694\n",
      "[900]\tvalid_0's rmse: 653.517\tvalid_0's l2: 427085\n",
      "[1000]\tvalid_0's rmse: 649.174\tvalid_0's l2: 421427\n",
      "[1100]\tvalid_0's rmse: 645.197\tvalid_0's l2: 416279\n",
      "[1200]\tvalid_0's rmse: 642.066\tvalid_0's l2: 412249\n",
      "[1300]\tvalid_0's rmse: 639.77\tvalid_0's l2: 409305\n",
      "[1400]\tvalid_0's rmse: 637.581\tvalid_0's l2: 406510\n",
      "[1500]\tvalid_0's rmse: 635.677\tvalid_0's l2: 404086\n",
      "[1600]\tvalid_0's rmse: 633.793\tvalid_0's l2: 401694\n",
      "[1700]\tvalid_0's rmse: 632.625\tvalid_0's l2: 400215\n",
      "[1800]\tvalid_0's rmse: 631.267\tvalid_0's l2: 398498\n",
      "[1900]\tvalid_0's rmse: 630.307\tvalid_0's l2: 397287\n",
      "[2000]\tvalid_0's rmse: 629.044\tvalid_0's l2: 395696\n",
      "[2100]\tvalid_0's rmse: 628.418\tvalid_0's l2: 394910\n",
      "[2200]\tvalid_0's rmse: 627.602\tvalid_0's l2: 393885\n",
      "[2300]\tvalid_0's rmse: 626.91\tvalid_0's l2: 393016\n",
      "[2400]\tvalid_0's rmse: 626.369\tvalid_0's l2: 392338\n",
      "Early stopping, best iteration is:\n",
      "[2455]\tvalid_0's rmse: 626.005\tvalid_0's l2: 391882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:46:11,982]\u001b[0m Trial 35 finished with value: 626.00492360261 and parameters: {'max_depth': 15, 'n_estimators': 2843, 'learning_rate': 0.4372952311204396, 'subsample': 0.6104315660850648, 'colsample_bytree': 0.8465454420121837, 'colsample_bylevel': 0.39725909836619544, 'reg_alpha': 42.39911703378748, 'reg_lambda': 25.639024192800804}. Best is trial 18 with value: 612.475207007456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 922.398\tvalid_0's l2: 850819\n",
      "[200]\tvalid_0's rmse: 835.661\tvalid_0's l2: 698330\n",
      "[300]\tvalid_0's rmse: 794.336\tvalid_0's l2: 630970\n",
      "[400]\tvalid_0's rmse: 766\tvalid_0's l2: 586757\n",
      "[500]\tvalid_0's rmse: 744.787\tvalid_0's l2: 554707\n",
      "[600]\tvalid_0's rmse: 729.356\tvalid_0's l2: 531960\n",
      "[700]\tvalid_0's rmse: 715.85\tvalid_0's l2: 512441\n",
      "[800]\tvalid_0's rmse: 703.975\tvalid_0's l2: 495580\n",
      "[900]\tvalid_0's rmse: 694.686\tvalid_0's l2: 482589\n",
      "[1000]\tvalid_0's rmse: 686.707\tvalid_0's l2: 471566\n",
      "[1100]\tvalid_0's rmse: 679.877\tvalid_0's l2: 462233\n",
      "[1200]\tvalid_0's rmse: 674.087\tvalid_0's l2: 454394\n",
      "[1300]\tvalid_0's rmse: 668.22\tvalid_0's l2: 446518\n",
      "[1400]\tvalid_0's rmse: 662.829\tvalid_0's l2: 439342\n",
      "[1500]\tvalid_0's rmse: 658.705\tvalid_0's l2: 433892\n",
      "[1600]\tvalid_0's rmse: 654.392\tvalid_0's l2: 428229\n",
      "[1700]\tvalid_0's rmse: 650.516\tvalid_0's l2: 423171\n",
      "[1800]\tvalid_0's rmse: 647.779\tvalid_0's l2: 419618\n",
      "[1900]\tvalid_0's rmse: 644.702\tvalid_0's l2: 415640\n",
      "[2000]\tvalid_0's rmse: 642.382\tvalid_0's l2: 412655\n",
      "[2100]\tvalid_0's rmse: 640.298\tvalid_0's l2: 409981\n",
      "[2200]\tvalid_0's rmse: 637.759\tvalid_0's l2: 406736\n",
      "[2300]\tvalid_0's rmse: 635.176\tvalid_0's l2: 403448\n",
      "[2400]\tvalid_0's rmse: 633.08\tvalid_0's l2: 400790\n",
      "[2500]\tvalid_0's rmse: 631.026\tvalid_0's l2: 398194\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2585]\tvalid_0's rmse: 629.457\tvalid_0's l2: 396216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:46:49,603]\u001b[0m Trial 36 finished with value: 629.4565804772902 and parameters: {'max_depth': 14, 'n_estimators': 2585, 'learning_rate': 0.14607699302716332, 'subsample': 0.8526110937487517, 'colsample_bytree': 0.7470562090502267, 'colsample_bylevel': 0.5145657887285517, 'reg_alpha': 20.021199685904037, 'reg_lambda': 16.668233821004574}. Best is trial 18 with value: 612.475207007456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 828.596\tvalid_0's l2: 686572\n",
      "[200]\tvalid_0's rmse: 761.03\tvalid_0's l2: 579166\n",
      "[300]\tvalid_0's rmse: 729.507\tvalid_0's l2: 532181\n",
      "[400]\tvalid_0's rmse: 709.651\tvalid_0's l2: 503605\n",
      "[500]\tvalid_0's rmse: 694.922\tvalid_0's l2: 482916\n",
      "[600]\tvalid_0's rmse: 685.367\tvalid_0's l2: 469729\n",
      "[700]\tvalid_0's rmse: 677.031\tvalid_0's l2: 458371\n",
      "[800]\tvalid_0's rmse: 671.548\tvalid_0's l2: 450977\n",
      "[900]\tvalid_0's rmse: 665.818\tvalid_0's l2: 443314\n",
      "[1000]\tvalid_0's rmse: 661.809\tvalid_0's l2: 437992\n",
      "[1100]\tvalid_0's rmse: 658.896\tvalid_0's l2: 434144\n",
      "[1200]\tvalid_0's rmse: 656.968\tvalid_0's l2: 431607\n",
      "[1300]\tvalid_0's rmse: 655.276\tvalid_0's l2: 429387\n",
      "[1400]\tvalid_0's rmse: 652.839\tvalid_0's l2: 426198\n",
      "[1500]\tvalid_0's rmse: 651.091\tvalid_0's l2: 423919\n",
      "[1600]\tvalid_0's rmse: 649.58\tvalid_0's l2: 421954\n",
      "[1700]\tvalid_0's rmse: 648.002\tvalid_0's l2: 419906\n",
      "[1800]\tvalid_0's rmse: 646.917\tvalid_0's l2: 418502\n",
      "[1900]\tvalid_0's rmse: 645.773\tvalid_0's l2: 417023\n",
      "[2000]\tvalid_0's rmse: 645.134\tvalid_0's l2: 416198\n",
      "[2100]\tvalid_0's rmse: 644.221\tvalid_0's l2: 415020\n",
      "[2200]\tvalid_0's rmse: 643.662\tvalid_0's l2: 414300\n",
      "[2300]\tvalid_0's rmse: 643.181\tvalid_0's l2: 413681\n",
      "[2400]\tvalid_0's rmse: 642.53\tvalid_0's l2: 412845\n",
      "Early stopping, best iteration is:\n",
      "[2412]\tvalid_0's rmse: 642.373\tvalid_0's l2: 412644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:47:23,070]\u001b[0m Trial 37 finished with value: 642.3733405154253 and parameters: {'max_depth': 8, 'n_estimators': 2993, 'learning_rate': 0.603805873443993, 'subsample': 0.3938718179057299, 'colsample_bytree': 0.6575932689757387, 'colsample_bylevel': 0.5919549950058641, 'reg_alpha': 26.62581121962726, 'reg_lambda': 7.573866454915888}. Best is trial 18 with value: 612.475207007456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 851.392\tvalid_0's l2: 724868\n",
      "[200]\tvalid_0's rmse: 776.451\tvalid_0's l2: 602876\n",
      "[300]\tvalid_0's rmse: 739.647\tvalid_0's l2: 547077\n",
      "[400]\tvalid_0's rmse: 716.978\tvalid_0's l2: 514057\n",
      "[500]\tvalid_0's rmse: 701.048\tvalid_0's l2: 491468\n",
      "[600]\tvalid_0's rmse: 688.811\tvalid_0's l2: 474461\n",
      "[700]\tvalid_0's rmse: 676.782\tvalid_0's l2: 458033\n",
      "[800]\tvalid_0's rmse: 668.533\tvalid_0's l2: 446936\n",
      "[900]\tvalid_0's rmse: 662.571\tvalid_0's l2: 439001\n",
      "[1000]\tvalid_0's rmse: 657.16\tvalid_0's l2: 431859\n",
      "[1100]\tvalid_0's rmse: 652.223\tvalid_0's l2: 425395\n",
      "[1200]\tvalid_0's rmse: 647.594\tvalid_0's l2: 419378\n",
      "[1300]\tvalid_0's rmse: 643.883\tvalid_0's l2: 414585\n",
      "[1400]\tvalid_0's rmse: 640.829\tvalid_0's l2: 410661\n",
      "[1500]\tvalid_0's rmse: 637.893\tvalid_0's l2: 406907\n",
      "[1600]\tvalid_0's rmse: 634.946\tvalid_0's l2: 403157\n",
      "[1700]\tvalid_0's rmse: 632.914\tvalid_0's l2: 400580\n",
      "[1800]\tvalid_0's rmse: 631.381\tvalid_0's l2: 398642\n",
      "[1900]\tvalid_0's rmse: 629.743\tvalid_0's l2: 396576\n",
      "[2000]\tvalid_0's rmse: 628.369\tvalid_0's l2: 394847\n",
      "[2100]\tvalid_0's rmse: 626.753\tvalid_0's l2: 392819\n",
      "[2200]\tvalid_0's rmse: 625.313\tvalid_0's l2: 391016\n",
      "[2300]\tvalid_0's rmse: 624.248\tvalid_0's l2: 389686\n",
      "[2400]\tvalid_0's rmse: 623.01\tvalid_0's l2: 388141\n",
      "[2500]\tvalid_0's rmse: 622.253\tvalid_0's l2: 387199\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2506]\tvalid_0's rmse: 622.206\tvalid_0's l2: 387141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:47:55,923]\u001b[0m Trial 38 finished with value: 622.2064712645657 and parameters: {'max_depth': 18, 'n_estimators': 2512, 'learning_rate': 0.34703252896089787, 'subsample': 0.5277027557368877, 'colsample_bytree': 0.5651884451710342, 'colsample_bylevel': 0.3153441201492238, 'reg_alpha': 98.84201458483702, 'reg_lambda': 11.240093808619658}. Best is trial 18 with value: 612.475207007456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 859.799\tvalid_0's l2: 739255\n",
      "[200]\tvalid_0's rmse: 792.362\tvalid_0's l2: 627838\n",
      "[300]\tvalid_0's rmse: 751.323\tvalid_0's l2: 564487\n",
      "[400]\tvalid_0's rmse: 726.746\tvalid_0's l2: 528160\n",
      "[500]\tvalid_0's rmse: 708.287\tvalid_0's l2: 501670\n",
      "[600]\tvalid_0's rmse: 693.611\tvalid_0's l2: 481096\n",
      "[700]\tvalid_0's rmse: 681.841\tvalid_0's l2: 464907\n",
      "[800]\tvalid_0's rmse: 673.196\tvalid_0's l2: 453193\n",
      "[900]\tvalid_0's rmse: 664.912\tvalid_0's l2: 442107\n",
      "[1000]\tvalid_0's rmse: 658.876\tvalid_0's l2: 434117\n",
      "[1100]\tvalid_0's rmse: 653.466\tvalid_0's l2: 427018\n",
      "[1200]\tvalid_0's rmse: 649.26\tvalid_0's l2: 421539\n",
      "[1300]\tvalid_0's rmse: 644.447\tvalid_0's l2: 415312\n",
      "[1400]\tvalid_0's rmse: 640.967\tvalid_0's l2: 410839\n",
      "[1500]\tvalid_0's rmse: 638.615\tvalid_0's l2: 407830\n",
      "[1600]\tvalid_0's rmse: 635.43\tvalid_0's l2: 403772\n",
      "[1700]\tvalid_0's rmse: 633.07\tvalid_0's l2: 400778\n",
      "[1800]\tvalid_0's rmse: 630.182\tvalid_0's l2: 397130\n",
      "[1900]\tvalid_0's rmse: 628.142\tvalid_0's l2: 394563\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1979]\tvalid_0's rmse: 626.433\tvalid_0's l2: 392418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:48:23,652]\u001b[0m Trial 39 finished with value: 626.4330556828464 and parameters: {'max_depth': 16, 'n_estimators': 1979, 'learning_rate': 0.2505646992160064, 'subsample': 0.1182599741727352, 'colsample_bytree': 0.6946576486459476, 'colsample_bylevel': 0.5313191127409088, 'reg_alpha': 34.462357479098515, 'reg_lambda': 81.27642812253166}. Best is trial 18 with value: 612.475207007456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 985.508\tvalid_0's l2: 971226\n",
      "[200]\tvalid_0's rmse: 895.384\tvalid_0's l2: 801713\n",
      "[300]\tvalid_0's rmse: 845.537\tvalid_0's l2: 714932\n",
      "[400]\tvalid_0's rmse: 813.232\tvalid_0's l2: 661346\n",
      "[500]\tvalid_0's rmse: 790.028\tvalid_0's l2: 624144\n",
      "[600]\tvalid_0's rmse: 771.46\tvalid_0's l2: 595150\n",
      "[700]\tvalid_0's rmse: 757.177\tvalid_0's l2: 573317\n",
      "[800]\tvalid_0's rmse: 744.752\tvalid_0's l2: 554656\n",
      "[900]\tvalid_0's rmse: 733.166\tvalid_0's l2: 537532\n",
      "[1000]\tvalid_0's rmse: 723.658\tvalid_0's l2: 523680\n",
      "[1100]\tvalid_0's rmse: 715.571\tvalid_0's l2: 512043\n",
      "[1200]\tvalid_0's rmse: 708.661\tvalid_0's l2: 502201\n",
      "[1300]\tvalid_0's rmse: 702.233\tvalid_0's l2: 493131\n",
      "[1400]\tvalid_0's rmse: 696.607\tvalid_0's l2: 485261\n",
      "[1500]\tvalid_0's rmse: 691.373\tvalid_0's l2: 477996\n",
      "[1600]\tvalid_0's rmse: 686.841\tvalid_0's l2: 471751\n",
      "[1700]\tvalid_0's rmse: 682.302\tvalid_0's l2: 465536\n",
      "[1800]\tvalid_0's rmse: 677.282\tvalid_0's l2: 458711\n",
      "[1900]\tvalid_0's rmse: 673.307\tvalid_0's l2: 453343\n",
      "[2000]\tvalid_0's rmse: 669.875\tvalid_0's l2: 448733\n",
      "[2100]\tvalid_0's rmse: 666.125\tvalid_0's l2: 443723\n",
      "[2200]\tvalid_0's rmse: 663.231\tvalid_0's l2: 439875\n",
      "[2300]\tvalid_0's rmse: 660.113\tvalid_0's l2: 435749\n",
      "[2400]\tvalid_0's rmse: 657.177\tvalid_0's l2: 431882\n",
      "[2500]\tvalid_0's rmse: 654.851\tvalid_0's l2: 428830\n",
      "[2600]\tvalid_0's rmse: 652.396\tvalid_0's l2: 425620\n",
      "[2700]\tvalid_0's rmse: 650.176\tvalid_0's l2: 422728\n",
      "[2800]\tvalid_0's rmse: 647.946\tvalid_0's l2: 419834\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2886]\tvalid_0's rmse: 645.993\tvalid_0's l2: 417307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:49:06,257]\u001b[0m Trial 40 finished with value: 645.9926890234257 and parameters: {'max_depth': 23, 'n_estimators': 2886, 'learning_rate': 0.08510997340644513, 'subsample': 0.6066691373256594, 'colsample_bytree': 0.7997756248477683, 'colsample_bylevel': 0.6546890896441271, 'reg_alpha': 3.807344647388902, 'reg_lambda': 0.2232366286464983}. Best is trial 18 with value: 612.475207007456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 864.693\tvalid_0's l2: 747694\n",
      "[200]\tvalid_0's rmse: 794.172\tvalid_0's l2: 630710\n",
      "[300]\tvalid_0's rmse: 753.248\tvalid_0's l2: 567382\n",
      "[400]\tvalid_0's rmse: 727.205\tvalid_0's l2: 528826\n",
      "[500]\tvalid_0's rmse: 708.305\tvalid_0's l2: 501696\n",
      "[600]\tvalid_0's rmse: 694.93\tvalid_0's l2: 482928\n",
      "[700]\tvalid_0's rmse: 683.071\tvalid_0's l2: 466586\n",
      "[800]\tvalid_0's rmse: 673.686\tvalid_0's l2: 453853\n",
      "[900]\tvalid_0's rmse: 665.516\tvalid_0's l2: 442911\n",
      "[1000]\tvalid_0's rmse: 659.556\tvalid_0's l2: 435014\n",
      "[1100]\tvalid_0's rmse: 654.035\tvalid_0's l2: 427762\n",
      "[1200]\tvalid_0's rmse: 649.109\tvalid_0's l2: 421342\n",
      "[1300]\tvalid_0's rmse: 645.041\tvalid_0's l2: 416078\n",
      "[1400]\tvalid_0's rmse: 642.106\tvalid_0's l2: 412300\n",
      "[1500]\tvalid_0's rmse: 638.834\tvalid_0's l2: 408108\n",
      "[1600]\tvalid_0's rmse: 636.4\tvalid_0's l2: 405005\n",
      "[1700]\tvalid_0's rmse: 634.083\tvalid_0's l2: 402061\n",
      "[1800]\tvalid_0's rmse: 631.907\tvalid_0's l2: 399307\n",
      "[1900]\tvalid_0's rmse: 629.792\tvalid_0's l2: 396638\n",
      "[2000]\tvalid_0's rmse: 627.796\tvalid_0's l2: 394128\n",
      "[2100]\tvalid_0's rmse: 625.914\tvalid_0's l2: 391769\n",
      "[2200]\tvalid_0's rmse: 624.277\tvalid_0's l2: 389722\n",
      "[2300]\tvalid_0's rmse: 623.09\tvalid_0's l2: 388241\n",
      "[2400]\tvalid_0's rmse: 622.112\tvalid_0's l2: 387023\n",
      "[2500]\tvalid_0's rmse: 620.883\tvalid_0's l2: 385495\n",
      "[2600]\tvalid_0's rmse: 619.475\tvalid_0's l2: 383749\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2680]\tvalid_0's rmse: 618.353\tvalid_0's l2: 382361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:49:42,516]\u001b[0m Trial 41 finished with value: 618.3532410608053 and parameters: {'max_depth': 27, 'n_estimators': 2680, 'learning_rate': 0.27125463691273816, 'subsample': 0.38166976365438593, 'colsample_bytree': 0.5763532825150915, 'colsample_bylevel': 0.4694237314826528, 'reg_alpha': 26.728013945504713, 'reg_lambda': 4.992129517979646}. Best is trial 18 with value: 612.475207007456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 918.416\tvalid_0's l2: 843488\n",
      "[200]\tvalid_0's rmse: 843.724\tvalid_0's l2: 711870\n",
      "[300]\tvalid_0's rmse: 798.935\tvalid_0's l2: 638298\n",
      "[400]\tvalid_0's rmse: 770.632\tvalid_0's l2: 593874\n",
      "[500]\tvalid_0's rmse: 750.265\tvalid_0's l2: 562898\n",
      "[600]\tvalid_0's rmse: 733.326\tvalid_0's l2: 537768\n",
      "[700]\tvalid_0's rmse: 720.686\tvalid_0's l2: 519389\n",
      "[800]\tvalid_0's rmse: 711.761\tvalid_0's l2: 506603\n",
      "[900]\tvalid_0's rmse: 702.916\tvalid_0's l2: 494091\n",
      "[1000]\tvalid_0's rmse: 694.522\tvalid_0's l2: 482361\n",
      "[1100]\tvalid_0's rmse: 687.77\tvalid_0's l2: 473027\n",
      "[1200]\tvalid_0's rmse: 681.492\tvalid_0's l2: 464431\n",
      "[1300]\tvalid_0's rmse: 675.777\tvalid_0's l2: 456675\n",
      "[1400]\tvalid_0's rmse: 670.955\tvalid_0's l2: 450180\n",
      "[1500]\tvalid_0's rmse: 666.44\tvalid_0's l2: 444142\n",
      "[1600]\tvalid_0's rmse: 662.752\tvalid_0's l2: 439240\n",
      "[1700]\tvalid_0's rmse: 658.914\tvalid_0's l2: 434168\n",
      "[1800]\tvalid_0's rmse: 654.916\tvalid_0's l2: 428915\n",
      "[1900]\tvalid_0's rmse: 652.013\tvalid_0's l2: 425122\n",
      "[2000]\tvalid_0's rmse: 648.986\tvalid_0's l2: 421183\n",
      "[2100]\tvalid_0's rmse: 645.366\tvalid_0's l2: 416498\n",
      "[2200]\tvalid_0's rmse: 643.139\tvalid_0's l2: 413627\n",
      "[2300]\tvalid_0's rmse: 640.378\tvalid_0's l2: 410084\n",
      "[2400]\tvalid_0's rmse: 638.494\tvalid_0's l2: 407674\n",
      "[2500]\tvalid_0's rmse: 636.593\tvalid_0's l2: 405251\n",
      "[2600]\tvalid_0's rmse: 634.713\tvalid_0's l2: 402860\n",
      "[2700]\tvalid_0's rmse: 633.336\tvalid_0's l2: 401115\n",
      "[2800]\tvalid_0's rmse: 631.677\tvalid_0's l2: 399016\n",
      "[2900]\tvalid_0's rmse: 629.982\tvalid_0's l2: 396877\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2958]\tvalid_0's rmse: 629.103\tvalid_0's l2: 395770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:50:19,132]\u001b[0m Trial 42 finished with value: 629.102599181574 and parameters: {'max_depth': 20, 'n_estimators': 2958, 'learning_rate': 0.16283514747264966, 'subsample': 0.5138325235872491, 'colsample_bytree': 0.45426217862592444, 'colsample_bylevel': 0.8276906119616724, 'reg_alpha': 11.092895478832403, 'reg_lambda': 0.7719093628215781}. Best is trial 18 with value: 612.475207007456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 854.181\tvalid_0's l2: 729625\n",
      "[200]\tvalid_0's rmse: 787.303\tvalid_0's l2: 619845\n",
      "[300]\tvalid_0's rmse: 747.511\tvalid_0's l2: 558773\n",
      "[400]\tvalid_0's rmse: 723.854\tvalid_0's l2: 523965\n",
      "[500]\tvalid_0's rmse: 704.259\tvalid_0's l2: 495981\n",
      "[600]\tvalid_0's rmse: 691.854\tvalid_0's l2: 478661\n",
      "[700]\tvalid_0's rmse: 680.3\tvalid_0's l2: 462809\n",
      "[800]\tvalid_0's rmse: 671.781\tvalid_0's l2: 451290\n",
      "[900]\tvalid_0's rmse: 664.023\tvalid_0's l2: 440926\n",
      "[1000]\tvalid_0's rmse: 657.729\tvalid_0's l2: 432607\n",
      "[1100]\tvalid_0's rmse: 653.941\tvalid_0's l2: 427639\n",
      "[1200]\tvalid_0's rmse: 649.161\tvalid_0's l2: 421410\n",
      "[1300]\tvalid_0's rmse: 645.103\tvalid_0's l2: 416157\n",
      "[1400]\tvalid_0's rmse: 641.759\tvalid_0's l2: 411854\n",
      "[1500]\tvalid_0's rmse: 639.058\tvalid_0's l2: 408396\n",
      "[1600]\tvalid_0's rmse: 636.848\tvalid_0's l2: 405575\n",
      "[1700]\tvalid_0's rmse: 634.29\tvalid_0's l2: 402324\n",
      "[1800]\tvalid_0's rmse: 632.428\tvalid_0's l2: 399965\n",
      "[1900]\tvalid_0's rmse: 630.413\tvalid_0's l2: 397421\n",
      "[2000]\tvalid_0's rmse: 628.17\tvalid_0's l2: 394598\n",
      "[2100]\tvalid_0's rmse: 626.215\tvalid_0's l2: 392145\n",
      "[2200]\tvalid_0's rmse: 625.112\tvalid_0's l2: 390766\n",
      "[2300]\tvalid_0's rmse: 623.889\tvalid_0's l2: 389238\n",
      "[2400]\tvalid_0's rmse: 622.395\tvalid_0's l2: 387376\n",
      "[2500]\tvalid_0's rmse: 621.312\tvalid_0's l2: 386029\n",
      "[2600]\tvalid_0's rmse: 620.813\tvalid_0's l2: 385409\n",
      "[2700]\tvalid_0's rmse: 620.04\tvalid_0's l2: 384449\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2738]\tvalid_0's rmse: 619.732\tvalid_0's l2: 384068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:50:57,385]\u001b[0m Trial 43 finished with value: 619.7324005767874 and parameters: {'max_depth': 10, 'n_estimators': 2743, 'learning_rate': 0.2887610697773822, 'subsample': 0.29170885248175277, 'colsample_bytree': 0.6226886843944694, 'colsample_bylevel': 0.41709572862290467, 'reg_alpha': 32.55090221744754, 'reg_lambda': 11.742543420577785}. Best is trial 18 with value: 612.475207007456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 887.477\tvalid_0's l2: 787615\n",
      "[200]\tvalid_0's rmse: 814.953\tvalid_0's l2: 664148\n",
      "[300]\tvalid_0's rmse: 774.414\tvalid_0's l2: 599718\n",
      "[400]\tvalid_0's rmse: 747.483\tvalid_0's l2: 558731\n",
      "[500]\tvalid_0's rmse: 727.626\tvalid_0's l2: 529439\n",
      "[600]\tvalid_0's rmse: 712.624\tvalid_0's l2: 507833\n",
      "[700]\tvalid_0's rmse: 700.194\tvalid_0's l2: 490271\n",
      "[800]\tvalid_0's rmse: 689.648\tvalid_0's l2: 475614\n",
      "[900]\tvalid_0's rmse: 681.257\tvalid_0's l2: 464111\n",
      "[1000]\tvalid_0's rmse: 673.791\tvalid_0's l2: 453994\n",
      "[1100]\tvalid_0's rmse: 668.19\tvalid_0's l2: 446478\n",
      "[1200]\tvalid_0's rmse: 661.817\tvalid_0's l2: 438001\n",
      "[1300]\tvalid_0's rmse: 657.15\tvalid_0's l2: 431846\n",
      "[1400]\tvalid_0's rmse: 652.485\tvalid_0's l2: 425736\n",
      "[1500]\tvalid_0's rmse: 648.04\tvalid_0's l2: 419956\n",
      "[1600]\tvalid_0's rmse: 644.459\tvalid_0's l2: 415327\n",
      "[1700]\tvalid_0's rmse: 641.135\tvalid_0's l2: 411053\n",
      "[1800]\tvalid_0's rmse: 638.44\tvalid_0's l2: 407606\n",
      "[1900]\tvalid_0's rmse: 635.811\tvalid_0's l2: 404256\n",
      "[2000]\tvalid_0's rmse: 633.636\tvalid_0's l2: 401494\n",
      "[2100]\tvalid_0's rmse: 632.125\tvalid_0's l2: 399582\n",
      "[2200]\tvalid_0's rmse: 630.11\tvalid_0's l2: 397039\n",
      "[2300]\tvalid_0's rmse: 628.259\tvalid_0's l2: 394710\n",
      "[2400]\tvalid_0's rmse: 626.723\tvalid_0's l2: 392782\n",
      "[2500]\tvalid_0's rmse: 624.693\tvalid_0's l2: 390241\n",
      "[2600]\tvalid_0's rmse: 623.581\tvalid_0's l2: 388853\n",
      "[2700]\tvalid_0's rmse: 622.086\tvalid_0's l2: 386991\n",
      "[2800]\tvalid_0's rmse: 620.492\tvalid_0's l2: 385010\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2890]\tvalid_0's rmse: 619.482\tvalid_0's l2: 383758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:51:36,927]\u001b[0m Trial 44 finished with value: 619.4823100013868 and parameters: {'max_depth': 14, 'n_estimators': 2890, 'learning_rate': 0.199684647896307, 'subsample': 0.425029596876918, 'colsample_bytree': 0.6053955223738223, 'colsample_bylevel': 0.7538018534110542, 'reg_alpha': 44.45494236157776, 'reg_lambda': 7.895401399245944}. Best is trial 18 with value: 612.475207007456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 849.037\tvalid_0's l2: 720864\n",
      "[200]\tvalid_0's rmse: 777.272\tvalid_0's l2: 604151\n",
      "[300]\tvalid_0's rmse: 738.624\tvalid_0's l2: 545565\n",
      "[400]\tvalid_0's rmse: 714.047\tvalid_0's l2: 509863\n",
      "[500]\tvalid_0's rmse: 697.084\tvalid_0's l2: 485926\n",
      "[600]\tvalid_0's rmse: 683.723\tvalid_0's l2: 467477\n",
      "[700]\tvalid_0's rmse: 674.464\tvalid_0's l2: 454902\n",
      "[800]\tvalid_0's rmse: 666.663\tvalid_0's l2: 444440\n",
      "[900]\tvalid_0's rmse: 661.387\tvalid_0's l2: 437433\n",
      "[1000]\tvalid_0's rmse: 655.591\tvalid_0's l2: 429799\n",
      "[1100]\tvalid_0's rmse: 651.143\tvalid_0's l2: 423987\n",
      "[1200]\tvalid_0's rmse: 647.002\tvalid_0's l2: 418611\n",
      "[1300]\tvalid_0's rmse: 643.194\tvalid_0's l2: 413699\n",
      "[1400]\tvalid_0's rmse: 640.915\tvalid_0's l2: 410772\n",
      "[1500]\tvalid_0's rmse: 638.732\tvalid_0's l2: 407978\n",
      "[1600]\tvalid_0's rmse: 637.335\tvalid_0's l2: 406196\n",
      "[1700]\tvalid_0's rmse: 635.698\tvalid_0's l2: 404112\n",
      "[1800]\tvalid_0's rmse: 634.166\tvalid_0's l2: 402167\n",
      "[1900]\tvalid_0's rmse: 632.52\tvalid_0's l2: 400081\n",
      "[2000]\tvalid_0's rmse: 631.086\tvalid_0's l2: 398270\n",
      "[2100]\tvalid_0's rmse: 629.413\tvalid_0's l2: 396160\n",
      "[2200]\tvalid_0's rmse: 628.449\tvalid_0's l2: 394948\n",
      "[2300]\tvalid_0's rmse: 627.024\tvalid_0's l2: 393160\n",
      "[2400]\tvalid_0's rmse: 626.008\tvalid_0's l2: 391886\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2410]\tvalid_0's rmse: 625.857\tvalid_0's l2: 391698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:52:08,419]\u001b[0m Trial 45 finished with value: 625.857477980137 and parameters: {'max_depth': 24, 'n_estimators': 2411, 'learning_rate': 0.4059106159641418, 'subsample': 0.5674543622582832, 'colsample_bytree': 0.5505247381869915, 'colsample_bylevel': 0.3252749786846766, 'reg_alpha': 19.602141663252816, 'reg_lambda': 19.08387412978517}. Best is trial 18 with value: 612.475207007456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 858.334\tvalid_0's l2: 736736\n",
      "[200]\tvalid_0's rmse: 786.122\tvalid_0's l2: 617987\n",
      "[300]\tvalid_0's rmse: 748.172\tvalid_0's l2: 559761\n",
      "[400]\tvalid_0's rmse: 723.118\tvalid_0's l2: 522899\n",
      "[500]\tvalid_0's rmse: 704.718\tvalid_0's l2: 496628\n",
      "[600]\tvalid_0's rmse: 691.761\tvalid_0's l2: 478533\n",
      "[700]\tvalid_0's rmse: 681.17\tvalid_0's l2: 463993\n",
      "[800]\tvalid_0's rmse: 672.026\tvalid_0's l2: 451618\n",
      "[900]\tvalid_0's rmse: 664.664\tvalid_0's l2: 441778\n",
      "[1000]\tvalid_0's rmse: 659.942\tvalid_0's l2: 435524\n",
      "[1100]\tvalid_0's rmse: 654.89\tvalid_0's l2: 428881\n",
      "[1200]\tvalid_0's rmse: 650.448\tvalid_0's l2: 423082\n",
      "[1300]\tvalid_0's rmse: 645.894\tvalid_0's l2: 417179\n",
      "[1400]\tvalid_0's rmse: 642.745\tvalid_0's l2: 413122\n",
      "[1500]\tvalid_0's rmse: 639.923\tvalid_0's l2: 409501\n",
      "[1600]\tvalid_0's rmse: 637.553\tvalid_0's l2: 406474\n",
      "[1700]\tvalid_0's rmse: 635.293\tvalid_0's l2: 403597\n",
      "[1800]\tvalid_0's rmse: 633.103\tvalid_0's l2: 400820\n",
      "[1900]\tvalid_0's rmse: 631.287\tvalid_0's l2: 398523\n",
      "[2000]\tvalid_0's rmse: 629.674\tvalid_0's l2: 396490\n",
      "[2100]\tvalid_0's rmse: 628.377\tvalid_0's l2: 394858\n",
      "[2200]\tvalid_0's rmse: 626.982\tvalid_0's l2: 393107\n",
      "[2300]\tvalid_0's rmse: 625.906\tvalid_0's l2: 391759\n",
      "[2400]\tvalid_0's rmse: 624.559\tvalid_0's l2: 390074\n",
      "[2500]\tvalid_0's rmse: 623.778\tvalid_0's l2: 389098\n",
      "[2600]\tvalid_0's rmse: 622.782\tvalid_0's l2: 387858\n",
      "[2700]\tvalid_0's rmse: 622.023\tvalid_0's l2: 386913\n",
      "[2800]\tvalid_0's rmse: 621.083\tvalid_0's l2: 385743\n",
      "[2900]\tvalid_0's rmse: 620.103\tvalid_0's l2: 384528\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2982]\tvalid_0's rmse: 619.496\tvalid_0's l2: 383775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:52:46,220]\u001b[0m Trial 46 finished with value: 619.4958115259526 and parameters: {'max_depth': 21, 'n_estimators': 2982, 'learning_rate': 0.33413808046988314, 'subsample': 0.6499382449922892, 'colsample_bytree': 0.46491527763008167, 'colsample_bylevel': 0.6549322624911713, 'reg_alpha': 29.560546209242354, 'reg_lambda': 26.8878408832997}. Best is trial 18 with value: 612.475207007456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 1189.85\tvalid_0's l2: 1.41573e+06\n",
      "[200]\tvalid_0's rmse: 1134.98\tvalid_0's l2: 1.28818e+06\n",
      "[300]\tvalid_0's rmse: 1104.81\tvalid_0's l2: 1.22061e+06\n",
      "[400]\tvalid_0's rmse: 1086.17\tvalid_0's l2: 1.17976e+06\n",
      "[500]\tvalid_0's rmse: 1074.39\tvalid_0's l2: 1.15431e+06\n",
      "[600]\tvalid_0's rmse: 1063.59\tvalid_0's l2: 1.13123e+06\n",
      "[700]\tvalid_0's rmse: 1055.94\tvalid_0's l2: 1.11501e+06\n",
      "[800]\tvalid_0's rmse: 1049.07\tvalid_0's l2: 1.10055e+06\n",
      "[900]\tvalid_0's rmse: 1043.84\tvalid_0's l2: 1.08961e+06\n",
      "[1000]\tvalid_0's rmse: 1038.72\tvalid_0's l2: 1.07894e+06\n",
      "[1100]\tvalid_0's rmse: 1032.95\tvalid_0's l2: 1.06699e+06\n",
      "[1200]\tvalid_0's rmse: 1027.31\tvalid_0's l2: 1.05537e+06\n",
      "[1300]\tvalid_0's rmse: 1023.2\tvalid_0's l2: 1.04693e+06\n",
      "[1400]\tvalid_0's rmse: 1019.3\tvalid_0's l2: 1.03898e+06\n",
      "[1500]\tvalid_0's rmse: 1014.99\tvalid_0's l2: 1.03021e+06\n",
      "[1600]\tvalid_0's rmse: 1009.9\tvalid_0's l2: 1.0199e+06\n",
      "[1700]\tvalid_0's rmse: 1007.01\tvalid_0's l2: 1.01408e+06\n",
      "[1800]\tvalid_0's rmse: 1003.95\tvalid_0's l2: 1.00792e+06\n",
      "[1900]\tvalid_0's rmse: 1002.15\tvalid_0's l2: 1.0043e+06\n",
      "[2000]\tvalid_0's rmse: 999.664\tvalid_0's l2: 999328\n",
      "[2100]\tvalid_0's rmse: 997.603\tvalid_0's l2: 995211\n",
      "[2200]\tvalid_0's rmse: 996.099\tvalid_0's l2: 992212\n",
      "[2300]\tvalid_0's rmse: 993.933\tvalid_0's l2: 987903\n",
      "[2400]\tvalid_0's rmse: 992.089\tvalid_0's l2: 984241\n",
      "[2500]\tvalid_0's rmse: 990.354\tvalid_0's l2: 980801\n",
      "[2600]\tvalid_0's rmse: 988.879\tvalid_0's l2: 977881\n",
      "[2700]\tvalid_0's rmse: 987.602\tvalid_0's l2: 975357\n",
      "[2800]\tvalid_0's rmse: 985.661\tvalid_0's l2: 971528\n",
      "[2900]\tvalid_0's rmse: 983.995\tvalid_0's l2: 968247\n",
      "[3000]\tvalid_0's rmse: 982.848\tvalid_0's l2: 965989\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\tvalid_0's rmse: 982.848\tvalid_0's l2: 965989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:53:19,673]\u001b[0m Trial 47 finished with value: 982.8475163510954 and parameters: {'max_depth': 2, 'n_estimators': 3000, 'learning_rate': 0.2469286007446214, 'subsample': 0.7400424644618119, 'colsample_bytree': 0.6778900848028435, 'colsample_bylevel': 0.5773635651696837, 'reg_alpha': 51.852479570790315, 'reg_lambda': 64.49197371003822}. Best is trial 18 with value: 612.475207007456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 924.576\tvalid_0's l2: 854841\n",
      "[200]\tvalid_0's rmse: 844.219\tvalid_0's l2: 712706\n",
      "[300]\tvalid_0's rmse: 798.547\tvalid_0's l2: 637677\n",
      "[400]\tvalid_0's rmse: 768.453\tvalid_0's l2: 590520\n",
      "[500]\tvalid_0's rmse: 748.949\tvalid_0's l2: 560924\n",
      "[600]\tvalid_0's rmse: 733.056\tvalid_0's l2: 537372\n",
      "[700]\tvalid_0's rmse: 719.959\tvalid_0's l2: 518342\n",
      "[800]\tvalid_0's rmse: 709.129\tvalid_0's l2: 502865\n",
      "[900]\tvalid_0's rmse: 700.035\tvalid_0's l2: 490049\n",
      "[1000]\tvalid_0's rmse: 691.114\tvalid_0's l2: 477639\n",
      "[1100]\tvalid_0's rmse: 684.059\tvalid_0's l2: 467937\n",
      "[1200]\tvalid_0's rmse: 677.701\tvalid_0's l2: 459278\n",
      "[1300]\tvalid_0's rmse: 671.845\tvalid_0's l2: 451376\n",
      "[1400]\tvalid_0's rmse: 666.658\tvalid_0's l2: 444433\n",
      "[1500]\tvalid_0's rmse: 662.671\tvalid_0's l2: 439133\n",
      "[1600]\tvalid_0's rmse: 657.96\tvalid_0's l2: 432911\n",
      "[1700]\tvalid_0's rmse: 653.764\tvalid_0's l2: 427408\n",
      "[1800]\tvalid_0's rmse: 649.898\tvalid_0's l2: 422367\n",
      "[1900]\tvalid_0's rmse: 646.739\tvalid_0's l2: 418271\n",
      "[2000]\tvalid_0's rmse: 643.812\tvalid_0's l2: 414493\n",
      "[2100]\tvalid_0's rmse: 641.22\tvalid_0's l2: 411164\n",
      "[2200]\tvalid_0's rmse: 638.895\tvalid_0's l2: 408187\n",
      "[2300]\tvalid_0's rmse: 636.932\tvalid_0's l2: 405683\n",
      "[2400]\tvalid_0's rmse: 634.619\tvalid_0's l2: 402741\n",
      "[2500]\tvalid_0's rmse: 632.913\tvalid_0's l2: 400578\n",
      "[2600]\tvalid_0's rmse: 630.637\tvalid_0's l2: 397703\n",
      "[2700]\tvalid_0's rmse: 628.816\tvalid_0's l2: 395409\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2722]\tvalid_0's rmse: 628.442\tvalid_0's l2: 394940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:53:59,162]\u001b[0m Trial 48 finished with value: 628.442461375163 and parameters: {'max_depth': 22, 'n_estimators': 2722, 'learning_rate': 0.1386465262047567, 'subsample': 0.32026214170026124, 'colsample_bytree': 0.7313383290157122, 'colsample_bylevel': 0.5397115671554401, 'reg_alpha': 36.94437271446968, 'reg_lambda': 46.5799583269687}. Best is trial 18 with value: 612.475207007456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 814.799\tvalid_0's l2: 663897\n",
      "[200]\tvalid_0's rmse: 751.732\tvalid_0's l2: 565101\n",
      "[300]\tvalid_0's rmse: 717.762\tvalid_0's l2: 515182\n",
      "[400]\tvalid_0's rmse: 697.227\tvalid_0's l2: 486126\n",
      "[500]\tvalid_0's rmse: 683.499\tvalid_0's l2: 467171\n",
      "[600]\tvalid_0's rmse: 673.093\tvalid_0's l2: 453054\n",
      "[700]\tvalid_0's rmse: 665.666\tvalid_0's l2: 443111\n",
      "[800]\tvalid_0's rmse: 659.327\tvalid_0's l2: 434712\n",
      "[900]\tvalid_0's rmse: 653.243\tvalid_0's l2: 426726\n",
      "[1000]\tvalid_0's rmse: 649.02\tvalid_0's l2: 421228\n",
      "[1100]\tvalid_0's rmse: 646.53\tvalid_0's l2: 418001\n",
      "[1200]\tvalid_0's rmse: 644.643\tvalid_0's l2: 415564\n",
      "[1300]\tvalid_0's rmse: 641.929\tvalid_0's l2: 412073\n",
      "[1400]\tvalid_0's rmse: 640.082\tvalid_0's l2: 409705\n",
      "[1500]\tvalid_0's rmse: 638.082\tvalid_0's l2: 407149\n",
      "[1600]\tvalid_0's rmse: 636.168\tvalid_0's l2: 404710\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1631]\tvalid_0's rmse: 635.703\tvalid_0's l2: 404119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:54:22,248]\u001b[0m Trial 49 finished with value: 635.7033060093679 and parameters: {'max_depth': 17, 'n_estimators': 1631, 'learning_rate': 0.4907009593235244, 'subsample': 0.4989093973043466, 'colsample_bytree': 0.8649334147171707, 'colsample_bylevel': 0.8320445947877897, 'reg_alpha': 64.08650129998705, 'reg_lambda': 14.006708241134946}. Best is trial 18 with value: 612.475207007456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 837.937\tvalid_0's l2: 702138\n",
      "[200]\tvalid_0's rmse: 771.168\tvalid_0's l2: 594701\n",
      "[300]\tvalid_0's rmse: 734.848\tvalid_0's l2: 540002\n",
      "[400]\tvalid_0's rmse: 711.759\tvalid_0's l2: 506600\n",
      "[500]\tvalid_0's rmse: 695.007\tvalid_0's l2: 483035\n",
      "[600]\tvalid_0's rmse: 682.179\tvalid_0's l2: 465368\n",
      "[700]\tvalid_0's rmse: 674.181\tvalid_0's l2: 454520\n",
      "[800]\tvalid_0's rmse: 666.93\tvalid_0's l2: 444795\n",
      "[900]\tvalid_0's rmse: 660.599\tvalid_0's l2: 436391\n",
      "[1000]\tvalid_0's rmse: 656.052\tvalid_0's l2: 430404\n",
      "[1100]\tvalid_0's rmse: 651.971\tvalid_0's l2: 425066\n",
      "[1200]\tvalid_0's rmse: 648.089\tvalid_0's l2: 420019\n",
      "[1300]\tvalid_0's rmse: 644.675\tvalid_0's l2: 415606\n",
      "[1400]\tvalid_0's rmse: 642.045\tvalid_0's l2: 412222\n",
      "[1500]\tvalid_0's rmse: 640.071\tvalid_0's l2: 409691\n",
      "[1600]\tvalid_0's rmse: 638.395\tvalid_0's l2: 407548\n",
      "[1700]\tvalid_0's rmse: 636.361\tvalid_0's l2: 404955\n",
      "[1800]\tvalid_0's rmse: 634.422\tvalid_0's l2: 402491\n",
      "[1900]\tvalid_0's rmse: 632.877\tvalid_0's l2: 400533\n",
      "[2000]\tvalid_0's rmse: 631.64\tvalid_0's l2: 398969\n",
      "[2100]\tvalid_0's rmse: 629.982\tvalid_0's l2: 396878\n",
      "[2200]\tvalid_0's rmse: 628.764\tvalid_0's l2: 395344\n",
      "[2300]\tvalid_0's rmse: 627.507\tvalid_0's l2: 393765\n",
      "[2400]\tvalid_0's rmse: 626.683\tvalid_0's l2: 392732\n",
      "[2500]\tvalid_0's rmse: 625.949\tvalid_0's l2: 391812\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2532]\tvalid_0's rmse: 625.777\tvalid_0's l2: 391596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:54:52,453]\u001b[0m Trial 50 finished with value: 625.7767021714067 and parameters: {'max_depth': 19, 'n_estimators': 2532, 'learning_rate': 0.4239090812323077, 'subsample': 0.6810055019429799, 'colsample_bytree': 0.5029124563896554, 'colsample_bylevel': 0.45555782344471374, 'reg_alpha': 0.11912073467461681, 'reg_lambda': 4.249460520859404}. Best is trial 18 with value: 612.475207007456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 860.368\tvalid_0's l2: 740234\n",
      "[200]\tvalid_0's rmse: 786.296\tvalid_0's l2: 618262\n",
      "[300]\tvalid_0's rmse: 748.599\tvalid_0's l2: 560401\n",
      "[400]\tvalid_0's rmse: 724.679\tvalid_0's l2: 525160\n",
      "[500]\tvalid_0's rmse: 705.601\tvalid_0's l2: 497873\n",
      "[600]\tvalid_0's rmse: 692.757\tvalid_0's l2: 479913\n",
      "[700]\tvalid_0's rmse: 682.691\tvalid_0's l2: 466067\n",
      "[800]\tvalid_0's rmse: 673.346\tvalid_0's l2: 453395\n",
      "[900]\tvalid_0's rmse: 665.683\tvalid_0's l2: 443134\n",
      "[1000]\tvalid_0's rmse: 658.991\tvalid_0's l2: 434269\n",
      "[1100]\tvalid_0's rmse: 653.305\tvalid_0's l2: 426807\n",
      "[1200]\tvalid_0's rmse: 648.678\tvalid_0's l2: 420783\n",
      "[1300]\tvalid_0's rmse: 645.101\tvalid_0's l2: 416156\n",
      "[1400]\tvalid_0's rmse: 641.423\tvalid_0's l2: 411424\n",
      "[1500]\tvalid_0's rmse: 637.864\tvalid_0's l2: 406870\n",
      "[1600]\tvalid_0's rmse: 635.267\tvalid_0's l2: 403565\n",
      "[1700]\tvalid_0's rmse: 632.037\tvalid_0's l2: 399471\n",
      "[1800]\tvalid_0's rmse: 629.72\tvalid_0's l2: 396547\n",
      "[1900]\tvalid_0's rmse: 627.539\tvalid_0's l2: 393805\n",
      "[2000]\tvalid_0's rmse: 625.487\tvalid_0's l2: 391234\n",
      "[2100]\tvalid_0's rmse: 623.476\tvalid_0's l2: 388723\n",
      "[2200]\tvalid_0's rmse: 622.151\tvalid_0's l2: 387072\n",
      "[2300]\tvalid_0's rmse: 620.605\tvalid_0's l2: 385150\n",
      "[2400]\tvalid_0's rmse: 618.864\tvalid_0's l2: 382992\n",
      "[2500]\tvalid_0's rmse: 617.871\tvalid_0's l2: 381764\n",
      "[2600]\tvalid_0's rmse: 616.554\tvalid_0's l2: 380138\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2684]\tvalid_0's rmse: 615.853\tvalid_0's l2: 379274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:55:30,404]\u001b[0m Trial 51 finished with value: 615.8525526188185 and parameters: {'max_depth': 19, 'n_estimators': 2686, 'learning_rate': 0.23520643685553316, 'subsample': 0.6448610027845098, 'colsample_bytree': 0.8799720041261182, 'colsample_bylevel': 0.5566181905603849, 'reg_alpha': 14.540316773446932, 'reg_lambda': 1.0542312653002703}. Best is trial 18 with value: 612.475207007456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 894.877\tvalid_0's l2: 800805\n",
      "[200]\tvalid_0's rmse: 812.202\tvalid_0's l2: 659672\n",
      "[300]\tvalid_0's rmse: 770.354\tvalid_0's l2: 593445\n",
      "[400]\tvalid_0's rmse: 744.293\tvalid_0's l2: 553973\n",
      "[500]\tvalid_0's rmse: 725.179\tvalid_0's l2: 525885\n",
      "[600]\tvalid_0's rmse: 710.083\tvalid_0's l2: 504217\n",
      "[700]\tvalid_0's rmse: 698.064\tvalid_0's l2: 487294\n",
      "[800]\tvalid_0's rmse: 688.338\tvalid_0's l2: 473809\n",
      "[900]\tvalid_0's rmse: 679.994\tvalid_0's l2: 462391\n",
      "[1000]\tvalid_0's rmse: 673.145\tvalid_0's l2: 453124\n",
      "[1100]\tvalid_0's rmse: 667.503\tvalid_0's l2: 445560\n",
      "[1200]\tvalid_0's rmse: 661.533\tvalid_0's l2: 437626\n",
      "[1300]\tvalid_0's rmse: 656.935\tvalid_0's l2: 431564\n",
      "[1400]\tvalid_0's rmse: 652.494\tvalid_0's l2: 425748\n",
      "[1500]\tvalid_0's rmse: 649.124\tvalid_0's l2: 421362\n",
      "[1600]\tvalid_0's rmse: 645.417\tvalid_0's l2: 416563\n",
      "[1700]\tvalid_0's rmse: 641.936\tvalid_0's l2: 412081\n",
      "[1800]\tvalid_0's rmse: 638.759\tvalid_0's l2: 408013\n",
      "[1900]\tvalid_0's rmse: 636.695\tvalid_0's l2: 405381\n",
      "[2000]\tvalid_0's rmse: 634.658\tvalid_0's l2: 402791\n",
      "[2100]\tvalid_0's rmse: 632.2\tvalid_0's l2: 399676\n",
      "[2200]\tvalid_0's rmse: 629.997\tvalid_0's l2: 396897\n",
      "[2300]\tvalid_0's rmse: 628.001\tvalid_0's l2: 394386\n",
      "[2400]\tvalid_0's rmse: 626.11\tvalid_0's l2: 392014\n",
      "[2500]\tvalid_0's rmse: 624.523\tvalid_0's l2: 390028\n",
      "[2600]\tvalid_0's rmse: 622.873\tvalid_0's l2: 387970\n",
      "[2700]\tvalid_0's rmse: 621.264\tvalid_0's l2: 385968\n",
      "[2800]\tvalid_0's rmse: 619.981\tvalid_0's l2: 384377\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2872]\tvalid_0's rmse: 619.209\tvalid_0's l2: 383419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:56:11,720]\u001b[0m Trial 52 finished with value: 619.2087188136655 and parameters: {'max_depth': 16, 'n_estimators': 2874, 'learning_rate': 0.1820783242085318, 'subsample': 0.681666194581824, 'colsample_bytree': 0.8353479140880946, 'colsample_bylevel': 0.5981689014427173, 'reg_alpha': 24.809239852562214, 'reg_lambda': 0.2398101459285855}. Best is trial 18 with value: 612.475207007456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 848.478\tvalid_0's l2: 719914\n",
      "[200]\tvalid_0's rmse: 777.325\tvalid_0's l2: 604234\n",
      "[300]\tvalid_0's rmse: 739.204\tvalid_0's l2: 546423\n",
      "[400]\tvalid_0's rmse: 714.68\tvalid_0's l2: 510767\n",
      "[500]\tvalid_0's rmse: 696.351\tvalid_0's l2: 484904\n",
      "[600]\tvalid_0's rmse: 682.01\tvalid_0's l2: 465137\n",
      "[700]\tvalid_0's rmse: 672.267\tvalid_0's l2: 451943\n",
      "[800]\tvalid_0's rmse: 664.156\tvalid_0's l2: 441104\n",
      "[900]\tvalid_0's rmse: 656.739\tvalid_0's l2: 431306\n",
      "[1000]\tvalid_0's rmse: 651.791\tvalid_0's l2: 424831\n",
      "[1100]\tvalid_0's rmse: 646.632\tvalid_0's l2: 418133\n",
      "[1200]\tvalid_0's rmse: 642.653\tvalid_0's l2: 413003\n",
      "[1300]\tvalid_0's rmse: 638.856\tvalid_0's l2: 408137\n",
      "[1400]\tvalid_0's rmse: 635.459\tvalid_0's l2: 403808\n",
      "[1500]\tvalid_0's rmse: 632.636\tvalid_0's l2: 400229\n",
      "[1600]\tvalid_0's rmse: 630.124\tvalid_0's l2: 397056\n",
      "[1700]\tvalid_0's rmse: 627.654\tvalid_0's l2: 393950\n",
      "[1800]\tvalid_0's rmse: 625.697\tvalid_0's l2: 391497\n",
      "[1900]\tvalid_0's rmse: 623.826\tvalid_0's l2: 389159\n",
      "[2000]\tvalid_0's rmse: 622.094\tvalid_0's l2: 387001\n",
      "[2100]\tvalid_0's rmse: 620.323\tvalid_0's l2: 384801\n",
      "[2200]\tvalid_0's rmse: 619.084\tvalid_0's l2: 383265\n",
      "[2300]\tvalid_0's rmse: 617.94\tvalid_0's l2: 381850\n",
      "[2400]\tvalid_0's rmse: 616.667\tvalid_0's l2: 380279\n",
      "[2500]\tvalid_0's rmse: 615.491\tvalid_0's l2: 378829\n",
      "[2600]\tvalid_0's rmse: 614.5\tvalid_0's l2: 377610\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2628]\tvalid_0's rmse: 614.318\tvalid_0's l2: 377387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:56:48,939]\u001b[0m Trial 53 finished with value: 614.3184011545476 and parameters: {'max_depth': 18, 'n_estimators': 2628, 'learning_rate': 0.2704936152867333, 'subsample': 0.822320898893014, 'colsample_bytree': 0.8999305363044018, 'colsample_bylevel': 0.505793916264023, 'reg_alpha': 28.31035945354876, 'reg_lambda': 4.085128851898301}. Best is trial 18 with value: 612.475207007456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 850.124\tvalid_0's l2: 722711\n",
      "[200]\tvalid_0's rmse: 779.042\tvalid_0's l2: 606907\n",
      "[300]\tvalid_0's rmse: 741.524\tvalid_0's l2: 549858\n",
      "[400]\tvalid_0's rmse: 718.107\tvalid_0's l2: 515678\n",
      "[500]\tvalid_0's rmse: 698.849\tvalid_0's l2: 488390\n",
      "[600]\tvalid_0's rmse: 685.604\tvalid_0's l2: 470052\n",
      "[700]\tvalid_0's rmse: 674.902\tvalid_0's l2: 455492\n",
      "[800]\tvalid_0's rmse: 667.777\tvalid_0's l2: 445926\n",
      "[900]\tvalid_0's rmse: 660.307\tvalid_0's l2: 436006\n",
      "[1000]\tvalid_0's rmse: 654.571\tvalid_0's l2: 428463\n",
      "[1100]\tvalid_0's rmse: 650.371\tvalid_0's l2: 422982\n",
      "[1200]\tvalid_0's rmse: 646.076\tvalid_0's l2: 417414\n",
      "[1300]\tvalid_0's rmse: 641.702\tvalid_0's l2: 411781\n",
      "[1400]\tvalid_0's rmse: 638.824\tvalid_0's l2: 408096\n",
      "[1500]\tvalid_0's rmse: 635.593\tvalid_0's l2: 403979\n",
      "[1600]\tvalid_0's rmse: 632.937\tvalid_0's l2: 400609\n",
      "[1700]\tvalid_0's rmse: 630.347\tvalid_0's l2: 397338\n",
      "[1800]\tvalid_0's rmse: 628.521\tvalid_0's l2: 395039\n",
      "[1900]\tvalid_0's rmse: 626.215\tvalid_0's l2: 392145\n",
      "[2000]\tvalid_0's rmse: 624.659\tvalid_0's l2: 390199\n",
      "[2100]\tvalid_0's rmse: 623.385\tvalid_0's l2: 388609\n",
      "[2200]\tvalid_0's rmse: 621.524\tvalid_0's l2: 386292\n",
      "[2300]\tvalid_0's rmse: 620.477\tvalid_0's l2: 384992\n",
      "[2400]\tvalid_0's rmse: 619.494\tvalid_0's l2: 383773\n",
      "[2500]\tvalid_0's rmse: 618.117\tvalid_0's l2: 382069\n",
      "[2600]\tvalid_0's rmse: 616.894\tvalid_0's l2: 380558\n",
      "[2700]\tvalid_0's rmse: 615.916\tvalid_0's l2: 379352\n",
      "[2800]\tvalid_0's rmse: 615.18\tvalid_0's l2: 378446\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2896]\tvalid_0's rmse: 614.294\tvalid_0's l2: 377357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:57:28,568]\u001b[0m Trial 54 finished with value: 614.2935372779568 and parameters: {'max_depth': 20, 'n_estimators': 2896, 'learning_rate': 0.2883773199169456, 'subsample': 0.9146737143465206, 'colsample_bytree': 0.8010864695495764, 'colsample_bylevel': 0.4926437494283484, 'reg_alpha': 29.72521395044518, 'reg_lambda': 9.558450657788837}. Best is trial 18 with value: 612.475207007456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 836.105\tvalid_0's l2: 699072\n",
      "[200]\tvalid_0's rmse: 769.263\tvalid_0's l2: 591765\n",
      "[300]\tvalid_0's rmse: 730.903\tvalid_0's l2: 534220\n",
      "[400]\tvalid_0's rmse: 708.923\tvalid_0's l2: 502572\n",
      "[500]\tvalid_0's rmse: 691.623\tvalid_0's l2: 478343\n",
      "[600]\tvalid_0's rmse: 678.958\tvalid_0's l2: 460983\n",
      "[700]\tvalid_0's rmse: 669.591\tvalid_0's l2: 448352\n",
      "[800]\tvalid_0's rmse: 661.976\tvalid_0's l2: 438212\n",
      "[900]\tvalid_0's rmse: 655.285\tvalid_0's l2: 429398\n",
      "[1000]\tvalid_0's rmse: 650.378\tvalid_0's l2: 422992\n",
      "[1100]\tvalid_0's rmse: 645.571\tvalid_0's l2: 416762\n",
      "[1200]\tvalid_0's rmse: 641.887\tvalid_0's l2: 412019\n",
      "[1300]\tvalid_0's rmse: 639.214\tvalid_0's l2: 408595\n",
      "[1400]\tvalid_0's rmse: 636.464\tvalid_0's l2: 405087\n",
      "[1500]\tvalid_0's rmse: 634.224\tvalid_0's l2: 402240\n",
      "[1600]\tvalid_0's rmse: 632.042\tvalid_0's l2: 399477\n",
      "[1700]\tvalid_0's rmse: 629.89\tvalid_0's l2: 396762\n",
      "[1800]\tvalid_0's rmse: 628.214\tvalid_0's l2: 394653\n",
      "[1900]\tvalid_0's rmse: 626.533\tvalid_0's l2: 392544\n",
      "[2000]\tvalid_0's rmse: 625.289\tvalid_0's l2: 390986\n",
      "[2100]\tvalid_0's rmse: 624.012\tvalid_0's l2: 389391\n",
      "[2200]\tvalid_0's rmse: 622.973\tvalid_0's l2: 388095\n",
      "[2300]\tvalid_0's rmse: 621.854\tvalid_0's l2: 386702\n",
      "[2400]\tvalid_0's rmse: 620.946\tvalid_0's l2: 385574\n",
      "[2500]\tvalid_0's rmse: 620.109\tvalid_0's l2: 384535\n",
      "[2600]\tvalid_0's rmse: 619.578\tvalid_0's l2: 383877\n",
      "[2700]\tvalid_0's rmse: 618.823\tvalid_0's l2: 382942\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2784]\tvalid_0's rmse: 618.428\tvalid_0's l2: 382454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:58:09,239]\u001b[0m Trial 55 finished with value: 618.4284127613452 and parameters: {'max_depth': 18, 'n_estimators': 2784, 'learning_rate': 0.3443249092897158, 'subsample': 0.8217909407835802, 'colsample_bytree': 0.8036930260300288, 'colsample_bylevel': 0.5006792752085769, 'reg_alpha': 21.104992983958805, 'reg_lambda': 9.240372024896544}. Best is trial 18 with value: 612.475207007456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 843.439\tvalid_0's l2: 711389\n",
      "[200]\tvalid_0's rmse: 770.445\tvalid_0's l2: 593585\n",
      "[300]\tvalid_0's rmse: 732.936\tvalid_0's l2: 537196\n",
      "[400]\tvalid_0's rmse: 709.967\tvalid_0's l2: 504053\n",
      "[500]\tvalid_0's rmse: 694.813\tvalid_0's l2: 482765\n",
      "[600]\tvalid_0's rmse: 682.879\tvalid_0's l2: 466324\n",
      "[700]\tvalid_0's rmse: 673.909\tvalid_0's l2: 454153\n",
      "[800]\tvalid_0's rmse: 665.571\tvalid_0's l2: 442984\n",
      "[900]\tvalid_0's rmse: 657.477\tvalid_0's l2: 432277\n",
      "[1000]\tvalid_0's rmse: 651.65\tvalid_0's l2: 424647\n",
      "[1100]\tvalid_0's rmse: 646.528\tvalid_0's l2: 417998\n",
      "[1200]\tvalid_0's rmse: 642.592\tvalid_0's l2: 412925\n",
      "[1300]\tvalid_0's rmse: 638.321\tvalid_0's l2: 407454\n",
      "[1400]\tvalid_0's rmse: 635.192\tvalid_0's l2: 403469\n",
      "[1500]\tvalid_0's rmse: 632.463\tvalid_0's l2: 400009\n",
      "[1600]\tvalid_0's rmse: 630.557\tvalid_0's l2: 397602\n",
      "[1700]\tvalid_0's rmse: 628.513\tvalid_0's l2: 395029\n",
      "[1800]\tvalid_0's rmse: 625.924\tvalid_0's l2: 391781\n",
      "[1900]\tvalid_0's rmse: 624.151\tvalid_0's l2: 389564\n",
      "[2000]\tvalid_0's rmse: 622.61\tvalid_0's l2: 387643\n",
      "[2100]\tvalid_0's rmse: 621.514\tvalid_0's l2: 386279\n",
      "[2200]\tvalid_0's rmse: 619.99\tvalid_0's l2: 384387\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2247]\tvalid_0's rmse: 619.243\tvalid_0's l2: 383462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:58:40,998]\u001b[0m Trial 56 finished with value: 619.242796958901 and parameters: {'max_depth': 20, 'n_estimators': 2247, 'learning_rate': 0.30013666951133067, 'subsample': 0.9236071046889615, 'colsample_bytree': 0.8978575789957245, 'colsample_bylevel': 0.3795160840561438, 'reg_alpha': 40.651404435671395, 'reg_lambda': 17.60310776110293}. Best is trial 18 with value: 612.475207007456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 805.045\tvalid_0's l2: 648097\n",
      "[200]\tvalid_0's rmse: 746.394\tvalid_0's l2: 557104\n",
      "[300]\tvalid_0's rmse: 718.428\tvalid_0's l2: 516138\n",
      "[400]\tvalid_0's rmse: 703.947\tvalid_0's l2: 495542\n",
      "[500]\tvalid_0's rmse: 694.2\tvalid_0's l2: 481913\n",
      "[600]\tvalid_0's rmse: 688.589\tvalid_0's l2: 474155\n",
      "[700]\tvalid_0's rmse: 683.805\tvalid_0's l2: 467590\n",
      "[800]\tvalid_0's rmse: 680.274\tvalid_0's l2: 462773\n",
      "[900]\tvalid_0's rmse: 678.016\tvalid_0's l2: 459706\n",
      "[1000]\tvalid_0's rmse: 675.841\tvalid_0's l2: 456761\n",
      "[1100]\tvalid_0's rmse: 673.025\tvalid_0's l2: 452963\n",
      "[1200]\tvalid_0's rmse: 671.885\tvalid_0's l2: 451429\n",
      "Early stopping, best iteration is:\n",
      "[1204]\tvalid_0's rmse: 671.832\tvalid_0's l2: 451359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:58:59,248]\u001b[0m Trial 57 finished with value: 671.8324938306591 and parameters: {'max_depth': 21, 'n_estimators': 2599, 'learning_rate': 0.8185535130408497, 'subsample': 0.8981670734098566, 'colsample_bytree': 0.8587260096421584, 'colsample_bylevel': 0.6492892322173385, 'reg_alpha': 28.616228376461567, 'reg_lambda': 4.093130701800636}. Best is trial 18 with value: 612.475207007456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 828.631\tvalid_0's l2: 686629\n",
      "[200]\tvalid_0's rmse: 759.049\tvalid_0's l2: 576155\n",
      "[300]\tvalid_0's rmse: 728.978\tvalid_0's l2: 531409\n",
      "[400]\tvalid_0's rmse: 705.958\tvalid_0's l2: 498377\n",
      "[500]\tvalid_0's rmse: 690.101\tvalid_0's l2: 476240\n",
      "[600]\tvalid_0's rmse: 677.8\tvalid_0's l2: 459413\n",
      "[700]\tvalid_0's rmse: 668.839\tvalid_0's l2: 447346\n",
      "[800]\tvalid_0's rmse: 662.076\tvalid_0's l2: 438345\n",
      "[900]\tvalid_0's rmse: 654.681\tvalid_0's l2: 428607\n",
      "[1000]\tvalid_0's rmse: 649.73\tvalid_0's l2: 422149\n",
      "[1100]\tvalid_0's rmse: 644.813\tvalid_0's l2: 415784\n",
      "[1200]\tvalid_0's rmse: 641.696\tvalid_0's l2: 411774\n",
      "[1300]\tvalid_0's rmse: 639.026\tvalid_0's l2: 408354\n",
      "[1400]\tvalid_0's rmse: 636.465\tvalid_0's l2: 405088\n",
      "[1500]\tvalid_0's rmse: 634.213\tvalid_0's l2: 402226\n",
      "[1600]\tvalid_0's rmse: 632.145\tvalid_0's l2: 399607\n",
      "[1700]\tvalid_0's rmse: 630.414\tvalid_0's l2: 397422\n",
      "[1800]\tvalid_0's rmse: 628.984\tvalid_0's l2: 395621\n",
      "[1900]\tvalid_0's rmse: 627.32\tvalid_0's l2: 393531\n",
      "[2000]\tvalid_0's rmse: 626.475\tvalid_0's l2: 392471\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2045]\tvalid_0's rmse: 625.979\tvalid_0's l2: 391850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:59:28,832]\u001b[0m Trial 58 finished with value: 625.9788587914676 and parameters: {'max_depth': 22, 'n_estimators': 2045, 'learning_rate': 0.3721939144277728, 'subsample': 0.7751685559934505, 'colsample_bytree': 0.8160639846175454, 'colsample_bylevel': 0.514380913156005, 'reg_alpha': 34.171000456871916, 'reg_lambda': 13.15556691904304}. Best is trial 18 with value: 612.475207007456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\tvalid_0's rmse: 966.297\tvalid_0's l2: 933729\n",
      "[200]\tvalid_0's rmse: 880.151\tvalid_0's l2: 774667\n",
      "[300]\tvalid_0's rmse: 834.395\tvalid_0's l2: 696215\n",
      "[400]\tvalid_0's rmse: 801.455\tvalid_0's l2: 642330\n",
      "[500]\tvalid_0's rmse: 777.909\tvalid_0's l2: 605142\n",
      "[600]\tvalid_0's rmse: 760.168\tvalid_0's l2: 577856\n",
      "[700]\tvalid_0's rmse: 746.052\tvalid_0's l2: 556593\n",
      "[800]\tvalid_0's rmse: 733.583\tvalid_0's l2: 538144\n",
      "[900]\tvalid_0's rmse: 723.855\tvalid_0's l2: 523967\n",
      "[1000]\tvalid_0's rmse: 714.648\tvalid_0's l2: 510721\n",
      "[1100]\tvalid_0's rmse: 706.24\tvalid_0's l2: 498776\n",
      "[1200]\tvalid_0's rmse: 699.584\tvalid_0's l2: 489417\n",
      "[1300]\tvalid_0's rmse: 693.341\tvalid_0's l2: 480721\n",
      "[1400]\tvalid_0's rmse: 688.446\tvalid_0's l2: 473958\n",
      "[1500]\tvalid_0's rmse: 683.829\tvalid_0's l2: 467622\n",
      "[1600]\tvalid_0's rmse: 678.873\tvalid_0's l2: 460869\n",
      "[1700]\tvalid_0's rmse: 674.509\tvalid_0's l2: 454962\n",
      "[1800]\tvalid_0's rmse: 670.202\tvalid_0's l2: 449170\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1848]\tvalid_0's rmse: 668.557\tvalid_0's l2: 446968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 04:59:58,589]\u001b[0m Trial 59 finished with value: 668.5565722063225 and parameters: {'max_depth': 18, 'n_estimators': 1848, 'learning_rate': 0.10012078335189462, 'subsample': 0.8182619382525824, 'colsample_bytree': 0.7849247745495359, 'colsample_bylevel': 0.41881706834260923, 'reg_alpha': 17.049106971452602, 'reg_lambda': 37.44318741874072}. Best is trial 18 with value: 612.475207007456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Optimized lgb RMSE 612.9962562452332\n",
      "Wall time: 31min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "def create_model(trial):\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 2, 30)\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 500, 3000)\n",
    "    learning_rate = trial.suggest_uniform('learning_rate', 0.01, 1)\n",
    "    subsample = trial.suggest_uniform('subsample', 0.1, 0.99)\n",
    "    colsample_bytree = trial.suggest_uniform('colsample_bytree', 0.1, 0.9)\n",
    "    colsample_bylevel = trial.suggest_uniform('colsample_bylevel', 0.1, 0.9)\n",
    "    #num_leaves = trial.suggest_int(\"num_leaves\", 2, 5000)\n",
    "    #min_child_samples = trial.suggest_int('min_child_samples', 3, 200)\n",
    "    reg_alpha = trial.suggest_float(\"reg_alpha\", 0.1, 100)\n",
    "    reg_lambda = trial.suggest_float(\"reg_lambda\", 0.1, 100)\n",
    "    model = LGBMRegressor(\n",
    "        max_depth = max_depth,\n",
    "        n_estimators = n_estimators,\n",
    "        learning_rate=learning_rate, \n",
    "        subsample = subsample,\n",
    "        colsample_bytree = colsample_bytree,\n",
    "        colsample_bylevel = colsample_bylevel,\n",
    "        #num_leaves=num_leaves, \n",
    "        #min_child_samples=min_child_samples,\n",
    "        random_state=1,\n",
    "        n_jobs = -1\n",
    "    )\n",
    "    return model\n",
    "\n",
    "sampler = TPESampler(seed=1)\n",
    "def objective(trial):\n",
    "    model = create_model(trial)\n",
    "    model.fit(X_trn, y_trn, eval_set = [ (X_val, y_val)], early_stopping_rounds = 40, verbose = 100, eval_metric = 'rmse')\n",
    "    preds = model.predict(X_val)\n",
    "    score = np.sqrt(mean_squared_error(y_val,preds))\n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\", sampler=sampler)\n",
    "study.optimize(objective, n_trials=60)\n",
    "\n",
    "lgb_params = study.best_params\n",
    "lgb_params['random_state'] = 1\n",
    "lgb = LGBMRegressor(**lgb_params)\n",
    "lgb.fit(X_trn, y_trn, eval_set = [(X_val, y_val)], early_stopping_rounds = 40, verbose = False)\n",
    "preds = lgb.predict(X_val)\n",
    "print('Optimized lgb RMSE', np.sqrt(mean_squared_error(y_val, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 05:00:43,730]\u001b[0m A new study created in memory with name: no-name-f8cee042-e9ac-4d4b-8895-f02ba69b9f6b\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2196.4957100\ttest: 2190.4424469\tbest: 2190.4424469 (0)\ttotal: 56.2ms\tremaining: 41.3s\n",
      "100:\tlearn: 1000.8142757\ttest: 1009.7461656\tbest: 1009.7461656 (100)\ttotal: 4.08s\tremaining: 25.6s\n",
      "200:\tlearn: 900.6567196\ttest: 913.4163850\tbest: 913.4163850 (200)\ttotal: 8.02s\tremaining: 21.3s\n",
      "300:\tlearn: 854.8367317\ttest: 869.8618055\tbest: 869.8618055 (300)\ttotal: 12s\tremaining: 17.2s\n",
      "400:\tlearn: 819.2115329\ttest: 837.4267090\tbest: 837.4267090 (400)\ttotal: 15.9s\tremaining: 13.2s\n",
      "500:\tlearn: 791.8359647\ttest: 814.4885992\tbest: 814.4885992 (500)\ttotal: 19.9s\tremaining: 9.3s\n",
      "600:\tlearn: 769.0390245\ttest: 794.4355990\tbest: 794.4355990 (600)\ttotal: 24s\tremaining: 5.35s\n",
      "700:\tlearn: 754.2459294\ttest: 782.5559941\tbest: 782.5559941 (700)\ttotal: 27.9s\tremaining: 1.35s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 05:01:13,595]\u001b[0m Trial 0 finished with value: 778.5885577771119 and parameters: {'depth': 6, 'n_estimators': 735, 'learning_rate': 0.7231212485077365, 'rsm': 0.10010179358743695, 'reg_alpha': 30.303024005920797, 'reg_lambda': 14.760913492629594}. Best is trial 0 with value: 778.5885577771119.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "734:\tlearn: 749.6648030\ttest: 778.5885578\tbest: 778.5885578 (734)\ttotal: 29.3s\tremaining: 0us\n",
      "\n",
      "bestTest = 778.5885578\n",
      "bestIteration = 734\n",
      "\n",
      "0:\tlearn: 3077.7481435\ttest: 3059.2464209\tbest: 3059.2464209 (0)\ttotal: 33.8ms\tremaining: 21.2s\n",
      "100:\tlearn: 1427.7181782\ttest: 1421.6306426\tbest: 1421.6306426 (100)\ttotal: 4.07s\tremaining: 21.3s\n",
      "200:\tlearn: 1391.5014511\ttest: 1385.8197252\tbest: 1385.8197252 (200)\ttotal: 7.74s\tremaining: 16.5s\n",
      "300:\tlearn: 1379.7409925\ttest: 1375.0239554\tbest: 1375.0239554 (300)\ttotal: 11.4s\tremaining: 12.5s\n",
      "400:\tlearn: 1373.3238964\ttest: 1369.1444235\tbest: 1369.1444235 (400)\ttotal: 15s\tremaining: 8.52s\n",
      "500:\tlearn: 1369.3119673\ttest: 1365.4930183\tbest: 1365.4930183 (500)\ttotal: 18.8s\tremaining: 4.81s\n",
      "600:\tlearn: 1366.5363733\ttest: 1362.9153447\tbest: 1362.9153447 (600)\ttotal: 22.5s\tremaining: 1.05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 05:01:37,581]\u001b[0m Trial 1 finished with value: 1362.3162444792135 and parameters: {'depth': 1, 'n_estimators': 629, 'learning_rate': 0.1943976092638942, 'rsm': 0.4075490470683125, 'reg_alpha': 39.73707067564393, 'reg_lambda': 53.92779172693536}. Best is trial 0 with value: 778.5885577771119.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "628:\tlearn: 1365.9096362\ttest: 1362.3162445\tbest: 1362.3162445 (628)\ttotal: 23.6s\tremaining: 0us\n",
      "\n",
      "bestTest = 1362.316244\n",
      "bestIteration = 628\n",
      "\n",
      "0:\tlearn: 1980.2426597\ttest: 1979.8910904\tbest: 1979.8910904 (0)\ttotal: 44.1ms\tremaining: 33.1s\n",
      "100:\tlearn: 953.8376030\ttest: 961.6464234\tbest: 961.6464234 (100)\ttotal: 4.16s\tremaining: 26.8s\n",
      "200:\tlearn: 860.6679939\ttest: 876.2502270\tbest: 876.2502270 (200)\ttotal: 8.42s\tremaining: 23.1s\n",
      "300:\tlearn: 806.2831465\ttest: 827.4474006\tbest: 827.4390333 (299)\ttotal: 12.8s\tremaining: 19.2s\n",
      "400:\tlearn: 774.6659119\ttest: 801.1209066\tbest: 801.1079553 (399)\ttotal: 17.1s\tremaining: 15s\n",
      "500:\tlearn: 748.3619911\ttest: 780.1114808\tbest: 780.1114808 (500)\ttotal: 21.3s\tremaining: 10.7s\n",
      "600:\tlearn: 729.3265261\ttest: 764.5235008\tbest: 764.5235008 (600)\ttotal: 25.6s\tremaining: 6.43s\n",
      "700:\tlearn: 712.1889522\ttest: 750.3236000\tbest: 750.3236000 (700)\ttotal: 29.9s\tremaining: 2.18s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 05:02:10,179]\u001b[0m Trial 2 finished with value: 745.2350365425733 and parameters: {'depth': 6, 'n_estimators': 752, 'learning_rate': 0.879336262027036, 'rsm': 0.12437495794615429, 'reg_alpha': 67.07970426682238, 'reg_lambda': 41.78874975647599}. Best is trial 2 with value: 745.2350365425733.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "751:\tlearn: 704.6383014\ttest: 745.2350386\tbest: 745.2350365 (750)\ttotal: 32.1s\tremaining: 0us\n",
      "\n",
      "bestTest = 745.2350365\n",
      "bestIteration = 750\n",
      "\n",
      "Shrink model to first 751 iterations.\n",
      "0:\tlearn: 2793.9791503\ttest: 2776.8587105\tbest: 2776.8587105 (0)\ttotal: 64.3ms\tremaining: 1m 20s\n",
      "100:\tlearn: 873.4275144\ttest: 887.3457121\tbest: 887.3457121 (100)\ttotal: 6.34s\tremaining: 1m 12s\n",
      "200:\tlearn: 760.1567306\ttest: 785.5144264\tbest: 785.5144264 (200)\ttotal: 12.9s\tremaining: 1m 7s\n",
      "300:\tlearn: 703.2883347\ttest: 739.6280228\tbest: 739.6280228 (300)\ttotal: 19.3s\tremaining: 1m 1s\n",
      "400:\tlearn: 666.7035916\ttest: 711.5246492\tbest: 711.5246492 (400)\ttotal: 25.7s\tremaining: 54.5s\n",
      "500:\tlearn: 637.3159945\ttest: 689.7543990\tbest: 689.7543990 (500)\ttotal: 32.4s\tremaining: 48.6s\n",
      "600:\tlearn: 616.4829002\ttest: 676.4391737\tbest: 676.4391737 (600)\ttotal: 38.6s\tremaining: 41.9s\n",
      "700:\tlearn: 598.5027642\ttest: 664.9984604\tbest: 664.9984604 (700)\ttotal: 45.3s\tremaining: 35.7s\n",
      "800:\tlearn: 583.1949255\ttest: 654.9338589\tbest: 654.9338589 (800)\ttotal: 51.7s\tremaining: 29.2s\n",
      "900:\tlearn: 569.7755673\ttest: 647.8344239\tbest: 647.8344239 (900)\ttotal: 58.3s\tremaining: 22.8s\n",
      "1000:\tlearn: 558.3193501\ttest: 641.4643684\tbest: 641.4643684 (1000)\ttotal: 1m 4s\tremaining: 16.3s\n",
      "1100:\tlearn: 547.6738211\ttest: 636.3759304\tbest: 636.3759304 (1100)\ttotal: 1m 11s\tremaining: 9.84s\n",
      "1200:\tlearn: 538.4728500\ttest: 631.7388921\tbest: 631.7388921 (1200)\ttotal: 1m 18s\tremaining: 3.38s\n",
      "1252:\tlearn: 533.4992025\ttest: 629.4911554\tbest: 629.4911554 (1252)\ttotal: 1m 21s\tremaining: 0us\n",
      "\n",
      "bestTest = 629.4911554\n",
      "bestIteration = 1252\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 05:03:32,803]\u001b[0m Trial 3 finished with value: 629.4911554137705 and parameters: {'depth': 10, 'n_estimators': 1253, 'learning_rate': 0.14898306920928145, 'rsm': 0.2763103252855421, 'reg_alpha': 80.09438241068611, 'reg_lambda': 96.82933141436781}. Best is trial 3 with value: 629.4911554137705.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1445.0125751\ttest: 1441.8603417\tbest: 1441.8603417 (0)\ttotal: 479ms\tremaining: 14m 39s\n",
      "100:\tlearn: 474.0097208\ttest: 682.8669265\tbest: 682.8669265 (100)\ttotal: 53.1s\tremaining: 15m 12s\n",
      "200:\tlearn: 370.1781679\ttest: 675.0955997\tbest: 674.9415401 (189)\ttotal: 1m 45s\tremaining: 14m 20s\n",
      "Stopped by overfitting detector  (40 iterations wait)\n",
      "\n",
      "bestTest = 674.9415401\n",
      "bestIteration = 189\n",
      "\n",
      "Shrink model to first 190 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 05:05:34,871]\u001b[0m Trial 4 finished with value: 674.941540148395 and parameters: {'depth': 14, 'n_estimators': 1837, 'learning_rate': 0.8776252607730779, 'rsm': 0.8961999305184241, 'reg_alpha': 8.595916715840813, 'reg_lambda': 4.001572844964948}. Best is trial 3 with value: 629.4911554137705.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1719.5338092\ttest: 1711.7365918\tbest: 1711.7365918 (0)\ttotal: 93.7ms\tremaining: 1m 46s\n",
      "100:\tlearn: 632.2633267\ttest: 704.7312828\tbest: 704.7312828 (100)\ttotal: 11s\tremaining: 1m 51s\n",
      "200:\tlearn: 547.8306704\ttest: 661.7277756\tbest: 661.7277756 (200)\ttotal: 22.3s\tremaining: 1m 43s\n",
      "300:\tlearn: 494.4927074\ttest: 644.8714851\tbest: 644.8714851 (300)\ttotal: 33.5s\tremaining: 1m 32s\n",
      "400:\tlearn: 461.6807843\ttest: 637.2210551\tbest: 637.1071164 (399)\ttotal: 44.6s\tremaining: 1m 21s\n",
      "500:\tlearn: 435.2044876\ttest: 633.8876061\tbest: 633.8703850 (495)\ttotal: 55.9s\tremaining: 1m 10s\n",
      "600:\tlearn: 413.0826584\ttest: 633.0427756\tbest: 632.9293195 (566)\ttotal: 1m 7s\tremaining: 59.5s\n",
      "Stopped by overfitting detector  (40 iterations wait)\n",
      "\n",
      "bestTest = 632.9293195\n",
      "bestIteration = 566\n",
      "\n",
      "Shrink model to first 567 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 05:06:43,442]\u001b[0m Trial 5 finished with value: 632.9293194966706 and parameters: {'depth': 11, 'n_estimators': 1133, 'learning_rate': 0.6738227596682561, 'rsm': 0.6278283112852706, 'reg_alpha': 67.19824433247122, 'reg_lambda': 41.237609109008396}. Best is trial 3 with value: 629.4911554137705.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2850.9037126\ttest: 2833.6529452\tbest: 2833.6529452 (0)\ttotal: 40.6ms\tremaining: 40.4s\n",
      "100:\tlearn: 1111.1120996\ttest: 1110.5110141\tbest: 1110.5110141 (100)\ttotal: 3.9s\tremaining: 34.6s\n",
      "200:\tlearn: 1029.9570083\ttest: 1031.9048069\tbest: 1031.9048069 (200)\ttotal: 7.84s\tremaining: 31s\n",
      "300:\tlearn: 984.2230470\ttest: 987.1287766\tbest: 987.1287766 (300)\ttotal: 12.1s\tremaining: 28s\n",
      "400:\tlearn: 957.2278106\ttest: 961.3073500\tbest: 961.3073500 (400)\ttotal: 15.9s\tremaining: 23.7s\n",
      "500:\tlearn: 933.0612920\ttest: 938.4164503\tbest: 938.4164503 (500)\ttotal: 19.9s\tremaining: 19.7s\n",
      "600:\tlearn: 914.6644739\ttest: 921.4121070\tbest: 921.4121070 (600)\ttotal: 23.8s\tremaining: 15.7s\n",
      "700:\tlearn: 901.5112766\ttest: 909.0759874\tbest: 909.0759874 (700)\ttotal: 27.9s\tremaining: 11.8s\n",
      "800:\tlearn: 888.5369203\ttest: 896.7876351\tbest: 896.7876351 (800)\ttotal: 31.8s\tremaining: 7.79s\n",
      "900:\tlearn: 877.2967625\ttest: 886.4032988\tbest: 886.4032988 (900)\ttotal: 35.8s\tremaining: 3.81s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 05:07:23,380]\u001b[0m Trial 6 finished with value: 877.7337246303528 and parameters: {'depth': 4, 'n_estimators': 997, 'learning_rate': 0.15069893412020738, 'rsm': 0.7971498806984487, 'reg_alpha': 41.31263026615231, 'reg_lambda': 3.513713987465321}. Best is trial 3 with value: 629.4911554137705.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "996:\tlearn: 867.9068702\ttest: 877.7337246\tbest: 877.7337246 (996)\ttotal: 39.5s\tremaining: 0us\n",
      "\n",
      "bestTest = 877.7337246\n",
      "bestIteration = 996\n",
      "\n",
      "0:\tlearn: 2264.1434687\ttest: 2263.3797006\tbest: 2263.3797006 (0)\ttotal: 35.3ms\tremaining: 18.1s\n",
      "100:\tlearn: 1068.9816410\ttest: 1072.4942914\tbest: 1072.4942914 (100)\ttotal: 3.47s\tremaining: 14.2s\n",
      "200:\tlearn: 1002.8675352\ttest: 1007.1110752\tbest: 1007.1110752 (200)\ttotal: 6.64s\tremaining: 10.4s\n",
      "300:\tlearn: 966.1245062\ttest: 972.0099248\tbest: 972.0099248 (300)\ttotal: 9.88s\tremaining: 7.02s\n",
      "400:\tlearn: 940.3585765\ttest: 946.2414261\tbest: 946.2414261 (400)\ttotal: 13.1s\tremaining: 3.72s\n",
      "500:\tlearn: 920.9418523\ttest: 927.2982806\tbest: 927.2982806 (500)\ttotal: 16.3s\tremaining: 456ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 05:07:40,557]\u001b[0m Trial 7 finished with value: 924.5393159993002 and parameters: {'depth': 3, 'n_estimators': 515, 'learning_rate': 0.6640293729356229, 'rsm': 0.36566081233020975, 'reg_alpha': 44.668837158002, 'reg_lambda': 22.290242298783944}. Best is trial 3 with value: 629.4911554137705.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514:\tlearn: 917.9480201\ttest: 924.5393160\tbest: 924.5393160 (514)\ttotal: 16.8s\tremaining: 0us\n",
      "\n",
      "bestTest = 924.539316\n",
      "bestIteration = 514\n",
      "\n",
      "0:\tlearn: 2118.0937869\ttest: 2106.4001634\tbest: 2106.4001634 (0)\ttotal: 70.3ms\tremaining: 2m 30s\n",
      "100:\tlearn: 745.4449000\ttest: 778.7882069\tbest: 778.7882069 (100)\ttotal: 5.73s\tremaining: 1m 55s\n",
      "200:\tlearn: 649.0238604\ttest: 706.5213369\tbest: 706.5213369 (200)\ttotal: 11.3s\tremaining: 1m 48s\n",
      "300:\tlearn: 599.6280527\ttest: 676.6191753\tbest: 676.6191753 (300)\ttotal: 17s\tremaining: 1m 43s\n",
      "400:\tlearn: 565.9649142\ttest: 659.5024361\tbest: 659.5024361 (400)\ttotal: 22.5s\tremaining: 1m 37s\n",
      "500:\tlearn: 541.2974677\ttest: 648.3618346\tbest: 648.3618346 (500)\ttotal: 27.8s\tremaining: 1m 30s\n",
      "600:\tlearn: 519.6903018\ttest: 641.0618851\tbest: 641.0618851 (600)\ttotal: 33.6s\tremaining: 1m 25s\n",
      "700:\tlearn: 502.5695541\ttest: 636.3115855\tbest: 636.3115855 (700)\ttotal: 39.1s\tremaining: 1m 20s\n",
      "800:\tlearn: 488.5091620\ttest: 631.7036482\tbest: 631.7036482 (800)\ttotal: 44.5s\tremaining: 1m 14s\n",
      "900:\tlearn: 475.1193132\ttest: 628.6518768\tbest: 628.6518768 (900)\ttotal: 50.2s\tremaining: 1m 9s\n",
      "1000:\tlearn: 463.8005188\ttest: 626.1893958\tbest: 626.1893958 (1000)\ttotal: 55.7s\tremaining: 1m 3s\n",
      "1100:\tlearn: 453.2928293\ttest: 624.1547868\tbest: 624.1547868 (1100)\ttotal: 1m 1s\tremaining: 57.7s\n",
      "1200:\tlearn: 443.9952516\ttest: 623.1056276\tbest: 623.1056276 (1200)\ttotal: 1m 6s\tremaining: 52.4s\n",
      "1300:\tlearn: 435.3753484\ttest: 622.4309503\tbest: 622.4309503 (1300)\ttotal: 1m 12s\tremaining: 46.8s\n",
      "1400:\tlearn: 427.3201392\ttest: 621.8360742\tbest: 621.8229562 (1399)\ttotal: 1m 18s\tremaining: 41.2s\n",
      "1500:\tlearn: 419.7314025\ttest: 620.8636607\tbest: 620.8636607 (1500)\ttotal: 1m 24s\tremaining: 35.8s\n",
      "Stopped by overfitting detector  (40 iterations wait)\n",
      "\n",
      "bestTest = 620.8636607\n",
      "bestIteration = 1500\n",
      "\n",
      "Shrink model to first 1501 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 05:09:07,964]\u001b[0m Trial 8 finished with value: 620.8636606513866 and parameters: {'depth': 10, 'n_estimators': 2140, 'learning_rate': 0.4745461411737617, 'rsm': 0.18559331179646088, 'reg_alpha': 90.34667963123884, 'reg_lambda': 12.037097751273611}. Best is trial 8 with value: 620.8636606513866.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1695.6728922\ttest: 1688.6205554\tbest: 1688.6205554 (0)\ttotal: 114ms\tremaining: 1m 32s\n",
      "100:\tlearn: 600.4215501\ttest: 692.2945391\tbest: 692.2945391 (100)\ttotal: 11.8s\tremaining: 1m 23s\n",
      "200:\tlearn: 511.1788781\ttest: 657.4875891\tbest: 657.4875891 (200)\ttotal: 23.2s\tremaining: 1m 10s\n",
      "300:\tlearn: 458.9439214\ttest: 646.7533043\tbest: 646.7533043 (300)\ttotal: 34.7s\tremaining: 59s\n",
      "400:\tlearn: 421.3607626\ttest: 642.0131119\tbest: 641.9597999 (389)\ttotal: 46.1s\tremaining: 47.4s\n",
      "500:\tlearn: 393.6249065\ttest: 640.7114214\tbest: 640.6416333 (486)\ttotal: 57.6s\tremaining: 35.9s\n",
      "Stopped by overfitting detector  (40 iterations wait)\n",
      "\n",
      "bestTest = 640.5147321\n",
      "bestIteration = 512\n",
      "\n",
      "Shrink model to first 513 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 05:10:12,444]\u001b[0m Trial 9 finished with value: 640.5147320807774 and parameters: {'depth': 12, 'n_estimators': 813, 'learning_rate': 0.682047177610492, 'rsm': 0.2883490232400525, 'reg_alpha': 26.628111271285402, 'reg_lambda': 49.2081586121058}. Best is trial 8 with value: 620.8636606513866.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2270.7320393\ttest: 2257.6170773\tbest: 2257.6170773 (0)\ttotal: 58.8ms\tremaining: 2m 40s\n",
      "100:\tlearn: 812.5555647\ttest: 827.4542605\tbest: 827.4542605 (100)\ttotal: 7.47s\tremaining: 3m 14s\n",
      "200:\tlearn: 724.6630559\ttest: 752.3838273\tbest: 752.3838273 (200)\ttotal: 15.1s\tremaining: 3m 11s\n",
      "300:\tlearn: 677.6302479\ttest: 715.5807460\tbest: 715.5807460 (300)\ttotal: 22.5s\tremaining: 3m 2s\n",
      "400:\tlearn: 645.1224343\ttest: 691.0963763\tbest: 691.0963763 (400)\ttotal: 30.2s\tremaining: 2m 56s\n",
      "500:\tlearn: 621.1982760\ttest: 674.9259911\tbest: 674.9259911 (500)\ttotal: 37.6s\tremaining: 2m 47s\n",
      "600:\tlearn: 602.8594759\ttest: 664.1258238\tbest: 664.1258238 (600)\ttotal: 45.1s\tremaining: 2m 40s\n",
      "700:\tlearn: 587.6497032\ttest: 656.0797897\tbest: 656.0797897 (700)\ttotal: 52.5s\tremaining: 2m 32s\n",
      "800:\tlearn: 574.1018322\ttest: 648.6083831\tbest: 648.6083831 (800)\ttotal: 1m\tremaining: 2m 25s\n",
      "900:\tlearn: 562.0388929\ttest: 642.2789279\tbest: 642.2789279 (900)\ttotal: 1m 7s\tremaining: 2m 17s\n",
      "1000:\tlearn: 552.1860271\ttest: 637.3344848\tbest: 637.3344848 (1000)\ttotal: 1m 15s\tremaining: 2m 10s\n",
      "1100:\tlearn: 542.9831783\ttest: 633.3722985\tbest: 633.3722985 (1100)\ttotal: 1m 22s\tremaining: 2m 2s\n",
      "1200:\tlearn: 534.6162024\ttest: 629.4104629\tbest: 629.4092609 (1199)\ttotal: 1m 30s\tremaining: 1m 55s\n",
      "1300:\tlearn: 526.4184821\ttest: 626.5264111\tbest: 626.5264111 (1300)\ttotal: 1m 37s\tremaining: 1m 47s\n",
      "1400:\tlearn: 519.3146796\ttest: 623.5431188\tbest: 623.5431188 (1400)\ttotal: 1m 45s\tremaining: 1m 40s\n",
      "1500:\tlearn: 512.8219089\ttest: 621.0680030\tbest: 621.0680030 (1500)\ttotal: 1m 52s\tremaining: 1m 32s\n",
      "1600:\tlearn: 506.6126318\ttest: 618.9252231\tbest: 618.9252231 (1600)\ttotal: 2m\tremaining: 1m 25s\n",
      "1700:\tlearn: 500.7995368\ttest: 617.1252879\tbest: 617.1252879 (1700)\ttotal: 2m 7s\tremaining: 1m 17s\n",
      "1800:\tlearn: 495.2964573\ttest: 615.9530568\tbest: 615.9345442 (1797)\ttotal: 2m 15s\tremaining: 1m 10s\n",
      "1900:\tlearn: 490.0097655\ttest: 614.2235481\tbest: 614.2141377 (1889)\ttotal: 2m 22s\tremaining: 1m 2s\n",
      "2000:\tlearn: 485.4459885\ttest: 613.2012682\tbest: 613.2002340 (1998)\ttotal: 2m 30s\tremaining: 55.2s\n",
      "2100:\tlearn: 480.9931882\ttest: 612.1407282\tbest: 612.1407282 (2100)\ttotal: 2m 37s\tremaining: 47.8s\n",
      "2200:\tlearn: 477.0823731\ttest: 611.2163236\tbest: 611.2163236 (2200)\ttotal: 2m 45s\tremaining: 40.2s\n",
      "2300:\tlearn: 473.2074425\ttest: 610.4657797\tbest: 610.4422614 (2298)\ttotal: 2m 52s\tremaining: 32.7s\n",
      "2400:\tlearn: 469.3033039\ttest: 609.6100383\tbest: 609.6100383 (2400)\ttotal: 3m\tremaining: 25.2s\n",
      "2500:\tlearn: 465.4041344\ttest: 609.0069330\tbest: 608.9943714 (2498)\ttotal: 3m 7s\tremaining: 17.7s\n",
      "2600:\tlearn: 461.4853189\ttest: 608.0449993\tbest: 608.0374463 (2594)\ttotal: 3m 15s\tremaining: 10.2s\n",
      "2700:\tlearn: 458.1210967\ttest: 607.4826380\tbest: 607.4660936 (2696)\ttotal: 3m 22s\tremaining: 2.7s\n",
      "2736:\tlearn: 456.9009490\ttest: 607.1915092\tbest: 607.1915092 (2736)\ttotal: 3m 25s\tremaining: 0us\n",
      "\n",
      "bestTest = 607.1915092\n",
      "bestIteration = 2736\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 05:13:38,919]\u001b[0m Trial 10 finished with value: 607.191509245361 and parameters: {'depth': 8, 'n_estimators': 2737, 'learning_rate': 0.40369728236215807, 'rsm': 0.5885407387026604, 'reg_alpha': 94.42225094540372, 'reg_lambda': 85.74476980826279}. Best is trial 10 with value: 607.191509245361.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2280.8982082\ttest: 2268.2069885\tbest: 2268.2069885 (0)\ttotal: 70.4ms\tremaining: 3m 13s\n",
      "100:\tlearn: 729.6546370\ttest: 757.0193745\tbest: 757.0193745 (100)\ttotal: 8.4s\tremaining: 3m 40s\n",
      "200:\tlearn: 641.0686378\ttest: 695.2396137\tbest: 695.2396137 (200)\ttotal: 17.2s\tremaining: 3m 38s\n",
      "300:\tlearn: 592.3435722\ttest: 665.1293139\tbest: 665.1293139 (300)\ttotal: 25.7s\tremaining: 3m 28s\n",
      "400:\tlearn: 559.3345121\ttest: 647.9928134\tbest: 647.9928134 (400)\ttotal: 34.3s\tremaining: 3m 20s\n",
      "500:\tlearn: 534.3341289\ttest: 637.6554898\tbest: 637.6554898 (500)\ttotal: 42.9s\tremaining: 3m 12s\n",
      "600:\tlearn: 513.6730772\ttest: 629.9608220\tbest: 629.9608220 (600)\ttotal: 51.4s\tremaining: 3m 3s\n",
      "700:\tlearn: 496.4221478\ttest: 623.3007500\tbest: 623.3007500 (700)\ttotal: 1m\tremaining: 2m 55s\n",
      "800:\tlearn: 481.1444480\ttest: 618.6682674\tbest: 618.6682674 (800)\ttotal: 1m 8s\tremaining: 2m 47s\n",
      "900:\tlearn: 468.7257649\ttest: 615.8968093\tbest: 615.8968093 (900)\ttotal: 1m 17s\tremaining: 2m 39s\n",
      "1000:\tlearn: 457.9071471\ttest: 613.7839505\tbest: 613.7307673 (996)\ttotal: 1m 25s\tremaining: 2m 30s\n",
      "1100:\tlearn: 448.2225376\ttest: 612.1980842\tbest: 612.1780964 (1095)\ttotal: 1m 34s\tremaining: 2m 21s\n",
      "1200:\tlearn: 438.9553837\ttest: 610.4450747\tbest: 610.4100494 (1197)\ttotal: 1m 42s\tremaining: 2m 12s\n",
      "1300:\tlearn: 429.9961815\ttest: 609.2687163\tbest: 609.1833702 (1296)\ttotal: 1m 51s\tremaining: 2m 4s\n",
      "Stopped by overfitting detector  (40 iterations wait)\n",
      "\n",
      "bestTest = 609.1833702\n",
      "bestIteration = 1296\n",
      "\n",
      "Shrink model to first 1297 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 05:15:34,588]\u001b[0m Trial 11 finished with value: 609.1833701978875 and parameters: {'depth': 10, 'n_estimators': 2750, 'learning_rate': 0.3799339330688083, 'rsm': 0.6267896699133165, 'reg_alpha': 95.42125576566109, 'reg_lambda': 99.20889183671716}. Best is trial 10 with value: 607.191509245361.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2336.9576766\ttest: 2327.0238858\tbest: 2327.0238858 (0)\ttotal: 59.6ms\tremaining: 2m 53s\n",
      "100:\tlearn: 829.0780635\ttest: 842.5739622\tbest: 842.5739622 (100)\ttotal: 7.55s\tremaining: 3m 30s\n",
      "200:\tlearn: 734.1228057\ttest: 760.1339321\tbest: 760.1339321 (200)\ttotal: 14.9s\tremaining: 3m 21s\n",
      "300:\tlearn: 686.5115407\ttest: 721.3491373\tbest: 721.3491373 (300)\ttotal: 22.6s\tremaining: 3m 16s\n",
      "400:\tlearn: 653.3303679\ttest: 697.1655215\tbest: 697.1655215 (400)\ttotal: 29.9s\tremaining: 3m 7s\n",
      "500:\tlearn: 627.9408584\ttest: 679.6644404\tbest: 679.6644404 (500)\ttotal: 37.4s\tremaining: 3m\n",
      "600:\tlearn: 609.3041061\ttest: 667.5528332\tbest: 667.5528332 (600)\ttotal: 44.7s\tremaining: 2m 52s\n",
      "700:\tlearn: 592.8191698\ttest: 658.4068155\tbest: 658.4068155 (700)\ttotal: 52.4s\tremaining: 2m 45s\n",
      "800:\tlearn: 578.6343800\ttest: 649.8683139\tbest: 649.8683139 (800)\ttotal: 59.9s\tremaining: 2m 38s\n",
      "900:\tlearn: 566.6801846\ttest: 643.9670176\tbest: 643.9670176 (900)\ttotal: 1m 7s\tremaining: 2m 30s\n",
      "1000:\tlearn: 555.9144168\ttest: 640.0677270\tbest: 640.0677270 (1000)\ttotal: 1m 14s\tremaining: 2m 23s\n",
      "1100:\tlearn: 546.5414947\ttest: 635.5594666\tbest: 635.5594666 (1100)\ttotal: 1m 22s\tremaining: 2m 15s\n",
      "1200:\tlearn: 538.2676619\ttest: 632.4980240\tbest: 632.4980240 (1200)\ttotal: 1m 29s\tremaining: 2m 8s\n",
      "1300:\tlearn: 530.4217250\ttest: 629.5496465\tbest: 629.5253384 (1298)\ttotal: 1m 37s\tremaining: 2m\n",
      "1400:\tlearn: 523.5399592\ttest: 626.5617683\tbest: 626.5617683 (1400)\ttotal: 1m 44s\tremaining: 1m 53s\n",
      "1500:\tlearn: 516.8658174\ttest: 623.6577346\tbest: 623.6577346 (1500)\ttotal: 1m 51s\tremaining: 1m 45s\n",
      "1600:\tlearn: 510.7741471\ttest: 621.9050200\tbest: 621.9050200 (1600)\ttotal: 1m 59s\tremaining: 1m 38s\n",
      "1700:\tlearn: 505.1571106\ttest: 620.2918551\tbest: 620.2918551 (1700)\ttotal: 2m 7s\tremaining: 1m 30s\n",
      "1800:\tlearn: 500.1049599\ttest: 618.9111209\tbest: 618.9111209 (1800)\ttotal: 2m 14s\tremaining: 1m 23s\n",
      "1900:\tlearn: 494.8809433\ttest: 616.9026916\tbest: 616.9026916 (1900)\ttotal: 2m 22s\tremaining: 1m 15s\n",
      "2000:\tlearn: 490.1088996\ttest: 615.7027798\tbest: 615.7027798 (2000)\ttotal: 2m 29s\tremaining: 1m 8s\n",
      "2100:\tlearn: 485.0707108\ttest: 614.1725848\tbest: 614.1725848 (2100)\ttotal: 2m 36s\tremaining: 1m\n",
      "2200:\tlearn: 480.8299306\ttest: 613.1468627\tbest: 613.1468627 (2200)\ttotal: 2m 44s\tremaining: 53.3s\n",
      "2300:\tlearn: 476.7491203\ttest: 611.8646864\tbest: 611.8536195 (2298)\ttotal: 2m 51s\tremaining: 45.8s\n",
      "2400:\tlearn: 472.6789522\ttest: 611.0717412\tbest: 611.0062714 (2395)\ttotal: 2m 58s\tremaining: 38.4s\n",
      "2500:\tlearn: 468.8296520\ttest: 610.3619729\tbest: 610.3619729 (2500)\ttotal: 3m 6s\tremaining: 30.9s\n",
      "2600:\tlearn: 465.0212822\ttest: 609.6126468\tbest: 609.6126468 (2600)\ttotal: 3m 13s\tremaining: 23.5s\n",
      "2700:\tlearn: 461.6450754\ttest: 609.1037116\tbest: 609.0138502 (2696)\ttotal: 3m 21s\tremaining: 16s\n",
      "2800:\tlearn: 458.1999366\ttest: 608.5080437\tbest: 608.4911839 (2796)\ttotal: 3m 28s\tremaining: 8.57s\n",
      "2900:\tlearn: 454.7662581\ttest: 607.3830808\tbest: 607.3830808 (2900)\ttotal: 3m 36s\tremaining: 1.12s\n",
      "2915:\tlearn: 454.3116309\ttest: 607.2948266\tbest: 607.2948266 (2915)\ttotal: 3m 37s\tremaining: 0us\n",
      "\n",
      "bestTest = 607.2948266\n",
      "bestIteration = 2915\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 05:19:12,722]\u001b[0m Trial 12 finished with value: 607.2948266449584 and parameters: {'depth': 8, 'n_estimators': 2916, 'learning_rate': 0.3766906864417002, 'rsm': 0.5971767499326258, 'reg_alpha': 98.2285668800291, 'reg_lambda': 98.10065982127823}. Best is trial 10 with value: 607.191509245361.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2423.2991022\ttest: 2408.7134634\tbest: 2408.7134634 (0)\ttotal: 55ms\tremaining: 2m 40s\n",
      "100:\tlearn: 835.7503975\ttest: 848.8111347\tbest: 848.8111347 (100)\ttotal: 7.34s\tremaining: 3m 24s\n",
      "200:\tlearn: 745.0517717\ttest: 768.0915517\tbest: 768.0915517 (200)\ttotal: 14.8s\tremaining: 3m 20s\n",
      "300:\tlearn: 697.5421078\ttest: 730.0046563\tbest: 730.0046563 (300)\ttotal: 22.1s\tremaining: 3m 12s\n",
      "400:\tlearn: 665.1415573\ttest: 704.7666635\tbest: 704.7666635 (400)\ttotal: 29.7s\tremaining: 3m 6s\n",
      "500:\tlearn: 639.4703399\ttest: 687.3518928\tbest: 687.3518928 (500)\ttotal: 37.1s\tremaining: 2m 59s\n",
      "600:\tlearn: 620.0191215\ttest: 674.0302679\tbest: 674.0302679 (600)\ttotal: 44.7s\tremaining: 2m 52s\n",
      "700:\tlearn: 603.5534956\ttest: 663.7885130\tbest: 663.7885130 (700)\ttotal: 51.9s\tremaining: 2m 44s\n",
      "800:\tlearn: 590.4617304\ttest: 655.6737869\tbest: 655.6737869 (800)\ttotal: 59.3s\tremaining: 2m 37s\n",
      "900:\tlearn: 578.6451812\ttest: 648.5719820\tbest: 648.5719820 (900)\ttotal: 1m 6s\tremaining: 2m 29s\n",
      "1000:\tlearn: 567.9618968\ttest: 642.9197264\tbest: 642.9197264 (1000)\ttotal: 1m 14s\tremaining: 2m 22s\n",
      "1100:\tlearn: 558.3544638\ttest: 638.0407340\tbest: 638.0407340 (1100)\ttotal: 1m 21s\tremaining: 2m 14s\n",
      "1200:\tlearn: 549.9023951\ttest: 634.1499138\tbest: 634.1499138 (1200)\ttotal: 1m 29s\tremaining: 2m 7s\n",
      "1300:\tlearn: 542.1557733\ttest: 630.9219891\tbest: 630.9176822 (1299)\ttotal: 1m 36s\tremaining: 1m 59s\n",
      "1400:\tlearn: 534.6993772\ttest: 627.6044744\tbest: 627.6044744 (1400)\ttotal: 1m 43s\tremaining: 1m 52s\n",
      "1500:\tlearn: 527.5228148\ttest: 624.4430632\tbest: 624.4430632 (1500)\ttotal: 1m 51s\tremaining: 1m 45s\n",
      "1600:\tlearn: 521.4452907\ttest: 622.1123741\tbest: 622.1123741 (1600)\ttotal: 1m 58s\tremaining: 1m 37s\n",
      "1700:\tlearn: 515.6856508\ttest: 619.6869799\tbest: 619.6869799 (1700)\ttotal: 2m 5s\tremaining: 1m 30s\n",
      "1800:\tlearn: 510.3894747\ttest: 617.1206789\tbest: 617.1206789 (1800)\ttotal: 2m 13s\tremaining: 1m 22s\n",
      "1900:\tlearn: 505.1920684\ttest: 615.2210142\tbest: 615.2210142 (1900)\ttotal: 2m 20s\tremaining: 1m 15s\n",
      "2000:\tlearn: 500.6259012\ttest: 613.6578221\tbest: 613.6578221 (2000)\ttotal: 2m 27s\tremaining: 1m 8s\n",
      "2100:\tlearn: 496.0418133\ttest: 612.4720512\tbest: 612.4720512 (2100)\ttotal: 2m 35s\tremaining: 1m\n",
      "2200:\tlearn: 491.6235629\ttest: 611.2982027\tbest: 611.2661543 (2193)\ttotal: 2m 42s\tremaining: 53.3s\n",
      "2300:\tlearn: 487.3308006\ttest: 610.1045167\tbest: 610.1045167 (2300)\ttotal: 2m 50s\tremaining: 45.9s\n",
      "2400:\tlearn: 483.1452477\ttest: 608.8740663\tbest: 608.8740663 (2400)\ttotal: 2m 57s\tremaining: 38.5s\n",
      "2500:\tlearn: 479.3087605\ttest: 607.9836429\tbest: 607.9836429 (2500)\ttotal: 3m 5s\tremaining: 31.1s\n",
      "2600:\tlearn: 475.7100027\ttest: 606.7389914\tbest: 606.7389914 (2600)\ttotal: 3m 12s\tremaining: 23.7s\n",
      "2700:\tlearn: 472.1812890\ttest: 605.7196384\tbest: 605.7196384 (2700)\ttotal: 3m 19s\tremaining: 16.3s\n",
      "Stopped by overfitting detector  (40 iterations wait)\n",
      "\n",
      "bestTest = 605.5380336\n",
      "bestIteration = 2719\n",
      "\n",
      "Shrink model to first 2720 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 05:22:38,092]\u001b[0m Trial 13 finished with value: 605.5380336306631 and parameters: {'depth': 8, 'n_estimators': 2921, 'learning_rate': 0.33123774597480676, 'rsm': 0.5310188236670167, 'reg_alpha': 99.91156493964795, 'reg_lambda': 80.1108760661826}. Best is trial 13 with value: 605.5380336306631.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2446.7363650\ttest: 2432.5103009\tbest: 2432.5103009 (0)\ttotal: 56.3ms\tremaining: 2m 23s\n",
      "100:\tlearn: 840.3908599\ttest: 854.9040158\tbest: 854.9040158 (100)\ttotal: 7.12s\tremaining: 2m 53s\n",
      "200:\tlearn: 752.3766163\ttest: 777.3774015\tbest: 777.3774015 (200)\ttotal: 14.6s\tremaining: 2m 51s\n",
      "300:\tlearn: 701.9082838\ttest: 735.8141890\tbest: 735.8141890 (300)\ttotal: 22s\tremaining: 2m 44s\n",
      "400:\tlearn: 669.5687405\ttest: 710.9829698\tbest: 710.9829698 (400)\ttotal: 29.4s\tremaining: 2m 37s\n",
      "500:\tlearn: 645.0931250\ttest: 692.8756284\tbest: 692.8756284 (500)\ttotal: 36.9s\tremaining: 2m 31s\n",
      "600:\tlearn: 624.9238970\ttest: 678.7140883\tbest: 678.7140883 (600)\ttotal: 44.2s\tremaining: 2m 23s\n",
      "700:\tlearn: 608.7301090\ttest: 668.1821310\tbest: 668.1821310 (700)\ttotal: 51.6s\tremaining: 2m 16s\n",
      "800:\tlearn: 594.3231870\ttest: 658.9649809\tbest: 658.9649809 (800)\ttotal: 59s\tremaining: 2m 9s\n",
      "900:\tlearn: 582.4186979\ttest: 652.8987000\tbest: 652.8987000 (900)\ttotal: 1m 6s\tremaining: 2m 1s\n",
      "1000:\tlearn: 571.7866637\ttest: 646.6061550\tbest: 646.6061550 (1000)\ttotal: 1m 14s\tremaining: 1m 54s\n",
      "1100:\tlearn: 561.7496080\ttest: 641.3852791\tbest: 641.3852791 (1100)\ttotal: 1m 21s\tremaining: 1m 47s\n",
      "1200:\tlearn: 553.2044092\ttest: 637.0200574\tbest: 637.0200574 (1200)\ttotal: 1m 28s\tremaining: 1m 40s\n",
      "1300:\tlearn: 545.2262129\ttest: 633.3831506\tbest: 633.3831506 (1300)\ttotal: 1m 36s\tremaining: 1m 32s\n",
      "1400:\tlearn: 537.7039349\ttest: 629.6430159\tbest: 629.6430159 (1400)\ttotal: 1m 43s\tremaining: 1m 25s\n",
      "1500:\tlearn: 531.2773230\ttest: 627.0725859\tbest: 627.0725859 (1500)\ttotal: 1m 51s\tremaining: 1m 17s\n",
      "1600:\tlearn: 525.4433340\ttest: 624.8615873\tbest: 624.8615873 (1600)\ttotal: 1m 58s\tremaining: 1m 10s\n",
      "1700:\tlearn: 519.7537688\ttest: 622.5204828\tbest: 622.5185997 (1699)\ttotal: 2m 6s\tremaining: 1m 3s\n",
      "1800:\tlearn: 514.2739534\ttest: 620.4778785\tbest: 620.4778785 (1800)\ttotal: 2m 13s\tremaining: 55.7s\n",
      "1900:\tlearn: 509.5035407\ttest: 619.3150182\tbest: 619.2727807 (1895)\ttotal: 2m 20s\tremaining: 48.3s\n",
      "2000:\tlearn: 504.4398459\ttest: 618.1478472\tbest: 618.1478472 (2000)\ttotal: 2m 28s\tremaining: 40.9s\n",
      "2100:\tlearn: 499.8450845\ttest: 616.5775770\tbest: 616.5775770 (2100)\ttotal: 2m 35s\tremaining: 33.5s\n",
      "2200:\tlearn: 495.7144251\ttest: 615.1328602\tbest: 615.1328602 (2200)\ttotal: 2m 42s\tremaining: 26.1s\n",
      "2300:\tlearn: 491.7324658\ttest: 614.1140738\tbest: 614.1140738 (2300)\ttotal: 2m 50s\tremaining: 18.7s\n",
      "2400:\tlearn: 487.7623167\ttest: 613.0011464\tbest: 613.0011464 (2400)\ttotal: 2m 57s\tremaining: 11.3s\n",
      "2500:\tlearn: 483.9148924\ttest: 612.1665973\tbest: 612.1665973 (2500)\ttotal: 3m 4s\tremaining: 3.91s\n",
      "2553:\tlearn: 481.9749205\ttest: 611.6269331\tbest: 611.5844324 (2552)\ttotal: 3m 8s\tremaining: 0us\n",
      "\n",
      "bestTest = 611.5844324\n",
      "bestIteration = 2552\n",
      "\n",
      "Shrink model to first 2553 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 05:25:47,510]\u001b[0m Trial 14 finished with value: 611.5844324281444 and parameters: {'depth': 8, 'n_estimators': 2554, 'learning_rate': 0.31760376670977003, 'rsm': 0.4873691521188104, 'reg_alpha': 78.7358298373212, 'reg_lambda': 77.77748489798856}. Best is trial 13 with value: 605.5380336306631.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2084.4212134\ttest: 2073.4680268\tbest: 2073.4680268 (0)\ttotal: 49.3ms\tremaining: 2m 1s\n",
      "100:\tlearn: 880.9090504\ttest: 892.2907276\tbest: 892.2907276 (100)\ttotal: 5.73s\tremaining: 2m 14s\n",
      "200:\tlearn: 799.7169619\ttest: 816.2508289\tbest: 816.2508289 (200)\ttotal: 11.5s\tremaining: 2m 10s\n",
      "300:\tlearn: 755.8113278\ttest: 776.5525456\tbest: 776.5525456 (300)\ttotal: 17.2s\tremaining: 2m 4s\n",
      "400:\tlearn: 722.3873960\ttest: 749.4369749\tbest: 749.4369749 (400)\ttotal: 22.9s\tremaining: 1m 58s\n",
      "500:\tlearn: 699.4841929\ttest: 731.6985936\tbest: 731.6985936 (500)\ttotal: 28.3s\tremaining: 1m 51s\n",
      "600:\tlearn: 680.4461959\ttest: 717.5548742\tbest: 717.5548742 (600)\ttotal: 34.2s\tremaining: 1m 46s\n",
      "700:\tlearn: 664.4393673\ttest: 704.8220950\tbest: 704.8210987 (698)\ttotal: 39.9s\tremaining: 1m 41s\n",
      "800:\tlearn: 651.2601103\ttest: 695.6557410\tbest: 695.6557410 (800)\ttotal: 45.7s\tremaining: 1m 35s\n",
      "900:\tlearn: 639.0521373\ttest: 686.3784886\tbest: 686.2395886 (899)\ttotal: 51.6s\tremaining: 1m 30s\n",
      "1000:\tlearn: 629.7263100\ttest: 680.5442973\tbest: 680.4226423 (997)\ttotal: 57.2s\tremaining: 1m 24s\n",
      "1100:\tlearn: 621.1959785\ttest: 674.8777331\tbest: 674.8505306 (1099)\ttotal: 1m 2s\tremaining: 1m 18s\n",
      "1200:\tlearn: 613.8604833\ttest: 670.4746272\tbest: 670.4746272 (1200)\ttotal: 1m 8s\tremaining: 1m 12s\n",
      "1300:\tlearn: 605.9670940\ttest: 666.2418728\tbest: 666.2418728 (1300)\ttotal: 1m 13s\tremaining: 1m 6s\n",
      "1400:\tlearn: 599.7739320\ttest: 663.2596041\tbest: 663.2596041 (1400)\ttotal: 1m 19s\tremaining: 1m 1s\n",
      "1500:\tlearn: 594.1164090\ttest: 660.8230593\tbest: 660.8085599 (1498)\ttotal: 1m 25s\tremaining: 55.4s\n",
      "1600:\tlearn: 588.2738771\ttest: 657.2302339\tbest: 657.2302339 (1600)\ttotal: 1m 30s\tremaining: 49.6s\n",
      "1700:\tlearn: 583.2187208\ttest: 654.4267098\tbest: 654.4267098 (1700)\ttotal: 1m 36s\tremaining: 43.9s\n",
      "1800:\tlearn: 578.0627840\ttest: 651.6221447\tbest: 651.6221447 (1800)\ttotal: 1m 42s\tremaining: 38.3s\n",
      "1900:\tlearn: 573.3721999\ttest: 648.9001684\tbest: 648.9001684 (1900)\ttotal: 1m 47s\tremaining: 32.6s\n",
      "2000:\tlearn: 569.0682003\ttest: 646.4078752\tbest: 646.4078752 (2000)\ttotal: 1m 53s\tremaining: 26.9s\n",
      "2100:\tlearn: 564.6695175\ttest: 644.5009760\tbest: 644.4995241 (2099)\ttotal: 1m 58s\tremaining: 21.2s\n",
      "2200:\tlearn: 560.7054262\ttest: 643.0432746\tbest: 643.0432746 (2200)\ttotal: 2m 3s\tremaining: 15.5s\n",
      "2300:\tlearn: 556.6966355\ttest: 641.3984829\tbest: 641.3984829 (2300)\ttotal: 2m 9s\tremaining: 9.93s\n",
      "2400:\tlearn: 553.0033181\ttest: 640.0669861\tbest: 640.0659060 (2399)\ttotal: 2m 15s\tremaining: 4.29s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 05:28:07,855]\u001b[0m Trial 15 finished with value: 638.8111113266621 and parameters: {'depth': 6, 'n_estimators': 2477, 'learning_rate': 0.5276125070697136, 'rsm': 0.7455676103854448, 'reg_alpha': 61.62744552626551, 'reg_lambda': 78.81136026830397}. Best is trial 13 with value: 605.5380336306631.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2476:\tlearn: 550.1566632\ttest: 638.8355397\tbest: 638.8111113 (2474)\ttotal: 2m 19s\tremaining: 0us\n",
      "\n",
      "bestTest = 638.8111113\n",
      "bestIteration = 2474\n",
      "\n",
      "Shrink model to first 2475 iterations.\n",
      "0:\tlearn: 3088.3441391\ttest: 3069.4254342\tbest: 3069.4254342 (0)\ttotal: 219ms\tremaining: 10m 42s\n",
      "100:\tlearn: 1140.4252723\ttest: 1143.6935312\tbest: 1143.6935312 (100)\ttotal: 22.4s\tremaining: 10m 27s\n",
      "200:\tlearn: 960.6450283\ttest: 972.0121737\tbest: 972.0121737 (200)\ttotal: 43.9s\tremaining: 9m 57s\n",
      "300:\tlearn: 870.4418269\ttest: 888.4643741\tbest: 888.4643741 (300)\ttotal: 1m 5s\tremaining: 9m 29s\n",
      "400:\tlearn: 807.5678576\ttest: 832.2405078\tbest: 832.2405078 (400)\ttotal: 1m 27s\tremaining: 9m 10s\n",
      "500:\tlearn: 767.1051121\ttest: 797.1704933\tbest: 797.1704933 (500)\ttotal: 1m 49s\tremaining: 8m 50s\n",
      "600:\tlearn: 731.9513726\ttest: 768.5527853\tbest: 768.5527853 (600)\ttotal: 2m 11s\tremaining: 8m 30s\n",
      "700:\tlearn: 705.0542914\ttest: 747.7395498\tbest: 747.7395498 (700)\ttotal: 2m 34s\tremaining: 8m 11s\n",
      "800:\tlearn: 683.0974634\ttest: 731.0195890\tbest: 731.0195890 (800)\ttotal: 2m 56s\tremaining: 7m 51s\n",
      "900:\tlearn: 663.3133830\ttest: 716.5403825\tbest: 716.5403825 (900)\ttotal: 3m 19s\tremaining: 7m 31s\n",
      "1000:\tlearn: 647.0000977\ttest: 705.2018680\tbest: 705.2018680 (1000)\ttotal: 3m 42s\tremaining: 7m 10s\n",
      "1100:\tlearn: 632.0402214\ttest: 695.0889239\tbest: 695.0889239 (1100)\ttotal: 4m 6s\tremaining: 6m 50s\n",
      "1200:\tlearn: 619.0413389\ttest: 686.8350988\tbest: 686.8350988 (1200)\ttotal: 4m 29s\tremaining: 6m 28s\n",
      "1300:\tlearn: 606.9238524\ttest: 678.8757665\tbest: 678.8757665 (1300)\ttotal: 4m 52s\tremaining: 6m 8s\n",
      "1400:\tlearn: 595.9643269\ttest: 672.1074106\tbest: 672.1074106 (1400)\ttotal: 5m 16s\tremaining: 5m 47s\n",
      "1500:\tlearn: 585.9787155\ttest: 666.3506531\tbest: 666.3506531 (1500)\ttotal: 5m 40s\tremaining: 5m 25s\n",
      "1600:\tlearn: 576.7126527\ttest: 661.2662405\tbest: 661.2662405 (1600)\ttotal: 6m 5s\tremaining: 5m 4s\n",
      "1700:\tlearn: 567.8464479\ttest: 656.3593102\tbest: 656.3593102 (1700)\ttotal: 6m 30s\tremaining: 4m 43s\n",
      "1800:\tlearn: 559.5126636\ttest: 651.6835473\tbest: 651.6835473 (1800)\ttotal: 6m 54s\tremaining: 4m 21s\n",
      "1900:\tlearn: 551.5542152\ttest: 647.6100624\tbest: 647.6100624 (1900)\ttotal: 7m 19s\tremaining: 3m 59s\n",
      "2000:\tlearn: 543.6790032\ttest: 643.7592256\tbest: 643.7592256 (2000)\ttotal: 7m 45s\tremaining: 3m 37s\n",
      "2100:\tlearn: 536.6381420\ttest: 640.6821539\tbest: 640.6821539 (2100)\ttotal: 8m 10s\tremaining: 3m 15s\n",
      "2200:\tlearn: 529.6035782\ttest: 637.3539180\tbest: 637.3539180 (2200)\ttotal: 8m 36s\tremaining: 2m 52s\n",
      "2300:\tlearn: 523.5317450\ttest: 634.5163245\tbest: 634.5163245 (2300)\ttotal: 9m 2s\tremaining: 2m 29s\n",
      "2400:\tlearn: 517.1384714\ttest: 631.9195448\tbest: 631.9195448 (2400)\ttotal: 9m 29s\tremaining: 2m 6s\n",
      "2500:\tlearn: 511.4524150\ttest: 629.6012556\tbest: 629.6012556 (2500)\ttotal: 9m 55s\tremaining: 1m 43s\n",
      "2600:\tlearn: 505.6461582\ttest: 627.2919366\tbest: 627.2919366 (2600)\ttotal: 10m 22s\tremaining: 1m 20s\n",
      "2700:\tlearn: 500.5560728\ttest: 625.3884200\tbest: 625.3884200 (2700)\ttotal: 10m 49s\tremaining: 56.5s\n",
      "2800:\tlearn: 495.6267716\ttest: 623.6361933\tbest: 623.6361933 (2800)\ttotal: 11m 16s\tremaining: 32.6s\n",
      "2900:\tlearn: 490.8491699\ttest: 621.8479378\tbest: 621.8479378 (2900)\ttotal: 11m 43s\tremaining: 8.49s\n",
      "2935:\tlearn: 489.2515296\ttest: 621.2042624\tbest: 621.2042624 (2935)\ttotal: 11m 53s\tremaining: 0us\n",
      "\n",
      "bestTest = 621.2042624\n",
      "bestIteration = 2935\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 05:40:09,231]\u001b[0m Trial 16 finished with value: 621.2042624479757 and parameters: {'depth': 13, 'n_estimators': 2936, 'learning_rate': 0.02618222906314377, 'rsm': 0.506736063405708, 'reg_alpha': 84.35365754665361, 'reg_lambda': 77.38899188617685}. Best is trial 13 with value: 605.5380336306631.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2043.0787754\ttest: 2031.8350990\tbest: 2031.8350990 (0)\ttotal: 54.8ms\tremaining: 2m 9s\n",
      "100:\tlearn: 782.9109174\ttest: 804.5299254\tbest: 804.5299254 (100)\ttotal: 7.7s\tremaining: 2m 52s\n",
      "200:\tlearn: 701.6431219\ttest: 734.9876746\tbest: 734.9876746 (200)\ttotal: 15s\tremaining: 2m 40s\n",
      "300:\tlearn: 655.1683439\ttest: 700.9258368\tbest: 700.9258368 (300)\ttotal: 22.6s\tremaining: 2m 34s\n",
      "400:\tlearn: 625.0074342\ttest: 681.9183560\tbest: 681.9183560 (400)\ttotal: 29.9s\tremaining: 2m 25s\n",
      "500:\tlearn: 602.2080651\ttest: 668.0132888\tbest: 668.0132888 (500)\ttotal: 37.4s\tremaining: 2m 18s\n",
      "600:\tlearn: 583.5007198\ttest: 657.7999732\tbest: 657.7999732 (600)\ttotal: 44.9s\tremaining: 2m 11s\n",
      "700:\tlearn: 567.2065393\ttest: 650.5119455\tbest: 650.5119455 (700)\ttotal: 52.3s\tremaining: 2m 3s\n",
      "800:\tlearn: 553.3021198\ttest: 643.2884195\tbest: 643.2884195 (800)\ttotal: 59.8s\tremaining: 1m 56s\n",
      "900:\tlearn: 542.3060083\ttest: 639.4609201\tbest: 639.4609201 (900)\ttotal: 1m 7s\tremaining: 1m 48s\n",
      "1000:\tlearn: 531.9779721\ttest: 636.2598824\tbest: 635.9618280 (992)\ttotal: 1m 14s\tremaining: 1m 41s\n",
      "1100:\tlearn: 523.1874141\ttest: 633.7409454\tbest: 633.7409454 (1100)\ttotal: 1m 22s\tremaining: 1m 34s\n",
      "1200:\tlearn: 514.6229651\ttest: 630.6241900\tbest: 630.6241900 (1200)\ttotal: 1m 29s\tremaining: 1m 26s\n",
      "1300:\tlearn: 506.4986139\ttest: 627.9374312\tbest: 627.9374312 (1300)\ttotal: 1m 37s\tremaining: 1m 18s\n",
      "1400:\tlearn: 498.7539885\ttest: 625.5003918\tbest: 625.5003918 (1400)\ttotal: 1m 44s\tremaining: 1m 11s\n",
      "1500:\tlearn: 492.2224839\ttest: 623.3527323\tbest: 623.3527323 (1500)\ttotal: 1m 52s\tremaining: 1m 4s\n",
      "1600:\tlearn: 486.1732319\ttest: 621.9421432\tbest: 621.9421432 (1600)\ttotal: 1m 59s\tremaining: 56.7s\n",
      "1700:\tlearn: 480.6162422\ttest: 620.7822397\tbest: 620.7822397 (1700)\ttotal: 2m 7s\tremaining: 49.2s\n",
      "1800:\tlearn: 475.5276134\ttest: 620.0310296\tbest: 619.9826621 (1779)\ttotal: 2m 14s\tremaining: 41.7s\n",
      "1900:\tlearn: 470.4677339\ttest: 619.2495477\tbest: 619.2350085 (1896)\ttotal: 2m 22s\tremaining: 34.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 05:42:38,303]\u001b[0m Trial 17 finished with value: 618.8639333679571 and parameters: {'depth': 8, 'n_estimators': 2358, 'learning_rate': 0.517365278709452, 'rsm': 0.7141206315481383, 'reg_alpha': 97.80845357709846, 'reg_lambda': 64.27751673001558}. Best is trial 13 with value: 605.5380336306631.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped by overfitting detector  (40 iterations wait)\n",
      "\n",
      "bestTest = 618.8639334\n",
      "bestIteration = 1943\n",
      "\n",
      "Shrink model to first 1944 iterations.\n",
      "0:\tlearn: 2647.0870513\ttest: 2631.6667604\tbest: 2631.6667604 (0)\ttotal: 38.5ms\tremaining: 60s\n",
      "100:\tlearn: 1053.0774433\ttest: 1055.4116505\tbest: 1055.4116505 (100)\ttotal: 3.52s\tremaining: 50.7s\n",
      "200:\tlearn: 976.2870047\ttest: 981.0905839\tbest: 981.0905839 (200)\ttotal: 6.99s\tremaining: 47.1s\n",
      "300:\tlearn: 935.9630227\ttest: 942.8900076\tbest: 942.8900076 (300)\ttotal: 10.4s\tremaining: 43.5s\n",
      "400:\tlearn: 906.2547752\ttest: 914.9727414\tbest: 914.9727414 (400)\ttotal: 13.9s\tremaining: 40.2s\n",
      "500:\tlearn: 884.0213328\ttest: 894.3051171\tbest: 894.3051171 (500)\ttotal: 17.7s\tremaining: 37.3s\n",
      "600:\tlearn: 866.4433264\ttest: 877.4364865\tbest: 877.4364865 (600)\ttotal: 21.2s\tremaining: 33.8s\n",
      "700:\tlearn: 851.9580408\ttest: 863.9874201\tbest: 863.9874201 (700)\ttotal: 24.8s\tremaining: 30.3s\n",
      "800:\tlearn: 838.0042927\ttest: 851.0328049\tbest: 851.0328049 (800)\ttotal: 28.2s\tremaining: 26.7s\n",
      "900:\tlearn: 826.5060829\ttest: 840.8978858\tbest: 840.8978858 (900)\ttotal: 32.2s\tremaining: 23.4s\n",
      "1000:\tlearn: 816.0711144\ttest: 831.5129612\tbest: 831.5129612 (1000)\ttotal: 35.7s\tremaining: 19.8s\n",
      "1100:\tlearn: 806.4244886\ttest: 822.0580299\tbest: 822.0580299 (1100)\ttotal: 39.1s\tremaining: 16.2s\n",
      "1200:\tlearn: 798.9277155\ttest: 815.3279214\tbest: 815.3279214 (1200)\ttotal: 42.6s\tremaining: 12.6s\n",
      "1300:\tlearn: 791.3840169\ttest: 808.5360460\tbest: 808.5258844 (1299)\ttotal: 46.2s\tremaining: 9.09s\n",
      "1400:\tlearn: 784.5904224\ttest: 802.5709348\tbest: 802.5709348 (1400)\ttotal: 50s\tremaining: 5.56s\n",
      "1500:\tlearn: 778.5281905\ttest: 797.1684332\tbest: 797.1684332 (1500)\ttotal: 53.4s\tremaining: 1.99s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 05:43:34,208]\u001b[0m Trial 18 finished with value: 793.5317720570383 and parameters: {'depth': 4, 'n_estimators': 1557, 'learning_rate': 0.2567658050011677, 'rsm': 0.9841027393319074, 'reg_alpha': 0.44151172915998416, 'reg_lambda': 88.5877919613698}. Best is trial 13 with value: 605.5380336306631.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1556:\tlearn: 774.4640312\ttest: 793.5317721\tbest: 793.5317721 (1556)\ttotal: 55.4s\tremaining: 0us\n",
      "\n",
      "bestTest = 793.5317721\n",
      "bestIteration = 1556\n",
      "\n",
      "0:\tlearn: 3118.7297597\ttest: 3099.6299076\tbest: 3099.6299076 (0)\ttotal: 47.4ms\tremaining: 1m 31s\n",
      "100:\tlearn: 1531.6037764\ttest: 1523.7070022\tbest: 1523.7070022 (100)\ttotal: 6.42s\tremaining: 1m 56s\n",
      "200:\tlearn: 1281.7186031\ttest: 1277.7014670\tbest: 1277.7014670 (200)\ttotal: 12.7s\tremaining: 1m 50s\n",
      "300:\tlearn: 1191.1140334\ttest: 1189.2796936\tbest: 1189.2796936 (300)\ttotal: 18.8s\tremaining: 1m 42s\n",
      "400:\tlearn: 1133.9487516\ttest: 1133.4611580\tbest: 1133.4611580 (400)\ttotal: 25.2s\tremaining: 1m 36s\n",
      "500:\tlearn: 1091.1114681\ttest: 1091.5245851\tbest: 1091.5245851 (500)\ttotal: 31.3s\tremaining: 1m 29s\n",
      "600:\tlearn: 1058.8860989\ttest: 1059.9640466\tbest: 1059.9640466 (600)\ttotal: 37.6s\tremaining: 1m 23s\n",
      "700:\tlearn: 1033.4879727\ttest: 1035.3927756\tbest: 1035.3927756 (700)\ttotal: 43.9s\tremaining: 1m 17s\n",
      "800:\tlearn: 1012.6569393\ttest: 1015.1313083\tbest: 1015.1313083 (800)\ttotal: 50.1s\tremaining: 1m 11s\n",
      "900:\tlearn: 994.7152632\ttest: 997.9255364\tbest: 997.9255364 (900)\ttotal: 56.5s\tremaining: 1m 5s\n",
      "1000:\tlearn: 978.6314232\ttest: 982.2873575\tbest: 982.2873575 (1000)\ttotal: 1m 2s\tremaining: 58.9s\n",
      "1100:\tlearn: 964.1108631\ttest: 968.1618275\tbest: 968.1618275 (1100)\ttotal: 1m 9s\tremaining: 52.7s\n",
      "1200:\tlearn: 951.7153687\ttest: 956.3522296\tbest: 956.3522296 (1200)\ttotal: 1m 15s\tremaining: 46.4s\n",
      "1300:\tlearn: 940.5062224\ttest: 945.6725062\tbest: 945.6725062 (1300)\ttotal: 1m 21s\tremaining: 40.1s\n",
      "1400:\tlearn: 930.2043119\ttest: 935.7922967\tbest: 935.7922967 (1400)\ttotal: 1m 27s\tremaining: 33.9s\n",
      "1500:\tlearn: 919.9703853\ttest: 925.9796382\tbest: 925.9796382 (1500)\ttotal: 1m 34s\tremaining: 27.6s\n",
      "1600:\tlearn: 911.2934269\ttest: 917.8075725\tbest: 917.8075725 (1600)\ttotal: 1m 40s\tremaining: 21.3s\n",
      "1700:\tlearn: 903.0911443\ttest: 909.9362510\tbest: 909.9362510 (1700)\ttotal: 1m 46s\tremaining: 15s\n",
      "1800:\tlearn: 895.3639845\ttest: 902.6658676\tbest: 902.6658676 (1800)\ttotal: 1m 52s\tremaining: 8.77s\n",
      "1900:\tlearn: 888.3427131\ttest: 896.0407189\tbest: 896.0407189 (1900)\ttotal: 1m 59s\tremaining: 2.51s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 05:45:36,674]\u001b[0m Trial 19 finished with value: 893.4257338613064 and parameters: {'depth': 7, 'n_estimators': 1941, 'learning_rate': 0.015147229613030833, 'rsm': 0.4332830251048859, 'reg_alpha': 54.006219500293255, 'reg_lambda': 64.17896481071529}. Best is trial 13 with value: 605.5380336306631.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1940:\tlearn: 885.5728880\ttest: 893.4257339\tbest: 893.4257339 (1940)\ttotal: 2m 1s\tremaining: 0us\n",
      "\n",
      "bestTest = 893.4257339\n",
      "bestIteration = 1940\n",
      "\n",
      "0:\tlearn: 2137.6070800\ttest: 2126.4769204\tbest: 2126.4769204 (0)\ttotal: 66.5ms\tremaining: 3m 2s\n",
      "100:\tlearn: 756.5303553\ttest: 779.1247017\tbest: 779.1247017 (100)\ttotal: 8.46s\tremaining: 3m 41s\n",
      "200:\tlearn: 666.1442436\ttest: 710.9854177\tbest: 710.9854177 (200)\ttotal: 17.3s\tremaining: 3m 39s\n",
      "300:\tlearn: 620.3289938\ttest: 681.7952836\tbest: 681.7952836 (300)\ttotal: 25.7s\tremaining: 3m 29s\n",
      "400:\tlearn: 588.7175775\ttest: 662.6739054\tbest: 662.6739054 (400)\ttotal: 34.3s\tremaining: 3m 20s\n",
      "500:\tlearn: 564.0717223\ttest: 650.0829597\tbest: 650.0829597 (500)\ttotal: 42.9s\tremaining: 3m 12s\n",
      "600:\tlearn: 544.1793281\ttest: 640.0392544\tbest: 639.9596934 (599)\ttotal: 51.5s\tremaining: 3m 3s\n",
      "700:\tlearn: 527.5625653\ttest: 634.3835351\tbest: 634.3748467 (699)\ttotal: 1m\tremaining: 2m 55s\n",
      "800:\tlearn: 514.2555250\ttest: 630.2485027\tbest: 630.2485027 (800)\ttotal: 1m 8s\tremaining: 2m 46s\n",
      "900:\tlearn: 502.8055708\ttest: 626.3496016\tbest: 626.3496016 (900)\ttotal: 1m 17s\tremaining: 2m 37s\n",
      "1000:\tlearn: 492.0475869\ttest: 622.8223872\tbest: 622.8223872 (1000)\ttotal: 1m 25s\tremaining: 2m 28s\n",
      "1100:\tlearn: 482.7442439\ttest: 620.3623752\tbest: 620.3623752 (1100)\ttotal: 1m 33s\tremaining: 2m 20s\n",
      "1200:\tlearn: 473.7845447\ttest: 618.5509287\tbest: 618.5406443 (1199)\ttotal: 1m 42s\tremaining: 2m 12s\n",
      "1300:\tlearn: 465.7257060\ttest: 617.0280154\tbest: 617.0280154 (1300)\ttotal: 1m 51s\tremaining: 2m 3s\n",
      "1400:\tlearn: 457.9313547\ttest: 615.1392950\tbest: 615.1392950 (1400)\ttotal: 1m 59s\tremaining: 1m 54s\n",
      "1500:\tlearn: 451.0055294\ttest: 614.2427340\tbest: 614.1881830 (1498)\ttotal: 2m 8s\tremaining: 1m 46s\n",
      "1600:\tlearn: 444.7977395\ttest: 613.4530085\tbest: 613.4530085 (1600)\ttotal: 2m 16s\tremaining: 1m 37s\n",
      "1700:\tlearn: 438.8713075\ttest: 612.8064478\tbest: 612.7254555 (1684)\ttotal: 2m 25s\tremaining: 1m 29s\n",
      "1800:\tlearn: 432.8468034\ttest: 612.0435435\tbest: 611.9313876 (1787)\ttotal: 2m 33s\tremaining: 1m 20s\n",
      "1900:\tlearn: 427.3438088\ttest: 611.1480266\tbest: 611.1480266 (1900)\ttotal: 2m 42s\tremaining: 1m 12s\n",
      "2000:\tlearn: 422.3019900\ttest: 610.7125478\tbest: 610.6958334 (1994)\ttotal: 2m 50s\tremaining: 1m 3s\n",
      "2100:\tlearn: 417.2476423\ttest: 610.1411617\tbest: 610.0974177 (2095)\ttotal: 2m 59s\tremaining: 55.1s\n",
      "Stopped by overfitting detector  (40 iterations wait)\n",
      "\n",
      "bestTest = 610.0974177\n",
      "bestIteration = 2095\n",
      "\n",
      "Shrink model to first 2096 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 05:48:40,047]\u001b[0m Trial 20 finished with value: 610.0974176576023 and parameters: {'depth': 9, 'n_estimators': 2747, 'learning_rate': 0.4555292050552718, 'rsm': 0.5781333028483008, 'reg_alpha': 75.20822426294444, 'reg_lambda': 87.79035935359865}. Best is trial 13 with value: 605.5380336306631.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2399.0375353\ttest: 2386.3294185\tbest: 2386.3294185 (0)\ttotal: 51.3ms\tremaining: 2m 32s\n",
      "100:\tlearn: 873.7058336\ttest: 884.7954394\tbest: 884.7954394 (100)\ttotal: 6.6s\tremaining: 3m 8s\n",
      "200:\tlearn: 789.4372135\ttest: 807.8019972\tbest: 807.8019972 (200)\ttotal: 13.1s\tremaining: 3m\n",
      "300:\tlearn: 739.0634850\ttest: 765.1104919\tbest: 765.1104919 (300)\ttotal: 19.5s\tremaining: 2m 53s\n",
      "400:\tlearn: 704.9318263\ttest: 736.0818706\tbest: 736.0818706 (400)\ttotal: 26.2s\tremaining: 2m 48s\n",
      "500:\tlearn: 682.0187420\ttest: 717.8221728\tbest: 717.8221728 (500)\ttotal: 32.6s\tremaining: 2m 41s\n",
      "600:\tlearn: 661.4431652\ttest: 702.0976943\tbest: 702.0976943 (600)\ttotal: 39.1s\tremaining: 2m 34s\n",
      "700:\tlearn: 645.4684534\ttest: 689.8981760\tbest: 689.8981760 (700)\ttotal: 45.6s\tremaining: 2m 28s\n",
      "800:\tlearn: 631.5807470\ttest: 680.5981924\tbest: 680.5981924 (800)\ttotal: 52.2s\tremaining: 2m 22s\n",
      "900:\tlearn: 620.3721915\ttest: 672.6687227\tbest: 672.6687227 (900)\ttotal: 58.8s\tremaining: 2m 15s\n",
      "1000:\tlearn: 610.1001255\ttest: 665.7651224\tbest: 665.7651224 (1000)\ttotal: 1m 5s\tremaining: 2m 9s\n",
      "1100:\tlearn: 600.3280887\ttest: 659.3776114\tbest: 659.3776114 (1100)\ttotal: 1m 12s\tremaining: 2m 2s\n",
      "1200:\tlearn: 591.4646297\ttest: 654.2622618\tbest: 654.2622618 (1200)\ttotal: 1m 18s\tremaining: 1m 56s\n",
      "1300:\tlearn: 583.9189733\ttest: 649.9619411\tbest: 649.9619411 (1300)\ttotal: 1m 25s\tremaining: 1m 49s\n",
      "1400:\tlearn: 577.0655550\ttest: 646.2543026\tbest: 646.2543026 (1400)\ttotal: 1m 31s\tremaining: 1m 43s\n",
      "1500:\tlearn: 570.8633695\ttest: 642.8065546\tbest: 642.8065546 (1500)\ttotal: 1m 38s\tremaining: 1m 36s\n",
      "1600:\tlearn: 564.8212132\ttest: 639.4156261\tbest: 639.4156261 (1600)\ttotal: 1m 44s\tremaining: 1m 30s\n",
      "1700:\tlearn: 558.9979935\ttest: 636.8882303\tbest: 636.8454875 (1698)\ttotal: 1m 51s\tremaining: 1m 23s\n",
      "1800:\tlearn: 554.0439303\ttest: 633.9514842\tbest: 633.9514842 (1800)\ttotal: 1m 58s\tremaining: 1m 17s\n",
      "1900:\tlearn: 549.2159756\ttest: 631.7591634\tbest: 631.7591634 (1900)\ttotal: 2m 4s\tremaining: 1m 10s\n",
      "2000:\tlearn: 544.0079653\ttest: 629.4156696\tbest: 629.4156696 (2000)\ttotal: 2m 11s\tremaining: 1m 4s\n",
      "2100:\tlearn: 538.9902872\ttest: 627.1797528\tbest: 627.1797528 (2100)\ttotal: 2m 17s\tremaining: 57.7s\n",
      "2200:\tlearn: 534.4490161\ttest: 625.5097597\tbest: 625.5097597 (2200)\ttotal: 2m 24s\tremaining: 51s\n",
      "2300:\tlearn: 530.3485725\ttest: 623.6203513\tbest: 623.6203513 (2300)\ttotal: 2m 30s\tremaining: 44.5s\n",
      "2400:\tlearn: 526.6552451\ttest: 622.5841019\tbest: 622.5841019 (2400)\ttotal: 2m 37s\tremaining: 38s\n",
      "2500:\tlearn: 523.0485236\ttest: 621.2389330\tbest: 621.2389330 (2500)\ttotal: 2m 44s\tremaining: 31.4s\n",
      "2600:\tlearn: 519.6609926\ttest: 619.9237064\tbest: 619.9237064 (2600)\ttotal: 2m 50s\tremaining: 24.9s\n",
      "2700:\tlearn: 516.3514049\ttest: 618.7882174\tbest: 618.7882174 (2700)\ttotal: 2m 57s\tremaining: 18.3s\n",
      "2800:\tlearn: 512.9184397\ttest: 617.9989216\tbest: 617.8450113 (2779)\ttotal: 3m 3s\tremaining: 11.7s\n",
      "2900:\tlearn: 509.8092068\ttest: 616.7469792\tbest: 616.7469792 (2900)\ttotal: 3m 10s\tremaining: 5.18s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 05:51:56,300]\u001b[0m Trial 21 finished with value: 615.8699939374359 and parameters: {'depth': 7, 'n_estimators': 2980, 'learning_rate': 0.358336693533483, 'rsm': 0.6714233419061727, 'reg_alpha': 98.23269415544573, 'reg_lambda': 91.7640491138602}. Best is trial 13 with value: 605.5380336306631.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2979:\tlearn: 507.5715689\ttest: 615.8699939\tbest: 615.8699939 (2979)\ttotal: 3m 15s\tremaining: 0us\n",
      "\n",
      "bestTest = 615.8699939\n",
      "bestIteration = 2979\n",
      "\n",
      "0:\tlearn: 2545.2255019\ttest: 2531.1354557\tbest: 2531.1354557 (0)\ttotal: 83.2ms\tremaining: 4m 6s\n",
      "100:\tlearn: 820.7072349\ttest: 835.9994908\tbest: 835.9994908 (100)\ttotal: 8.5s\tremaining: 4m 1s\n",
      "200:\tlearn: 724.2563483\ttest: 752.1000187\tbest: 752.1000187 (200)\ttotal: 17.1s\tremaining: 3m 55s\n",
      "300:\tlearn: 673.7898835\ttest: 713.0107374\tbest: 713.0107374 (300)\ttotal: 25.6s\tremaining: 3m 46s\n",
      "400:\tlearn: 638.5617493\ttest: 688.1802774\tbest: 688.1802774 (400)\ttotal: 34.2s\tremaining: 3m 38s\n",
      "500:\tlearn: 612.9895952\ttest: 672.0554677\tbest: 672.0554677 (500)\ttotal: 42.6s\tremaining: 3m 29s\n",
      "600:\tlearn: 594.1341716\ttest: 661.2442349\tbest: 661.2442349 (600)\ttotal: 51.3s\tremaining: 3m 21s\n",
      "700:\tlearn: 577.3154087\ttest: 651.3189866\tbest: 651.3189866 (700)\ttotal: 59.7s\tremaining: 3m 12s\n",
      "800:\tlearn: 562.5909575\ttest: 642.7585391\tbest: 642.7585391 (800)\ttotal: 1m 8s\tremaining: 3m 4s\n",
      "900:\tlearn: 549.2333017\ttest: 636.1120121\tbest: 636.1120121 (900)\ttotal: 1m 16s\tremaining: 2m 56s\n",
      "1000:\tlearn: 537.4842106\ttest: 631.2012112\tbest: 631.2012112 (1000)\ttotal: 1m 25s\tremaining: 2m 47s\n",
      "1100:\tlearn: 527.8701991\ttest: 627.1313605\tbest: 627.1291165 (1099)\ttotal: 1m 34s\tremaining: 2m 39s\n",
      "1200:\tlearn: 519.3736792\ttest: 623.6092230\tbest: 623.6092230 (1200)\ttotal: 1m 42s\tremaining: 2m 30s\n",
      "1300:\tlearn: 511.1732316\ttest: 620.8591906\tbest: 620.8591906 (1300)\ttotal: 1m 50s\tremaining: 2m 21s\n",
      "1400:\tlearn: 503.8514626\ttest: 618.1961616\tbest: 618.1405149 (1395)\ttotal: 1m 59s\tremaining: 2m 13s\n",
      "1500:\tlearn: 496.9163277\ttest: 616.0559479\tbest: 616.0428331 (1499)\ttotal: 2m 8s\tremaining: 2m 4s\n",
      "1600:\tlearn: 490.1849130\ttest: 613.7691742\tbest: 613.7691742 (1600)\ttotal: 2m 16s\tremaining: 1m 56s\n",
      "1700:\tlearn: 484.0554037\ttest: 611.9341952\tbest: 611.9128343 (1698)\ttotal: 2m 25s\tremaining: 1m 48s\n",
      "1800:\tlearn: 478.7527365\ttest: 610.4170718\tbest: 610.4170718 (1800)\ttotal: 2m 33s\tremaining: 1m 39s\n",
      "1900:\tlearn: 473.0168207\ttest: 608.5843597\tbest: 608.5729134 (1899)\ttotal: 2m 42s\tremaining: 1m 30s\n",
      "2000:\tlearn: 467.8523659\ttest: 607.6313237\tbest: 607.6313237 (2000)\ttotal: 2m 51s\tremaining: 1m 22s\n",
      "2100:\tlearn: 462.9874635\ttest: 606.5143358\tbest: 606.5041206 (2099)\ttotal: 2m 59s\tremaining: 1m 13s\n",
      "2200:\tlearn: 458.1484803\ttest: 605.2153074\tbest: 605.2055968 (2199)\ttotal: 3m 8s\tremaining: 1m 5s\n",
      "2300:\tlearn: 453.8956178\ttest: 604.0558444\tbest: 604.0558444 (2300)\ttotal: 3m 16s\tremaining: 56.6s\n",
      "2400:\tlearn: 449.8307472\ttest: 603.4232237\tbest: 603.4232237 (2400)\ttotal: 3m 24s\tremaining: 48s\n",
      "2500:\tlearn: 445.8609870\ttest: 602.6068595\tbest: 602.6068595 (2500)\ttotal: 3m 33s\tremaining: 39.5s\n",
      "2600:\tlearn: 442.1307580\ttest: 601.8593123\tbest: 601.8492024 (2599)\ttotal: 3m 42s\tremaining: 31s\n",
      "2700:\tlearn: 438.4337103\ttest: 601.2664630\tbest: 601.2664630 (2700)\ttotal: 3m 50s\tremaining: 22.5s\n",
      "Stopped by overfitting detector  (40 iterations wait)\n",
      "\n",
      "bestTest = 600.9798964\n",
      "bestIteration = 2745\n",
      "\n",
      "Shrink model to first 2746 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 05:55:56,108]\u001b[0m Trial 22 finished with value: 600.9798963852005 and parameters: {'depth': 9, 'n_estimators': 2964, 'learning_rate': 0.26535789933886844, 'rsm': 0.5626728765701511, 'reg_alpha': 89.36893710321459, 'reg_lambda': 99.9313264458704}. Best is trial 22 with value: 600.9798963852005.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2565.0752074\ttest: 2550.3558898\tbest: 2550.3558898 (0)\ttotal: 65ms\tremaining: 2m 56s\n",
      "100:\tlearn: 821.9961661\ttest: 838.4162040\tbest: 838.4162040 (100)\ttotal: 8.61s\tremaining: 3m 43s\n",
      "200:\tlearn: 727.9690013\ttest: 756.5053339\tbest: 756.5053339 (200)\ttotal: 16.9s\tremaining: 3m 31s\n",
      "300:\tlearn: 677.2373904\ttest: 715.9323876\tbest: 715.9323876 (300)\ttotal: 25.4s\tremaining: 3m 24s\n",
      "400:\tlearn: 643.4931845\ttest: 691.0978974\tbest: 691.0978974 (400)\ttotal: 33.9s\tremaining: 3m 16s\n",
      "500:\tlearn: 618.6694677\ttest: 675.2694797\tbest: 675.2694797 (500)\ttotal: 42.3s\tremaining: 3m 7s\n",
      "600:\tlearn: 597.7176130\ttest: 662.6447952\tbest: 662.6447952 (600)\ttotal: 51s\tremaining: 2m 59s\n",
      "700:\tlearn: 581.6799750\ttest: 653.0527870\tbest: 653.0527870 (700)\ttotal: 59.5s\tremaining: 2m 51s\n",
      "800:\tlearn: 567.8302017\ttest: 645.0992584\tbest: 645.0992584 (800)\ttotal: 1m 8s\tremaining: 2m 42s\n",
      "900:\tlearn: 555.4053445\ttest: 638.8391539\tbest: 638.8391539 (900)\ttotal: 1m 16s\tremaining: 2m 34s\n",
      "1000:\tlearn: 544.5673444\ttest: 633.4063314\tbest: 633.4063314 (1000)\ttotal: 1m 25s\tremaining: 2m 26s\n",
      "1100:\tlearn: 534.3120259\ttest: 628.8491462\tbest: 628.8491462 (1100)\ttotal: 1m 33s\tremaining: 2m 17s\n",
      "1200:\tlearn: 525.7723588\ttest: 624.9909392\tbest: 624.9909392 (1200)\ttotal: 1m 42s\tremaining: 2m 9s\n",
      "1300:\tlearn: 517.3428572\ttest: 621.4834822\tbest: 621.4834822 (1300)\ttotal: 1m 50s\tremaining: 2m 1s\n",
      "1400:\tlearn: 509.2478816\ttest: 618.6596398\tbest: 618.6596398 (1400)\ttotal: 2m\tremaining: 1m 52s\n",
      "1500:\tlearn: 502.1374080\ttest: 615.8884664\tbest: 615.8884664 (1500)\ttotal: 2m 8s\tremaining: 1m 44s\n",
      "1600:\tlearn: 495.9753234\ttest: 613.9548744\tbest: 613.9548744 (1600)\ttotal: 2m 16s\tremaining: 1m 35s\n",
      "1700:\tlearn: 489.8686223\ttest: 612.2553929\tbest: 612.2220923 (1699)\ttotal: 2m 25s\tremaining: 1m 27s\n",
      "1800:\tlearn: 484.1234595\ttest: 610.3281785\tbest: 610.3274272 (1799)\ttotal: 2m 33s\tremaining: 1m 18s\n",
      "1900:\tlearn: 478.6402955\ttest: 608.8634175\tbest: 608.8634175 (1900)\ttotal: 2m 42s\tremaining: 1m 9s\n",
      "2000:\tlearn: 473.2905986\ttest: 607.4598710\tbest: 607.4598710 (2000)\ttotal: 2m 50s\tremaining: 1m 1s\n",
      "2100:\tlearn: 468.4277084\ttest: 605.9790191\tbest: 605.9790191 (2100)\ttotal: 2m 59s\tremaining: 52.8s\n",
      "2200:\tlearn: 463.6295326\ttest: 604.4262227\tbest: 604.4262227 (2200)\ttotal: 3m 7s\tremaining: 44.2s\n",
      "2300:\tlearn: 459.4576470\ttest: 603.6796428\tbest: 603.6781324 (2299)\ttotal: 3m 16s\tremaining: 35.7s\n",
      "2400:\tlearn: 455.2630300\ttest: 602.9987036\tbest: 602.9987036 (2400)\ttotal: 3m 24s\tremaining: 27.2s\n",
      "2500:\tlearn: 451.2308392\ttest: 602.0335006\tbest: 602.0272976 (2499)\ttotal: 3m 33s\tremaining: 18.7s\n",
      "2600:\tlearn: 447.2624303\ttest: 601.0105605\tbest: 601.0062000 (2599)\ttotal: 3m 41s\tremaining: 10.1s\n",
      "2700:\tlearn: 443.3706145\ttest: 600.1364054\tbest: 600.1364054 (2700)\ttotal: 3m 50s\tremaining: 1.62s\n",
      "2719:\tlearn: 442.6606144\ttest: 599.9827960\tbest: 599.9827960 (2719)\ttotal: 3m 51s\tremaining: 0us\n",
      "\n",
      "bestTest = 599.982796\n",
      "bestIteration = 2719\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 05:59:49,458]\u001b[0m Trial 23 finished with value: 599.9827959584984 and parameters: {'depth': 9, 'n_estimators': 2720, 'learning_rate': 0.25375471616765366, 'rsm': 0.524065637380884, 'reg_alpha': 87.79801367369025, 'reg_lambda': 70.54718555232739}. Best is trial 23 with value: 599.9827959584984.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2500.6543247\ttest: 2485.5928007\tbest: 2485.5928007 (0)\ttotal: 93.4ms\tremaining: 3m 26s\n",
      "100:\tlearn: 730.6712475\ttest: 763.8352315\tbest: 763.8352315 (100)\ttotal: 10.2s\tremaining: 3m 32s\n",
      "200:\tlearn: 634.2865347\ttest: 692.1531689\tbest: 692.1531689 (200)\ttotal: 20s\tremaining: 3m 19s\n",
      "300:\tlearn: 579.8604511\ttest: 659.9747794\tbest: 659.9747794 (300)\ttotal: 30s\tremaining: 3m 10s\n",
      "400:\tlearn: 545.0130577\ttest: 643.0122098\tbest: 643.0122098 (400)\ttotal: 40s\tremaining: 3m\n",
      "500:\tlearn: 519.4660875\ttest: 633.4222934\tbest: 633.4222934 (500)\ttotal: 49.9s\tremaining: 2m 49s\n",
      "600:\tlearn: 497.3027756\ttest: 624.8339241\tbest: 624.8339241 (600)\ttotal: 1m\tremaining: 2m 40s\n",
      "700:\tlearn: 479.0991879\ttest: 618.8014552\tbest: 618.8014552 (700)\ttotal: 1m 9s\tremaining: 2m 30s\n",
      "800:\tlearn: 464.2694206\ttest: 614.7853993\tbest: 614.7853993 (800)\ttotal: 1m 20s\tremaining: 2m 20s\n",
      "900:\tlearn: 450.4467068\ttest: 612.0895730\tbest: 612.0895730 (900)\ttotal: 1m 30s\tremaining: 2m 11s\n",
      "1000:\tlearn: 437.8847943\ttest: 609.5708838\tbest: 609.5708838 (1000)\ttotal: 1m 40s\tremaining: 2m\n",
      "1100:\tlearn: 426.4287577\ttest: 607.4251018\tbest: 607.4251018 (1100)\ttotal: 1m 50s\tremaining: 1m 50s\n",
      "1200:\tlearn: 416.1414704\ttest: 605.9706024\tbest: 605.9706024 (1200)\ttotal: 2m\tremaining: 1m 40s\n",
      "1300:\tlearn: 406.4177765\ttest: 604.7329230\tbest: 604.6995929 (1297)\ttotal: 2m 10s\tremaining: 1m 30s\n",
      "1400:\tlearn: 397.9838844\ttest: 604.0074446\tbest: 604.0058546 (1399)\ttotal: 2m 20s\tremaining: 1m 20s\n",
      "1500:\tlearn: 390.1147242\ttest: 603.2716339\tbest: 603.2578414 (1499)\ttotal: 2m 30s\tremaining: 1m 10s\n",
      "1600:\tlearn: 382.7365634\ttest: 602.8768200\tbest: 602.8326719 (1582)\ttotal: 2m 40s\tremaining: 1m\n",
      "1700:\tlearn: 375.6857357\ttest: 602.2360773\tbest: 602.1373294 (1695)\ttotal: 2m 50s\tremaining: 50.8s\n",
      "Stopped by overfitting detector  (40 iterations wait)\n",
      "\n",
      "bestTest = 602.1373294\n",
      "bestIteration = 1695\n",
      "\n",
      "Shrink model to first 1696 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-05 06:02:45,373]\u001b[0m Trial 24 finished with value: 602.1373294183957 and parameters: {'depth': 11, 'n_estimators': 2207, 'learning_rate': 0.27695977575054354, 'rsm': 0.5041962651404619, 'reg_alpha': 87.63954656070024, 'reg_lambda': 67.47697370044297}. Best is trial 23 with value: 599.9827959584984.\u001b[0m\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'reg_alpha'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'reg_alpha'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "def create_model(trial):\n",
    "    depth = trial.suggest_int(\"depth\", 1, 14)\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 500, 3000)\n",
    "    learning_rate = trial.suggest_uniform('learning_rate', 0.01, 1)\n",
    "    rsm = trial.suggest_uniform('rsm', 0.1, 0.99)\n",
    "    #colsample_bytree = trial.suggest_uniform('colsample_bytree', 0.1, 0.9)\n",
    "    #colsample_bylevel = trial.suggest_uniform('colsample_bylevel', 0.1, 0.9)\n",
    "    #num_leaves = trial.suggest_int(\"num_leaves\", 2, 5000)\n",
    "    #min_child_samples = trial.suggest_int('min_child_samples', 3, 200)\n",
    "    reg_alpha = trial.suggest_float(\"reg_alpha\", 0.1, 100)\n",
    "    reg_lambda = trial.suggest_float(\"reg_lambda\", 0.1, 100)\n",
    "    model = CatBoostRegressor(\n",
    "        depth = depth,\n",
    "        n_estimators = n_estimators,\n",
    "        learning_rate=learning_rate, \n",
    "        rsm = rsm,\n",
    "        #colsample_bytree = colsample_bytree,\n",
    "        #colsample_bylevel = colsample_bylevel,\n",
    "        #num_leaves=num_leaves, \n",
    "        #min_child_samples=min_child_samples,\n",
    "        random_state=1,\n",
    "        verbose=False\n",
    "    )\n",
    "    return model\n",
    "\n",
    "sampler = TPESampler(seed=1)\n",
    "def objective(trial):\n",
    "    model = create_model(trial)\n",
    "    model.fit(X_trn, y_trn, eval_set = [ (X_val, y_val)], early_stopping_rounds = 40, verbose = 100)\n",
    "    preds = model.predict(X_val)\n",
    "    score = np.sqrt(mean_squared_error(y_val,preds))\n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\", sampler=sampler)\n",
    "study.optimize(objective, n_trials=25)\n",
    "\n",
    "cat_params = study.best_params\n",
    "cat_params['random_state'] = 1\n",
    "cat = CatBoostRegressor(**cat_params)\n",
    "cat.fit(X_trn, y_trn, eval_set = [(X_val, y_val)], early_stopping_rounds = 40, verbose = False)\n",
    "preds = cat.predict(X_val)\n",
    "print('Optimized cat RMSE', np.sqrt(mean_squared_error(y_val, preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_params = {'depth': 9, 'n_estimators': 2720, 'learning_rate': 0.25375471616765366,\n",
    "              'rsm': 0.524065637380884,'reg_lambda': 70.54718555232739}\n",
    "cat = CatBoostRegressor(random_state = 1, **cat_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_params = {'depth': 9, 'n_estimators': 2720, 'learning_rate': 0.25375471616765366,\n",
    "              'rsm': 0.524065637380884,'reg_lambda': 70.54718555232739}\n",
    "cat_2 = CatBoostRegressor(random_state = 1,cat_features = ['Store', 'Promo'], **cat_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {'max_depth': 19, 'n_estimators': 2975, 'learning_rate': 0.23479563219782487, \n",
    "              'subsample': 0.6669019444682756, 'colsample_bytree': 0.8910004819287553,'num_leaves' : 200,\n",
    "              'reg_alpha': 25.932205148585854, 'reg_lambda': 0.24707010414012526}\n",
    "lgb = LGBMRegressor(random_state=1, **lgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {'max_depth': 9, 'n_estimators': 819, 'learning_rate': 0.10187280055433054, \n",
    "              'subsample': 0.5611557685582812, 'colsample_bytree': 0.7920162015831868, \n",
    "              'colsample_bylevel': 0.7633175258937133, 'reg_alpha': 82.97737560347895, 'reg_lambda': 27.377692424253066}\n",
    "xgb = XGBRegressor(random_state = 1, **xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation for Boosting\n",
    "def cross_val(regressor, train, test, features, name):\n",
    "    N_splits = 5\n",
    "    \n",
    "    oofs = np.zeros(len(train))\n",
    "    preds = np.zeros(len(test))\n",
    "    \n",
    "    target_col = train[target]\n",
    "    \n",
    "    folds = StratifiedKFold(n_splits = N_splits, shuffle = True,random_state = 1999)\n",
    "    stratified_target = pd.qcut( train[target], 10, labels=False, duplicates='drop')\n",
    "    for index, (trn_idx, val_idx) in enumerate(folds.split(train, stratified_target)):\n",
    "        print(f'\\n================================Fold{index + 1}===================================')\n",
    "        \n",
    "        #### Train Set\n",
    "        X_trn, y_trn = train[features].iloc[trn_idx], train[target].iloc[trn_idx]\n",
    "        \n",
    "        #### Validation Set\n",
    "        X_val, y_val = train[features].iloc[val_idx], train[target].iloc[val_idx]\n",
    "        \n",
    "        #### Test Set\n",
    "        X_test = test[features]\n",
    "        \n",
    "        ############ Fitting #############\n",
    "        _ = regressor.fit(X_trn, y_trn, eval_set = [(X_val, y_val)], early_stopping_rounds = 60, verbose = 100)\n",
    "        \n",
    "        ############ Predicting #############\n",
    "        val_preds = np.abs(regressor.predict(X_val))\n",
    "        test_preds = np.abs(regressor.predict(X_test))\n",
    "        \n",
    "        error = np.sqrt(mean_squared_error(y_val, val_preds))\n",
    "        print(f'\\n Root Mean Squared Error for Validation set is : {error}')\n",
    "        \n",
    "        oofs[val_idx] = val_preds\n",
    "        preds += test_preds / N_splits\n",
    "        \n",
    "    total_error = np.sqrt(mean_squared_error(target_col, oofs))\n",
    "    print(f'\\n\\Root Mean Squared Error for oofs is {total_error}')\n",
    "    \n",
    "    return oofs, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================Fold1===================================\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "[200]\tvalid_0's rmse: 663.765\tvalid_0's l2: 440583\n",
      "[400]\tvalid_0's rmse: 635.667\tvalid_0's l2: 404073\n",
      "[600]\tvalid_0's rmse: 624.492\tvalid_0's l2: 389990\n",
      "[800]\tvalid_0's rmse: 620.377\tvalid_0's l2: 384868\n",
      "[1000]\tvalid_0's rmse: 617.719\tvalid_0's l2: 381577\n",
      "[1200]\tvalid_0's rmse: 616.582\tvalid_0's l2: 380173\n",
      "Early stopping, best iteration is:\n",
      "[1306]\tvalid_0's rmse: 616.265\tvalid_0's l2: 379782\n",
      "\n",
      " Root Mean Squared Error for Validation set is : 616.264632821031\n",
      "\n",
      "================================Fold2===================================\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "[200]\tvalid_0's rmse: 653.292\tvalid_0's l2: 426790\n",
      "[400]\tvalid_0's rmse: 623.398\tvalid_0's l2: 388625\n",
      "[600]\tvalid_0's rmse: 612.652\tvalid_0's l2: 375342\n",
      "[800]\tvalid_0's rmse: 606.992\tvalid_0's l2: 368439\n",
      "[1000]\tvalid_0's rmse: 604.446\tvalid_0's l2: 365355\n",
      "[1200]\tvalid_0's rmse: 602.667\tvalid_0's l2: 363208\n",
      "[1400]\tvalid_0's rmse: 602.049\tvalid_0's l2: 362463\n",
      "Early stopping, best iteration is:\n",
      "[1395]\tvalid_0's rmse: 601.954\tvalid_0's l2: 362349\n",
      "\n",
      " Root Mean Squared Error for Validation set is : 601.9541154353027\n",
      "\n",
      "================================Fold3===================================\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "[200]\tvalid_0's rmse: 646.813\tvalid_0's l2: 418367\n",
      "[400]\tvalid_0's rmse: 617.74\tvalid_0's l2: 381603\n",
      "[600]\tvalid_0's rmse: 607.944\tvalid_0's l2: 369596\n",
      "[800]\tvalid_0's rmse: 603.597\tvalid_0's l2: 364330\n",
      "[1000]\tvalid_0's rmse: 602.01\tvalid_0's l2: 362416\n",
      "[1200]\tvalid_0's rmse: 601.301\tvalid_0's l2: 361563\n",
      "[1400]\tvalid_0's rmse: 600.592\tvalid_0's l2: 360711\n",
      "Early stopping, best iteration is:\n",
      "[1467]\tvalid_0's rmse: 600.394\tvalid_0's l2: 360473\n",
      "\n",
      " Root Mean Squared Error for Validation set is : 600.3636420353511\n",
      "\n",
      "================================Fold4===================================\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "[200]\tvalid_0's rmse: 650.219\tvalid_0's l2: 422785\n",
      "[400]\tvalid_0's rmse: 618.904\tvalid_0's l2: 383042\n",
      "[600]\tvalid_0's rmse: 607.815\tvalid_0's l2: 369439\n",
      "[800]\tvalid_0's rmse: 602.858\tvalid_0's l2: 363437\n",
      "[1000]\tvalid_0's rmse: 600.283\tvalid_0's l2: 360339\n",
      "[1200]\tvalid_0's rmse: 599.502\tvalid_0's l2: 359403\n",
      "[1400]\tvalid_0's rmse: 598.799\tvalid_0's l2: 358561\n",
      "Early stopping, best iteration is:\n",
      "[1446]\tvalid_0's rmse: 598.519\tvalid_0's l2: 358225\n",
      "\n",
      " Root Mean Squared Error for Validation set is : 598.5190851403162\n",
      "\n",
      "================================Fold5===================================\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "[200]\tvalid_0's rmse: 657.379\tvalid_0's l2: 432147\n",
      "[400]\tvalid_0's rmse: 628.994\tvalid_0's l2: 395633\n",
      "[600]\tvalid_0's rmse: 617.707\tvalid_0's l2: 381562\n",
      "[800]\tvalid_0's rmse: 612.438\tvalid_0's l2: 375080\n",
      "[1000]\tvalid_0's rmse: 609.424\tvalid_0's l2: 371398\n",
      "[1200]\tvalid_0's rmse: 608.607\tvalid_0's l2: 370403\n",
      "[1400]\tvalid_0's rmse: 608.228\tvalid_0's l2: 369941\n",
      "Early stopping, best iteration is:\n",
      "[1415]\tvalid_0's rmse: 608.042\tvalid_0's l2: 369716\n",
      "\n",
      " Root Mean Squared Error for Validation set is : 608.0424559604837\n",
      "\n",
      "\\Root Mean Squared Error for oofs is 605.0633218242773\n",
      "Wall time: 2min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgb_oofs, lgb_preds = cross_val(lgb, train, test, features, 'lgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================Fold1===================================\n",
      "[0]\tvalidation_0-rmse:7015.91406\n",
      "[200]\tvalidation_0-rmse:755.67450\n",
      "[400]\tvalidation_0-rmse:696.70782\n",
      "[600]\tvalidation_0-rmse:671.10193\n",
      "[800]\tvalidation_0-rmse:655.69531\n",
      "[818]\tvalidation_0-rmse:654.54309\n",
      "\n",
      " Root Mean Squared Error for Validation set is : 654.5432680230269\n",
      "\n",
      "================================Fold2===================================\n",
      "[0]\tvalidation_0-rmse:7016.25049\n",
      "[200]\tvalidation_0-rmse:741.09778\n",
      "[400]\tvalidation_0-rmse:682.91968\n",
      "[600]\tvalidation_0-rmse:656.85876\n",
      "[800]\tvalidation_0-rmse:641.06433\n",
      "[818]\tvalidation_0-rmse:639.98114\n",
      "\n",
      " Root Mean Squared Error for Validation set is : 639.9813898617849\n",
      "\n",
      "================================Fold3===================================\n",
      "[0]\tvalidation_0-rmse:7007.70215\n",
      "[200]\tvalidation_0-rmse:740.74060\n",
      "[400]\tvalidation_0-rmse:676.87231\n",
      "[600]\tvalidation_0-rmse:650.95544\n",
      "[800]\tvalidation_0-rmse:636.32263\n",
      "[818]\tvalidation_0-rmse:635.27905\n",
      "\n",
      " Root Mean Squared Error for Validation set is : 635.2794458291955\n",
      "\n",
      "================================Fold4===================================\n",
      "[0]\tvalidation_0-rmse:7012.27051\n",
      "[200]\tvalidation_0-rmse:751.49591\n",
      "[400]\tvalidation_0-rmse:687.50806\n",
      "[600]\tvalidation_0-rmse:658.40045\n",
      "[800]\tvalidation_0-rmse:642.17535\n",
      "[818]\tvalidation_0-rmse:640.55939\n",
      "\n",
      " Root Mean Squared Error for Validation set is : 640.5597161809382\n",
      "\n",
      "================================Fold5===================================\n",
      "[0]\tvalidation_0-rmse:7009.12842\n",
      "[200]\tvalidation_0-rmse:744.54071\n",
      "[400]\tvalidation_0-rmse:684.70429\n",
      "[600]\tvalidation_0-rmse:658.04974\n",
      "[800]\tvalidation_0-rmse:643.06561\n",
      "[818]\tvalidation_0-rmse:642.10358\n",
      "\n",
      " Root Mean Squared Error for Validation set is : 642.1036811035765\n",
      "\n",
      "\\Root Mean Squared Error for oofs is 642.5257903978102\n",
      "Wall time: 17min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb_oofs, xgb_preds = cross_val(xgb, train, test, features, 'xgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================Fold1===================================\n",
      "0:\tlearn: 2588.5777942\ttest: 2598.3732218\tbest: 2598.3732218 (0)\ttotal: 69ms\tremaining: 3m 7s\n",
      "100:\tlearn: 872.8997244\ttest: 891.1360953\tbest: 891.1360953 (100)\ttotal: 8.13s\tremaining: 3m 30s\n",
      "200:\tlearn: 778.8776638\ttest: 804.6466032\tbest: 804.6466032 (200)\ttotal: 16.3s\tremaining: 3m 24s\n",
      "300:\tlearn: 732.8852870\ttest: 763.6729913\tbest: 763.6729913 (300)\ttotal: 24.9s\tremaining: 3m 19s\n",
      "400:\tlearn: 701.6018228\ttest: 737.5411413\tbest: 737.5411413 (400)\ttotal: 33.1s\tremaining: 3m 11s\n",
      "500:\tlearn: 675.6997139\ttest: 716.8934143\tbest: 716.8934143 (500)\ttotal: 41s\tremaining: 3m 1s\n",
      "600:\tlearn: 661.2622755\ttest: 705.8399511\tbest: 705.8399511 (600)\ttotal: 48.2s\tremaining: 2m 49s\n",
      "700:\tlearn: 647.7475151\ttest: 695.8048122\tbest: 695.8048122 (700)\ttotal: 55.8s\tremaining: 2m 40s\n",
      "800:\tlearn: 633.4595554\ttest: 686.1466600\tbest: 686.1466600 (800)\ttotal: 1m 3s\tremaining: 2m 32s\n",
      "900:\tlearn: 620.2811338\ttest: 676.9400581\tbest: 676.9400581 (900)\ttotal: 1m 11s\tremaining: 2m 24s\n",
      "1000:\tlearn: 609.9309357\ttest: 670.0766038\tbest: 670.0766038 (1000)\ttotal: 1m 19s\tremaining: 2m 16s\n",
      "1100:\tlearn: 600.1923825\ttest: 663.8891396\tbest: 663.8891396 (1100)\ttotal: 1m 27s\tremaining: 2m 8s\n",
      "1200:\tlearn: 591.8513977\ttest: 659.0331690\tbest: 659.0331690 (1200)\ttotal: 1m 35s\tremaining: 2m\n",
      "1300:\tlearn: 584.5559859\ttest: 654.6108691\tbest: 654.6108691 (1300)\ttotal: 1m 42s\tremaining: 1m 52s\n",
      "1400:\tlearn: 577.8438592\ttest: 650.6505389\tbest: 650.6505389 (1400)\ttotal: 1m 50s\tremaining: 1m 44s\n",
      "1500:\tlearn: 571.0789537\ttest: 647.0826807\tbest: 647.0826807 (1500)\ttotal: 1m 58s\tremaining: 1m 36s\n",
      "1600:\tlearn: 565.2145074\ttest: 643.8833063\tbest: 643.8833063 (1600)\ttotal: 2m 5s\tremaining: 1m 28s\n",
      "1700:\tlearn: 560.0520957\ttest: 641.3381620\tbest: 641.3381620 (1700)\ttotal: 2m 13s\tremaining: 1m 20s\n",
      "1800:\tlearn: 555.3694896\ttest: 638.9670360\tbest: 638.9663145 (1799)\ttotal: 2m 21s\tremaining: 1m 12s\n",
      "1900:\tlearn: 550.4736873\ttest: 636.7810208\tbest: 636.7810208 (1900)\ttotal: 2m 28s\tremaining: 1m 4s\n",
      "2000:\tlearn: 545.8854525\ttest: 634.7063035\tbest: 634.7063035 (2000)\ttotal: 2m 36s\tremaining: 56.2s\n",
      "2100:\tlearn: 541.7696634\ttest: 632.8996462\tbest: 632.8996462 (2100)\ttotal: 2m 43s\tremaining: 48.3s\n",
      "2200:\tlearn: 537.7389113\ttest: 631.1101634\tbest: 631.0976466 (2198)\ttotal: 2m 51s\tremaining: 40.5s\n",
      "2300:\tlearn: 533.4745882\ttest: 629.2024192\tbest: 629.2024192 (2300)\ttotal: 2m 59s\tremaining: 32.7s\n",
      "2400:\tlearn: 529.8632788\ttest: 627.8422677\tbest: 627.8422677 (2400)\ttotal: 3m 7s\tremaining: 24.9s\n",
      "2500:\tlearn: 526.3477933\ttest: 626.4377817\tbest: 626.4377817 (2500)\ttotal: 3m 14s\tremaining: 17s\n",
      "2600:\tlearn: 522.7453611\ttest: 624.8631001\tbest: 624.8631001 (2600)\ttotal: 3m 22s\tremaining: 9.26s\n",
      "2700:\tlearn: 519.7717264\ttest: 623.6629685\tbest: 623.6629685 (2700)\ttotal: 3m 30s\tremaining: 1.48s\n",
      "2719:\tlearn: 519.2038713\ttest: 623.4338625\tbest: 623.4229871 (2718)\ttotal: 3m 31s\tremaining: 0us\n",
      "\n",
      "bestTest = 623.4229871\n",
      "bestIteration = 2718\n",
      "\n",
      "Shrink model to first 2719 iterations.\n",
      "\n",
      " Root Mean Squared Error for Validation set is : 623.4229870859198\n",
      "\n",
      "================================Fold2===================================\n",
      "0:\tlearn: 2586.0217673\ttest: 2593.2541777\tbest: 2593.2541777 (0)\ttotal: 63.5ms\tremaining: 2m 52s\n",
      "100:\tlearn: 874.3329822\ttest: 883.1405954\tbest: 883.1405954 (100)\ttotal: 7.8s\tremaining: 3m 22s\n",
      "200:\tlearn: 786.2841008\ttest: 799.1355414\tbest: 799.1355414 (200)\ttotal: 15.7s\tremaining: 3m 17s\n",
      "300:\tlearn: 739.4349281\ttest: 757.7282038\tbest: 757.7282038 (300)\ttotal: 23.5s\tremaining: 3m 8s\n",
      "400:\tlearn: 713.1138663\ttest: 735.6329506\tbest: 735.6329506 (400)\ttotal: 30.9s\tremaining: 2m 58s\n",
      "500:\tlearn: 686.3241311\ttest: 713.5114786\tbest: 713.5114786 (500)\ttotal: 39.3s\tremaining: 2m 53s\n",
      "600:\tlearn: 664.5424853\ttest: 696.1907453\tbest: 696.1907453 (600)\ttotal: 48s\tremaining: 2m 49s\n",
      "700:\tlearn: 649.6553358\ttest: 685.2642478\tbest: 685.2642478 (700)\ttotal: 56.1s\tremaining: 2m 41s\n",
      "800:\tlearn: 634.7615315\ttest: 674.4832553\tbest: 674.4832553 (800)\ttotal: 1m 4s\tremaining: 2m 34s\n",
      "900:\tlearn: 622.6311613\ttest: 665.9194459\tbest: 665.9194459 (900)\ttotal: 1m 12s\tremaining: 2m 25s\n",
      "1000:\tlearn: 612.0205414\ttest: 658.6981064\tbest: 658.6981064 (1000)\ttotal: 1m 20s\tremaining: 2m 18s\n",
      "1100:\tlearn: 602.5404140\ttest: 653.0347884\tbest: 653.0347884 (1100)\ttotal: 1m 28s\tremaining: 2m 10s\n",
      "1200:\tlearn: 594.6181292\ttest: 648.0584919\tbest: 648.0584919 (1200)\ttotal: 1m 36s\tremaining: 2m 2s\n",
      "1300:\tlearn: 587.3673816\ttest: 643.8489988\tbest: 643.8489988 (1300)\ttotal: 1m 44s\tremaining: 1m 54s\n",
      "1400:\tlearn: 580.3251678\ttest: 639.9676932\tbest: 639.9676932 (1400)\ttotal: 1m 52s\tremaining: 1m 46s\n",
      "1500:\tlearn: 574.7439701\ttest: 636.9574648\tbest: 636.9574648 (1500)\ttotal: 2m\tremaining: 1m 37s\n",
      "1600:\tlearn: 568.9349758\ttest: 633.5665564\tbest: 633.5665564 (1600)\ttotal: 2m 8s\tremaining: 1m 29s\n",
      "1700:\tlearn: 563.0361201\ttest: 630.3330771\tbest: 630.3330771 (1700)\ttotal: 2m 16s\tremaining: 1m 22s\n",
      "1800:\tlearn: 557.9651183\ttest: 627.5756469\tbest: 627.5756469 (1800)\ttotal: 2m 24s\tremaining: 1m 13s\n",
      "1900:\tlearn: 552.8818174\ttest: 625.0385188\tbest: 625.0385188 (1900)\ttotal: 2m 32s\tremaining: 1m 5s\n",
      "2000:\tlearn: 548.1597302\ttest: 622.7792709\tbest: 622.7792709 (2000)\ttotal: 2m 40s\tremaining: 57.6s\n",
      "2100:\tlearn: 543.4705449\ttest: 620.4361767\tbest: 620.4361767 (2100)\ttotal: 2m 48s\tremaining: 49.5s\n",
      "2200:\tlearn: 539.8276058\ttest: 618.8831760\tbest: 618.8831021 (2199)\ttotal: 2m 55s\tremaining: 41.5s\n",
      "2300:\tlearn: 535.8209530\ttest: 616.8997090\tbest: 616.8997090 (2300)\ttotal: 3m 3s\tremaining: 33.4s\n",
      "2400:\tlearn: 532.0500596\ttest: 615.2601380\tbest: 615.2601380 (2400)\ttotal: 3m 11s\tremaining: 25.5s\n",
      "2500:\tlearn: 528.3164619\ttest: 613.7744107\tbest: 613.7744107 (2500)\ttotal: 3m 19s\tremaining: 17.5s\n",
      "2600:\tlearn: 524.8183958\ttest: 612.0495628\tbest: 612.0495628 (2600)\ttotal: 3m 27s\tremaining: 9.49s\n",
      "2700:\tlearn: 521.5549319\ttest: 610.5919013\tbest: 610.5919013 (2700)\ttotal: 3m 35s\tremaining: 1.51s\n",
      "2719:\tlearn: 520.8294992\ttest: 610.3759074\tbest: 610.3759074 (2719)\ttotal: 3m 36s\tremaining: 0us\n",
      "\n",
      "bestTest = 610.3759074\n",
      "bestIteration = 2719\n",
      "\n",
      "\n",
      " Root Mean Squared Error for Validation set is : 610.3759074275175\n",
      "\n",
      "================================Fold3===================================\n",
      "0:\tlearn: 2589.0704085\ttest: 2580.2322515\tbest: 2580.2322515 (0)\ttotal: 63.2ms\tremaining: 2m 51s\n",
      "100:\tlearn: 866.9029459\ttest: 865.0077050\tbest: 865.0077050 (100)\ttotal: 7.91s\tremaining: 3m 25s\n",
      "200:\tlearn: 783.7780507\ttest: 786.3984213\tbest: 786.3984213 (200)\ttotal: 15.7s\tremaining: 3m 16s\n",
      "300:\tlearn: 734.1354467\ttest: 742.8528925\tbest: 742.8528925 (300)\ttotal: 23.6s\tremaining: 3m 9s\n",
      "400:\tlearn: 704.0643118\ttest: 717.9504351\tbest: 717.9504351 (400)\ttotal: 31.6s\tremaining: 3m 2s\n",
      "500:\tlearn: 682.5017467\ttest: 700.8521705\tbest: 700.8521705 (500)\ttotal: 39.8s\tremaining: 2m 56s\n",
      "600:\tlearn: 663.2605303\ttest: 685.5670576\tbest: 685.5670576 (600)\ttotal: 47.6s\tremaining: 2m 47s\n",
      "700:\tlearn: 647.2738288\ttest: 673.4348555\tbest: 673.4348555 (700)\ttotal: 55.5s\tremaining: 2m 39s\n",
      "800:\tlearn: 634.2305376\ttest: 664.4880695\tbest: 664.4880695 (800)\ttotal: 1m 3s\tremaining: 2m 31s\n",
      "900:\tlearn: 623.5307767\ttest: 657.2580812\tbest: 657.2580812 (900)\ttotal: 1m 11s\tremaining: 2m 23s\n",
      "1000:\tlearn: 613.0035172\ttest: 650.5941827\tbest: 650.5941827 (1000)\ttotal: 1m 19s\tremaining: 2m 15s\n",
      "1100:\tlearn: 604.4412249\ttest: 645.0688015\tbest: 645.0688015 (1100)\ttotal: 1m 27s\tremaining: 2m 8s\n",
      "1200:\tlearn: 596.1388411\ttest: 639.9713214\tbest: 639.9713214 (1200)\ttotal: 1m 34s\tremaining: 2m\n",
      "1300:\tlearn: 590.7620351\ttest: 636.8155337\tbest: 636.8155337 (1300)\ttotal: 1m 42s\tremaining: 1m 51s\n",
      "1400:\tlearn: 583.9292046\ttest: 632.8749465\tbest: 632.8749465 (1400)\ttotal: 1m 50s\tremaining: 1m 43s\n",
      "1500:\tlearn: 577.3253444\ttest: 628.8566560\tbest: 628.8566560 (1500)\ttotal: 1m 58s\tremaining: 1m 36s\n",
      "1600:\tlearn: 571.5933807\ttest: 625.6555130\tbest: 625.6555130 (1600)\ttotal: 2m 6s\tremaining: 1m 28s\n",
      "1700:\tlearn: 565.4556028\ttest: 622.2446443\tbest: 622.2446443 (1700)\ttotal: 2m 14s\tremaining: 1m 20s\n",
      "1800:\tlearn: 560.3774786\ttest: 619.5373297\tbest: 619.5373297 (1800)\ttotal: 2m 21s\tremaining: 1m 12s\n",
      "1900:\tlearn: 554.9835871\ttest: 617.0229019\tbest: 617.0229019 (1900)\ttotal: 2m 29s\tremaining: 1m 4s\n",
      "2000:\tlearn: 549.9977218\ttest: 614.5495818\tbest: 614.5495818 (2000)\ttotal: 2m 37s\tremaining: 56.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100:\tlearn: 544.9433535\ttest: 612.2133251\tbest: 612.2133251 (2100)\ttotal: 2m 45s\tremaining: 48.8s\n",
      "2200:\tlearn: 540.6919877\ttest: 610.3175419\tbest: 610.3175419 (2200)\ttotal: 2m 53s\tremaining: 40.9s\n",
      "2300:\tlearn: 536.7970191\ttest: 608.7312422\tbest: 608.7312422 (2300)\ttotal: 3m 1s\tremaining: 33s\n",
      "2400:\tlearn: 533.0700602\ttest: 607.3064320\tbest: 607.3064320 (2400)\ttotal: 3m 8s\tremaining: 25.1s\n",
      "2500:\tlearn: 529.0136333\ttest: 605.5902178\tbest: 605.5902178 (2500)\ttotal: 3m 16s\tremaining: 17.2s\n",
      "2600:\tlearn: 525.2496892\ttest: 603.9797669\tbest: 603.9797669 (2600)\ttotal: 3m 24s\tremaining: 9.37s\n",
      "2700:\tlearn: 521.7306703\ttest: 602.6676670\tbest: 602.6676670 (2700)\ttotal: 3m 32s\tremaining: 1.5s\n",
      "2719:\tlearn: 521.1095064\ttest: 602.4168609\tbest: 602.4168609 (2719)\ttotal: 3m 34s\tremaining: 0us\n",
      "\n",
      "bestTest = 602.4168609\n",
      "bestIteration = 2719\n",
      "\n",
      "\n",
      " Root Mean Squared Error for Validation set is : 602.4168609121801\n",
      "\n",
      "================================Fold4===================================\n",
      "0:\tlearn: 2587.1657950\ttest: 2589.3403714\tbest: 2589.3403714 (0)\ttotal: 63ms\tremaining: 2m 51s\n",
      "100:\tlearn: 872.8648221\ttest: 885.6033059\tbest: 885.6033059 (100)\ttotal: 7.77s\tremaining: 3m 21s\n",
      "200:\tlearn: 781.3565945\ttest: 797.3706118\tbest: 797.3706118 (200)\ttotal: 15.6s\tremaining: 3m 15s\n",
      "300:\tlearn: 735.4297924\ttest: 755.1937766\tbest: 755.1937766 (300)\ttotal: 23.3s\tremaining: 3m 7s\n",
      "400:\tlearn: 703.6610120\ttest: 727.2487678\tbest: 727.2487678 (400)\ttotal: 31.2s\tremaining: 3m\n",
      "500:\tlearn: 680.2784582\ttest: 707.7033277\tbest: 707.7033277 (500)\ttotal: 39s\tremaining: 2m 52s\n",
      "600:\tlearn: 660.0707414\ttest: 690.9955483\tbest: 690.9955483 (600)\ttotal: 47s\tremaining: 2m 45s\n",
      "700:\tlearn: 644.5662762\ttest: 679.1541766\tbest: 679.1541766 (700)\ttotal: 54.8s\tremaining: 2m 37s\n",
      "800:\tlearn: 630.7998692\ttest: 669.0168220\tbest: 669.0168220 (800)\ttotal: 1m 2s\tremaining: 2m 30s\n",
      "900:\tlearn: 624.4324910\ttest: 664.1286749\tbest: 664.1286749 (900)\ttotal: 1m 9s\tremaining: 2m 20s\n",
      "1000:\tlearn: 614.7894518\ttest: 657.6878309\tbest: 657.6878309 (1000)\ttotal: 1m 17s\tremaining: 2m 13s\n",
      "1100:\tlearn: 605.8629910\ttest: 651.9568420\tbest: 651.9568420 (1100)\ttotal: 1m 25s\tremaining: 2m 5s\n",
      "1200:\tlearn: 597.2933233\ttest: 646.3318241\tbest: 646.3318241 (1200)\ttotal: 1m 33s\tremaining: 1m 57s\n",
      "1300:\tlearn: 589.8499283\ttest: 641.4817508\tbest: 641.4817508 (1300)\ttotal: 1m 40s\tremaining: 1m 50s\n",
      "1400:\tlearn: 582.7927581\ttest: 637.3287754\tbest: 637.3287754 (1400)\ttotal: 1m 48s\tremaining: 1m 42s\n",
      "1500:\tlearn: 576.0768259\ttest: 633.3321821\tbest: 633.3321821 (1500)\ttotal: 1m 56s\tremaining: 1m 34s\n",
      "1600:\tlearn: 570.2817486\ttest: 630.0708388\tbest: 630.0708388 (1600)\ttotal: 2m 4s\tremaining: 1m 26s\n",
      "1700:\tlearn: 565.2957854\ttest: 627.3687277\tbest: 627.3687277 (1700)\ttotal: 2m 12s\tremaining: 1m 19s\n",
      "1800:\tlearn: 560.0865878\ttest: 624.5030368\tbest: 624.5030368 (1800)\ttotal: 2m 20s\tremaining: 1m 11s\n",
      "1900:\tlearn: 554.8464616\ttest: 621.8631672\tbest: 621.8631672 (1900)\ttotal: 2m 27s\tremaining: 1m 3s\n",
      "2000:\tlearn: 550.2279900\ttest: 619.4973814\tbest: 619.4973814 (2000)\ttotal: 2m 35s\tremaining: 56s\n",
      "2100:\tlearn: 545.6140857\ttest: 616.8230697\tbest: 616.8230697 (2100)\ttotal: 2m 43s\tremaining: 48.2s\n",
      "2200:\tlearn: 541.5948330\ttest: 614.9154524\tbest: 614.9154524 (2200)\ttotal: 2m 51s\tremaining: 40.4s\n",
      "2300:\tlearn: 537.6034174\ttest: 612.9855125\tbest: 612.9855125 (2300)\ttotal: 2m 59s\tremaining: 32.8s\n",
      "2400:\tlearn: 533.3530526\ttest: 611.0431697\tbest: 611.0431697 (2400)\ttotal: 3m 7s\tremaining: 24.9s\n",
      "2500:\tlearn: 529.4156788\ttest: 609.5522494\tbest: 609.5522494 (2500)\ttotal: 3m 16s\tremaining: 17.2s\n",
      "2600:\tlearn: 525.5797338\ttest: 608.0927206\tbest: 608.0927206 (2600)\ttotal: 3m 24s\tremaining: 9.38s\n",
      "2700:\tlearn: 521.8810240\ttest: 606.5812629\tbest: 606.5812629 (2700)\ttotal: 3m 32s\tremaining: 1.5s\n",
      "2719:\tlearn: 521.1710027\ttest: 606.1164863\tbest: 606.1164863 (2719)\ttotal: 3m 34s\tremaining: 0us\n",
      "\n",
      "bestTest = 606.1164863\n",
      "bestIteration = 2719\n",
      "\n",
      "\n",
      " Root Mean Squared Error for Validation set is : 606.1164863025086\n",
      "\n",
      "================================Fold5===================================\n",
      "0:\tlearn: 2588.6559316\ttest: 2578.6020692\tbest: 2578.6020692 (0)\ttotal: 68.5ms\tremaining: 3m 6s\n",
      "100:\tlearn: 870.4542437\ttest: 881.3372424\tbest: 881.3372424 (100)\ttotal: 8.21s\tremaining: 3m 32s\n",
      "200:\tlearn: 781.1289489\ttest: 798.7270633\tbest: 798.7270633 (200)\ttotal: 16.3s\tremaining: 3m 24s\n",
      "300:\tlearn: 735.2910996\ttest: 757.9823167\tbest: 757.9823167 (300)\ttotal: 24.4s\tremaining: 3m 16s\n",
      "400:\tlearn: 704.1047175\ttest: 730.8718976\tbest: 730.8718976 (400)\ttotal: 32.4s\tremaining: 3m 7s\n",
      "500:\tlearn: 681.0764599\ttest: 712.1554030\tbest: 712.1554030 (500)\ttotal: 40.4s\tremaining: 2m 58s\n",
      "600:\tlearn: 662.2820524\ttest: 696.3343693\tbest: 696.3343693 (600)\ttotal: 48s\tremaining: 2m 49s\n",
      "700:\tlearn: 648.0314620\ttest: 685.8524215\tbest: 685.8524215 (700)\ttotal: 56s\tremaining: 2m 41s\n",
      "800:\tlearn: 634.5169709\ttest: 676.4851851\tbest: 676.4851851 (800)\ttotal: 1m 4s\tremaining: 2m 33s\n",
      "900:\tlearn: 623.2048470\ttest: 668.6533961\tbest: 668.6533961 (900)\ttotal: 1m 12s\tremaining: 2m 25s\n",
      "1000:\tlearn: 613.6667038\ttest: 662.1683900\tbest: 662.1683900 (1000)\ttotal: 1m 20s\tremaining: 2m 17s\n",
      "1100:\tlearn: 604.8904283\ttest: 656.6426788\tbest: 656.6426788 (1100)\ttotal: 1m 28s\tremaining: 2m 9s\n",
      "1200:\tlearn: 596.6364822\ttest: 651.6549600\tbest: 651.6549600 (1200)\ttotal: 1m 36s\tremaining: 2m 1s\n",
      "1300:\tlearn: 588.7096686\ttest: 646.4262850\tbest: 646.4262850 (1300)\ttotal: 1m 44s\tremaining: 1m 53s\n",
      "1400:\tlearn: 581.5439854\ttest: 642.3614762\tbest: 642.3614762 (1400)\ttotal: 1m 52s\tremaining: 1m 45s\n",
      "1500:\tlearn: 575.6131581\ttest: 638.9010079\tbest: 638.9010079 (1500)\ttotal: 2m\tremaining: 1m 37s\n",
      "1600:\tlearn: 569.1162932\ttest: 635.5331861\tbest: 635.5331861 (1600)\ttotal: 2m 8s\tremaining: 1m 29s\n",
      "1700:\tlearn: 563.2568220\ttest: 632.2471594\tbest: 632.2471594 (1700)\ttotal: 2m 15s\tremaining: 1m 21s\n",
      "1800:\tlearn: 557.9340866\ttest: 629.4538835\tbest: 629.4538835 (1800)\ttotal: 2m 23s\tremaining: 1m 13s\n",
      "1900:\tlearn: 553.5135120\ttest: 627.2487226\tbest: 627.2487226 (1900)\ttotal: 2m 31s\tremaining: 1m 5s\n",
      "2000:\tlearn: 548.7898021\ttest: 624.8229139\tbest: 624.8229139 (2000)\ttotal: 2m 39s\tremaining: 57.4s\n",
      "2100:\tlearn: 544.6182372\ttest: 622.8759708\tbest: 622.8759708 (2100)\ttotal: 2m 47s\tremaining: 49.4s\n",
      "2200:\tlearn: 540.7149119\ttest: 621.3731732\tbest: 621.3731732 (2200)\ttotal: 2m 55s\tremaining: 41.4s\n",
      "2300:\tlearn: 536.5426113\ttest: 619.5278711\tbest: 619.5278711 (2300)\ttotal: 3m 3s\tremaining: 33.4s\n",
      "2400:\tlearn: 532.7175755\ttest: 617.7958895\tbest: 617.7958895 (2400)\ttotal: 3m 11s\tremaining: 25.5s\n",
      "2500:\tlearn: 529.2127819\ttest: 616.3986911\tbest: 616.3986911 (2500)\ttotal: 3m 19s\tremaining: 17.5s\n",
      "2600:\tlearn: 525.7194711\ttest: 614.9744727\tbest: 614.9744727 (2600)\ttotal: 3m 27s\tremaining: 9.48s\n",
      "2700:\tlearn: 521.7881794\ttest: 613.3322833\tbest: 613.3322833 (2700)\ttotal: 3m 35s\tremaining: 1.51s\n",
      "2719:\tlearn: 521.1586235\ttest: 613.0937949\tbest: 613.0937949 (2719)\ttotal: 3m 36s\tremaining: 0us\n",
      "\n",
      "bestTest = 613.0937949\n",
      "bestIteration = 2719\n",
      "\n",
      "\n",
      " Root Mean Squared Error for Validation set is : 613.0937948959456\n",
      "\n",
      "\\Root Mean Squared Error for oofs is 611.1271997056723\n",
      "Wall time: 18min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cat_oofs, cat_preds = cross_val(cat, train, test, features, 'cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================Fold1===================================\n",
      "0:\tlearn: 2575.3362059\ttest: 2584.0898417\tbest: 2584.0898417 (0)\ttotal: 161ms\tremaining: 7m 18s\n",
      "100:\tlearn: 864.6955729\ttest: 879.6069617\tbest: 879.6069617 (100)\ttotal: 16s\tremaining: 6m 54s\n",
      "200:\tlearn: 775.6896473\ttest: 798.4332311\tbest: 798.4332311 (200)\ttotal: 32.1s\tremaining: 6m 42s\n",
      "300:\tlearn: 729.7596465\ttest: 757.9615553\tbest: 757.9615553 (300)\ttotal: 47s\tremaining: 6m 17s\n",
      "400:\tlearn: 700.5797951\ttest: 733.7361743\tbest: 733.7361743 (400)\ttotal: 1m 2s\tremaining: 5m 59s\n",
      "500:\tlearn: 678.1173685\ttest: 716.1042302\tbest: 716.1042302 (500)\ttotal: 1m 17s\tremaining: 5m 43s\n",
      "600:\tlearn: 660.3052656\ttest: 702.6708746\tbest: 702.6708746 (600)\ttotal: 1m 32s\tremaining: 5m 27s\n",
      "700:\tlearn: 646.2423619\ttest: 692.9951450\tbest: 692.9951450 (700)\ttotal: 1m 47s\tremaining: 5m 10s\n",
      "800:\tlearn: 633.5708330\ttest: 683.8148063\tbest: 683.8148063 (800)\ttotal: 2m 2s\tremaining: 4m 54s\n",
      "900:\tlearn: 622.5208030\ttest: 676.2595311\tbest: 676.2595311 (900)\ttotal: 2m 17s\tremaining: 4m 38s\n",
      "1000:\tlearn: 614.4960733\ttest: 671.0269774\tbest: 671.0269774 (1000)\ttotal: 2m 32s\tremaining: 4m 22s\n",
      "1100:\tlearn: 606.0091812\ttest: 665.4118817\tbest: 665.4118817 (1100)\ttotal: 2m 48s\tremaining: 4m 7s\n",
      "1200:\tlearn: 597.2345551\ttest: 659.9373616\tbest: 659.9373616 (1200)\ttotal: 3m 3s\tremaining: 3m 52s\n",
      "1300:\tlearn: 590.3156174\ttest: 656.0977014\tbest: 656.0977014 (1300)\ttotal: 3m 18s\tremaining: 3m 36s\n",
      "1400:\tlearn: 583.5774924\ttest: 652.6151046\tbest: 652.6151046 (1400)\ttotal: 3m 34s\tremaining: 3m 21s\n",
      "1500:\tlearn: 577.7638518\ttest: 649.6420798\tbest: 649.6344397 (1499)\ttotal: 3m 52s\tremaining: 3m 8s\n",
      "1600:\tlearn: 572.7074012\ttest: 646.9105065\tbest: 646.9105065 (1600)\ttotal: 4m 9s\tremaining: 2m 54s\n",
      "1700:\tlearn: 567.3877865\ttest: 644.2793894\tbest: 644.2756865 (1699)\ttotal: 4m 27s\tremaining: 2m 40s\n",
      "1800:\tlearn: 561.9260180\ttest: 641.3933010\tbest: 641.3933010 (1800)\ttotal: 4m 43s\tremaining: 2m 24s\n",
      "1900:\tlearn: 556.8477785\ttest: 639.1207175\tbest: 639.1207175 (1900)\ttotal: 5m\tremaining: 2m 9s\n",
      "2000:\tlearn: 552.4060370\ttest: 637.0943748\tbest: 637.0943748 (2000)\ttotal: 5m 15s\tremaining: 1m 53s\n",
      "2100:\tlearn: 547.7278889\ttest: 635.0105878\tbest: 635.0105878 (2100)\ttotal: 5m 31s\tremaining: 1m 37s\n",
      "2200:\tlearn: 543.7316336\ttest: 633.2071868\tbest: 633.2071868 (2200)\ttotal: 5m 47s\tremaining: 1m 21s\n",
      "2300:\tlearn: 540.3549230\ttest: 631.7208350\tbest: 631.7208350 (2300)\ttotal: 6m 3s\tremaining: 1m 6s\n",
      "2400:\tlearn: 536.7554712\ttest: 630.2260348\tbest: 630.2260348 (2400)\ttotal: 6m 24s\tremaining: 51s\n",
      "2500:\tlearn: 533.6201318\ttest: 628.8595217\tbest: 628.8595217 (2500)\ttotal: 6m 39s\tremaining: 35s\n",
      "2600:\tlearn: 530.0061048\ttest: 627.6435648\tbest: 627.6348644 (2599)\ttotal: 6m 56s\tremaining: 19.1s\n",
      "2700:\tlearn: 526.7681428\ttest: 626.4136578\tbest: 626.4136578 (2700)\ttotal: 7m 11s\tremaining: 3.04s\n",
      "2719:\tlearn: 526.2644227\ttest: 626.1292153\tbest: 626.1292153 (2719)\ttotal: 7m 14s\tremaining: 0us\n",
      "\n",
      "bestTest = 626.1292153\n",
      "bestIteration = 2719\n",
      "\n",
      "\n",
      " Root Mean Squared Error for Validation set is : 626.1292152707364\n",
      "\n",
      "================================Fold2===================================\n",
      "0:\tlearn: 2575.9136402\ttest: 2583.2821653\tbest: 2583.2821653 (0)\ttotal: 187ms\tremaining: 8m 29s\n",
      "100:\tlearn: 854.8700949\ttest: 861.5788842\tbest: 861.5788842 (100)\ttotal: 17.4s\tremaining: 7m 31s\n",
      "200:\tlearn: 776.5893681\ttest: 788.3167665\tbest: 788.3167665 (200)\ttotal: 34.5s\tremaining: 7m 11s\n",
      "300:\tlearn: 729.8229826\ttest: 746.6397858\tbest: 746.6397858 (300)\ttotal: 51.8s\tremaining: 6m 56s\n",
      "400:\tlearn: 700.7638269\ttest: 722.6243356\tbest: 722.6243356 (400)\ttotal: 1m 8s\tremaining: 6m 34s\n",
      "500:\tlearn: 678.3261192\ttest: 704.6920953\tbest: 704.6920953 (500)\ttotal: 1m 24s\tremaining: 6m 13s\n",
      "600:\tlearn: 660.7053672\ttest: 690.8484256\tbest: 690.8484256 (600)\ttotal: 1m 40s\tremaining: 5m 55s\n",
      "700:\tlearn: 646.4085188\ttest: 680.0765575\tbest: 680.0765575 (700)\ttotal: 1m 56s\tremaining: 5m 36s\n",
      "800:\tlearn: 636.7501647\ttest: 673.7288004\tbest: 673.7282217 (799)\ttotal: 2m 11s\tremaining: 5m 14s\n",
      "900:\tlearn: 627.9662942\ttest: 667.7964715\tbest: 667.7964715 (900)\ttotal: 2m 26s\tremaining: 4m 54s\n",
      "1000:\tlearn: 619.2203165\ttest: 661.9445264\tbest: 661.9445264 (1000)\ttotal: 2m 42s\tremaining: 4m 38s\n",
      "1100:\tlearn: 610.1589073\ttest: 655.7224209\tbest: 655.7224209 (1100)\ttotal: 2m 59s\tremaining: 4m 23s\n",
      "1200:\tlearn: 602.4936495\ttest: 650.6632445\tbest: 650.6632445 (1200)\ttotal: 3m 17s\tremaining: 4m 9s\n",
      "1300:\tlearn: 595.4484582\ttest: 646.4154331\tbest: 646.4152056 (1299)\ttotal: 3m 33s\tremaining: 3m 52s\n",
      "1400:\tlearn: 589.5825379\ttest: 642.9087202\tbest: 642.9087202 (1400)\ttotal: 3m 48s\tremaining: 3m 34s\n",
      "1500:\tlearn: 583.6083638\ttest: 639.5888165\tbest: 639.5888165 (1500)\ttotal: 4m 3s\tremaining: 3m 17s\n",
      "1600:\tlearn: 578.3765323\ttest: 636.8179729\tbest: 636.8179729 (1600)\ttotal: 4m 18s\tremaining: 3m\n",
      "1700:\tlearn: 573.4309985\ttest: 634.3580282\tbest: 634.3580282 (1700)\ttotal: 4m 35s\tremaining: 2m 45s\n",
      "1800:\tlearn: 568.2348498\ttest: 631.7272965\tbest: 631.7272965 (1800)\ttotal: 4m 52s\tremaining: 2m 29s\n",
      "1900:\tlearn: 563.3655600\ttest: 629.3063822\tbest: 629.3063822 (1900)\ttotal: 5m 8s\tremaining: 2m 12s\n",
      "2000:\tlearn: 558.9384070\ttest: 627.0516782\tbest: 627.0516782 (2000)\ttotal: 5m 24s\tremaining: 1m 56s\n",
      "2100:\tlearn: 554.5005449\ttest: 624.8217176\tbest: 624.8217176 (2100)\ttotal: 5m 40s\tremaining: 1m 40s\n",
      "2200:\tlearn: 550.7464600\ttest: 623.2011438\tbest: 623.2011438 (2200)\ttotal: 5m 56s\tremaining: 1m 24s\n",
      "2300:\tlearn: 546.3178026\ttest: 621.1366300\tbest: 621.1366300 (2300)\ttotal: 6m 12s\tremaining: 1m 7s\n",
      "2400:\tlearn: 542.4988699\ttest: 619.5004213\tbest: 619.5004213 (2400)\ttotal: 6m 28s\tremaining: 51.6s\n",
      "2500:\tlearn: 538.9406292\ttest: 617.6788166\tbest: 617.6788166 (2500)\ttotal: 6m 44s\tremaining: 35.4s\n",
      "2600:\tlearn: 535.4600809\ttest: 616.2563360\tbest: 616.2503605 (2599)\ttotal: 7m\tremaining: 19.2s\n",
      "2700:\tlearn: 532.2594871\ttest: 614.8640870\tbest: 614.8640870 (2700)\ttotal: 7m 16s\tremaining: 3.07s\n",
      "2719:\tlearn: 531.7875320\ttest: 614.7265157\tbest: 614.7265157 (2719)\ttotal: 7m 19s\tremaining: 0us\n",
      "\n",
      "bestTest = 614.7265157\n",
      "bestIteration = 2719\n",
      "\n",
      "\n",
      " Root Mean Squared Error for Validation set is : 614.7265157164146\n",
      "\n",
      "================================Fold3===================================\n",
      "0:\tlearn: 2578.3916022\ttest: 2569.0512054\tbest: 2569.0512054 (0)\ttotal: 172ms\tremaining: 7m 46s\n",
      "100:\tlearn: 856.1447145\ttest: 853.0961507\tbest: 853.0961507 (100)\ttotal: 16.7s\tremaining: 7m 13s\n",
      "200:\tlearn: 778.0951243\ttest: 779.8369558\tbest: 779.8369558 (200)\ttotal: 33.2s\tremaining: 6m 55s\n",
      "300:\tlearn: 730.1105881\ttest: 736.6960754\tbest: 736.6960754 (300)\ttotal: 50.5s\tremaining: 6m 46s\n",
      "400:\tlearn: 701.0017848\ttest: 712.9036973\tbest: 712.9036973 (400)\ttotal: 1m 6s\tremaining: 6m 26s\n",
      "500:\tlearn: 680.4898359\ttest: 695.9972653\tbest: 695.9972653 (500)\ttotal: 1m 23s\tremaining: 6m 10s\n",
      "600:\tlearn: 664.6561398\ttest: 683.8913384\tbest: 683.8913384 (600)\ttotal: 1m 39s\tremaining: 5m 52s\n",
      "700:\tlearn: 652.0221050\ttest: 674.6802602\tbest: 674.6802602 (700)\ttotal: 1m 56s\tremaining: 5m 35s\n",
      "800:\tlearn: 639.3810516\ttest: 666.0530053\tbest: 666.0530053 (800)\ttotal: 2m 12s\tremaining: 5m 18s\n",
      "900:\tlearn: 628.9297815\ttest: 659.1382725\tbest: 659.1382725 (900)\ttotal: 2m 29s\tremaining: 5m 2s\n",
      "1000:\tlearn: 618.7668282\ttest: 652.4503080\tbest: 652.4503080 (1000)\ttotal: 2m 45s\tremaining: 4m 44s\n",
      "1100:\tlearn: 610.8644256\ttest: 647.4399431\tbest: 647.4399431 (1100)\ttotal: 3m 2s\tremaining: 4m 27s\n",
      "1200:\tlearn: 602.8158713\ttest: 642.6929781\tbest: 642.6925516 (1199)\ttotal: 3m 17s\tremaining: 4m 9s\n",
      "1300:\tlearn: 595.3407844\ttest: 638.2304135\tbest: 638.2304135 (1300)\ttotal: 3m 33s\tremaining: 3m 52s\n",
      "1400:\tlearn: 588.4311985\ttest: 634.7660836\tbest: 634.7660836 (1400)\ttotal: 3m 48s\tremaining: 3m 35s\n",
      "1500:\tlearn: 582.4638643\ttest: 631.4854854\tbest: 631.4854854 (1500)\ttotal: 4m 4s\tremaining: 3m 18s\n",
      "1600:\tlearn: 576.8880824\ttest: 628.4963674\tbest: 628.4963674 (1600)\ttotal: 4m 19s\tremaining: 3m 1s\n",
      "1700:\tlearn: 570.9627078\ttest: 625.4611273\tbest: 625.4611273 (1700)\ttotal: 4m 35s\tremaining: 2m 44s\n",
      "1800:\tlearn: 565.7782787\ttest: 623.0206790\tbest: 623.0206790 (1800)\ttotal: 4m 50s\tremaining: 2m 28s\n",
      "1900:\tlearn: 560.9960684\ttest: 620.9863645\tbest: 620.9863645 (1900)\ttotal: 5m 6s\tremaining: 2m 12s\n",
      "2000:\tlearn: 556.1970433\ttest: 618.6100503\tbest: 618.6100503 (2000)\ttotal: 5m 22s\tremaining: 1m 55s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100:\tlearn: 551.6589576\ttest: 616.5812919\tbest: 616.5812919 (2100)\ttotal: 5m 38s\tremaining: 1m 39s\n",
      "2200:\tlearn: 547.5546929\ttest: 614.6834033\tbest: 614.6834033 (2200)\ttotal: 5m 53s\tremaining: 1m 23s\n",
      "2300:\tlearn: 543.5640834\ttest: 613.0419906\tbest: 613.0419906 (2300)\ttotal: 6m 8s\tremaining: 1m 7s\n",
      "2400:\tlearn: 540.0853511\ttest: 611.7096810\tbest: 611.7096810 (2400)\ttotal: 6m 24s\tremaining: 51.1s\n",
      "2500:\tlearn: 536.3708095\ttest: 610.1244910\tbest: 610.1244910 (2500)\ttotal: 6m 40s\tremaining: 35.1s\n",
      "2600:\tlearn: 532.8879893\ttest: 608.6197296\tbest: 608.6197296 (2600)\ttotal: 6m 56s\tremaining: 19.1s\n",
      "2700:\tlearn: 529.5688355\ttest: 607.3897974\tbest: 607.3897974 (2700)\ttotal: 7m 12s\tremaining: 3.04s\n",
      "2719:\tlearn: 529.0027046\ttest: 607.1826327\tbest: 607.1807535 (2717)\ttotal: 7m 15s\tremaining: 0us\n",
      "\n",
      "bestTest = 607.1807535\n",
      "bestIteration = 2717\n",
      "\n",
      "Shrink model to first 2718 iterations.\n",
      "\n",
      " Root Mean Squared Error for Validation set is : 607.180753495472\n",
      "\n",
      "================================Fold4===================================\n",
      "0:\tlearn: 2576.1496309\ttest: 2578.9482172\tbest: 2578.9482172 (0)\ttotal: 145ms\tremaining: 6m 34s\n",
      "100:\tlearn: 859.5697518\ttest: 869.8247668\tbest: 869.8247668 (100)\ttotal: 15.9s\tremaining: 6m 52s\n",
      "200:\tlearn: 775.4739539\ttest: 788.1573940\tbest: 788.1573940 (200)\ttotal: 32.2s\tremaining: 6m 43s\n",
      "300:\tlearn: 728.6095173\ttest: 745.5222026\tbest: 745.5222026 (300)\ttotal: 48s\tremaining: 6m 25s\n",
      "400:\tlearn: 700.0707255\ttest: 721.0319248\tbest: 721.0319248 (400)\ttotal: 1m 5s\tremaining: 6m 15s\n",
      "500:\tlearn: 678.5355097\ttest: 703.1076204\tbest: 703.1076204 (500)\ttotal: 1m 21s\tremaining: 5m 59s\n",
      "600:\tlearn: 661.9747257\ttest: 690.1689937\tbest: 690.1689937 (600)\ttotal: 1m 39s\tremaining: 5m 49s\n",
      "700:\tlearn: 647.5810209\ttest: 679.0489291\tbest: 679.0489291 (700)\ttotal: 1m 55s\tremaining: 5m 32s\n",
      "800:\tlearn: 634.4682013\ttest: 669.4458705\tbest: 669.4458705 (800)\ttotal: 2m 11s\tremaining: 5m 14s\n",
      "900:\tlearn: 624.0773662\ttest: 662.4552644\tbest: 662.4552644 (900)\ttotal: 2m 28s\tremaining: 5m\n",
      "1000:\tlearn: 615.1059769\ttest: 656.3000289\tbest: 656.3000289 (1000)\ttotal: 2m 45s\tremaining: 4m 44s\n",
      "1100:\tlearn: 607.2796735\ttest: 651.3141193\tbest: 651.3141193 (1100)\ttotal: 3m 1s\tremaining: 4m 27s\n",
      "1200:\tlearn: 598.9632090\ttest: 646.1027618\tbest: 646.1027618 (1200)\ttotal: 3m 18s\tremaining: 4m 11s\n",
      "1300:\tlearn: 592.1972018\ttest: 641.9992060\tbest: 641.9992060 (1300)\ttotal: 3m 36s\tremaining: 3m 55s\n",
      "1400:\tlearn: 585.7334436\ttest: 638.3127195\tbest: 638.3127195 (1400)\ttotal: 3m 53s\tremaining: 3m 39s\n",
      "1500:\tlearn: 579.4168411\ttest: 634.8272039\tbest: 634.8253195 (1499)\ttotal: 4m 9s\tremaining: 3m 22s\n",
      "1600:\tlearn: 574.3338924\ttest: 631.9646798\tbest: 631.9646798 (1600)\ttotal: 4m 24s\tremaining: 3m 5s\n",
      "1700:\tlearn: 569.2687445\ttest: 629.1881579\tbest: 629.1881579 (1700)\ttotal: 4m 41s\tremaining: 2m 48s\n",
      "1800:\tlearn: 564.7804370\ttest: 626.8987009\tbest: 626.8987009 (1800)\ttotal: 4m 57s\tremaining: 2m 31s\n",
      "1900:\tlearn: 560.2191924\ttest: 624.5925079\tbest: 624.5925079 (1900)\ttotal: 5m 13s\tremaining: 2m 15s\n",
      "2000:\tlearn: 555.4531159\ttest: 622.2118850\tbest: 622.2118850 (2000)\ttotal: 5m 30s\tremaining: 1m 58s\n",
      "2100:\tlearn: 551.1849910\ttest: 620.2478758\tbest: 620.2478758 (2100)\ttotal: 5m 46s\tremaining: 1m 42s\n",
      "2200:\tlearn: 547.2985312\ttest: 618.5261566\tbest: 618.5261566 (2200)\ttotal: 6m 2s\tremaining: 1m 25s\n",
      "2300:\tlearn: 543.5159890\ttest: 616.8601897\tbest: 616.8601897 (2300)\ttotal: 6m 19s\tremaining: 1m 9s\n",
      "2400:\tlearn: 539.8095916\ttest: 615.1985108\tbest: 615.1985108 (2400)\ttotal: 6m 36s\tremaining: 52.7s\n",
      "2500:\tlearn: 536.0908269\ttest: 613.3226377\tbest: 613.3226377 (2500)\ttotal: 6m 53s\tremaining: 36.2s\n",
      "2600:\tlearn: 532.4535504\ttest: 611.7496589\tbest: 611.7496589 (2600)\ttotal: 7m 9s\tremaining: 19.6s\n",
      "2700:\tlearn: 529.1199827\ttest: 610.3513141\tbest: 610.3505267 (2699)\ttotal: 7m 25s\tremaining: 3.14s\n",
      "2719:\tlearn: 528.4647671\ttest: 610.0906165\tbest: 610.0905723 (2718)\ttotal: 7m 28s\tremaining: 0us\n",
      "\n",
      "bestTest = 610.0905723\n",
      "bestIteration = 2718\n",
      "\n",
      "Shrink model to first 2719 iterations.\n",
      "\n",
      " Root Mean Squared Error for Validation set is : 610.0905723032791\n",
      "\n",
      "================================Fold5===================================\n",
      "0:\tlearn: 2578.3145623\ttest: 2568.4567053\tbest: 2568.4567053 (0)\ttotal: 148ms\tremaining: 6m 43s\n",
      "100:\tlearn: 861.2843946\ttest: 869.8462300\tbest: 869.8462300 (100)\ttotal: 17s\tremaining: 7m 19s\n",
      "200:\tlearn: 778.2666694\ttest: 793.3094695\tbest: 793.3094695 (200)\ttotal: 33.6s\tremaining: 7m 1s\n",
      "300:\tlearn: 730.4124444\ttest: 750.9762538\tbest: 750.9762538 (300)\ttotal: 54.9s\tremaining: 7m 20s\n",
      "400:\tlearn: 700.7475033\ttest: 725.5103869\tbest: 725.5103869 (400)\ttotal: 1m 11s\tremaining: 6m 56s\n",
      "500:\tlearn: 677.3172110\ttest: 706.4742954\tbest: 706.4742954 (500)\ttotal: 1m 29s\tremaining: 6m 36s\n",
      "600:\tlearn: 663.4432266\ttest: 695.5264596\tbest: 695.5264596 (600)\ttotal: 1m 52s\tremaining: 6m 36s\n",
      "700:\tlearn: 649.0444801\ttest: 684.8877866\tbest: 684.8877866 (700)\ttotal: 2m 10s\tremaining: 6m 17s\n",
      "800:\tlearn: 635.8644771\ttest: 675.5177770\tbest: 675.5177770 (800)\ttotal: 2m 26s\tremaining: 5m 51s\n",
      "900:\tlearn: 625.2429066\ttest: 668.2035223\tbest: 668.2035223 (900)\ttotal: 2m 42s\tremaining: 5m 27s\n",
      "1000:\tlearn: 615.2845665\ttest: 661.1948967\tbest: 661.1948967 (1000)\ttotal: 2m 57s\tremaining: 5m 5s\n",
      "1100:\tlearn: 607.1397608\ttest: 656.1672083\tbest: 656.1672083 (1100)\ttotal: 3m 12s\tremaining: 4m 43s\n",
      "1200:\tlearn: 599.9169166\ttest: 651.6197627\tbest: 651.6197627 (1200)\ttotal: 3m 27s\tremaining: 4m 22s\n",
      "1300:\tlearn: 592.8327653\ttest: 647.5666920\tbest: 647.5612506 (1299)\ttotal: 3m 43s\tremaining: 4m 3s\n",
      "1400:\tlearn: 586.4144171\ttest: 643.6753444\tbest: 643.6753444 (1400)\ttotal: 3m 58s\tremaining: 3m 44s\n",
      "1500:\tlearn: 580.8464098\ttest: 640.3378499\tbest: 640.3378499 (1500)\ttotal: 4m 13s\tremaining: 3m 26s\n",
      "1600:\tlearn: 574.7998303\ttest: 637.0929438\tbest: 637.0929438 (1600)\ttotal: 4m 29s\tremaining: 3m 8s\n",
      "1700:\tlearn: 568.8955907\ttest: 633.9934338\tbest: 633.9934338 (1700)\ttotal: 4m 46s\tremaining: 2m 51s\n",
      "1800:\tlearn: 563.9656531\ttest: 631.6873363\tbest: 631.6873363 (1800)\ttotal: 5m 1s\tremaining: 2m 34s\n",
      "1900:\tlearn: 559.2464059\ttest: 629.3221749\tbest: 629.3221749 (1900)\ttotal: 5m 18s\tremaining: 2m 17s\n",
      "2000:\tlearn: 555.1746820\ttest: 627.3645542\tbest: 627.3645542 (2000)\ttotal: 5m 34s\tremaining: 2m\n",
      "2100:\tlearn: 550.8194395\ttest: 625.4161877\tbest: 625.4161877 (2100)\ttotal: 5m 49s\tremaining: 1m 43s\n",
      "2200:\tlearn: 546.8442548\ttest: 623.6465491\tbest: 623.6465491 (2200)\ttotal: 6m 5s\tremaining: 1m 26s\n",
      "2300:\tlearn: 543.1844976\ttest: 621.9144229\tbest: 621.9056560 (2299)\ttotal: 6m 22s\tremaining: 1m 9s\n",
      "2400:\tlearn: 539.5450923\ttest: 620.3719711\tbest: 620.3719711 (2400)\ttotal: 6m 38s\tremaining: 52.9s\n",
      "2500:\tlearn: 536.0763886\ttest: 619.0825878\tbest: 619.0825878 (2500)\ttotal: 6m 54s\tremaining: 36.3s\n",
      "2600:\tlearn: 532.5788625\ttest: 617.7576792\tbest: 617.7576792 (2600)\ttotal: 7m 10s\tremaining: 19.7s\n",
      "2700:\tlearn: 529.4142552\ttest: 616.7087148\tbest: 616.7087148 (2700)\ttotal: 7m 25s\tremaining: 3.13s\n",
      "2719:\tlearn: 528.8730302\ttest: 616.5386494\tbest: 616.5386494 (2719)\ttotal: 7m 28s\tremaining: 0us\n",
      "\n",
      "bestTest = 616.5386494\n",
      "bestIteration = 2719\n",
      "\n",
      "\n",
      " Root Mean Squared Error for Validation set is : 616.5386493725026\n",
      "\n",
      "\\Root Mean Squared Error for oofs is 614.967543464717\n",
      "Wall time: 37min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cat_2_oofs, cat_2_preds = cross_val(cat_2, train, test, features, 'cat_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation for Boosting\n",
    "def lgb_cross_val(regressor, train, test, features, params):\n",
    "    N_splits = 5\n",
    "    \n",
    "    oofs = np.zeros(len(train))\n",
    "    preds = np.zeros(len(test))\n",
    "    \n",
    "    target_col = train[target]\n",
    "    \n",
    "    folds = StratifiedKFold(n_splits = N_splits, shuffle = True,random_state = 1999)\n",
    "    stratified_target = pd.qcut( train[target], 10, labels=False, duplicates='drop')\n",
    "    for index, (trn_idx, val_idx) in enumerate(folds.split(train, stratified_target)):\n",
    "        print(f'\\n================================Fold{index + 1}===================================')\n",
    "        \n",
    "        #### Train Set\n",
    "        X_trn, y_trn = train[features].iloc[trn_idx], train[target].iloc[trn_idx]\n",
    "        \n",
    "        #### Validation Set\n",
    "        X_val, y_val = train[features].iloc[val_idx], train[target].iloc[val_idx]\n",
    "        \n",
    "        #### Test Set\n",
    "        X_test = test[features]\n",
    "        \n",
    "        \n",
    "        ## Pre Model\n",
    "        pre_model = LGBMRegressor(random_state = 1, **params)\n",
    "        pre_model.fit(X_trn, y_trn, eval_set = [(X_val, y_val)], early_stopping_rounds = 60, verbose = 100, eval_metric = 'rmse')\n",
    "        ############ Fitting #############\n",
    "        params2 = params.copy()\n",
    "        params2['learning_rate'] = params['learning_rate'] * 0.1\n",
    "        regressor = LGBMRegressor(random_state = 1, **params2)\n",
    "        _ = regressor.fit(X_trn, y_trn, eval_set = [(X_val, y_val)],\n",
    "                          early_stopping_rounds = 60, verbose = 100,\n",
    "                         init_model = pre_model, eval_metric = 'rmse')\n",
    "        \n",
    "        ############ Predicting #############\n",
    "        val_preds = np.abs(regressor.predict(X_val))\n",
    "        test_preds = np.abs(regressor.predict(X_test))\n",
    "        \n",
    "        error = np.sqrt(mean_squared_error(y_val, val_preds))\n",
    "        print(f'\\n Root Mean Squared Error for Validation set is : {error}')\n",
    "        \n",
    "        oofs[val_idx] = val_preds\n",
    "        preds += test_preds / N_splits\n",
    "        \n",
    "    total_error = np.sqrt(mean_squared_error(target_col, oofs))\n",
    "    print(f'\\n\\Root Mean Squared Error for oofs is {total_error}')\n",
    "    \n",
    "    return oofs, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================Fold1===================================\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "[100]\tvalid_0's rmse: 707.696\tvalid_0's l2: 500834\n",
      "[200]\tvalid_0's rmse: 663.765\tvalid_0's l2: 440583\n",
      "[300]\tvalid_0's rmse: 645.343\tvalid_0's l2: 416468\n",
      "[400]\tvalid_0's rmse: 635.667\tvalid_0's l2: 404073\n",
      "[500]\tvalid_0's rmse: 629.509\tvalid_0's l2: 396282\n",
      "[600]\tvalid_0's rmse: 624.492\tvalid_0's l2: 389990\n",
      "[700]\tvalid_0's rmse: 622.074\tvalid_0's l2: 386977\n",
      "[800]\tvalid_0's rmse: 620.377\tvalid_0's l2: 384868\n",
      "[900]\tvalid_0's rmse: 618.899\tvalid_0's l2: 383035\n",
      "[1000]\tvalid_0's rmse: 617.719\tvalid_0's l2: 381577\n",
      "[1100]\tvalid_0's rmse: 617.117\tvalid_0's l2: 380833\n",
      "[1200]\tvalid_0's rmse: 616.582\tvalid_0's l2: 380173\n",
      "[1300]\tvalid_0's rmse: 616.368\tvalid_0's l2: 379910\n",
      "Early stopping, best iteration is:\n",
      "[1306]\tvalid_0's rmse: 616.265\tvalid_0's l2: 379782\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1332]\tvalid_0's rmse: 616.239\tvalid_0's l2: 379751\n",
      "\n",
      " Root Mean Squared Error for Validation set is : 616.2394180630504\n",
      "\n",
      "================================Fold2===================================\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "[100]\tvalid_0's rmse: 698.002\tvalid_0's l2: 487206\n",
      "[200]\tvalid_0's rmse: 653.292\tvalid_0's l2: 426790\n",
      "[300]\tvalid_0's rmse: 632.688\tvalid_0's l2: 400294\n",
      "[400]\tvalid_0's rmse: 623.398\tvalid_0's l2: 388625\n",
      "[500]\tvalid_0's rmse: 616.734\tvalid_0's l2: 380361\n",
      "[600]\tvalid_0's rmse: 612.652\tvalid_0's l2: 375342\n",
      "[700]\tvalid_0's rmse: 609.483\tvalid_0's l2: 371469\n",
      "[800]\tvalid_0's rmse: 606.992\tvalid_0's l2: 368439\n",
      "[900]\tvalid_0's rmse: 605.35\tvalid_0's l2: 366449\n",
      "[1000]\tvalid_0's rmse: 604.446\tvalid_0's l2: 365355\n",
      "[1100]\tvalid_0's rmse: 603.482\tvalid_0's l2: 364191\n",
      "[1200]\tvalid_0's rmse: 602.667\tvalid_0's l2: 363208\n",
      "[1300]\tvalid_0's rmse: 602.475\tvalid_0's l2: 362976\n",
      "[1400]\tvalid_0's rmse: 602.049\tvalid_0's l2: 362463\n",
      "Early stopping, best iteration is:\n",
      "[1395]\tvalid_0's rmse: 601.954\tvalid_0's l2: 362349\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "[1400]\tvalid_0's rmse: 601.943\tvalid_0's l2: 362335\n",
      "[1500]\tvalid_0's rmse: 601.886\tvalid_0's l2: 362267\n",
      "[1600]\tvalid_0's rmse: 601.803\tvalid_0's l2: 362167\n",
      "[1700]\tvalid_0's rmse: 601.764\tvalid_0's l2: 362120\n",
      "[1800]\tvalid_0's rmse: 601.683\tvalid_0's l2: 362022\n",
      "[1900]\tvalid_0's rmse: 601.629\tvalid_0's l2: 361957\n",
      "[2000]\tvalid_0's rmse: 601.591\tvalid_0's l2: 361911\n",
      "[2100]\tvalid_0's rmse: 601.508\tvalid_0's l2: 361812\n",
      "[2200]\tvalid_0's rmse: 601.476\tvalid_0's l2: 361773\n",
      "[2300]\tvalid_0's rmse: 601.42\tvalid_0's l2: 361706\n",
      "[2400]\tvalid_0's rmse: 601.359\tvalid_0's l2: 361633\n",
      "[2500]\tvalid_0's rmse: 601.303\tvalid_0's l2: 361565\n",
      "[2600]\tvalid_0's rmse: 601.242\tvalid_0's l2: 361492\n",
      "[2700]\tvalid_0's rmse: 601.189\tvalid_0's l2: 361428\n",
      "[2800]\tvalid_0's rmse: 601.151\tvalid_0's l2: 361383\n",
      "[2900]\tvalid_0's rmse: 601.104\tvalid_0's l2: 361326\n",
      "Early stopping, best iteration is:\n",
      "[2902]\tvalid_0's rmse: 601.101\tvalid_0's l2: 361322\n",
      "\n",
      " Root Mean Squared Error for Validation set is : 601.1010354489598\n",
      "\n",
      "================================Fold3===================================\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "[100]\tvalid_0's rmse: 690.346\tvalid_0's l2: 476578\n",
      "[200]\tvalid_0's rmse: 646.813\tvalid_0's l2: 418367\n",
      "[300]\tvalid_0's rmse: 627.608\tvalid_0's l2: 393892\n",
      "[400]\tvalid_0's rmse: 617.74\tvalid_0's l2: 381603\n",
      "[500]\tvalid_0's rmse: 611.616\tvalid_0's l2: 374074\n",
      "[600]\tvalid_0's rmse: 607.944\tvalid_0's l2: 369596\n",
      "[700]\tvalid_0's rmse: 605.674\tvalid_0's l2: 366841\n",
      "[800]\tvalid_0's rmse: 603.597\tvalid_0's l2: 364330\n",
      "[900]\tvalid_0's rmse: 602.866\tvalid_0's l2: 363448\n",
      "[1000]\tvalid_0's rmse: 602.01\tvalid_0's l2: 362416\n",
      "[1100]\tvalid_0's rmse: 601.473\tvalid_0's l2: 361770\n",
      "[1200]\tvalid_0's rmse: 601.301\tvalid_0's l2: 361563\n",
      "[1300]\tvalid_0's rmse: 600.926\tvalid_0's l2: 361112\n",
      "[1400]\tvalid_0's rmse: 600.592\tvalid_0's l2: 360711\n",
      "[1500]\tvalid_0's rmse: 600.609\tvalid_0's l2: 360731\n",
      "Early stopping, best iteration is:\n",
      "[1467]\tvalid_0's rmse: 600.394\tvalid_0's l2: 360473\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "[1500]\tvalid_0's rmse: 600.372\tvalid_0's l2: 360446\n",
      "[1600]\tvalid_0's rmse: 600.322\tvalid_0's l2: 360387\n",
      "[1700]\tvalid_0's rmse: 600.297\tvalid_0's l2: 360356\n",
      "[1800]\tvalid_0's rmse: 600.24\tvalid_0's l2: 360288\n",
      "[1900]\tvalid_0's rmse: 600.209\tvalid_0's l2: 360251\n",
      "[2000]\tvalid_0's rmse: 600.192\tvalid_0's l2: 360231\n",
      "[2100]\tvalid_0's rmse: 600.158\tvalid_0's l2: 360189\n",
      "[2200]\tvalid_0's rmse: 600.137\tvalid_0's l2: 360164\n",
      "Early stopping, best iteration is:\n",
      "[2173]\tvalid_0's rmse: 600.124\tvalid_0's l2: 360149\n",
      "\n",
      " Root Mean Squared Error for Validation set is : 600.0930945569535\n",
      "\n",
      "================================Fold4===================================\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "[100]\tvalid_0's rmse: 695.185\tvalid_0's l2: 483282\n",
      "[200]\tvalid_0's rmse: 650.219\tvalid_0's l2: 422785\n",
      "[300]\tvalid_0's rmse: 629.936\tvalid_0's l2: 396819\n",
      "[400]\tvalid_0's rmse: 618.904\tvalid_0's l2: 383042\n",
      "[500]\tvalid_0's rmse: 612.182\tvalid_0's l2: 374767\n",
      "[600]\tvalid_0's rmse: 607.815\tvalid_0's l2: 369439\n",
      "[700]\tvalid_0's rmse: 604.635\tvalid_0's l2: 365583\n",
      "[800]\tvalid_0's rmse: 602.858\tvalid_0's l2: 363437\n",
      "[900]\tvalid_0's rmse: 601.438\tvalid_0's l2: 361728\n",
      "[1000]\tvalid_0's rmse: 600.283\tvalid_0's l2: 360339\n",
      "[1100]\tvalid_0's rmse: 599.807\tvalid_0's l2: 359768\n",
      "[1200]\tvalid_0's rmse: 599.502\tvalid_0's l2: 359403\n",
      "[1300]\tvalid_0's rmse: 599.083\tvalid_0's l2: 358900\n",
      "[1400]\tvalid_0's rmse: 598.799\tvalid_0's l2: 358561\n",
      "[1500]\tvalid_0's rmse: 598.806\tvalid_0's l2: 358568\n",
      "Early stopping, best iteration is:\n",
      "[1446]\tvalid_0's rmse: 598.519\tvalid_0's l2: 358225\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "[1500]\tvalid_0's rmse: 598.51\tvalid_0's l2: 358215\n",
      "[1600]\tvalid_0's rmse: 598.48\tvalid_0's l2: 358178\n",
      "[1700]\tvalid_0's rmse: 598.459\tvalid_0's l2: 358153\n",
      "[1800]\tvalid_0's rmse: 598.459\tvalid_0's l2: 358153\n",
      "Early stopping, best iteration is:\n",
      "[1768]\tvalid_0's rmse: 598.444\tvalid_0's l2: 358136\n",
      "\n",
      " Root Mean Squared Error for Validation set is : 598.4444549059398\n",
      "\n",
      "================================Fold5===================================\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "[100]\tvalid_0's rmse: 699.169\tvalid_0's l2: 488837\n",
      "[200]\tvalid_0's rmse: 657.379\tvalid_0's l2: 432147\n",
      "[300]\tvalid_0's rmse: 640.023\tvalid_0's l2: 409629\n",
      "[400]\tvalid_0's rmse: 628.994\tvalid_0's l2: 395633\n",
      "[500]\tvalid_0's rmse: 621.176\tvalid_0's l2: 385859\n",
      "[600]\tvalid_0's rmse: 617.707\tvalid_0's l2: 381562\n",
      "[700]\tvalid_0's rmse: 614.873\tvalid_0's l2: 378069\n",
      "[800]\tvalid_0's rmse: 612.438\tvalid_0's l2: 375080\n",
      "[900]\tvalid_0's rmse: 610.688\tvalid_0's l2: 372940\n",
      "[1000]\tvalid_0's rmse: 609.424\tvalid_0's l2: 371398\n",
      "[1100]\tvalid_0's rmse: 608.71\tvalid_0's l2: 370528\n",
      "[1200]\tvalid_0's rmse: 608.607\tvalid_0's l2: 370403\n",
      "[1300]\tvalid_0's rmse: 608.278\tvalid_0's l2: 370002\n",
      "[1400]\tvalid_0's rmse: 608.228\tvalid_0's l2: 369941\n",
      "Early stopping, best iteration is:\n",
      "[1415]\tvalid_0's rmse: 608.042\tvalid_0's l2: 369716\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "[1500]\tvalid_0's rmse: 607.997\tvalid_0's l2: 369660\n",
      "[1600]\tvalid_0's rmse: 607.965\tvalid_0's l2: 369621\n",
      "[1700]\tvalid_0's rmse: 607.896\tvalid_0's l2: 369537\n",
      "[1800]\tvalid_0's rmse: 607.835\tvalid_0's l2: 369463\n",
      "[1900]\tvalid_0's rmse: 607.796\tvalid_0's l2: 369416\n",
      "[2000]\tvalid_0's rmse: 607.73\tvalid_0's l2: 369336\n",
      "[2100]\tvalid_0's rmse: 607.691\tvalid_0's l2: 369288\n",
      "[2200]\tvalid_0's rmse: 607.643\tvalid_0's l2: 369230\n",
      "[2300]\tvalid_0's rmse: 607.563\tvalid_0's l2: 369133\n",
      "[2400]\tvalid_0's rmse: 607.513\tvalid_0's l2: 369072\n",
      "[2500]\tvalid_0's rmse: 607.476\tvalid_0's l2: 369027\n",
      "[2600]\tvalid_0's rmse: 607.463\tvalid_0's l2: 369011\n",
      "Early stopping, best iteration is:\n",
      "[2544]\tvalid_0's rmse: 607.46\tvalid_0's l2: 369008\n",
      "\n",
      " Root Mean Squared Error for Validation set is : 607.4603527834486\n",
      "\n",
      "\\Root Mean Squared Error for oofs is 604.7030806320585\n",
      "Wall time: 5min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgb_k_oofs, lgb_k_preds = lgb_cross_val(lgb, train, test, features, lgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation for Boosting\n",
    "def normal_cross_val(regressor, train, test, features, name):\n",
    "    N_splits = 5\n",
    "    \n",
    "    oofs = np.zeros(len(train))\n",
    "    preds = np.zeros(len(test))\n",
    "    \n",
    "    target_col = train[target]\n",
    "    \n",
    "    folds = StratifiedKFold(n_splits = N_splits, shuffle = True,random_state = 1999)\n",
    "    stratified_target = pd.qcut( train[target], 10, labels=False, duplicates='drop')\n",
    "    for index, (trn_idx, val_idx) in enumerate(folds.split(train, stratified_target)):\n",
    "        print(f'\\n================================Fold{index + 1}===================================')\n",
    "        \n",
    "        #### Train Set\n",
    "        X_trn, y_trn = train[features].iloc[trn_idx], train[target].iloc[trn_idx]\n",
    "        \n",
    "        #### Validation Set\n",
    "        X_val, y_val = train[features].iloc[val_idx], train[target].iloc[val_idx]\n",
    "        \n",
    "        #### Test Set\n",
    "        X_test = test[features]\n",
    "        \n",
    "        ############ Fitting #############\n",
    "        _ = regressor.fit(X_trn, y_trn)\n",
    "        \n",
    "        ############ Predicting #############\n",
    "        val_preds = np.abs(regressor.predict(X_val))\n",
    "        test_preds = np.abs(regressor.predict(X_test))\n",
    "        \n",
    "        error = np.sqrt(mean_squared_error(y_val, val_preds))\n",
    "        print(f'\\n Root Mean Squared Error for Validation set is : {error}')\n",
    "        \n",
    "        oofs[val_idx] = val_preds\n",
    "        preds += test_preds / N_splits\n",
    "        \n",
    "    total_error = np.sqrt(mean_squared_error(target_col, oofs))\n",
    "    print(f'\\n\\Root Mean Squared Error for oofs is {total_error}')\n",
    "    \n",
    "    return oofs, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[target] = None\n",
    "\n",
    "train_new = train[[target, 'Store']].copy()\n",
    "test_new = test[[target, 'Store']].copy()\n",
    "\n",
    "train_new['lgb_1'] = lgb_oofs\n",
    "test_new['lgb_1'] = lgb_preds\n",
    "\n",
    "train_new['lgb_2'] = lgb_k_oofs\n",
    "test_new['lgb_2'] = lgb_k_preds\n",
    "\n",
    "train_new['xgb'] = xgb_oofs\n",
    "test_new['xgb'] = xgb_preds\n",
    "\n",
    "train_new['cat'] = cat_oofs\n",
    "test_new['cat'] = cat_preds\n",
    "\n",
    "train_new['cat_2'] = cat_2_oofs\n",
    "test_new['cat_2'] = cat_2_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_features = [c for c in train_new.columns if c not in [target, 'Store']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================Fold1===================================\n",
      "\n",
      " Root Mean Squared Error for Validation set is : 627.114424920179\n",
      "\n",
      "================================Fold2===================================\n",
      "\n",
      " Root Mean Squared Error for Validation set is : 614.6042775932685\n",
      "\n",
      "================================Fold3===================================\n",
      "\n",
      " Root Mean Squared Error for Validation set is : 608.7003163692752\n",
      "\n",
      "================================Fold4===================================\n",
      "\n",
      " Root Mean Squared Error for Validation set is : 607.4606578701178\n",
      "\n",
      "================================Fold5===================================\n",
      "\n",
      " Root Mean Squared Error for Validation set is : 615.1850671852678\n",
      "\n",
      "\\Root Mean Squared Error for oofs is 614.6524516846856\n",
      "Wall time: 7.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "level_1_lgb_oofs, level_1_lgb_preds = normal_cross_val(LGBMRegressor(), train_new, test_new, ens_features, 'lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test['Predictions'] = level_1_lgb_preds\n",
    "test.loc[ test['Open'] == 0, 'Predictions'] = 0\n",
    "preds = test['Predictions']\n",
    "\n",
    "index = [i for i in range(test.shape[0])]\n",
    "\n",
    "d = list(zip(index, preds))\n",
    "\n",
    "ss = pd.DataFrame(d, columns = ['index', 'Sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.to_csv(path + \"\\\\ens.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Store</th>\n",
       "      <td>554.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DayOfWeek</th>\n",
       "      <td>554.0</td>\n",
       "      <td>3.498195</td>\n",
       "      <td>1.716054</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sales</th>\n",
       "      <td>554.0</td>\n",
       "      <td>4716.821300</td>\n",
       "      <td>1047.665103</td>\n",
       "      <td>2362.0</td>\n",
       "      <td>3919.25</td>\n",
       "      <td>4599.5</td>\n",
       "      <td>5284.5</td>\n",
       "      <td>9528.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Customers</th>\n",
       "      <td>554.0</td>\n",
       "      <td>555.579422</td>\n",
       "      <td>96.259135</td>\n",
       "      <td>298.0</td>\n",
       "      <td>493.00</td>\n",
       "      <td>542.0</td>\n",
       "      <td>599.0</td>\n",
       "      <td>1130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Open</th>\n",
       "      <td>554.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Promo</th>\n",
       "      <td>554.0</td>\n",
       "      <td>0.447653</td>\n",
       "      <td>0.497702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StateHoliday</th>\n",
       "      <td>554.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <td>554.0</td>\n",
       "      <td>0.193141</td>\n",
       "      <td>0.395119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>554.0</td>\n",
       "      <td>2014.178700</td>\n",
       "      <td>0.649535</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>2014.00</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>554.0</td>\n",
       "      <td>6.341155</td>\n",
       "      <td>3.551360</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>554.0</td>\n",
       "      <td>15.844765</td>\n",
       "      <td>8.725329</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>16.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dayofweek</th>\n",
       "      <td>554.0</td>\n",
       "      <td>2.498195</td>\n",
       "      <td>1.716054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week</th>\n",
       "      <td>554.0</td>\n",
       "      <td>25.698556</td>\n",
       "      <td>15.382681</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Store_Type</th>\n",
       "      <td>554.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Store_Assortment</th>\n",
       "      <td>554.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Store_distance</th>\n",
       "      <td>554.0</td>\n",
       "      <td>1270.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>1270.00</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>1270.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Store_CompetitionOpenSinceMonth</th>\n",
       "      <td>554.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Store_CompetitionOpenSinceYear</th>\n",
       "      <td>554.0</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>2008.00</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>2008.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Store_Promo2</th>\n",
       "      <td>554.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Store_Promo2SinceWeek</th>\n",
       "      <td>554.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Store_Promo2SinceYear</th>\n",
       "      <td>554.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Store_PromoInterval</th>\n",
       "      <td>554.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 count         mean          std     min  \\\n",
       "Store                            554.0     1.000000     0.000000     1.0   \n",
       "DayOfWeek                        554.0     3.498195     1.716054     1.0   \n",
       "Sales                            554.0  4716.821300  1047.665103  2362.0   \n",
       "Customers                        554.0   555.579422    96.259135   298.0   \n",
       "Open                             554.0     1.000000     0.000000     1.0   \n",
       "Promo                            554.0     0.447653     0.497702     0.0   \n",
       "StateHoliday                     554.0     0.000000     0.000000     0.0   \n",
       "SchoolHoliday                    554.0     0.193141     0.395119     0.0   \n",
       "year                             554.0  2014.178700     0.649535  2013.0   \n",
       "month                            554.0     6.341155     3.551360     1.0   \n",
       "day                              554.0    15.844765     8.725329     1.0   \n",
       "dayofweek                        554.0     2.498195     1.716054     0.0   \n",
       "week                             554.0    25.698556    15.382681     1.0   \n",
       "Store_Type                       554.0     3.000000     0.000000     3.0   \n",
       "Store_Assortment                 554.0     1.000000     0.000000     1.0   \n",
       "Store_distance                   554.0  1270.000000     0.000000  1270.0   \n",
       "Store_CompetitionOpenSinceMonth  554.0     9.000000     0.000000     9.0   \n",
       "Store_CompetitionOpenSinceYear   554.0  2008.000000     0.000000  2008.0   \n",
       "Store_Promo2                     554.0     0.000000     0.000000     0.0   \n",
       "Store_Promo2SinceWeek            554.0     0.000000     0.000000     0.0   \n",
       "Store_Promo2SinceYear            554.0     0.000000     0.000000     0.0   \n",
       "Store_PromoInterval              554.0     0.000000     0.000000     0.0   \n",
       "\n",
       "                                     25%     50%     75%     max  \n",
       "Store                               1.00     1.0     1.0     1.0  \n",
       "DayOfWeek                           2.00     3.0     5.0     6.0  \n",
       "Sales                            3919.25  4599.5  5284.5  9528.0  \n",
       "Customers                         493.00   542.0   599.0  1130.0  \n",
       "Open                                1.00     1.0     1.0     1.0  \n",
       "Promo                               0.00     0.0     1.0     1.0  \n",
       "StateHoliday                        0.00     0.0     0.0     0.0  \n",
       "SchoolHoliday                       0.00     0.0     0.0     1.0  \n",
       "year                             2014.00  2014.0  2015.0  2015.0  \n",
       "month                               3.00     6.0    10.0    12.0  \n",
       "day                                 8.00    16.0    23.0    31.0  \n",
       "dayofweek                           1.00     2.0     4.0     5.0  \n",
       "week                               12.00    25.0    41.0    52.0  \n",
       "Store_Type                          3.00     3.0     3.0     3.0  \n",
       "Store_Assortment                    1.00     1.0     1.0     1.0  \n",
       "Store_distance                   1270.00  1270.0  1270.0  1270.0  \n",
       "Store_CompetitionOpenSinceMonth     9.00     9.0     9.0     9.0  \n",
       "Store_CompetitionOpenSinceYear   2008.00  2008.0  2008.0  2008.0  \n",
       "Store_Promo2                        0.00     0.0     0.0     0.0  \n",
       "Store_Promo2SinceWeek               0.00     0.0     0.0     0.0  \n",
       "Store_Promo2SinceYear               0.00     0.0     0.0     0.0  \n",
       "Store_PromoInterval                 0.00     0.0     0.0     0.0  "
      ]
     },
     "execution_count": 626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[ train['Store'] == 1].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>week</th>\n",
       "      <th>Store_Type</th>\n",
       "      <th>Store_Assortment</th>\n",
       "      <th>Store_distance</th>\n",
       "      <th>Store_CompetitionOpenSinceMonth</th>\n",
       "      <th>Store_CompetitionOpenSinceYear</th>\n",
       "      <th>Store_Promo2</th>\n",
       "      <th>Store_Promo2SinceWeek</th>\n",
       "      <th>Store_Promo2SinceYear</th>\n",
       "      <th>Store_PromoInterval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>619155</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-12-23</td>\n",
       "      <td>9528</td>\n",
       "      <td>1130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1270</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Store  DayOfWeek       Date  Sales  Customers  Open  Promo  \\\n",
       "619155      1          1 2013-12-23   9528       1130     1      0   \n",
       "\n",
       "        StateHoliday  SchoolHoliday  year  month  day  dayofweek  week  \\\n",
       "619155             0              1  2013     12   23          0    52   \n",
       "\n",
       "        Store_Type  Store_Assortment  Store_distance  \\\n",
       "619155           3                 1            1270   \n",
       "\n",
       "        Store_CompetitionOpenSinceMonth  Store_CompetitionOpenSinceYear  \\\n",
       "619155                                9                            2008   \n",
       "\n",
       "        Store_Promo2  Store_Promo2SinceWeek  Store_Promo2SinceYear  \\\n",
       "619155             0                      0                      0   \n",
       "\n",
       "        Store_PromoInterval  \n",
       "619155                    0  "
      ]
     },
     "execution_count": 627,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
