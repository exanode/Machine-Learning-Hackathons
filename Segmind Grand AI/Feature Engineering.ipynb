{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "path = os.getcwd()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, BaggingRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_squared_log_error\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\sunil\\\\Projects\\\\Dockship\\\\segmind_grand_ai_challenge_2021-dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunil\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(path + \"\\\\dataset\\\\TRAIN.csv\")\n",
    "test = pd.read_csv(path + \"\\\\dataset\\\\TEST.csv\")\n",
    "ss = pd.read_csv(path + \"\\\\dataset\\\\sample_submission.csv\")\n",
    "shop = pd.read_csv(path + \"\\\\dataset\\\\store.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Date'] = pd.to_datetime(train['Date'])\n",
    "test['Date'] = pd.to_datetime(test['Date'])\n",
    "\n",
    "train['year'] = train['Date'].dt.year\n",
    "train['month'] = train['Date'].dt.month\n",
    "train['day'] = train['Date'].dt.day\n",
    "train['dayofweek'] = train['Date'].dt.dayofweek\n",
    "train['week'] = train['Date'].dt.week\n",
    "\n",
    "test['year'] = test['Date'].dt.year\n",
    "test['month'] = test['Date'].dt.month\n",
    "test['day'] = test['Date'].dt.day\n",
    "test['dayofweek'] = test['Date'].dt.dayofweek\n",
    "test['week'] = test['Date'].dt.week\n",
    "\n",
    "train['StateHoliday'].replace({0 : 0, '0':0, 'a':1, 'b':2, 'c':3}, inplace = True)\n",
    "test['StateHoliday'].replace({0 : 0, '0':0, 'a':1, 'b':2, 'c':3}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging\n",
    "\n",
    "store_type = dict(zip(shop['Store'], shop['StoreType']))\n",
    "store_ass = dict(zip(shop['Store'], shop['Assortment']))\n",
    "store_com = dict(zip(shop['Store'], shop['CompetitionDistance']))\n",
    "store_month = dict(zip(shop['Store'], shop['CompetitionOpenSinceMonth']))\n",
    "store_year = dict(zip(shop['Store'], shop['CompetitionOpenSinceYear']))\n",
    "store_p2 = dict(zip(shop['Store'], shop['Promo2']))\n",
    "store_pweek = dict(zip(shop['Store'], shop['Promo2SinceWeek']))\n",
    "store_pyear = dict(zip(shop['Store'], shop['Promo2SinceYear']))\n",
    "store_pi = dict(zip(shop['Store'], shop['PromoInterval']))\n",
    "\n",
    "train['Store_Type'] = train['Store'].map(store_type)\n",
    "train['Store_Assortment'] = train['Store'].map(store_ass)\n",
    "train['Store_distance'] = train['Store'].map(store_com)\n",
    "train['Store_CompetitionOpenSinceMonth'] = train['Store'].map(store_month)\n",
    "train['Store_CompetitionOpenSinceYear'] = train['Store'].map(store_year)\n",
    "train['Store_Promo2'] = train['Store'].map(store_p2)\n",
    "train['Store_Promo2SinceWeek'] = train['Store'].map(store_pweek)\n",
    "train['Store_Promo2SinceYear'] = train['Store'].map(store_pyear)\n",
    "train['Store_PromoInterval'] = train['Store'].map(store_pi)\n",
    "\n",
    "\n",
    "test['Store_Type'] = test['Store'].map(store_type)\n",
    "test['Store_Assortment'] = test['Store'].map(store_ass)\n",
    "test['Store_distance'] = test['Store'].map(store_com)\n",
    "test['Store_CompetitionOpenSinceMonth'] = test['Store'].map(store_month)\n",
    "test['Store_CompetitionOpenSinceYear'] = test['Store'].map(store_year)\n",
    "test['Store_Promo2'] = test['Store'].map(store_p2)\n",
    "test['Store_Promo2SinceWeek'] = test['Store'].map(store_pweek)\n",
    "test['Store_Promo2SinceYear'] = test['Store'].map(store_pyear)\n",
    "test['Store_PromoInterval'] = test['Store'].map(store_pi)\n",
    "\n",
    "\n",
    "train['Store_Assortment'].unique()\n",
    "train['Store_Assortment'].replace({'a':1, 'b':2, 'c':3}, inplace = True)\n",
    "test['Store_Assortment'].replace({'a':1, 'b':2, 'c':3}, inplace = True)\n",
    "\n",
    "\n",
    "a = [0, 'Jan,Apr,Jul,Oct', 'Feb,May,Aug,Nov', 'Mar,Jun,Sept,Dec']\n",
    "b = [0, 1, 2, 3]\n",
    "\n",
    "train['Store_PromoInterval'].replace(dict(zip(a, b)), inplace = True)\n",
    "test['Store_PromoInterval'].replace(dict(zip(a, b)), inplace = True)\n",
    "\n",
    "train['Store_Type'].replace({'a':1, 'b':2, 'c':3, 'd':4}, inplace = True)\n",
    "test['Store_Type'].replace({'a':1, 'b':2, 'c':3, 'd':4}, inplace = True)\n",
    "\n",
    "train.fillna(0, inplace = True)\n",
    "test.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing Datatype\n",
    "\n",
    "int8_cols = ['DayOfWeek', 'Open', 'Promo','StateHoliday', 'SchoolHoliday', \n",
    "'month', 'day', 'dayofweek','week', 'Store_Type', 'Store_Assortment',\n",
    "'Store_CompetitionOpenSinceMonth','Store_Promo2', \n",
    "'Store_Promo2SinceWeek','Store_PromoInterval']\n",
    "\n",
    "int16_cols = ['Customers', 'year', 'Store', 'Store_CompetitionOpenSinceYear', 'Store_Promo2SinceYear']\n",
    "\n",
    "int32_cols = ['Sales', 'Store_distance']\n",
    "\n",
    "def int8(x):\n",
    "    train[x] = train[x].astype('int8')\n",
    "    \n",
    "    test[x] = test[x].astype('int8')\n",
    "\n",
    "def int16(x):\n",
    "    train[x] = train[x].astype('int16')\n",
    "    if x != 'Customers':\n",
    "        test[x] = test[x].astype('int16')\n",
    "\n",
    "def int32(x):\n",
    "    train[x] = train[x].astype('int32')\n",
    "    if x != 'Sales':\n",
    "        test[x] = test[x].astype('int32')\n",
    "\n",
    "for col in int8_cols:\n",
    "    int8(col)\n",
    "\n",
    "for col in int16_cols:\n",
    "    int16(col)\n",
    "\n",
    "for col in int32_cols:\n",
    "    int32(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dropping Samples with Open=0\n",
    "\n",
    "# index = train[ train['Open'] == 0].index\n",
    "# train.drop(index, inplace = True, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Sales'] = np.sqrt(train['Sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Sales'\n",
    "date = 'Date'\n",
    "customer = 'Customers'\n",
    "\n",
    "cat_cols = ['Store', 'DayOfWeek', 'Open', 'Promo',\n",
    "       'StateHoliday', 'SchoolHoliday', 'year', 'month', 'day', 'dayofweek',\n",
    "       'week', 'Store_Type', 'Store_Assortment',\n",
    "       'Store_CompetitionOpenSinceMonth', 'Store_CompetitionOpenSinceYear',\n",
    "       'Store_Promo2', 'Store_Promo2SinceWeek', 'Store_Promo2SinceYear',\n",
    "       'Store_PromoInterval']\n",
    "\n",
    "features = [col for col in train.columns if col not in [target, date, customer]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn, val = train_test_split(train, test_size = 0.2, random_state = 1999)\n",
    "\n",
    "##### Input for model\n",
    "X_trn, X_val = trn[features], val[features]\n",
    "\n",
    "##### Target column\n",
    "y_trn, y_val = trn[target], val[target]\n",
    "\n",
    "##### Features for test data that we will be predicting\n",
    "X_test = test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join(train_, test_):\n",
    "    df = pd.concat([train_, test_], axis = 0).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def split(df):\n",
    "    train_, test_ = df[:train.shape[0]], df[train.shape[0]:].reset_index(drop=True)\n",
    "    return train_, test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store's mean, max, min sale\n",
    "\n",
    "mean = train.groupby(['Store'])['Sales'].mean()\n",
    "median = train.groupby(['Store'])['Sales'].median()\n",
    "max_ = train.groupby(['Store'])['Sales'].max()\n",
    "min_ = train.groupby(['Store'])['Sales'].min()\n",
    "\n",
    "train['Mean_sales'] = train['Store'].apply(lambda x: mean[x])\n",
    "train['Median_sales'] = train['Store'].apply(lambda x: median[x])\n",
    "train['Max_sales'] = train['Store'].apply(lambda x: max_[x])\n",
    "train['Min_sales'] = train['Store'].apply(lambda x: min_[x])\n",
    "\n",
    "test['Mean_sales'] = test['Store'].apply(lambda x: mean[x])\n",
    "test['Median_sales'] = test['Store'].apply(lambda x: median[x])\n",
    "test['Max_sales'] = test['Store'].apply(lambda x: max_[x])\n",
    "test['Min_sales'] = test['Store'].apply(lambda x: min_[x])\n",
    "\n",
    "#lb 1039"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store's mean, max, min sale\n",
    "\n",
    "mean = train.groupby(['Store'])['Customers'].mean()\n",
    "median = train.groupby(['Store'])['Customers'].median()\n",
    "max_ = train.groupby(['Store'])['Customers'].max()\n",
    "min_ = train[train['Customers']!=0].groupby(['Store'])['Customers'].min()\n",
    "\n",
    "train['Mean_customers'] = train['Store'].apply(lambda x: mean[x])\n",
    "train['Median_customers'] = train['Store'].apply(lambda x: median[x])\n",
    "train['Max_customers'] = train['Store'].apply(lambda x: max_[x])\n",
    "train['Min_customers'] = train['Store'].apply(lambda x: min_[x])\n",
    "\n",
    "test['Mean_customers'] = test['Store'].apply(lambda x: mean[x])\n",
    "test['Median_customers'] = test['Store'].apply(lambda x: median[x])\n",
    "test['Max_customers'] = test['Store'].apply(lambda x: max_[x])\n",
    "test['Min_customers'] = test['Store'].apply(lambda x: min_[x])\n",
    "\n",
    "#lb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sales/mean,median customers\n",
    "\n",
    "train['Mean_Sales_/_Customer'] = train['Mean_sales'] / train['Mean_customers']\n",
    "train['Median_Sales_/_Customer'] = train['Median_sales'] / train['Median_customers']\n",
    "test['Mean_Sales_/_Customer'] = test['Mean_sales'] / test['Mean_customers']\n",
    "test['Median_Sales_/_Customer'] = test['Median_sales'] / test['Median_customers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store's Sale Per day_of_week\n",
    "\n",
    "week_day_mean = train.groupby(['Store', 'DayOfWeek'])['Sales'].mean().to_dict()\n",
    "week_day_median = train.groupby(['Store', 'DayOfWeek'])['Sales'].median().to_dict()\n",
    "week_day_min = train.groupby(['Store', 'DayOfWeek'])['Sales'].min().to_dict()\n",
    "week_day_max = train.groupby(['Store', 'DayOfWeek'])['Sales'].max().to_dict()\n",
    "\n",
    "train['day_of_week_Sale_mean'] = train.apply(lambda x: week_day_mean[(x['Store'], x['DayOfWeek'])], axis = 1)\n",
    "test['day_of_week_Sale_mean'] = test.apply(lambda x: week_day_mean[(x['Store'], x['DayOfWeek'])], axis = 1)\n",
    "\n",
    "train['day_of_week_Sale_median'] = train.apply(lambda x: week_day_median[(x['Store'], x['DayOfWeek'])], axis = 1)\n",
    "test['day_of_week_Sale_median'] = test.apply(lambda x: week_day_median[(x['Store'], x['DayOfWeek'])], axis = 1)\n",
    "\n",
    "train['day_of_week_Sale_min'] = train.apply(lambda x: week_day_min[(x['Store'], x['DayOfWeek'])], axis = 1)\n",
    "test['day_of_week_Sale_min'] = test.apply(lambda x: week_day_min[(x['Store'], x['DayOfWeek'])], axis = 1)\n",
    "\n",
    "train['day_of_week_Sale_max'] = train.apply(lambda x: week_day_max[(x['Store'], x['DayOfWeek'])], axis = 1)\n",
    "test['day_of_week_Sale_max'] = test.apply(lambda x: week_day_max[(x['Store'], x['DayOfWeek'])], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store's Sale Per day_of_week and promo\n",
    "\n",
    "week_day_mean = train.groupby(['Store', 'DayOfWeek', 'Promo'])['Sales'].mean().to_dict()\n",
    "week_day_median = train.groupby(['Store', 'DayOfWeek', 'Promo'])['Sales'].median().to_dict()\n",
    "week_day_min = train.groupby(['Store', 'DayOfWeek', 'Promo'])['Sales'].min().to_dict()\n",
    "week_day_max = train.groupby(['Store', 'DayOfWeek', 'Promo'])['Sales'].max().to_dict()\n",
    "\n",
    "train['day_of_week_Sale_mean_promo'] = train.apply(lambda x: week_day_mean[(x['Store'], x['DayOfWeek'], x['Promo'])], axis = 1)\n",
    "test['day_of_week_Sale_mean_promo'] = test.apply(lambda x: week_day_mean[(x['Store'], x['DayOfWeek'], x['Promo'])], axis = 1)\n",
    "\n",
    "train['day_of_week_Sale_median_promo'] = train.apply(lambda x: week_day_median[(x['Store'], x['DayOfWeek'], x['Promo'])], axis = 1)\n",
    "test['day_of_week_Sale_median_promo'] = test.apply(lambda x: week_day_median[(x['Store'], x['DayOfWeek'], x['Promo'])], axis = 1)\n",
    "\n",
    "train['day_of_week_Sale_min_promo'] = train.apply(lambda x: week_day_min[(x['Store'], x['DayOfWeek'], x['Promo'])], axis = 1)\n",
    "test['day_of_week_Sale_min_promo'] = test.apply(lambda x: week_day_min[(x['Store'], x['DayOfWeek'], x['Promo'])], axis = 1)\n",
    "\n",
    "train['day_of_week_Sale_max_promo'] = train.apply(lambda x: week_day_max[(x['Store'], x['DayOfWeek'], x['Promo'])], axis = 1)\n",
    "test['day_of_week_Sale_max_promo'] = test.apply(lambda x: week_day_max[(x['Store'], x['DayOfWeek'], x['Promo'])], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Samples with Open=0\n",
    "\n",
    "index = train[ train['Open'] == 0].index\n",
    "train.drop(index, inplace = True, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store's Sale Per day_of_week and promo\n",
    "\n",
    "week_day_mean = train.groupby(['Store', 'week'])['Sales'].mean().to_dict()\n",
    "week_day_median = train.groupby(['Store', 'week'])['Sales'].median().to_dict()\n",
    "week_day_min = train.groupby(['Store', 'week'])['Sales'].min().to_dict()\n",
    "week_day_max = train.groupby(['Store', 'week'])['Sales'].max().to_dict()\n",
    "\n",
    "def imputer(d, x):\n",
    "    try:\n",
    "        val = d[(x['Store'], x['week'])]\n",
    "        return val\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "train['week_Sale_mean'] = train.apply(lambda x: imputer(week_day_mean, x), axis = 1)\n",
    "test['week_Sale_mean'] = test.apply(lambda x: imputer(week_day_mean, x), axis = 1)\n",
    "\n",
    "train['week_Sale_median'] = train.apply(lambda x: imputer(week_day_median, x), axis = 1)\n",
    "test['week_Sale_median'] = test.apply(lambda x: imputer(week_day_median, x), axis = 1)\n",
    "\n",
    "train['week_Sale_min'] = train.apply(lambda x: imputer(week_day_min, x), axis = 1)\n",
    "test['week_Sale_min'] = test.apply(lambda x: imputer(week_day_min, x), axis = 1)\n",
    "\n",
    "train['week_Sale_max'] = train.apply(lambda x: imputer(week_day_max, x), axis = 1)\n",
    "test['week_Sale_max'] = test.apply(lambda x: imputer(week_day_max, x), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Sale/Cus'] = train['Sales']/train['Customers']\n",
    "\n",
    "train_mean = train.groupby(['Store'])['Sale/Cus'].mean().to_dict()\n",
    "train_median = train.groupby(['Store'])['Sale/Cus'].median().to_dict()\n",
    "train_min = train.groupby(['Store'])['Sale/Cus'].min().to_dict()\n",
    "train_max = train.groupby(['Store'])['Sale/Cus'].max().to_dict()\n",
    "\n",
    "test['Sale/Cus'] = test['Store'].apply(lambda x: train_mean[x])\n",
    "test['Sale/Cus'] = test['Store'].apply(lambda x: train_median[x])\n",
    "test['Sale/Cus'] = test['Store'].apply(lambda x: train_min[x])\n",
    "test['Sale/Cus'] = test['Store'].apply(lambda x: train_max[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in train.columns if col not in [target, date, customer]]\n",
    "\n",
    "trn, val = train_test_split(train, test_size = 0.2, random_state = 1999)\n",
    "\n",
    "##### Input for model\n",
    "X_trn, X_val = trn[features], val[features]\n",
    "\n",
    "##### Target column\n",
    "y_trn, y_val = trn[target], val[target]\n",
    "\n",
    "##### Features for test data that we will be predicting\n",
    "X_test = test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_log_error is : 565.7701377090194\n",
      "Wall time: 23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr = XGBRegressor(random_state = 1,tree_method = 'gpu_hist',n_estimators = 1000, max_depth = 6, learning_rate = 0.3)\n",
    "lr.fit(X_trn, y_trn)\n",
    "\n",
    "preds = lr.predict(X_val)\n",
    "preds = np.abs(preds)\n",
    "\n",
    "error = np.sqrt(mean_squared_error((y_val)**2, (preds)**2))\n",
    "\n",
    "print(f'mean_squared_log_error is : {error}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_log_error is : 584.357366063345\n",
      "Wall time: 12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#lr = XGBRegressor(random_state=1, tree_method = 'gpu_hist', n_estimators = 1000,\n",
    "#                  max_depth = 7, learning_rate = 0.3)\n",
    "\n",
    "#lr = XGBRegressor(random_state = 1, tree_method = 'gpu_hist', n_estimators = 500, learning_rate = 0.5, max_depth = 8)\n",
    "lr = XGBRegressor(random_state = 1,tree_method = 'gpu_hist',n_estimators = 500)\n",
    "lr.fit(X_trn, y_trn)\n",
    "\n",
    "preds = lr.predict(X_val)\n",
    "preds = np.abs(preds)\n",
    "\n",
    "error = np.sqrt(mean_squared_error((y_val)**2, (preds)**2))\n",
    "\n",
    "print(f'mean_squared_log_error is : {error}')\n",
    "\n",
    "# lr = LGBMRegressor(random_state=1)\n",
    "\n",
    "# lr.fit(X_trn, y_trn)\n",
    "\n",
    "# preds = lr.predict(X_val)\n",
    "# preds = np.abs(preds)\n",
    "\n",
    "# error = np.sqrt(mean_squared_error((y_val)**2, (preds)**2))\n",
    "\n",
    "# print(f'mean_squared_log_error is : {error}')\n",
    "#645"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgb = XGBRegressor(random_state=1, max_depth = 7, n_estimators = 1200, learning_rate = 0.01, subsample=0.9, min_child_weight = 13, tree_method='gpu_hist')\n",
    "# xgb = XGBRegressor(random_state=1, tree_method = 'gpu_hist', n_estimators = 1000,\n",
    "#                   max_depth = 7, learning_rate = 0.3)\n",
    "\n",
    "# xgb = XGBRegressor(random_state = 1, tree_method = 'gpu_hist', n_estimators = 500,\n",
    "#                    learning_rate = 0.5, max_depth = 8)\n",
    "xgb = XGBRegressor(random_state = 1,tree_method = 'gpu_hist',n_estimators = 1000, max_depth = 6, learning_rate = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation for Boosting\n",
    "def cross_val(regressor, train, test, features, name):\n",
    "    N_splits = 5\n",
    "    \n",
    "    oofs = np.zeros(len(train))\n",
    "    preds = np.zeros(len(test))\n",
    "    \n",
    "    target_col = train[target]\n",
    "    \n",
    "    folds = StratifiedKFold(n_splits = N_splits, shuffle = True,random_state = 1999)\n",
    "    stratified_target = pd.qcut( train[target], 10, labels=False, duplicates='drop')\n",
    "    for index, (trn_idx, val_idx) in enumerate(folds.split(train, stratified_target)):\n",
    "        print(f'\\n================================Fold{index + 1}===================================')\n",
    "        \n",
    "        #### Train Set\n",
    "        X_trn, y_trn = train[features].iloc[trn_idx], train[target].iloc[trn_idx]\n",
    "        \n",
    "        #### Validation Set\n",
    "        X_val, y_val = train[features].iloc[val_idx], train[target].iloc[val_idx]\n",
    "        \n",
    "        #### Test Set\n",
    "        X_test = test[features]\n",
    "        \n",
    "        ############ Fitting #############\n",
    "        _ = regressor.fit(X_trn, y_trn, eval_set = [(X_val, y_val)], early_stopping_rounds = 50, verbose = 100, eval_metric='rmse')\n",
    "        \n",
    "        ############ Predicting #############\n",
    "        val_preds = np.abs(regressor.predict(X_val))\n",
    "        test_preds = np.abs(regressor.predict(X_test))\n",
    "        \n",
    "        error = np.sqrt(mean_squared_error((y_val)**2, (val_preds)**2))\n",
    "        print(f'\\n Root Mean Squared Error for Validation set is : {error}')\n",
    "        \n",
    "        oofs[val_idx] = val_preds\n",
    "        preds += test_preds / N_splits\n",
    "        \n",
    "    total_error = np.sqrt(mean_squared_error((target_col)**2, (oofs)**2))\n",
    "    print(f'\\n\\Root Mean Squared Error for oofs is {total_error}')\n",
    "    \n",
    "    return oofs, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================Fold1===================================\n",
      "[0]\tvalidation_0-rmse:58.75579\n",
      "[100]\tvalidation_0-rmse:3.59620\n",
      "[200]\tvalidation_0-rmse:3.43378\n",
      "[300]\tvalidation_0-rmse:3.36143\n",
      "[400]\tvalidation_0-rmse:3.30277\n",
      "[500]\tvalidation_0-rmse:3.26603\n",
      "[600]\tvalidation_0-rmse:3.24284\n",
      "[700]\tvalidation_0-rmse:3.21943\n",
      "[800]\tvalidation_0-rmse:3.20555\n",
      "[900]\tvalidation_0-rmse:3.19347\n",
      "[999]\tvalidation_0-rmse:3.18298\n",
      "\n",
      " Root Mean Squared Error for Validation set is : 572.7916291865711\n",
      "\n",
      "================================Fold2===================================\n",
      "[0]\tvalidation_0-rmse:58.76134\n",
      "[100]\tvalidation_0-rmse:3.59801\n",
      "[200]\tvalidation_0-rmse:3.45367\n",
      "[300]\tvalidation_0-rmse:3.37943\n",
      "[400]\tvalidation_0-rmse:3.32844\n",
      "[500]\tvalidation_0-rmse:3.29058\n",
      "[600]\tvalidation_0-rmse:3.26610\n",
      "[700]\tvalidation_0-rmse:3.24468\n",
      "[800]\tvalidation_0-rmse:3.22613\n",
      "[900]\tvalidation_0-rmse:3.21452\n",
      "[999]\tvalidation_0-rmse:3.20239\n",
      "\n",
      " Root Mean Squared Error for Validation set is : 572.6782350754131\n",
      "\n",
      "================================Fold3===================================\n",
      "[0]\tvalidation_0-rmse:58.72991\n",
      "[100]\tvalidation_0-rmse:3.57904\n",
      "[200]\tvalidation_0-rmse:3.42112\n",
      "[300]\tvalidation_0-rmse:3.34319\n",
      "[400]\tvalidation_0-rmse:3.28657\n",
      "[500]\tvalidation_0-rmse:3.24797\n",
      "[600]\tvalidation_0-rmse:3.22387\n",
      "[700]\tvalidation_0-rmse:3.20031\n",
      "[800]\tvalidation_0-rmse:3.18704\n",
      "[900]\tvalidation_0-rmse:3.17602\n",
      "[999]\tvalidation_0-rmse:3.16167\n",
      "\n",
      " Root Mean Squared Error for Validation set is : 559.8700706766919\n",
      "\n",
      "================================Fold4===================================\n",
      "[0]\tvalidation_0-rmse:58.75539\n",
      "[100]\tvalidation_0-rmse:3.61521\n",
      "[200]\tvalidation_0-rmse:3.44850\n",
      "[300]\tvalidation_0-rmse:3.36890\n",
      "[400]\tvalidation_0-rmse:3.31950\n",
      "[500]\tvalidation_0-rmse:3.27269\n",
      "[600]\tvalidation_0-rmse:3.24531\n",
      "[700]\tvalidation_0-rmse:3.21956\n",
      "[800]\tvalidation_0-rmse:3.19913\n",
      "[900]\tvalidation_0-rmse:3.18437\n",
      "[999]\tvalidation_0-rmse:3.17262\n",
      "\n",
      " Root Mean Squared Error for Validation set is : 564.4343694676782\n",
      "\n",
      "================================Fold5===================================\n",
      "[0]\tvalidation_0-rmse:58.73897\n",
      "[100]\tvalidation_0-rmse:3.65517\n",
      "[200]\tvalidation_0-rmse:3.48538\n",
      "[300]\tvalidation_0-rmse:3.40444\n",
      "[400]\tvalidation_0-rmse:3.34355\n",
      "[500]\tvalidation_0-rmse:3.30564\n",
      "[600]\tvalidation_0-rmse:3.27385\n",
      "[700]\tvalidation_0-rmse:3.25210\n",
      "[800]\tvalidation_0-rmse:3.23481\n",
      "[900]\tvalidation_0-rmse:3.22122\n",
      "[999]\tvalidation_0-rmse:3.20882\n",
      "\n",
      " Root Mean Squared Error for Validation set is : 574.5557630478297\n",
      "\n",
      "\\Root Mean Squared Error for oofs is 568.8946436229064\n",
      "Wall time: 2min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb_oofs, xgb_preds = cross_val(xgb, train, test, features, 'xgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# lr = XGBRegressor(random_state=1, n_jobs = -1)\n",
    "\n",
    "# lr.fit(train[features], train[target])\n",
    "\n",
    "# preds = lr.predict(test[features])\n",
    "# preds = np.abs(preds)\n",
    "# # With eval set and no cat_cols: lb score 1093\n",
    "#xgb_preds = xgb_preds**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Predictions'] = xgb_preds**2\n",
    "test.loc[ test['Open'] == 0, 'Predictions'] = 0\n",
    "preds = test['Predictions']\n",
    "\n",
    "index = [i for i in range(test.shape[0])]\n",
    "\n",
    "d = list(zip(index, preds))\n",
    "\n",
    "ss = pd.DataFrame(d, columns = ['index', 'Sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.to_csv(path + \"\\\\new_feats.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3378.579705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4610.134875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3580.485045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4726.274411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305158</th>\n",
       "      <td>305158</td>\n",
       "      <td>9508.029039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305159</th>\n",
       "      <td>305159</td>\n",
       "      <td>4600.701374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305160</th>\n",
       "      <td>305160</td>\n",
       "      <td>3905.258718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305161</th>\n",
       "      <td>305161</td>\n",
       "      <td>2588.719775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305162</th>\n",
       "      <td>305162</td>\n",
       "      <td>4589.409172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>305163 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index        Sales\n",
       "0            0     0.000000\n",
       "1            1  3378.579705\n",
       "2            2  4610.134875\n",
       "3            3  3580.485045\n",
       "4            4  4726.274411\n",
       "...        ...          ...\n",
       "305158  305158  9508.029039\n",
       "305159  305159  4600.701374\n",
       "305160  305160  3905.258718\n",
       "305161  305161  2588.719775\n",
       "305162  305162  4589.409172\n",
       "\n",
       "[305163 rows x 2 columns]"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
