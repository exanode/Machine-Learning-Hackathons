{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "path = os.getcwd()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, BaggingRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_squared_log_error\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\sunil\\\\Projects\\\\Dockship\\\\segmind_grand_ai_challenge_2021-dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunil\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(path + \"\\\\dataset\\\\TRAIN.csv\")\n",
    "test = pd.read_csv(path + \"\\\\dataset\\\\TEST.csv\")\n",
    "ss = pd.read_csv(path + \"\\\\dataset\\\\sample_submission.csv\")\n",
    "shop = pd.read_csv(path + \"\\\\dataset\\\\store.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Date'] = pd.to_datetime(train['Date'])\n",
    "test['Date'] = pd.to_datetime(test['Date'])\n",
    "\n",
    "train['year'] = train['Date'].dt.year\n",
    "train['month'] = train['Date'].dt.month\n",
    "train['day'] = train['Date'].dt.day\n",
    "train['week'] = train['Date'].dt.week\n",
    "\n",
    "test['year'] = test['Date'].dt.year\n",
    "test['month'] = test['Date'].dt.month\n",
    "test['day'] = test['Date'].dt.day\n",
    "test['week'] = test['Date'].dt.week\n",
    "\n",
    "train['StateHoliday'].replace({0 : 4, '0':0, 'a':1, 'b':2, 'c':3}, inplace = True)\n",
    "test['StateHoliday'].replace({0 : 4, '0':0, 'a':1, 'b':2, 'c':3}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging\n",
    "\n",
    "train = pd.merge(train, shop, how = 'left', on = 'Store')\n",
    "test = pd.merge(test, shop, how = 'left', on = 'Store')\n",
    "\n",
    "train['Assortment'].unique()\n",
    "train['Assortment'].replace({'a':1, 'b':2, 'c':3}, inplace = True)\n",
    "test['Assortment'].replace({'a':1, 'b':2, 'c':3}, inplace = True)\n",
    "\n",
    "\n",
    "a = [0, 'Jan,Apr,Jul,Oct', 'Feb,May,Aug,Nov', 'Mar,Jun,Sept,Dec']\n",
    "b = [0, 1, 2, 3]\n",
    "\n",
    "train['PromoInterval'].replace(dict(zip(a, b)), inplace = True)\n",
    "test['PromoInterval'].replace(dict(zip(a, b)), inplace = True)\n",
    "\n",
    "train['StoreType'].replace({'a':1, 'b':2, 'c':3, 'd':4}, inplace = True)\n",
    "test['StoreType'].replace({'a':1, 'b':2, 'c':3, 'd':4}, inplace = True)\n",
    "\n",
    "\n",
    "train['CompetitionDistance'].fillna(train['CompetitionDistance'].mean(), inplace = True)\n",
    "test['CompetitionDistance'].fillna(test['CompetitionDistance'].mean(), inplace = True)\n",
    "\n",
    "train.fillna(0, inplace = True)\n",
    "test.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing Datatype\n",
    "\n",
    "int8_cols = ['DayOfWeek', 'Open', 'Promo','StateHoliday', 'SchoolHoliday', \n",
    "'month', 'day','week', 'Store_Type', 'Store_Assortment',\n",
    "'Store_CompetitionOpenSinceMonth','Store_Promo2', \n",
    "'Store_Promo2SinceWeek','Store_PromoInterval']\n",
    "\n",
    "int16_cols = ['Customers', 'year', 'Store', 'Store_CompetitionOpenSinceYear', 'Store_Promo2SinceYear']\n",
    "\n",
    "int32_cols = ['Sales', 'Store_distance']\n",
    "\n",
    "def int8(x):\n",
    "    train[x] = train[x].astype('int8')\n",
    "    \n",
    "    test[x] = test[x].astype('int8')\n",
    "\n",
    "def int16(x):\n",
    "    train[x] = train[x].astype('int16')\n",
    "    if x != 'Customers':\n",
    "        test[x] = test[x].astype('int16')\n",
    "\n",
    "def int32(x):\n",
    "    train[x] = train[x].astype('int32')\n",
    "    if x != 'Sales':\n",
    "        test[x] = test[x].astype('int32')\n",
    "\n",
    "for col in int8_cols:\n",
    "    int8(col)\n",
    "\n",
    "for col in int16_cols:\n",
    "    int16(col)\n",
    "\n",
    "for col in int32_cols:\n",
    "    int32(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Sales'\n",
    "date = 'Date'\n",
    "customer = 'Customers'\n",
    "\n",
    "cat_cols = ['Store', 'DayOfWeek', 'Open', 'Promo',\n",
    "       'StateHoliday', 'SchoolHoliday', 'year', 'month', 'day', 'dayofweek',\n",
    "       'week', 'Store_Type', 'Store_Assortment',\n",
    "       'Store_CompetitionOpenSinceMonth', 'Store_CompetitionOpenSinceYear',\n",
    "       'Store_Promo2', 'Store_Promo2SinceWeek', 'Store_Promo2SinceYear',\n",
    "       'Store_PromoInterval']\n",
    "\n",
    "features = [col for col in train.columns if col not in [target, date, customer]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn, val = train_test_split(train, test_size = 0.2, random_state = 1)\n",
    "\n",
    "##### Input for model\n",
    "X_trn, X_val = trn[features], val[features]\n",
    "\n",
    "##### Target column\n",
    "y_trn, y_val = trn[target], val[target]\n",
    "\n",
    "##### Features for test data that we will be predicting\n",
    "X_test = test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation for Boosting\n",
    "def cross_val(regressor, train, test, features, name):\n",
    "    N_splits = 5\n",
    "    \n",
    "    oofs = np.zeros(len(train))\n",
    "    preds = np.zeros(len(test))\n",
    "    \n",
    "    target_col = train[target]\n",
    "    \n",
    "    folds = StratifiedKFold(n_splits = N_splits, shuffle = True,random_state = 1999)\n",
    "    stratified_target = pd.qcut( train[target], 10, labels=False, duplicates='drop')\n",
    "    for index, (trn_idx, val_idx) in enumerate(folds.split(train, stratified_target)):\n",
    "        print(f'\\n================================Fold{index + 1}===================================')\n",
    "        \n",
    "        #### Train Set\n",
    "        X_trn, y_trn = train[features].iloc[trn_idx], train[target].iloc[trn_idx]\n",
    "        \n",
    "        #### Validation Set\n",
    "        X_val, y_val = train[features].iloc[val_idx], train[target].iloc[val_idx]\n",
    "        \n",
    "        #### Test Set\n",
    "        X_test = test[features]\n",
    "        \n",
    "        ############ Fitting #############\n",
    "        _ = regressor.fit(X_trn, y_trn, eval_set = [(X_val, y_val)], early_stopping_rounds = 50, verbose = 100, eval_metric='rmse')\n",
    "        \n",
    "        ############ Predicting #############\n",
    "        val_preds = np.abs(regressor.predict(X_val))\n",
    "        test_preds = np.abs(regressor.predict(X_test))\n",
    "        \n",
    "        error = np.sqrt(mean_squared_error((y_val), (val_preds)))\n",
    "        print(f'\\n Root Mean Squared Error for Validation set is : {error}')\n",
    "        \n",
    "        oofs[val_idx] = val_preds\n",
    "        preds += test_preds / N_splits\n",
    "        \n",
    "    total_error = np.sqrt(mean_squared_error((target_col), (oofs)))\n",
    "    print(f'\\n\\Root Mean Squared Error for oofs is {total_error}')\n",
    "    \n",
    "    return oofs, preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join(train_, test_):\n",
    "    df = pd.concat([train_, test_], axis = 0).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def split(df):\n",
    "    train_, test_ = df[:train.shape[0]], df[train.shape[0]:].reset_index(drop=True)\n",
    "    return train_, test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = join(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = join(train, test)\n",
    "# df['Store_Count'] = df.groupby('Store')['Date'].transform('count')\n",
    "# train_feat, test_feat = split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = join(train_feat, test_feat)\n",
    "# df['Store_Cus_Count'] = df.groupby('Store')['Customers'].transform('sum')/df['Store_Count']\n",
    "# train_feat, test_feat = split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = join(train_feat, test_feat)\n",
    "# df['Store_Mean_Sales'] = df.groupby('Store')['Sales'].transform('mean')\n",
    "# train_feat, test_feat = split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = join(train_feat, test_feat)\n",
    "# df['Open_Closed_Sales'] = df.groupby(['Store', 'Open'])['Sales'].transform('mean')\n",
    "# train_feat, test_feat = split(df)\n",
    "# test_feat['Open_Closed_Sales'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "columns = ['SchoolHoliday', 'StateHoliday', 'Promo']\n",
    "bwd = df[['Store']+columns].sort_index().groupby([\"Store\"]).rolling(7, min_periods=1).sum()\n",
    "\n",
    "\n",
    "df = df.merge(bwd, 'left', [\"Store\"], suffixes=['', '_bw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in train_feat.columns if col not in [target, date, customer]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb = XGBRegressor(random_state=1, tree_method='gpu_hist', n_estimators = 500)\n",
    "# lgb = LGBMRegressor(random_state=1, n_estimators = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params_2 = {'n_estimators': 1496, 'learning_rate': 0.15096576157577118, 'max_depth': 8,\n",
    "                'colsample_bytree': 0.6155314602051218, 'subsample': 0.7039538177172424, 'min_child_weight': 17}\n",
    "xgb = XGBRegressor(random_state = 5, tree_method = 'gpu_hist', **xgb_params_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================Fold1===================================\n",
      "[0]\tvalidation_0-rmse:6044.18408\n",
      "[100]\tvalidation_0-rmse:769.80560\n",
      "[200]\tvalidation_0-rmse:697.17108\n",
      "[300]\tvalidation_0-rmse:660.17297\n",
      "[400]\tvalidation_0-rmse:640.26642\n",
      "[500]\tvalidation_0-rmse:624.68304\n",
      "[600]\tvalidation_0-rmse:614.33551\n",
      "[700]\tvalidation_0-rmse:606.61017\n",
      "[800]\tvalidation_0-rmse:600.52978\n",
      "[900]\tvalidation_0-rmse:596.56799\n",
      "[1000]\tvalidation_0-rmse:592.79828\n",
      "[1100]\tvalidation_0-rmse:589.76440\n",
      "[1200]\tvalidation_0-rmse:586.91412\n",
      "[1300]\tvalidation_0-rmse:585.05695\n",
      "[1400]\tvalidation_0-rmse:583.55255\n",
      "[1495]\tvalidation_0-rmse:582.24493\n",
      "\n",
      " Root Mean Squared Error for Validation set is : 582.2370893568828\n",
      "\n",
      "================================Fold2===================================\n",
      "[0]\tvalidation_0-rmse:6055.73828\n",
      "[100]\tvalidation_0-rmse:761.54211\n",
      "[200]\tvalidation_0-rmse:690.72699\n",
      "[300]\tvalidation_0-rmse:655.50061\n",
      "[400]\tvalidation_0-rmse:635.77881\n",
      "[500]\tvalidation_0-rmse:622.07031\n",
      "[600]\tvalidation_0-rmse:612.38684\n",
      "[700]\tvalidation_0-rmse:605.03052\n",
      "[800]\tvalidation_0-rmse:599.32190\n",
      "[900]\tvalidation_0-rmse:594.72644\n",
      "[1000]\tvalidation_0-rmse:590.94427\n",
      "[1100]\tvalidation_0-rmse:587.64948\n",
      "[1200]\tvalidation_0-rmse:585.11029\n",
      "[1300]\tvalidation_0-rmse:583.52667\n",
      "[1400]\tvalidation_0-rmse:581.80664\n",
      "[1495]\tvalidation_0-rmse:580.44739\n",
      "\n",
      " Root Mean Squared Error for Validation set is : 580.405845397525\n",
      "\n",
      "================================Fold3===================================\n",
      "[0]\tvalidation_0-rmse:6053.66748\n",
      "[100]\tvalidation_0-rmse:763.18524\n",
      "[200]\tvalidation_0-rmse:685.40332\n",
      "[300]\tvalidation_0-rmse:653.26477\n",
      "[400]\tvalidation_0-rmse:633.07227\n",
      "[500]\tvalidation_0-rmse:618.90411\n",
      "[600]\tvalidation_0-rmse:608.75232\n",
      "[700]\tvalidation_0-rmse:600.66803\n",
      "[800]\tvalidation_0-rmse:594.34375\n",
      "[900]\tvalidation_0-rmse:590.60718\n",
      "[1000]\tvalidation_0-rmse:586.62683\n",
      "[1100]\tvalidation_0-rmse:583.03986\n",
      "[1200]\tvalidation_0-rmse:580.44330\n",
      "[1300]\tvalidation_0-rmse:578.38336\n",
      "[1400]\tvalidation_0-rmse:576.99152\n",
      "[1495]\tvalidation_0-rmse:575.84613\n",
      "\n",
      " Root Mean Squared Error for Validation set is : 575.8408980020833\n",
      "\n",
      "================================Fold4===================================\n",
      "[0]\tvalidation_0-rmse:6046.37793\n",
      "[100]\tvalidation_0-rmse:772.06854\n",
      "[200]\tvalidation_0-rmse:701.48993\n",
      "[300]\tvalidation_0-rmse:667.42835\n",
      "[400]\tvalidation_0-rmse:648.07208\n",
      "[500]\tvalidation_0-rmse:633.97723\n",
      "[600]\tvalidation_0-rmse:623.09753\n",
      "[700]\tvalidation_0-rmse:615.06879\n",
      "[800]\tvalidation_0-rmse:608.74628\n",
      "[900]\tvalidation_0-rmse:604.47900\n",
      "[1000]\tvalidation_0-rmse:600.66290\n",
      "[1100]\tvalidation_0-rmse:597.77405\n",
      "[1200]\tvalidation_0-rmse:595.17065\n",
      "[1300]\tvalidation_0-rmse:593.35339\n",
      "[1400]\tvalidation_0-rmse:591.87781\n",
      "[1495]\tvalidation_0-rmse:590.34998\n",
      "\n",
      " Root Mean Squared Error for Validation set is : 590.342587762199\n",
      "\n",
      "================================Fold5===================================\n",
      "[0]\tvalidation_0-rmse:6060.89404\n",
      "[100]\tvalidation_0-rmse:768.05524\n",
      "[200]\tvalidation_0-rmse:690.92163\n",
      "[300]\tvalidation_0-rmse:655.26489\n",
      "[400]\tvalidation_0-rmse:634.25513\n",
      "[500]\tvalidation_0-rmse:620.85626\n",
      "[600]\tvalidation_0-rmse:611.29034\n",
      "[700]\tvalidation_0-rmse:603.57245\n",
      "[800]\tvalidation_0-rmse:597.55188\n",
      "[900]\tvalidation_0-rmse:593.17334\n",
      "[1000]\tvalidation_0-rmse:589.49219\n",
      "[1100]\tvalidation_0-rmse:586.64703\n",
      "[1200]\tvalidation_0-rmse:583.92871\n",
      "[1300]\tvalidation_0-rmse:581.67767\n",
      "[1400]\tvalidation_0-rmse:580.05438\n",
      "[1495]\tvalidation_0-rmse:578.81433\n",
      "\n",
      " Root Mean Squared Error for Validation set is : 578.7966641794122\n",
      "\n",
      "\\Root Mean Squared Error for oofs is 581.545126099776\n",
      "Wall time: 8min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb_oofs, xgb_preds = cross_val(xgb, train_feat, test_feat, features, 'xgb') #749\n",
    "#637"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[index, 'Predictions'] = xgb_preds\n",
    "test.loc[ test['Open'] == 0, 'Predictions'] = 0\n",
    "preds = test['Predictions']\n",
    "\n",
    "index = [i for i in range(test.shape[0])]\n",
    "\n",
    "d = list(zip(index, preds))\n",
    "\n",
    "ss = pd.DataFrame(d, columns = ['index', 'Sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.to_csv(path + \"\\\\xgb_base_tuned.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, cv=KFold(10, shuffle = True, random_state = 1999)): \n",
    "\n",
    "    param_xgb = {\n",
    "        \"random_state\": 1,\n",
    "        'objective': 'reg:squarederror',\n",
    "        \"metric\": \"rmse\",\n",
    "        # \"categorical_feature\": cat_indices,\n",
    "        \"verbosity\": 0,\n",
    "        # 'alpha': trial.suggest_int('alpha', 1, 100),\n",
    "        # 'lambda': trial.suggest_float('lambda', 0.001, 100),\n",
    "        # 'gamma': trial.suggest_float('gamma', 0.001, 100),\n",
    "        \"n_estimators\": trial.suggest_int('n_estimators', 1, 1600),\n",
    "        \"learning_rate\": trial.suggest_float('learning_rate', 0.01, 1),\n",
    "        # 'num_leaves': trial.suggest_int('num_leaves', 2, 1024),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 8),\n",
    "        # 'reg_alpha': trial.suggest_float('reg_alpha', 1e-4, 25),\n",
    "        # 'reg_lambda': trial.suggest_float('reg_lambda', 1e-4, 25),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.001, 1.0),\n",
    "        # 'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.001, 1.0),\n",
    "        # 'colsample_bynode': trial.suggest_float('colsample_bynode', 0.001, 1.0),\n",
    "        'subsample': trial.suggest_float('subsample', 0.1, 1.0),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 100)\n",
    "        # 'cat_smooth': trial.suggest_float('cat_smooth', 1.0, 50.0) \n",
    "        # 'max_delta_step' \n",
    "    }\n",
    "\n",
    "    val_aucs = []\n",
    "    aucs = []\n",
    "\n",
    "\n",
    "    X_trn, X_valid, y_trn, y_valid = train_test_split(features[xgb_features], targets, \n",
    "                                                    test_size=0.20, random_state=42, shuffle=True)\n",
    "\n",
    "    model = xgb.XGBRegressor(**param_xgb, tree_method='gpu_hist')        \n",
    "\n",
    "    model.fit(X_trn, y_trn, eval_set=[(X_valid, y_valid)], early_stopping_rounds=100, verbose=0)    \n",
    "\n",
    "    preds = model.predict(X_valid)\n",
    "\n",
    "    auc = np.sqrt(mean_squared_error(y_valid, preds)) \n",
    "\n",
    "    # auc = np.sqrt(mean_squared_log_error(np.expm1(y_valid), np.expm1(preds)))\n",
    "    # aucs.append(auc)\n",
    "\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set to False if you want to skip it\n",
    "OPTUNA_OPTIMIZATION = True\n",
    "N_TRIALS = 20   \n",
    "\n",
    "if OPTUNA_OPTIMIZATION:\n",
    "    study = optuna.create_study(study_name = 'XGB', direction=\"minimize\") \n",
    "    \n",
    "    study.optimize(objective, n_trials=N_TRIALS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
